{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-30 17:45:22.759023: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-12-30 17:45:25.673366: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /device:GPU:0 with 46718 MB memory:  -> device: 0, name: NVIDIA RTX A6000, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2021-12-30 17:45:25.683392: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /device:GPU:1 with 46718 MB memory:  -> device: 1, name: NVIDIA RTX A6000, pci bus id: 0000:02:00.0, compute capability: 8.6\n",
      "2021-12-30 17:45:25.684563: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /device:GPU:2 with 46718 MB memory:  -> device: 2, name: NVIDIA RTX A6000, pci bus id: 0000:81:00.0, compute capability: 8.6\n",
      "2021-12-30 17:45:25.685745: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /device:GPU:3 with 46718 MB memory:  -> device: 3, name: NVIDIA RTX A6000, pci bus id: 0000:82:00.0, compute capability: 8.6\n",
      "2021-12-30 17:45:25.686904: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device "
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/device:GPU:0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/device:GPU:4 with 46718 MB memory:  -> device: 4, name: NVIDIA RTX A6000, pci bus id: 0000:c1:00.0, compute capability: 8.6\n",
      "2021-12-30 17:45:25.688081: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /device:GPU:5 with 46718 MB memory:  -> device: 5, name: NVIDIA RTX A6000, pci bus id: 0000:c2:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "40Ti35Hlziyq"
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dELU7Op4z5bn",
    "outputId": "90b28efa-9877-4a5b-ff44-4c0fe4d82c43"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.bashrc',\n",
       " '.profile',\n",
       " '.vast_containerlabel',\n",
       " 'onstart.sh',\n",
       " 'onstart.log',\n",
       " '.ssh',\n",
       " '.jupyter',\n",
       " '.local',\n",
       " '.cache',\n",
       " '.ipython',\n",
       " 'project.ipynb',\n",
       " '.ipynb_checkpoints',\n",
       " '.keras',\n",
       " '.nv']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "62jOpPky1yQB",
    "outputId": "90651382-4e89-449b-f5e9-2025df5df173"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wget\n",
      "  Downloading wget-3.2.zip (10 kB)\n",
      "Building wheels for collected packages: wget\n",
      "  Building wheel for wget (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9672 sha256=a9149bd14fbe15b9319f2a95f150c4ab7011267b00220549fbf95b75f863d796\n",
      "  Stored in directory: /root/.cache/pip/wheels/bd/a8/c3/3cf2c14a1837a4e04bd98631724e81f33f462d86a1d895fae0\n",
      "Successfully built wget\n",
      "Installing collected packages: wget\n",
      "Successfully installed wget-3.2\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install wget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EAFrx1aQ-Y-G"
   },
   "source": [
    "# Get the urls for the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "DjOsmtqN4skn"
   },
   "outputs": [],
   "source": [
    "url1 = \"https://storage.googleapis.com/kaggle-data-sets/1636/792972/compressed/combined_data_1.txt.zip?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com%40kaggle-161607.iam.gserviceaccount.com%2F20211228%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20211228T115307Z&X-Goog-Expires=259199&X-Goog-SignedHeaders=host&X-Goog-Signature=a07cc451f9317f3f0effa724d90d55d78d5837bf808749e57600cd92ca8de4084a930af18eba00cdf7d92444f5551a8414e405dd01b528e879238eca6ba89b1f0b85f7d712b746a69023d0303361520caecf781673612411c0a02c7798e0eba9cbcf831c33ca4caaf634ba902146a77dabb77d922e52c64cb2c0d2fdf60206e18bad7c2a2a800ae3eeb2054e9182df4fd5d2bd55c3ac5fc4896af05f934c2cb99148cc5c175b2c5f1d08aa732ce226085f046e246a360111ecc0457fe12ef617d7ea26f9c9215fb2c94bb979ffb2cbfaae1c01d642929cb414c09dbdec33f85c416c7577f19e61602769946301174019deccddf0b4bdcbe52bdbe2b6b945b570\"\n",
    "url2 = \"https://storage.googleapis.com/kaggle-data-sets/1636/792972/compressed/combined_data_2.txt.zip?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com%40kaggle-161607.iam.gserviceaccount.com%2F20211228%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20211228T115406Z&X-Goog-Expires=259199&X-Goog-SignedHeaders=host&X-Goog-Signature=4fa597d238c84ec5cce14f060ce720076bf85e605b74148e6c21291a2441adc18f005d32e0aa608c7a19762277c61704171cae9e3501afa5a0cf7ea437601d17cb78cbf63af35831f9d397c79b288c4c59c9600caf04fb7e31e9ef1d6458bab1ac3164588a0b6b3af4d7a70570248034e0c25137e2cb4016c4498d1e6b7bda7ab5efc176ba5cbbce12703771989f8ae69576c14f9d318bc32753812d97c3aaf92821b3404c59470ab3618cc552ce42ce39b4b00103e69e357004f5ca472d7e3a4e678e9f3128b47d072bff018dcce949148e7ce6bf1871320125e17089de7139de75ebf061c9a50a9da9d4f7402d1ead209489d4f6ea0c241d3f5b59e512af6b\"\n",
    "url3 = \"https://storage.googleapis.com/kaggle-data-sets/1636/792972/compressed/combined_data_3.txt.zip?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com%40kaggle-161607.iam.gserviceaccount.com%2F20211228%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20211228T115412Z&X-Goog-Expires=259199&X-Goog-SignedHeaders=host&X-Goog-Signature=51e560193087438ff13e87da0801390299fc8b3e786ad0092e34e345bcf36b7f5576381dea1111482db0421b1cb4761145e28f652ecfc919d907f7e5fcd32bbb318efa08328480474670400920a4d01166bda4e6bf4782eab326bda3430e3d4bff39820c96465c110098ac936041b5136e936f159512c28ff6fd371561c2b485814187bda28b7ad1c0ed1cee2e47751e0c16587e1065e05641c2039c0a33bad63ba992b934deccf2a1c28f1225569661536357f58c3c66dd0cf804d106a94de8ce9d9cac4f0c68072a06169f383b315a173c55972d261294375b201d581aa5a56d06fecee5674b65aa6691c31586e6943c6825ee3f6a5a585866656aa30d1799\"\n",
    "url4 = \"https://storage.googleapis.com/kaggle-data-sets/1636/792972/compressed/combined_data_4.txt.zip?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com%40kaggle-161607.iam.gserviceaccount.com%2F20211228%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20211228T115415Z&X-Goog-Expires=259199&X-Goog-SignedHeaders=host&X-Goog-Signature=a8b2da2c486276c8334d4ef362258bebd6ff6593781f789630ba571ec551115c06c0bc87b4acb38ed02acdcc905ae1e2642c1059b9101d7d3de67c072c12f92f18e230dce83bb3271de5c03ada699055e3d212b664ad5574e94a5f9af000068c2debb9880a6b177a42f450020592d3dc9c60b29cb9f99a63ab5dd37095450a79ca146d2dade019e0e5b12780de4d9e8f5b04fbda2c5d96998827ced319d1f039b44e7d033933c29ba1ffd86cb2d50cf17a800a801cd55800cf1a240082484ab83986136b757085185aee411fc8aeb3472c45471b3f2eb6d8f96570b11c7e42dc1a743da3a00559ca211caa367839814182ac2ddbd3e463e5426f5eed609d03e7\"\n",
    "\n",
    "urls = [url1,url2,url3,url4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3zIj6285-VcP"
   },
   "source": [
    "# Download the data and unzipping it in the directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "paQhRZwK3ZLI"
   },
   "outputs": [],
   "source": [
    "import wget\n",
    "import zipfile\n",
    "\n",
    "# out = \"/content/drive/MyDrive/Scalable ML/project/data\"\n",
    "out = \".\"\n",
    "for url in urls:\n",
    "  filename = wget.download(url,out=out)\n",
    "  with zipfile.ZipFile(filename, 'r') as zip_ref:\n",
    "    zip_ref.extractall(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8ENqJxSx-do2"
   },
   "source": [
    "# Convert the txt files into csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7YbO4C559rBs",
    "outputId": "e8afe1d7-c1bb-4dbb-811b-9be12821da86"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combined_data_1 opened...\n",
      "combined_data_1 closed...\n",
      "combined_data_2 opened...\n",
      "combined_data_2 closed...\n",
      "combined_data_3 opened...\n",
      "combined_data_3 closed...\n",
      "combined_data_4 opened...\n",
      "combined_data_4 closed...\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "files = ['combined_data_1','combined_data_2','combined_data_3','combined_data_4']\n",
    "for j in files:\n",
    "    file1 = open(os.path.join(out, j+\".txt\"),\"r+\")\n",
    "    print(j + \" opened...\")\n",
    "    file2 = open(os.path.join(out, j + \".csv\"),\"a\")\n",
    "    for i in file1.readlines():\n",
    "        temp = re.match(\"(\\d*)[:]\", i)\n",
    "        if(temp):\n",
    "            movienumber = temp.group(1)\n",
    "        else:\n",
    "            file2.write(str(movienumber)+\",\"+i)\n",
    "    file1.close()\n",
    "    file2.close() \n",
    "    print(j + \" closed...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "so0cy9_t-3n5"
   },
   "source": [
    "# Create one Dataframe and save to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KIq0OYjFDNrK"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "out = \"/content/drive/MyDrive/Scalable ML/project/data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ePeCWldmDpqw",
    "outputId": "fe5ce3c3-bec7-4751-a9f9-e4c84fa55195"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4499"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_csv(os.path.join(out, 'combined_data_1.csv'), header=None, names=['Movie', 'User', 'Rating', 'Date'], usecols=[0, 1, 2, 3])\n",
    "max(df1.Movie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tyfUVDIQEfm0",
    "outputId": "0264ecbe-1cbc-4c41-fd01-78efab721051"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9210"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.read_csv(os.path.join(out, 'combined_data_2.csv'), header=None, names=['Movie', 'User', 'Rating', 'Date'], usecols=[0, 1, 2, 3])\n",
    "max(df2.Movie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DDAN6iAVEf95",
    "outputId": "b030716a-29b0-4228-e466-9ed390450402"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13367"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "df3 = pd.read_csv(os.path.join(out, 'combined_data_3.csv'), header=None, names=['Movie', 'User', 'Rating', 'Date'], usecols=[0, 1, 2, 3])\n",
    "max(df3.Movie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XAOmd-fSEgF5",
    "outputId": "03ecc833-fffa-402b-e48c-6f82b1254347"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17770"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "df4 = pd.read_csv(os.path.join(out, 'combined_data_4.csv'), header=None, names=['Movie', 'User', 'Rating', 'Date'], usecols=[0, 1, 2, 3])\n",
    "max(df4.Movie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GaHfCwOIEkFi"
   },
   "outputs": [],
   "source": [
    "df = pd.concat([df1,df2,df3,df4],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "38KKunnRGcaZ",
    "outputId": "47282b3d-d34c-4038-c977-ed527a395358"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100480507"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "r66rxZI8Gf6S",
    "outputId": "c33fcadc-f739-49b8-b27c-da53bd5da91d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-349a464c-aec9-4eb3-89c6-080678de0ba0\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Movie</th>\n",
       "      <th>User</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1488844</td>\n",
       "      <td>3</td>\n",
       "      <td>2005-09-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>822109</td>\n",
       "      <td>5</td>\n",
       "      <td>2005-05-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>885013</td>\n",
       "      <td>4</td>\n",
       "      <td>2005-10-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>30878</td>\n",
       "      <td>4</td>\n",
       "      <td>2005-12-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>823519</td>\n",
       "      <td>3</td>\n",
       "      <td>2004-05-03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-349a464c-aec9-4eb3-89c6-080678de0ba0')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-349a464c-aec9-4eb3-89c6-080678de0ba0 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-349a464c-aec9-4eb3-89c6-080678de0ba0');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "   Movie     User  Rating        Date\n",
       "0      1  1488844       3  2005-09-06\n",
       "1      1   822109       5  2005-05-13\n",
       "2      1   885013       4  2005-10-19\n",
       "3      1    30878       4  2005-12-26\n",
       "4      1   823519       3  2004-05-03"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vqB_AeHRHCAQ",
    "outputId": "ef18efc8-90ef-4475-c395-a5657ba4ad3f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df) == len(df1) + len(df2) + len(df3) + len(df4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VZis-DQ4HGTa",
    "outputId": "3472207f-9590-456a-d8e4-593977584d42"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17770"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(df.Movie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KRRRgN6ZHQIf"
   },
   "outputs": [],
   "source": [
    "df = df[['Movie','User','Rating']]\n",
    "df.to_csv(out+\"/combined_data.csv\") # takes 3 minutes 41 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uFyOpuNUI9GE"
   },
   "source": [
    "# Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "adxCowOHHszx",
    "outputId": "b23bd379-ffa9-4eb5-a81e-9cf38dfb5dc1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/numpy/lib/arraysetops.py:580: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "out = \"/content/drive/MyDrive/Scalable ML/project/data\"\n",
    "df = pd.read_csv(out+\"/combined_data.csv\",index_col=[0]) # takes 1 minute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8nmb6NmuNMez"
   },
   "source": [
    "# Define Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "# out = \"/content/drive/MyDrive/Scalable ML/project/data\"\n",
    "out = \".\"\n",
    "df = pd.read_csv(os.path.join(out, 'combined_data_1.csv'), header=None, names=['Movie', 'User', 'Rating', 'Date'], usecols=[0, 1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RE3ZsHD9NJln",
    "outputId": "10a846d0-68f2-41d8-facf-e62a87fcb778"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-30 18:14:49.673209: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-12-30 18:14:52.242832: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 46718 MB memory:  -> device: 0, name: NVIDIA RTX A6000, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2021-12-30 18:14:52.243839: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 46718 MB memory:  -> device: 1, name: NVIDIA RTX A6000, pci bus id: 0000:02:00.0, compute capability: 8.6\n",
      "2021-12-30 18:14:52.244708: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 46718 MB memory:  -> device: 2, name: NVIDIA RTX A6000, pci bus id: 0000:81:00.0, compute capability: 8.6\n",
      "2021-12-30 18:14:52.245682: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 46718 MB memory:  -> device: 3, name: NVIDIA RTX A6000, pci bus id: 0000:82:00.0, compute capability: 8.6\n",
      "2021-12-30 18:14:52.246538: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:4 with 46718 MB memory:  -> device: 4, name: NVIDIA RTX A6000, pci bus id: 0000:c1:00.0, compute capability: 8.6\n",
      "2021-12-30 18:14:52.247389: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:5 with 46718 MB memory:  -> device: 5, name: NVIDIA RTX A6000, pci bus id: 0000:c2:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(9621,), dtype=int64, numpy=array([30, 28,  8, ..., 30, 30,  8])>,\n",
       " <tf.Tensor: shape=(9621,), dtype=int64, numpy=array([1058270, 1725366, 2216088, ..., 2239625, 1385344, 2409219])>,\n",
       " <tf.Tensor: shape=(9621,), dtype=int64, numpy=array([4, 3, 3, ..., 4, 5, 3])>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((df['Movie'].values,df['User'].values, df['Rating'].values)).shuffle(10, reshuffle_each_iteration=False)\n",
    "train_dataset = dataset.enumerate().map(lambda x,y: y).shuffle(len(df)//200).batch(len(df)//2500)#5000)\n",
    "for x, y, z in train_dataset.take(1):\n",
    "    pass\n",
    "x,y,z   # takes 49 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wDm0TzIJLu5k"
   },
   "source": [
    "# Define the CNF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oDlTkDh_Lnh7",
    "outputId": "65d81ca3-ef55-4fe7-f6d6-9ad8e6c2da54"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"cnf\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       multiple                  450000    \n",
      "                                                                 \n",
      " embedding_1 (Embedding)     multiple                  264943000 \n",
      "                                                                 \n",
      " dense (Dense)               multiple                  10100     \n",
      "                                                                 \n",
      " dense_1 (Dense)             multiple                  2525      \n",
      "                                                                 \n",
      " dense_2 (Dense)             multiple                  26        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 265,405,651\n",
      "Trainable params: 265,405,651\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-30 18:14:58.933069: I tensorflow/stream_executor/cuda/cuda_blas.cc:1774] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    }
   ],
   "source": [
    "class CNF(tf.keras.Model):\n",
    "    def __init__(self, num_movies, num_users, size_of_embeddings=100):\n",
    "        super(CNF, self).__init__()\n",
    "        self.size_of_embeddings = size_of_embeddings\n",
    "        self.j = size_of_embeddings//2\n",
    "        self.DotWeights = tf.random.normal([self.size_of_embeddings-self.j], 0, 1, tf.float32)\n",
    "        self.embeddings_for_movies = tf.keras.layers.Embedding(num_movies, size_of_embeddings, embeddings_regularizer=tf.keras.regularizers.L2(l2=0.00001))\n",
    "        self.embeddings_for_users = tf.keras.layers.Embedding(num_users, size_of_embeddings,embeddings_regularizer=tf.keras.regularizers.L2(l2=0.00001))\n",
    "        self.hidden_layer_1 = tf.keras.layers.Dense(100, activation=tf.nn.relu, kernel_regularizer=tf.keras.regularizers.L2(l2=0.00001))\n",
    "        self.hidden_layer_2 = tf.keras.layers.Dense(25, activation=tf.nn.relu, kernel_regularizer=tf.keras.regularizers.L2(l2=0.00001))\n",
    "        self.output_layer = tf.keras.layers.Dense(1, activation=tf.nn.relu, kernel_regularizer=tf.keras.regularizers.L2(l2=0.00001))\n",
    "    def call(self, inputs_movies, inputs_users):\n",
    "        x = self.embeddings_for_movies(inputs_movies)\n",
    "        y = self.embeddings_for_users(inputs_users)\n",
    "        j = self.size_of_embeddings//2\n",
    "        xMLP, xGMF = tf.split(x, [self.j, self.size_of_embeddings-self.j], 1)\n",
    "        yMLP, yGMF = tf.split(y, [self.j, self.size_of_embeddings-self.j], 1)\n",
    "        return tf.math.add(tf.math.reduce_sum(tf.math.multiply(yGMF, tf.math.multiply(self.DotWeights, xGMF)), axis=1), \n",
    "                          tf.squeeze(self.output_layer(self.hidden_layer_2(self.hidden_layer_1(tf.concat([xMLP,yMLP], axis=1))))))\n",
    "\n",
    "num_movies=max(df.Movie) # 17770 + 1\n",
    "num_users=max(df.User) # 2649429 + 1\n",
    "size_of_embeddings = 100\n",
    "\n",
    "model = CNF(num_movies+1, num_users+1, 100)\n",
    "model(x,y)\n",
    "model.summary()    # takes 27 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "zFamr0fOL3BY"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def train():\n",
    "\n",
    "    num_epochs = 5\n",
    "    criterion = tf.keras.losses.mean_squared_error\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "\n",
    "    train_loss_results_MLP = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Starting epoch {epoch}/{num_epochs}\")\n",
    "\n",
    "        epoch_start = time.time()\n",
    "        epoch_loss_avg_train = tf.keras.metrics.Mean()\n",
    "\n",
    "        for i,(x, y, z) in enumerate(train_dataset):\n",
    "            \n",
    "            iter_start = time.time()\n",
    "\n",
    "            # compute the gradients\n",
    "            with tf.GradientTape() as tape:\n",
    "                y_pred = model(x, y, training=True)\n",
    "                train_loss = criterion(y_true=z, y_pred=y_pred)\n",
    "            grads = tape.gradient(train_loss, model.trainable_variables)\n",
    "\n",
    "            # update the weights using the gradients\n",
    "            optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "            # Update the loss\n",
    "            epoch_loss_avg_train.update_state(train_loss)\n",
    "            \n",
    "            train_loss_results_MLP.append(epoch_loss_avg_train.result().numpy())\n",
    "\n",
    "            print(f\"Epoch {epoch}: iteration {i}/{len(train_dataset)} train_loss: {epoch_loss_avg_train.result()} time_taken: {time.time()-iter_start}\")\n",
    "        \n",
    "        print(f\"Finished epoch {epoch} took {time.time()-epoch_start}\")\n",
    "    return train_loss_results_MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3gwyCpUFNAjc",
    "outputId": "837062c8-0850-4a19-aed6-fbe971b8b984",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 0/5\n",
      "Epoch 0: iteration 0/2501 train_loss: 14.062491416931152 time_taken: 0.06293082237243652\n",
      "Epoch 0: iteration 1/2501 train_loss: 13.723618507385254 time_taken: 0.05666208267211914\n",
      "Epoch 0: iteration 2/2501 train_loss: 13.302535057067871 time_taken: 0.05660724639892578\n",
      "Epoch 0: iteration 3/2501 train_loss: 12.781968116760254 time_taken: 0.05640864372253418\n",
      "Epoch 0: iteration 4/2501 train_loss: 12.097996711730957 time_taken: 0.0572052001953125\n",
      "Epoch 0: iteration 5/2501 train_loss: 11.240797996520996 time_taken: 0.05669736862182617\n",
      "Epoch 0: iteration 6/2501 train_loss: 10.225480079650879 time_taken: 0.056440114974975586\n",
      "Epoch 0: iteration 7/2501 train_loss: 9.160215377807617 time_taken: 0.05673575401306152\n",
      "Epoch 0: iteration 8/2501 train_loss: 8.29801082611084 time_taken: 0.057955026626586914\n",
      "Epoch 0: iteration 9/2501 train_loss: 7.836322784423828 time_taken: 0.056937456130981445\n",
      "Epoch 0: iteration 10/2501 train_loss: 7.490638732910156 time_taken: 0.05699801445007324\n",
      "Epoch 0: iteration 11/2501 train_loss: 7.107414722442627 time_taken: 0.05677223205566406\n",
      "Epoch 0: iteration 12/2501 train_loss: 6.7141947746276855 time_taken: 0.056160688400268555\n",
      "Epoch 0: iteration 13/2501 train_loss: 6.3687615394592285 time_taken: 0.057227134704589844\n",
      "Epoch 0: iteration 14/2501 train_loss: 6.089912414550781 time_taken: 0.056981563568115234\n",
      "Epoch 0: iteration 15/2501 train_loss: 5.853824138641357 time_taken: 0.056549072265625\n",
      "Epoch 0: iteration 16/2501 train_loss: 5.651773929595947 time_taken: 0.056333303451538086\n",
      "Epoch 0: iteration 17/2501 train_loss: 5.479626178741455 time_taken: 0.056554317474365234\n",
      "Epoch 0: iteration 18/2501 train_loss: 5.31113338470459 time_taken: 0.056418657302856445\n",
      "Epoch 0: iteration 19/2501 train_loss: 5.144262790679932 time_taken: 0.05678963661193848\n",
      "Epoch 0: iteration 20/2501 train_loss: 4.985701084136963 time_taken: 0.056910037994384766\n",
      "Epoch 0: iteration 21/2501 train_loss: 4.834844589233398 time_taken: 0.10076570510864258\n",
      "Epoch 0: iteration 22/2501 train_loss: 4.6945695877075195 time_taken: 0.05603766441345215\n",
      "Epoch 0: iteration 23/2501 train_loss: 4.5700788497924805 time_taken: 0.05747509002685547\n",
      "Epoch 0: iteration 24/2501 train_loss: 4.462475776672363 time_taken: 0.05705714225769043\n",
      "Epoch 0: iteration 25/2501 train_loss: 4.363726615905762 time_taken: 0.05642127990722656\n",
      "Epoch 0: iteration 26/2501 train_loss: 4.266199588775635 time_taken: 0.05683469772338867\n",
      "Epoch 0: iteration 27/2501 train_loss: 4.170674800872803 time_taken: 0.05746340751647949\n",
      "Epoch 0: iteration 28/2501 train_loss: 4.073222637176514 time_taken: 0.05662250518798828\n",
      "Epoch 0: iteration 29/2501 train_loss: 3.9780852794647217 time_taken: 0.0560147762298584\n",
      "Epoch 0: iteration 30/2501 train_loss: 3.886470079421997 time_taken: 0.06530570983886719\n",
      "Epoch 0: iteration 31/2501 train_loss: 3.8019051551818848 time_taken: 0.05690145492553711\n",
      "Epoch 0: iteration 32/2501 train_loss: 3.724954605102539 time_taken: 0.05650806427001953\n",
      "Epoch 0: iteration 33/2501 train_loss: 3.6518781185150146 time_taken: 0.05707097053527832\n",
      "Epoch 0: iteration 34/2501 train_loss: 3.5848000049591064 time_taken: 0.057244062423706055\n",
      "Epoch 0: iteration 35/2501 train_loss: 3.5252954959869385 time_taken: 0.056993961334228516\n",
      "Epoch 0: iteration 36/2501 train_loss: 3.4700887203216553 time_taken: 0.056374311447143555\n",
      "Epoch 0: iteration 37/2501 train_loss: 3.416887044906616 time_taken: 0.05736589431762695\n",
      "Epoch 0: iteration 38/2501 train_loss: 3.3638782501220703 time_taken: 0.05786943435668945\n",
      "Epoch 0: iteration 39/2501 train_loss: 3.3118348121643066 time_taken: 0.05657839775085449\n",
      "Epoch 0: iteration 40/2501 train_loss: 3.261525869369507 time_taken: 0.05661749839782715\n",
      "Epoch 0: iteration 41/2501 train_loss: 3.212411880493164 time_taken: 0.05685591697692871\n",
      "Epoch 0: iteration 42/2501 train_loss: 3.166186571121216 time_taken: 0.05673623085021973\n",
      "Epoch 0: iteration 43/2501 train_loss: 3.1219136714935303 time_taken: 0.05704450607299805\n",
      "Epoch 0: iteration 44/2501 train_loss: 3.0796163082122803 time_taken: 0.0569148063659668\n",
      "Epoch 0: iteration 45/2501 train_loss: 3.0380890369415283 time_taken: 0.05690264701843262\n",
      "Epoch 0: iteration 46/2501 train_loss: 2.99933123588562 time_taken: 0.05798053741455078\n",
      "Epoch 0: iteration 47/2501 train_loss: 2.9613571166992188 time_taken: 0.0574498176574707\n",
      "Epoch 0: iteration 48/2501 train_loss: 2.9256765842437744 time_taken: 0.05664968490600586\n",
      "Epoch 0: iteration 49/2501 train_loss: 2.8913679122924805 time_taken: 0.05697178840637207\n",
      "Epoch 0: iteration 50/2501 train_loss: 2.8576529026031494 time_taken: 0.05776190757751465\n",
      "Epoch 0: iteration 51/2501 train_loss: 2.823888063430786 time_taken: 0.05695676803588867\n",
      "Epoch 0: iteration 52/2501 train_loss: 2.791917562484741 time_taken: 0.05767464637756348\n",
      "Epoch 0: iteration 53/2501 train_loss: 2.7615420818328857 time_taken: 0.0572206974029541\n",
      "Epoch 0: iteration 54/2501 train_loss: 2.7306737899780273 time_taken: 0.05725383758544922\n",
      "Epoch 0: iteration 55/2501 train_loss: 2.6999993324279785 time_taken: 0.05731844902038574\n",
      "Epoch 0: iteration 56/2501 train_loss: 2.670948028564453 time_taken: 0.05761313438415527\n",
      "Epoch 0: iteration 57/2501 train_loss: 2.6435341835021973 time_taken: 0.05725812911987305\n",
      "Epoch 0: iteration 58/2501 train_loss: 2.6169681549072266 time_taken: 0.05653238296508789\n",
      "Epoch 0: iteration 59/2501 train_loss: 2.5909974575042725 time_taken: 0.05691194534301758\n",
      "Epoch 0: iteration 60/2501 train_loss: 2.5661699771881104 time_taken: 0.07416057586669922\n",
      "Epoch 0: iteration 61/2501 train_loss: 2.541569232940674 time_taken: 0.05702543258666992\n",
      "Epoch 0: iteration 62/2501 train_loss: 2.518071413040161 time_taken: 0.05727267265319824\n",
      "Epoch 0: iteration 63/2501 train_loss: 2.4956350326538086 time_taken: 0.05697822570800781\n",
      "Epoch 0: iteration 64/2501 train_loss: 2.473306655883789 time_taken: 0.05645918846130371\n",
      "Epoch 0: iteration 65/2501 train_loss: 2.4511208534240723 time_taken: 0.05613088607788086\n",
      "Epoch 0: iteration 66/2501 train_loss: 2.428720235824585 time_taken: 0.05702710151672363\n",
      "Epoch 0: iteration 67/2501 train_loss: 2.4069325923919678 time_taken: 0.056870460510253906\n",
      "Epoch 0: iteration 68/2501 train_loss: 2.385634183883667 time_taken: 0.057143449783325195\n",
      "Epoch 0: iteration 69/2501 train_loss: 2.3653924465179443 time_taken: 0.057401180267333984\n",
      "Epoch 0: iteration 70/2501 train_loss: 2.345078945159912 time_taken: 0.05716562271118164\n",
      "Epoch 0: iteration 71/2501 train_loss: 2.3247182369232178 time_taken: 0.056827545166015625\n",
      "Epoch 0: iteration 72/2501 train_loss: 2.305814504623413 time_taken: 0.056864261627197266\n",
      "Epoch 0: iteration 73/2501 train_loss: 2.2869441509246826 time_taken: 0.05723762512207031\n",
      "Epoch 0: iteration 74/2501 train_loss: 2.26830792427063 time_taken: 0.05645895004272461\n",
      "Epoch 0: iteration 75/2501 train_loss: 2.250216245651245 time_taken: 0.056974172592163086\n",
      "Epoch 0: iteration 76/2501 train_loss: 2.2329559326171875 time_taken: 0.05656123161315918\n",
      "Epoch 0: iteration 77/2501 train_loss: 2.216132640838623 time_taken: 0.05634355545043945\n",
      "Epoch 0: iteration 78/2501 train_loss: 2.199542284011841 time_taken: 0.057116031646728516\n",
      "Epoch 0: iteration 79/2501 train_loss: 2.183311700820923 time_taken: 0.056786298751831055\n",
      "Epoch 0: iteration 80/2501 train_loss: 2.167618989944458 time_taken: 0.05695509910583496\n",
      "Epoch 0: iteration 81/2501 train_loss: 2.152859687805176 time_taken: 0.057056427001953125\n",
      "Epoch 0: iteration 82/2501 train_loss: 2.138575315475464 time_taken: 0.056378841400146484\n",
      "Epoch 0: iteration 83/2501 train_loss: 2.1243960857391357 time_taken: 0.057407379150390625\n",
      "Epoch 0: iteration 84/2501 train_loss: 2.1106040477752686 time_taken: 0.05728602409362793\n",
      "Epoch 0: iteration 85/2501 train_loss: 2.0974245071411133 time_taken: 0.05782151222229004\n",
      "Epoch 0: iteration 86/2501 train_loss: 2.084704637527466 time_taken: 0.05690479278564453\n",
      "Epoch 0: iteration 87/2501 train_loss: 2.072535514831543 time_taken: 0.05783700942993164\n",
      "Epoch 0: iteration 88/2501 train_loss: 2.060732364654541 time_taken: 0.05714249610900879\n",
      "Epoch 0: iteration 89/2501 train_loss: 2.0497002601623535 time_taken: 0.056485652923583984\n",
      "Epoch 0: iteration 90/2501 train_loss: 2.0390784740448 time_taken: 0.056706905364990234\n",
      "Epoch 0: iteration 91/2501 train_loss: 2.028047561645508 time_taken: 0.05696249008178711\n",
      "Epoch 0: iteration 92/2501 train_loss: 2.017404556274414 time_taken: 0.056325674057006836\n",
      "Epoch 0: iteration 93/2501 train_loss: 2.006420135498047 time_taken: 0.07936239242553711\n",
      "Epoch 0: iteration 94/2501 train_loss: 1.9954501390457153 time_taken: 0.07193446159362793\n",
      "Epoch 0: iteration 95/2501 train_loss: 1.9844532012939453 time_taken: 0.057274580001831055\n",
      "Epoch 0: iteration 96/2501 train_loss: 1.9734865427017212 time_taken: 0.056929826736450195\n",
      "Epoch 0: iteration 97/2501 train_loss: 1.9627411365509033 time_taken: 0.056844234466552734\n",
      "Epoch 0: iteration 98/2501 train_loss: 1.952028512954712 time_taken: 0.05696225166320801\n",
      "Epoch 0: iteration 99/2501 train_loss: 1.942009687423706 time_taken: 0.05685687065124512\n",
      "Epoch 0: iteration 100/2501 train_loss: 1.931800127029419 time_taken: 0.05685853958129883\n",
      "Epoch 0: iteration 101/2501 train_loss: 1.9219058752059937 time_taken: 0.05656313896179199\n",
      "Epoch 0: iteration 102/2501 train_loss: 1.9125279188156128 time_taken: 0.05690288543701172\n",
      "Epoch 0: iteration 103/2501 train_loss: 1.9032012224197388 time_taken: 0.05727791786193848\n",
      "Epoch 0: iteration 104/2501 train_loss: 1.8939539194107056 time_taken: 0.05742835998535156\n",
      "Epoch 0: iteration 105/2501 train_loss: 1.8848241567611694 time_taken: 0.05623292922973633\n",
      "Epoch 0: iteration 106/2501 train_loss: 1.8757357597351074 time_taken: 0.057145118713378906\n",
      "Epoch 0: iteration 107/2501 train_loss: 1.8666422367095947 time_taken: 0.05729055404663086\n",
      "Epoch 0: iteration 108/2501 train_loss: 1.8579829931259155 time_taken: 0.05680727958679199\n",
      "Epoch 0: iteration 109/2501 train_loss: 1.8491685390472412 time_taken: 0.056748151779174805\n",
      "Epoch 0: iteration 110/2501 train_loss: 1.8405500650405884 time_taken: 0.056920528411865234\n",
      "Epoch 0: iteration 111/2501 train_loss: 1.8322240114212036 time_taken: 0.05652260780334473\n",
      "Epoch 0: iteration 112/2501 train_loss: 1.8244577646255493 time_taken: 0.05679011344909668\n",
      "Epoch 0: iteration 113/2501 train_loss: 1.8170485496520996 time_taken: 0.05726218223571777\n",
      "Epoch 0: iteration 114/2501 train_loss: 1.8096909523010254 time_taken: 0.05634474754333496\n",
      "Epoch 0: iteration 115/2501 train_loss: 1.8024951219558716 time_taken: 0.05707430839538574\n",
      "Epoch 0: iteration 116/2501 train_loss: 1.7954987287521362 time_taken: 0.05650925636291504\n",
      "Epoch 0: iteration 117/2501 train_loss: 1.7888431549072266 time_taken: 0.05685925483703613\n",
      "Epoch 0: iteration 118/2501 train_loss: 1.781875729560852 time_taken: 0.05690717697143555\n",
      "Epoch 0: iteration 119/2501 train_loss: 1.7751909494400024 time_taken: 0.056667327880859375\n",
      "Epoch 0: iteration 120/2501 train_loss: 1.7683364152908325 time_taken: 0.056585073471069336\n",
      "Epoch 0: iteration 121/2501 train_loss: 1.7617876529693604 time_taken: 0.056459665298461914\n",
      "Epoch 0: iteration 122/2501 train_loss: 1.7555502653121948 time_taken: 0.056838274002075195\n",
      "Epoch 0: iteration 123/2501 train_loss: 1.7493464946746826 time_taken: 0.05765986442565918\n",
      "Epoch 0: iteration 124/2501 train_loss: 1.7432125806808472 time_taken: 0.05702686309814453\n",
      "Epoch 0: iteration 125/2501 train_loss: 1.737421989440918 time_taken: 0.057662248611450195\n",
      "Epoch 0: iteration 126/2501 train_loss: 1.7317602634429932 time_taken: 0.05693626403808594\n",
      "Epoch 0: iteration 127/2501 train_loss: 1.7260383367538452 time_taken: 0.05717062950134277\n",
      "Epoch 0: iteration 128/2501 train_loss: 1.720694661140442 time_taken: 0.05704975128173828\n",
      "Epoch 0: iteration 129/2501 train_loss: 1.7152937650680542 time_taken: 0.056955575942993164\n",
      "Epoch 0: iteration 130/2501 train_loss: 1.7101739645004272 time_taken: 0.05695629119873047\n",
      "Epoch 0: iteration 131/2501 train_loss: 1.7050395011901855 time_taken: 0.05674552917480469\n",
      "Epoch 0: iteration 132/2501 train_loss: 1.6998471021652222 time_taken: 0.05693411827087402\n",
      "Epoch 0: iteration 133/2501 train_loss: 1.6945780515670776 time_taken: 0.057108402252197266\n",
      "Epoch 0: iteration 134/2501 train_loss: 1.6895381212234497 time_taken: 0.0567927360534668\n",
      "Epoch 0: iteration 135/2501 train_loss: 1.6843483448028564 time_taken: 0.05657839775085449\n",
      "Epoch 0: iteration 136/2501 train_loss: 1.6790715456008911 time_taken: 0.05658149719238281\n",
      "Epoch 0: iteration 137/2501 train_loss: 1.6739952564239502 time_taken: 0.056832313537597656\n",
      "Epoch 0: iteration 138/2501 train_loss: 1.6690294742584229 time_taken: 0.0575559139251709\n",
      "Epoch 0: iteration 139/2501 train_loss: 1.6641324758529663 time_taken: 0.05692028999328613\n",
      "Epoch 0: iteration 140/2501 train_loss: 1.6591932773590088 time_taken: 0.05721926689147949\n",
      "Epoch 0: iteration 141/2501 train_loss: 1.6543071269989014 time_taken: 0.05704045295715332\n",
      "Epoch 0: iteration 142/2501 train_loss: 1.649538278579712 time_taken: 0.05757451057434082\n",
      "Epoch 0: iteration 143/2501 train_loss: 1.6448763608932495 time_taken: 0.056883811950683594\n",
      "Epoch 0: iteration 144/2501 train_loss: 1.6399946212768555 time_taken: 0.057172298431396484\n",
      "Epoch 0: iteration 145/2501 train_loss: 1.6354480981826782 time_taken: 0.056632280349731445\n",
      "Epoch 0: iteration 146/2501 train_loss: 1.6309894323349 time_taken: 0.05674314498901367\n",
      "Epoch 0: iteration 147/2501 train_loss: 1.6265689134597778 time_taken: 0.056674957275390625\n",
      "Epoch 0: iteration 148/2501 train_loss: 1.6218969821929932 time_taken: 0.057108163833618164\n",
      "Epoch 0: iteration 149/2501 train_loss: 1.6174159049987793 time_taken: 0.057599782943725586\n",
      "Epoch 0: iteration 150/2501 train_loss: 1.6132501363754272 time_taken: 0.057111501693725586\n",
      "Epoch 0: iteration 151/2501 train_loss: 1.6091521978378296 time_taken: 0.056658029556274414\n",
      "Epoch 0: iteration 152/2501 train_loss: 1.6051274538040161 time_taken: 0.05624818801879883\n",
      "Epoch 0: iteration 153/2501 train_loss: 1.6013303995132446 time_taken: 0.05677056312561035\n",
      "Epoch 0: iteration 154/2501 train_loss: 1.5973470211029053 time_taken: 0.05666041374206543\n",
      "Epoch 0: iteration 155/2501 train_loss: 1.593658208847046 time_taken: 0.057257652282714844\n",
      "Epoch 0: iteration 156/2501 train_loss: 1.5898929834365845 time_taken: 0.05680727958679199\n",
      "Epoch 0: iteration 157/2501 train_loss: 1.5863975286483765 time_taken: 0.05715441703796387\n",
      "Epoch 0: iteration 158/2501 train_loss: 1.5827919244766235 time_taken: 0.0570526123046875\n",
      "Epoch 0: iteration 159/2501 train_loss: 1.5793492794036865 time_taken: 0.05661201477050781\n",
      "Epoch 0: iteration 160/2501 train_loss: 1.5760732889175415 time_taken: 0.05650782585144043\n",
      "Epoch 0: iteration 161/2501 train_loss: 1.5729900598526 time_taken: 0.05683302879333496\n",
      "Epoch 0: iteration 162/2501 train_loss: 1.569830060005188 time_taken: 0.057010650634765625\n",
      "Epoch 0: iteration 163/2501 train_loss: 1.5667412281036377 time_taken: 0.056856393814086914\n",
      "Epoch 0: iteration 164/2501 train_loss: 1.5637307167053223 time_taken: 0.05623364448547363\n",
      "Epoch 0: iteration 165/2501 train_loss: 1.5607417821884155 time_taken: 0.05677509307861328\n",
      "Epoch 0: iteration 166/2501 train_loss: 1.557860016822815 time_taken: 0.06575679779052734\n",
      "Epoch 0: iteration 167/2501 train_loss: 1.5549676418304443 time_taken: 0.056261301040649414\n",
      "Epoch 0: iteration 168/2501 train_loss: 1.5520353317260742 time_taken: 0.05594754219055176\n",
      "Epoch 0: iteration 169/2501 train_loss: 1.5491582155227661 time_taken: 0.057004451751708984\n",
      "Epoch 0: iteration 170/2501 train_loss: 1.546188235282898 time_taken: 0.056711435317993164\n",
      "Epoch 0: iteration 171/2501 train_loss: 1.5431569814682007 time_taken: 0.056446075439453125\n",
      "Epoch 0: iteration 172/2501 train_loss: 1.5401229858398438 time_taken: 0.05637812614440918\n",
      "Epoch 0: iteration 173/2501 train_loss: 1.5372314453125 time_taken: 0.05697226524353027\n",
      "Epoch 0: iteration 174/2501 train_loss: 1.5343108177185059 time_taken: 0.05677652359008789\n",
      "Epoch 0: iteration 175/2501 train_loss: 1.53151273727417 time_taken: 0.05690765380859375\n",
      "Epoch 0: iteration 176/2501 train_loss: 1.528652548789978 time_taken: 0.05758810043334961\n",
      "Epoch 0: iteration 177/2501 train_loss: 1.5257400274276733 time_taken: 0.056246042251586914\n",
      "Epoch 0: iteration 178/2501 train_loss: 1.5228900909423828 time_taken: 0.05949234962463379\n",
      "Epoch 0: iteration 179/2501 train_loss: 1.5199272632598877 time_taken: 0.05598807334899902\n",
      "Epoch 0: iteration 180/2501 train_loss: 1.5171829462051392 time_taken: 0.05650734901428223\n",
      "Epoch 0: iteration 181/2501 train_loss: 1.5143959522247314 time_taken: 0.05627560615539551\n",
      "Epoch 0: iteration 182/2501 train_loss: 1.5117167234420776 time_taken: 0.05656695365905762\n",
      "Epoch 0: iteration 183/2501 train_loss: 1.5091625452041626 time_taken: 0.05649399757385254\n",
      "Epoch 0: iteration 184/2501 train_loss: 1.5064420700073242 time_taken: 0.05615234375\n",
      "Epoch 0: iteration 185/2501 train_loss: 1.5036911964416504 time_taken: 0.05630826950073242\n",
      "Epoch 0: iteration 186/2501 train_loss: 1.5009486675262451 time_taken: 0.05681800842285156\n",
      "Epoch 0: iteration 187/2501 train_loss: 1.4982681274414062 time_taken: 0.05702972412109375\n",
      "Epoch 0: iteration 188/2501 train_loss: 1.4955893754959106 time_taken: 0.05624580383300781\n",
      "Epoch 0: iteration 189/2501 train_loss: 1.4929823875427246 time_taken: 0.05685853958129883\n",
      "Epoch 0: iteration 190/2501 train_loss: 1.4903689622879028 time_taken: 0.056656599044799805\n",
      "Epoch 0: iteration 191/2501 train_loss: 1.487740159034729 time_taken: 0.05619072914123535\n",
      "Epoch 0: iteration 192/2501 train_loss: 1.4852463006973267 time_taken: 0.05651092529296875\n",
      "Epoch 0: iteration 193/2501 train_loss: 1.4827193021774292 time_taken: 0.057180166244506836\n",
      "Epoch 0: iteration 194/2501 train_loss: 1.4804017543792725 time_taken: 0.05707359313964844\n",
      "Epoch 0: iteration 195/2501 train_loss: 1.4781407117843628 time_taken: 0.057062625885009766\n",
      "Epoch 0: iteration 196/2501 train_loss: 1.4761884212493896 time_taken: 0.05697131156921387\n",
      "Epoch 0: iteration 197/2501 train_loss: 1.4741259813308716 time_taken: 0.056336164474487305\n",
      "Epoch 0: iteration 198/2501 train_loss: 1.4720618724822998 time_taken: 0.05689263343811035\n",
      "Epoch 0: iteration 199/2501 train_loss: 1.470121145248413 time_taken: 0.056417226791381836\n",
      "Epoch 0: iteration 200/2501 train_loss: 1.4681938886642456 time_taken: 0.05701327323913574\n",
      "Epoch 0: iteration 201/2501 train_loss: 1.466477394104004 time_taken: 0.058383941650390625\n",
      "Epoch 0: iteration 202/2501 train_loss: 1.4646819829940796 time_taken: 0.05666089057922363\n",
      "Epoch 0: iteration 203/2501 train_loss: 1.4627203941345215 time_taken: 0.05697917938232422\n",
      "Epoch 0: iteration 204/2501 train_loss: 1.4608770608901978 time_taken: 0.05693340301513672\n",
      "Epoch 0: iteration 205/2501 train_loss: 1.4588086605072021 time_taken: 0.05671334266662598\n",
      "Epoch 0: iteration 206/2501 train_loss: 1.4567092657089233 time_taken: 0.057008981704711914\n",
      "Epoch 0: iteration 207/2501 train_loss: 1.454754114151001 time_taken: 0.05704951286315918\n",
      "Epoch 0: iteration 208/2501 train_loss: 1.452773094177246 time_taken: 0.061591148376464844\n",
      "Epoch 0: iteration 209/2501 train_loss: 1.4507418870925903 time_taken: 0.05666399002075195\n",
      "Epoch 0: iteration 210/2501 train_loss: 1.4485576152801514 time_taken: 0.056687355041503906\n",
      "Epoch 0: iteration 211/2501 train_loss: 1.446367859840393 time_taken: 0.057245731353759766\n",
      "Epoch 0: iteration 212/2501 train_loss: 1.4438873529434204 time_taken: 0.056852102279663086\n",
      "Epoch 0: iteration 213/2501 train_loss: 1.4415624141693115 time_taken: 0.056761741638183594\n",
      "Epoch 0: iteration 214/2501 train_loss: 1.4392467737197876 time_taken: 0.05677652359008789\n",
      "Epoch 0: iteration 215/2501 train_loss: 1.4370301961898804 time_taken: 0.056969642639160156\n",
      "Epoch 0: iteration 216/2501 train_loss: 1.434700846672058 time_taken: 0.057729482650756836\n",
      "Epoch 0: iteration 217/2501 train_loss: 1.4325398206710815 time_taken: 0.05628776550292969\n",
      "Epoch 0: iteration 218/2501 train_loss: 1.4306349754333496 time_taken: 0.056558847427368164\n",
      "Epoch 0: iteration 219/2501 train_loss: 1.4286608695983887 time_taken: 0.056733131408691406\n",
      "Epoch 0: iteration 220/2501 train_loss: 1.4267724752426147 time_taken: 0.05682802200317383\n",
      "Epoch 0: iteration 221/2501 train_loss: 1.4250233173370361 time_taken: 0.05699777603149414\n",
      "Epoch 0: iteration 222/2501 train_loss: 1.4231520891189575 time_taken: 0.056416988372802734\n",
      "Epoch 0: iteration 223/2501 train_loss: 1.4214195013046265 time_taken: 0.0572667121887207\n",
      "Epoch 0: iteration 224/2501 train_loss: 1.4197429418563843 time_taken: 0.05701708793640137\n",
      "Epoch 0: iteration 225/2501 train_loss: 1.4178632497787476 time_taken: 0.05664229393005371\n",
      "Epoch 0: iteration 226/2501 train_loss: 1.4159144163131714 time_taken: 0.05750441551208496\n",
      "Epoch 0: iteration 227/2501 train_loss: 1.4138442277908325 time_taken: 0.05649685859680176\n",
      "Epoch 0: iteration 228/2501 train_loss: 1.411733627319336 time_taken: 0.05651044845581055\n",
      "Epoch 0: iteration 229/2501 train_loss: 1.4094853401184082 time_taken: 0.05638527870178223\n",
      "Epoch 0: iteration 230/2501 train_loss: 1.4072272777557373 time_taken: 0.05690741539001465\n",
      "Epoch 0: iteration 231/2501 train_loss: 1.4049808979034424 time_taken: 0.0560150146484375\n",
      "Epoch 0: iteration 232/2501 train_loss: 1.4026353359222412 time_taken: 0.05607938766479492\n",
      "Epoch 0: iteration 233/2501 train_loss: 1.400528907775879 time_taken: 0.05673575401306152\n",
      "Epoch 0: iteration 234/2501 train_loss: 1.398542046546936 time_taken: 0.057183265686035156\n",
      "Epoch 0: iteration 235/2501 train_loss: 1.3965295553207397 time_taken: 0.057044029235839844\n",
      "Epoch 0: iteration 236/2501 train_loss: 1.3945603370666504 time_taken: 0.05638456344604492\n",
      "Epoch 0: iteration 237/2501 train_loss: 1.392608880996704 time_taken: 0.05691885948181152\n",
      "Epoch 0: iteration 238/2501 train_loss: 1.3907530307769775 time_taken: 0.058005332946777344\n",
      "Epoch 0: iteration 239/2501 train_loss: 1.3889633417129517 time_taken: 0.056940555572509766\n",
      "Epoch 0: iteration 240/2501 train_loss: 1.3872562646865845 time_taken: 0.05747032165527344\n",
      "Epoch 0: iteration 241/2501 train_loss: 1.3855270147323608 time_taken: 0.056531667709350586\n",
      "Epoch 0: iteration 242/2501 train_loss: 1.3839432001113892 time_taken: 0.05641818046569824\n",
      "Epoch 0: iteration 243/2501 train_loss: 1.382372260093689 time_taken: 0.05699276924133301\n",
      "Epoch 0: iteration 244/2501 train_loss: 1.380759358406067 time_taken: 0.05681252479553223\n",
      "Epoch 0: iteration 245/2501 train_loss: 1.3791965246200562 time_taken: 0.05665230751037598\n",
      "Epoch 0: iteration 246/2501 train_loss: 1.3777152299880981 time_taken: 0.05716347694396973\n",
      "Epoch 0: iteration 247/2501 train_loss: 1.3761290311813354 time_taken: 0.05714130401611328\n",
      "Epoch 0: iteration 248/2501 train_loss: 1.374686360359192 time_taken: 0.057466745376586914\n",
      "Epoch 0: iteration 249/2501 train_loss: 1.3732373714447021 time_taken: 0.057179927825927734\n",
      "Epoch 0: iteration 250/2501 train_loss: 1.3720191717147827 time_taken: 0.056429386138916016\n",
      "Epoch 0: iteration 251/2501 train_loss: 1.3707293272018433 time_taken: 0.057152748107910156\n",
      "Epoch 0: iteration 252/2501 train_loss: 1.36936354637146 time_taken: 0.05651211738586426\n",
      "Epoch 0: iteration 253/2501 train_loss: 1.3680109977722168 time_taken: 0.05721759796142578\n",
      "Epoch 0: iteration 254/2501 train_loss: 1.3667221069335938 time_taken: 0.057276010513305664\n",
      "Epoch 0: iteration 255/2501 train_loss: 1.365354061126709 time_taken: 0.05732417106628418\n",
      "Epoch 0: iteration 256/2501 train_loss: 1.3640412092208862 time_taken: 0.06267285346984863\n",
      "Epoch 0: iteration 257/2501 train_loss: 1.3628216981887817 time_taken: 0.05647993087768555\n",
      "Epoch 0: iteration 258/2501 train_loss: 1.3614944219589233 time_taken: 0.05694127082824707\n",
      "Epoch 0: iteration 259/2501 train_loss: 1.3600190877914429 time_taken: 0.057233333587646484\n",
      "Epoch 0: iteration 260/2501 train_loss: 1.3586868047714233 time_taken: 0.056819915771484375\n",
      "Epoch 0: iteration 261/2501 train_loss: 1.3572239875793457 time_taken: 0.05692625045776367\n",
      "Epoch 0: iteration 262/2501 train_loss: 1.355751633644104 time_taken: 0.05699586868286133\n",
      "Epoch 0: iteration 263/2501 train_loss: 1.3543353080749512 time_taken: 0.057024240493774414\n",
      "Epoch 0: iteration 264/2501 train_loss: 1.3528295755386353 time_taken: 0.05705976486206055\n",
      "Epoch 0: iteration 265/2501 train_loss: 1.3514213562011719 time_taken: 0.05636477470397949\n",
      "Epoch 0: iteration 266/2501 train_loss: 1.3499804735183716 time_taken: 0.07103300094604492\n",
      "Epoch 0: iteration 267/2501 train_loss: 1.3486613035202026 time_taken: 0.05658721923828125\n",
      "Epoch 0: iteration 268/2501 train_loss: 1.3471977710723877 time_taken: 0.056873321533203125\n",
      "Epoch 0: iteration 269/2501 train_loss: 1.3457937240600586 time_taken: 0.05633234977722168\n",
      "Epoch 0: iteration 270/2501 train_loss: 1.3444255590438843 time_taken: 0.057303428649902344\n",
      "Epoch 0: iteration 271/2501 train_loss: 1.342982530593872 time_taken: 0.05682039260864258\n",
      "Epoch 0: iteration 272/2501 train_loss: 1.3415186405181885 time_taken: 0.05785536766052246\n",
      "Epoch 0: iteration 273/2501 train_loss: 1.3400688171386719 time_taken: 0.05683755874633789\n",
      "Epoch 0: iteration 274/2501 train_loss: 1.3386716842651367 time_taken: 0.05655264854431152\n",
      "Epoch 0: iteration 275/2501 train_loss: 1.337295413017273 time_taken: 0.056351423263549805\n",
      "Epoch 0: iteration 276/2501 train_loss: 1.335771083831787 time_taken: 0.05622601509094238\n",
      "Epoch 0: iteration 277/2501 train_loss: 1.3342818021774292 time_taken: 0.05648088455200195\n",
      "Epoch 0: iteration 278/2501 train_loss: 1.332789659500122 time_taken: 0.05676102638244629\n",
      "Epoch 0: iteration 279/2501 train_loss: 1.3311777114868164 time_taken: 0.057466983795166016\n",
      "Epoch 0: iteration 280/2501 train_loss: 1.3296061754226685 time_taken: 0.056459903717041016\n",
      "Epoch 0: iteration 281/2501 train_loss: 1.3281185626983643 time_taken: 0.05709099769592285\n",
      "Epoch 0: iteration 282/2501 train_loss: 1.326629400253296 time_taken: 0.05762076377868652\n",
      "Epoch 0: iteration 283/2501 train_loss: 1.3252829313278198 time_taken: 0.056929588317871094\n",
      "Epoch 0: iteration 284/2501 train_loss: 1.323706865310669 time_taken: 0.05762982368469238\n",
      "Epoch 0: iteration 285/2501 train_loss: 1.3223639726638794 time_taken: 0.057379722595214844\n",
      "Epoch 0: iteration 286/2501 train_loss: 1.3210561275482178 time_taken: 0.05652642250061035\n",
      "Epoch 0: iteration 287/2501 train_loss: 1.3198162317276 time_taken: 0.05682659149169922\n",
      "Epoch 0: iteration 288/2501 train_loss: 1.3185889720916748 time_taken: 0.05693864822387695\n",
      "Epoch 0: iteration 289/2501 train_loss: 1.3173801898956299 time_taken: 0.05650615692138672\n",
      "Epoch 0: iteration 290/2501 train_loss: 1.3161364793777466 time_taken: 0.05670452117919922\n",
      "Epoch 0: iteration 291/2501 train_loss: 1.3150067329406738 time_taken: 0.05657029151916504\n",
      "Epoch 0: iteration 292/2501 train_loss: 1.3139102458953857 time_taken: 0.05668973922729492\n",
      "Epoch 0: iteration 293/2501 train_loss: 1.3127169609069824 time_taken: 0.05732917785644531\n",
      "Epoch 0: iteration 294/2501 train_loss: 1.311493992805481 time_taken: 0.05674600601196289\n",
      "Epoch 0: iteration 295/2501 train_loss: 1.3102954626083374 time_taken: 0.05686235427856445\n",
      "Epoch 0: iteration 296/2501 train_loss: 1.3092368841171265 time_taken: 0.0562748908996582\n",
      "Epoch 0: iteration 297/2501 train_loss: 1.3082025051116943 time_taken: 0.05606842041015625\n",
      "Epoch 0: iteration 298/2501 train_loss: 1.3072410821914673 time_taken: 0.05658841133117676\n",
      "Epoch 0: iteration 299/2501 train_loss: 1.3061864376068115 time_taken: 0.056865692138671875\n",
      "Epoch 0: iteration 300/2501 train_loss: 1.3050799369812012 time_taken: 0.05611586570739746\n",
      "Epoch 0: iteration 301/2501 train_loss: 1.3040337562561035 time_taken: 0.05636858940124512\n",
      "Epoch 0: iteration 302/2501 train_loss: 1.3030178546905518 time_taken: 0.056704044342041016\n",
      "Epoch 0: iteration 303/2501 train_loss: 1.3019075393676758 time_taken: 0.05634737014770508\n",
      "Epoch 0: iteration 304/2501 train_loss: 1.3008601665496826 time_taken: 0.05650067329406738\n",
      "Epoch 0: iteration 305/2501 train_loss: 1.299820065498352 time_taken: 0.05641579627990723\n",
      "Epoch 0: iteration 306/2501 train_loss: 1.2987383604049683 time_taken: 0.05680060386657715\n",
      "Epoch 0: iteration 307/2501 train_loss: 1.297762393951416 time_taken: 0.056288957595825195\n",
      "Epoch 0: iteration 308/2501 train_loss: 1.2967568635940552 time_taken: 0.05729937553405762\n",
      "Epoch 0: iteration 309/2501 train_loss: 1.2957367897033691 time_taken: 0.05696439743041992\n",
      "Epoch 0: iteration 310/2501 train_loss: 1.2947263717651367 time_taken: 0.056671142578125\n",
      "Epoch 0: iteration 311/2501 train_loss: 1.2937222719192505 time_taken: 0.056298017501831055\n",
      "Epoch 0: iteration 312/2501 train_loss: 1.2929190397262573 time_taken: 0.05684638023376465\n",
      "Epoch 0: iteration 313/2501 train_loss: 1.291978120803833 time_taken: 0.05662083625793457\n",
      "Epoch 0: iteration 314/2501 train_loss: 1.2910648584365845 time_taken: 0.05595731735229492\n",
      "Epoch 0: iteration 315/2501 train_loss: 1.290201187133789 time_taken: 0.05613422393798828\n",
      "Epoch 0: iteration 316/2501 train_loss: 1.2893621921539307 time_taken: 0.0561823844909668\n",
      "Epoch 0: iteration 317/2501 train_loss: 1.28854238986969 time_taken: 0.05597949028015137\n",
      "Epoch 0: iteration 318/2501 train_loss: 1.287671685218811 time_taken: 0.05664658546447754\n",
      "Epoch 0: iteration 319/2501 train_loss: 1.286808967590332 time_taken: 0.05598902702331543\n",
      "Epoch 0: iteration 320/2501 train_loss: 1.2859853506088257 time_taken: 0.0569460391998291\n",
      "Epoch 0: iteration 321/2501 train_loss: 1.2850488424301147 time_taken: 0.0567469596862793\n",
      "Epoch 0: iteration 322/2501 train_loss: 1.2840648889541626 time_taken: 0.05614519119262695\n",
      "Epoch 0: iteration 323/2501 train_loss: 1.2829983234405518 time_taken: 0.05604100227355957\n",
      "Epoch 0: iteration 324/2501 train_loss: 1.2819769382476807 time_taken: 0.05658745765686035\n",
      "Epoch 0: iteration 325/2501 train_loss: 1.280901551246643 time_taken: 0.05572986602783203\n",
      "Epoch 0: iteration 326/2501 train_loss: 1.2798259258270264 time_taken: 0.05678200721740723\n",
      "Epoch 0: iteration 327/2501 train_loss: 1.2787020206451416 time_taken: 0.056665658950805664\n",
      "Epoch 0: iteration 328/2501 train_loss: 1.2774786949157715 time_taken: 0.05645585060119629\n",
      "Epoch 0: iteration 329/2501 train_loss: 1.2763352394104004 time_taken: 0.05590963363647461\n",
      "Epoch 0: iteration 330/2501 train_loss: 1.275069236755371 time_taken: 0.05607771873474121\n",
      "Epoch 0: iteration 331/2501 train_loss: 1.2738685607910156 time_taken: 0.05586838722229004\n",
      "Epoch 0: iteration 332/2501 train_loss: 1.272620439529419 time_taken: 0.05626511573791504\n",
      "Epoch 0: iteration 333/2501 train_loss: 1.271411418914795 time_taken: 0.05569791793823242\n",
      "Epoch 0: iteration 334/2501 train_loss: 1.2703847885131836 time_taken: 0.057096004486083984\n",
      "Epoch 0: iteration 335/2501 train_loss: 1.2693254947662354 time_taken: 0.05623364448547363\n",
      "Epoch 0: iteration 336/2501 train_loss: 1.2681958675384521 time_taken: 0.06934881210327148\n",
      "Epoch 0: iteration 337/2501 train_loss: 1.2671010494232178 time_taken: 0.056084394454956055\n",
      "Epoch 0: iteration 338/2501 train_loss: 1.2659800052642822 time_taken: 0.05586504936218262\n",
      "Epoch 0: iteration 339/2501 train_loss: 1.264872670173645 time_taken: 0.055794477462768555\n",
      "Epoch 0: iteration 340/2501 train_loss: 1.2637301683425903 time_taken: 0.05587577819824219\n",
      "Epoch 0: iteration 341/2501 train_loss: 1.2625916004180908 time_taken: 0.056027889251708984\n",
      "Epoch 0: iteration 342/2501 train_loss: 1.2613996267318726 time_taken: 0.056053876876831055\n",
      "Epoch 0: iteration 343/2501 train_loss: 1.2602423429489136 time_taken: 0.056690216064453125\n",
      "Epoch 0: iteration 344/2501 train_loss: 1.2590618133544922 time_taken: 0.05627131462097168\n",
      "Epoch 0: iteration 345/2501 train_loss: 1.2578752040863037 time_taken: 0.05631899833679199\n",
      "Epoch 0: iteration 346/2501 train_loss: 1.2565840482711792 time_taken: 0.057067155838012695\n",
      "Epoch 0: iteration 347/2501 train_loss: 1.2553719282150269 time_taken: 0.05612468719482422\n",
      "Epoch 0: iteration 348/2501 train_loss: 1.2541605234146118 time_taken: 0.056449174880981445\n",
      "Epoch 0: iteration 349/2501 train_loss: 1.2530330419540405 time_taken: 0.05639171600341797\n",
      "Epoch 0: iteration 350/2501 train_loss: 1.2518116235733032 time_taken: 0.05631208419799805\n",
      "Epoch 0: iteration 351/2501 train_loss: 1.2505322694778442 time_taken: 0.05663299560546875\n",
      "Epoch 0: iteration 352/2501 train_loss: 1.2493678331375122 time_taken: 0.055977582931518555\n",
      "Epoch 0: iteration 353/2501 train_loss: 1.2482494115829468 time_taken: 0.05666518211364746\n",
      "Epoch 0: iteration 354/2501 train_loss: 1.2471294403076172 time_taken: 0.056867361068725586\n",
      "Epoch 0: iteration 355/2501 train_loss: 1.2460739612579346 time_taken: 0.05607461929321289\n",
      "Epoch 0: iteration 356/2501 train_loss: 1.2450587749481201 time_taken: 0.05660367012023926\n",
      "Epoch 0: iteration 357/2501 train_loss: 1.2440327405929565 time_taken: 0.05662107467651367\n",
      "Epoch 0: iteration 358/2501 train_loss: 1.2429133653640747 time_taken: 0.05617833137512207\n",
      "Epoch 0: iteration 359/2501 train_loss: 1.24185049533844 time_taken: 0.056549072265625\n",
      "Epoch 0: iteration 360/2501 train_loss: 1.240843653678894 time_taken: 0.05660080909729004\n",
      "Epoch 0: iteration 361/2501 train_loss: 1.2396875619888306 time_taken: 0.05659818649291992\n",
      "Epoch 0: iteration 362/2501 train_loss: 1.2385178804397583 time_taken: 0.05671119689941406\n",
      "Epoch 0: iteration 363/2501 train_loss: 1.2372794151306152 time_taken: 0.05588483810424805\n",
      "Epoch 0: iteration 364/2501 train_loss: 1.236135721206665 time_taken: 0.056580305099487305\n",
      "Epoch 0: iteration 365/2501 train_loss: 1.2350056171417236 time_taken: 0.05709075927734375\n",
      "Epoch 0: iteration 366/2501 train_loss: 1.2338422536849976 time_taken: 0.05582714080810547\n",
      "Epoch 0: iteration 367/2501 train_loss: 1.232723355293274 time_taken: 0.0565488338470459\n",
      "Epoch 0: iteration 368/2501 train_loss: 1.231541633605957 time_taken: 0.05586504936218262\n",
      "Epoch 0: iteration 369/2501 train_loss: 1.230484127998352 time_taken: 0.05596113204956055\n",
      "Epoch 0: iteration 370/2501 train_loss: 1.2293678522109985 time_taken: 0.05625343322753906\n",
      "Epoch 0: iteration 371/2501 train_loss: 1.2282973527908325 time_taken: 0.057183027267456055\n",
      "Epoch 0: iteration 372/2501 train_loss: 1.2271915674209595 time_taken: 0.05648493766784668\n",
      "Epoch 0: iteration 373/2501 train_loss: 1.2260630130767822 time_taken: 0.05671548843383789\n",
      "Epoch 0: iteration 374/2501 train_loss: 1.2250257730484009 time_taken: 0.0819246768951416\n",
      "Epoch 0: iteration 375/2501 train_loss: 1.223914623260498 time_taken: 0.05708026885986328\n",
      "Epoch 0: iteration 376/2501 train_loss: 1.2228845357894897 time_taken: 0.05751776695251465\n",
      "Epoch 0: iteration 377/2501 train_loss: 1.2217761278152466 time_taken: 0.08583354949951172\n",
      "Epoch 0: iteration 378/2501 train_loss: 1.2207376956939697 time_taken: 0.056487083435058594\n",
      "Epoch 0: iteration 379/2501 train_loss: 1.2197519540786743 time_taken: 0.056413888931274414\n",
      "Epoch 0: iteration 380/2501 train_loss: 1.2187747955322266 time_taken: 0.05637502670288086\n",
      "Epoch 0: iteration 381/2501 train_loss: 1.2178411483764648 time_taken: 0.057050466537475586\n",
      "Epoch 0: iteration 382/2501 train_loss: 1.2170166969299316 time_taken: 0.05651068687438965\n",
      "Epoch 0: iteration 383/2501 train_loss: 1.2161937952041626 time_taken: 0.05967831611633301\n",
      "Epoch 0: iteration 384/2501 train_loss: 1.215378999710083 time_taken: 0.0564119815826416\n",
      "Epoch 0: iteration 385/2501 train_loss: 1.2145882844924927 time_taken: 0.05624246597290039\n",
      "Epoch 0: iteration 386/2501 train_loss: 1.2138153314590454 time_taken: 0.05691385269165039\n",
      "Epoch 0: iteration 387/2501 train_loss: 1.2129749059677124 time_taken: 0.05687451362609863\n",
      "Epoch 0: iteration 388/2501 train_loss: 1.2121011018753052 time_taken: 0.05761599540710449\n",
      "Epoch 0: iteration 389/2501 train_loss: 1.2112627029418945 time_taken: 0.05667591094970703\n",
      "Epoch 0: iteration 390/2501 train_loss: 1.2104977369308472 time_taken: 0.056568145751953125\n",
      "Epoch 0: iteration 391/2501 train_loss: 1.2098097801208496 time_taken: 0.05693840980529785\n",
      "Epoch 0: iteration 392/2501 train_loss: 1.2090274095535278 time_taken: 0.05730795860290527\n",
      "Epoch 0: iteration 393/2501 train_loss: 1.2082018852233887 time_taken: 0.05644488334655762\n",
      "Epoch 0: iteration 394/2501 train_loss: 1.2073981761932373 time_taken: 0.05690360069274902\n",
      "Epoch 0: iteration 395/2501 train_loss: 1.2065601348876953 time_taken: 0.05720353126525879\n",
      "Epoch 0: iteration 396/2501 train_loss: 1.205702781677246 time_taken: 0.05644416809082031\n",
      "Epoch 0: iteration 397/2501 train_loss: 1.2048155069351196 time_taken: 0.056848764419555664\n",
      "Epoch 0: iteration 398/2501 train_loss: 1.2039841413497925 time_taken: 0.05637550354003906\n",
      "Epoch 0: iteration 399/2501 train_loss: 1.2031117677688599 time_taken: 0.05721592903137207\n",
      "Epoch 0: iteration 400/2501 train_loss: 1.2022123336791992 time_taken: 0.056720733642578125\n",
      "Epoch 0: iteration 401/2501 train_loss: 1.20135498046875 time_taken: 0.05755901336669922\n",
      "Epoch 0: iteration 402/2501 train_loss: 1.200482726097107 time_taken: 0.0560605525970459\n",
      "Epoch 0: iteration 403/2501 train_loss: 1.19955575466156 time_taken: 0.05635428428649902\n",
      "Epoch 0: iteration 404/2501 train_loss: 1.1986305713653564 time_taken: 0.05675339698791504\n",
      "Epoch 0: iteration 405/2501 train_loss: 1.1977852582931519 time_taken: 0.05655312538146973\n",
      "Epoch 0: iteration 406/2501 train_loss: 1.196940541267395 time_taken: 0.056563615798950195\n",
      "Epoch 0: iteration 407/2501 train_loss: 1.196012258529663 time_taken: 0.05716276168823242\n",
      "Epoch 0: iteration 408/2501 train_loss: 1.1952170133590698 time_taken: 0.05676388740539551\n",
      "Epoch 0: iteration 409/2501 train_loss: 1.1944202184677124 time_taken: 0.05644631385803223\n",
      "Epoch 0: iteration 410/2501 train_loss: 1.1937073469161987 time_taken: 0.05635666847229004\n",
      "Epoch 0: iteration 411/2501 train_loss: 1.1929596662521362 time_taken: 0.05650472640991211\n",
      "Epoch 0: iteration 412/2501 train_loss: 1.1922287940979004 time_taken: 0.05619311332702637\n",
      "Epoch 0: iteration 413/2501 train_loss: 1.1914883852005005 time_taken: 0.05658435821533203\n",
      "Epoch 0: iteration 414/2501 train_loss: 1.1907159090042114 time_taken: 0.0582423210144043\n",
      "Epoch 0: iteration 415/2501 train_loss: 1.1900367736816406 time_taken: 0.056856393814086914\n",
      "Epoch 0: iteration 416/2501 train_loss: 1.1893446445465088 time_taken: 0.05684041976928711\n",
      "Epoch 0: iteration 417/2501 train_loss: 1.1886039972305298 time_taken: 0.057203054428100586\n",
      "Epoch 0: iteration 418/2501 train_loss: 1.1878844499588013 time_taken: 0.05642580986022949\n",
      "Epoch 0: iteration 419/2501 train_loss: 1.1871204376220703 time_taken: 0.05711770057678223\n",
      "Epoch 0: iteration 420/2501 train_loss: 1.186349868774414 time_taken: 0.05664849281311035\n",
      "Epoch 0: iteration 421/2501 train_loss: 1.185603380203247 time_taken: 0.061820268630981445\n",
      "Epoch 0: iteration 422/2501 train_loss: 1.1848750114440918 time_taken: 0.05733823776245117\n",
      "Epoch 0: iteration 423/2501 train_loss: 1.1840745210647583 time_taken: 0.056604862213134766\n",
      "Epoch 0: iteration 424/2501 train_loss: 1.1833362579345703 time_taken: 0.06276273727416992\n",
      "Epoch 0: iteration 425/2501 train_loss: 1.1825443506240845 time_taken: 0.05656719207763672\n",
      "Epoch 0: iteration 426/2501 train_loss: 1.1817911863327026 time_taken: 0.06222724914550781\n",
      "Epoch 0: iteration 427/2501 train_loss: 1.1809943914413452 time_taken: 0.05666470527648926\n",
      "Epoch 0: iteration 428/2501 train_loss: 1.1803014278411865 time_taken: 0.05675482749938965\n",
      "Epoch 0: iteration 429/2501 train_loss: 1.179606556892395 time_taken: 0.056557416915893555\n",
      "Epoch 0: iteration 430/2501 train_loss: 1.1788421869277954 time_taken: 0.05646705627441406\n",
      "Epoch 0: iteration 431/2501 train_loss: 1.1780462265014648 time_taken: 0.056916236877441406\n",
      "Epoch 0: iteration 432/2501 train_loss: 1.1772593259811401 time_taken: 0.056633949279785156\n",
      "Epoch 0: iteration 433/2501 train_loss: 1.1764929294586182 time_taken: 0.05948758125305176\n",
      "Epoch 0: iteration 434/2501 train_loss: 1.1757675409317017 time_taken: 0.056105852127075195\n",
      "Epoch 0: iteration 435/2501 train_loss: 1.1750614643096924 time_taken: 0.05611562728881836\n",
      "Epoch 0: iteration 436/2501 train_loss: 1.1743525266647339 time_taken: 0.05642533302307129\n",
      "Epoch 0: iteration 437/2501 train_loss: 1.1735917329788208 time_taken: 0.10356831550598145\n",
      "Epoch 0: iteration 438/2501 train_loss: 1.1728049516677856 time_taken: 0.05588078498840332\n",
      "Epoch 0: iteration 439/2501 train_loss: 1.1721521615982056 time_taken: 0.05624246597290039\n",
      "Epoch 0: iteration 440/2501 train_loss: 1.1714396476745605 time_taken: 0.05622434616088867\n",
      "Epoch 0: iteration 441/2501 train_loss: 1.1707268953323364 time_taken: 0.05920839309692383\n",
      "Epoch 0: iteration 442/2501 train_loss: 1.1701011657714844 time_taken: 0.05632805824279785\n",
      "Epoch 0: iteration 443/2501 train_loss: 1.1694432497024536 time_taken: 0.056707143783569336\n",
      "Epoch 0: iteration 444/2501 train_loss: 1.16874361038208 time_taken: 0.05628013610839844\n",
      "Epoch 0: iteration 445/2501 train_loss: 1.1680296659469604 time_taken: 0.06293964385986328\n",
      "Epoch 0: iteration 446/2501 train_loss: 1.1673362255096436 time_taken: 0.05620718002319336\n",
      "Epoch 0: iteration 447/2501 train_loss: 1.1665802001953125 time_taken: 0.056290388107299805\n",
      "Epoch 0: iteration 448/2501 train_loss: 1.1658903360366821 time_taken: 0.059839487075805664\n",
      "Epoch 0: iteration 449/2501 train_loss: 1.16521155834198 time_taken: 0.05943751335144043\n",
      "Epoch 0: iteration 450/2501 train_loss: 1.164573073387146 time_taken: 0.05703234672546387\n",
      "Epoch 0: iteration 451/2501 train_loss: 1.163861870765686 time_taken: 0.05662107467651367\n",
      "Epoch 0: iteration 452/2501 train_loss: 1.163193941116333 time_taken: 0.05652475357055664\n",
      "Epoch 0: iteration 453/2501 train_loss: 1.1625107526779175 time_taken: 0.057001590728759766\n",
      "Epoch 0: iteration 454/2501 train_loss: 1.1618528366088867 time_taken: 0.05659341812133789\n",
      "Epoch 0: iteration 455/2501 train_loss: 1.1611359119415283 time_taken: 0.0562131404876709\n",
      "Epoch 0: iteration 456/2501 train_loss: 1.1604502201080322 time_taken: 0.05707859992980957\n",
      "Epoch 0: iteration 457/2501 train_loss: 1.1596661806106567 time_taken: 0.055901527404785156\n",
      "Epoch 0: iteration 458/2501 train_loss: 1.1589076519012451 time_taken: 0.056777238845825195\n",
      "Epoch 0: iteration 459/2501 train_loss: 1.1580586433410645 time_taken: 0.057190895080566406\n",
      "Epoch 0: iteration 460/2501 train_loss: 1.1572158336639404 time_taken: 0.05683755874633789\n",
      "Epoch 0: iteration 461/2501 train_loss: 1.1564407348632812 time_taken: 0.06177544593811035\n",
      "Epoch 0: iteration 462/2501 train_loss: 1.155635118484497 time_taken: 0.05678200721740723\n",
      "Epoch 0: iteration 463/2501 train_loss: 1.1548473834991455 time_taken: 0.05657625198364258\n",
      "Epoch 0: iteration 464/2501 train_loss: 1.154137372970581 time_taken: 0.05585765838623047\n",
      "Epoch 0: iteration 465/2501 train_loss: 1.1533725261688232 time_taken: 0.05629777908325195\n",
      "Epoch 0: iteration 466/2501 train_loss: 1.1525408029556274 time_taken: 0.05593538284301758\n",
      "Epoch 0: iteration 467/2501 train_loss: 1.1517055034637451 time_taken: 0.05633878707885742\n",
      "Epoch 0: iteration 468/2501 train_loss: 1.1508222818374634 time_taken: 0.05631709098815918\n",
      "Epoch 0: iteration 469/2501 train_loss: 1.1500457525253296 time_taken: 0.05674552917480469\n",
      "Epoch 0: iteration 470/2501 train_loss: 1.1492758989334106 time_taken: 0.061093807220458984\n",
      "Epoch 0: iteration 471/2501 train_loss: 1.1484787464141846 time_taken: 0.05640244483947754\n",
      "Epoch 0: iteration 472/2501 train_loss: 1.1477890014648438 time_taken: 0.05614471435546875\n",
      "Epoch 0: iteration 473/2501 train_loss: 1.1470563411712646 time_taken: 0.056017160415649414\n",
      "Epoch 0: iteration 474/2501 train_loss: 1.1463385820388794 time_taken: 0.056496381759643555\n",
      "Epoch 0: iteration 475/2501 train_loss: 1.1456794738769531 time_taken: 0.05632305145263672\n",
      "Epoch 0: iteration 476/2501 train_loss: 1.144999384880066 time_taken: 0.05588698387145996\n",
      "Epoch 0: iteration 477/2501 train_loss: 1.144341230392456 time_taken: 0.05600404739379883\n",
      "Epoch 0: iteration 478/2501 train_loss: 1.1436160802841187 time_taken: 0.057204246520996094\n",
      "Epoch 0: iteration 479/2501 train_loss: 1.1428982019424438 time_taken: 0.056624650955200195\n",
      "Epoch 0: iteration 480/2501 train_loss: 1.1421995162963867 time_taken: 0.05646181106567383\n",
      "Epoch 0: iteration 481/2501 train_loss: 1.1415189504623413 time_taken: 0.056424617767333984\n",
      "Epoch 0: iteration 482/2501 train_loss: 1.1408520936965942 time_taken: 0.05606269836425781\n",
      "Epoch 0: iteration 483/2501 train_loss: 1.1402196884155273 time_taken: 0.05628228187561035\n",
      "Epoch 0: iteration 484/2501 train_loss: 1.1396164894104004 time_taken: 0.05736136436462402\n",
      "Epoch 0: iteration 485/2501 train_loss: 1.1390053033828735 time_taken: 0.05750298500061035\n",
      "Epoch 0: iteration 486/2501 train_loss: 1.1383554935455322 time_taken: 0.05695605278015137\n",
      "Epoch 0: iteration 487/2501 train_loss: 1.1377089023590088 time_taken: 0.056044816970825195\n",
      "Epoch 0: iteration 488/2501 train_loss: 1.1370083093643188 time_taken: 0.056203603744506836\n",
      "Epoch 0: iteration 489/2501 train_loss: 1.1363046169281006 time_taken: 0.05627918243408203\n",
      "Epoch 0: iteration 490/2501 train_loss: 1.1356545686721802 time_taken: 0.05667376518249512\n",
      "Epoch 0: iteration 491/2501 train_loss: 1.1350702047348022 time_taken: 0.056793928146362305\n",
      "Epoch 0: iteration 492/2501 train_loss: 1.134500503540039 time_taken: 0.05744004249572754\n",
      "Epoch 0: iteration 493/2501 train_loss: 1.133937954902649 time_taken: 0.057271480560302734\n",
      "Epoch 0: iteration 494/2501 train_loss: 1.1334319114685059 time_taken: 0.06166338920593262\n",
      "Epoch 0: iteration 495/2501 train_loss: 1.132918119430542 time_taken: 0.056860923767089844\n",
      "Epoch 0: iteration 496/2501 train_loss: 1.1324373483657837 time_taken: 0.05612373352050781\n",
      "Epoch 0: iteration 497/2501 train_loss: 1.1319332122802734 time_taken: 0.05668520927429199\n",
      "Epoch 0: iteration 498/2501 train_loss: 1.1314769983291626 time_taken: 0.055957794189453125\n",
      "Epoch 0: iteration 499/2501 train_loss: 1.1309467554092407 time_taken: 0.05624675750732422\n",
      "Epoch 0: iteration 500/2501 train_loss: 1.1304643154144287 time_taken: 0.056356191635131836\n",
      "Epoch 0: iteration 501/2501 train_loss: 1.1299914121627808 time_taken: 0.056172847747802734\n",
      "Epoch 0: iteration 502/2501 train_loss: 1.1295530796051025 time_taken: 0.05668449401855469\n",
      "Epoch 0: iteration 503/2501 train_loss: 1.1291621923446655 time_taken: 0.05722308158874512\n",
      "Epoch 0: iteration 504/2501 train_loss: 1.128697395324707 time_taken: 0.056138038635253906\n",
      "Epoch 0: iteration 505/2501 train_loss: 1.1282585859298706 time_taken: 0.05658984184265137\n",
      "Epoch 0: iteration 506/2501 train_loss: 1.1277787685394287 time_taken: 0.056587934494018555\n",
      "Epoch 0: iteration 507/2501 train_loss: 1.1273603439331055 time_taken: 0.05626106262207031\n",
      "Epoch 0: iteration 508/2501 train_loss: 1.1268898248672485 time_taken: 0.05617260932922363\n",
      "Epoch 0: iteration 509/2501 train_loss: 1.126394510269165 time_taken: 0.05638456344604492\n",
      "Epoch 0: iteration 510/2501 train_loss: 1.1258984804153442 time_taken: 0.05626845359802246\n",
      "Epoch 0: iteration 511/2501 train_loss: 1.1255115270614624 time_taken: 0.05657196044921875\n",
      "Epoch 0: iteration 512/2501 train_loss: 1.1250791549682617 time_taken: 0.0563814640045166\n",
      "Epoch 0: iteration 513/2501 train_loss: 1.124611258506775 time_taken: 0.05638766288757324\n",
      "Epoch 0: iteration 514/2501 train_loss: 1.1241509914398193 time_taken: 0.05654430389404297\n",
      "Epoch 0: iteration 515/2501 train_loss: 1.123670220375061 time_taken: 0.05710124969482422\n",
      "Epoch 0: iteration 516/2501 train_loss: 1.1230982542037964 time_taken: 0.05730843544006348\n",
      "Epoch 0: iteration 517/2501 train_loss: 1.122530221939087 time_taken: 0.05701804161071777\n",
      "Epoch 0: iteration 518/2501 train_loss: 1.1219463348388672 time_taken: 0.05680704116821289\n",
      "Epoch 0: iteration 519/2501 train_loss: 1.1213562488555908 time_taken: 0.057038307189941406\n",
      "Epoch 0: iteration 520/2501 train_loss: 1.1208100318908691 time_taken: 0.05746722221374512\n",
      "Epoch 0: iteration 521/2501 train_loss: 1.1202538013458252 time_taken: 0.056586503982543945\n",
      "Epoch 0: iteration 522/2501 train_loss: 1.119655728340149 time_taken: 0.056470632553100586\n",
      "Epoch 0: iteration 523/2501 train_loss: 1.1190699338912964 time_taken: 0.056845903396606445\n",
      "Epoch 0: iteration 524/2501 train_loss: 1.1185318231582642 time_taken: 0.0568242073059082\n",
      "Epoch 0: iteration 525/2501 train_loss: 1.1180064678192139 time_taken: 0.056638479232788086\n",
      "Epoch 0: iteration 526/2501 train_loss: 1.1174801588058472 time_taken: 0.057402610778808594\n",
      "Epoch 0: iteration 527/2501 train_loss: 1.1170108318328857 time_taken: 0.05697464942932129\n",
      "Epoch 0: iteration 528/2501 train_loss: 1.1165164709091187 time_taken: 0.0579376220703125\n",
      "Epoch 0: iteration 529/2501 train_loss: 1.1160181760787964 time_taken: 0.05695843696594238\n",
      "Epoch 0: iteration 530/2501 train_loss: 1.1155521869659424 time_taken: 0.05684518814086914\n",
      "Epoch 0: iteration 531/2501 train_loss: 1.1150527000427246 time_taken: 0.05686497688293457\n",
      "Epoch 0: iteration 532/2501 train_loss: 1.1145343780517578 time_taken: 0.05652642250061035\n",
      "Epoch 0: iteration 533/2501 train_loss: 1.113957166671753 time_taken: 0.05681896209716797\n",
      "Epoch 0: iteration 534/2501 train_loss: 1.1133904457092285 time_taken: 0.056371450424194336\n",
      "Epoch 0: iteration 535/2501 train_loss: 1.112878441810608 time_taken: 0.05692934989929199\n",
      "Epoch 0: iteration 536/2501 train_loss: 1.1122971773147583 time_taken: 0.05654191970825195\n",
      "Epoch 0: iteration 537/2501 train_loss: 1.1116942167282104 time_taken: 0.05695962905883789\n",
      "Epoch 0: iteration 538/2501 train_loss: 1.1110939979553223 time_taken: 0.05720806121826172\n",
      "Epoch 0: iteration 539/2501 train_loss: 1.1104722023010254 time_taken: 0.0577692985534668\n",
      "Epoch 0: iteration 540/2501 train_loss: 1.1098061800003052 time_taken: 0.05663871765136719\n",
      "Epoch 0: iteration 541/2501 train_loss: 1.109220266342163 time_taken: 0.05750465393066406\n",
      "Epoch 0: iteration 542/2501 train_loss: 1.1087286472320557 time_taken: 0.0571904182434082\n",
      "Epoch 0: iteration 543/2501 train_loss: 1.1081610918045044 time_taken: 0.05649256706237793\n",
      "Epoch 0: iteration 544/2501 train_loss: 1.1076152324676514 time_taken: 0.05638909339904785\n",
      "Epoch 0: iteration 545/2501 train_loss: 1.1070748567581177 time_taken: 0.056824684143066406\n",
      "Epoch 0: iteration 546/2501 train_loss: 1.1066573858261108 time_taken: 0.05703306198120117\n",
      "Epoch 0: iteration 547/2501 train_loss: 1.1062586307525635 time_taken: 0.056569814682006836\n",
      "Epoch 0: iteration 548/2501 train_loss: 1.1057665348052979 time_taken: 0.05631852149963379\n",
      "Epoch 0: iteration 549/2501 train_loss: 1.1052438020706177 time_taken: 0.05635547637939453\n",
      "Epoch 0: iteration 550/2501 train_loss: 1.1048245429992676 time_taken: 0.05701947212219238\n",
      "Epoch 0: iteration 551/2501 train_loss: 1.1043119430541992 time_taken: 0.05647158622741699\n",
      "Epoch 0: iteration 552/2501 train_loss: 1.1038473844528198 time_taken: 0.05683255195617676\n",
      "Epoch 0: iteration 553/2501 train_loss: 1.1033979654312134 time_taken: 0.056537628173828125\n",
      "Epoch 0: iteration 554/2501 train_loss: 1.102900505065918 time_taken: 0.05687522888183594\n",
      "Epoch 0: iteration 555/2501 train_loss: 1.1024407148361206 time_taken: 0.05684232711791992\n",
      "Epoch 0: iteration 556/2501 train_loss: 1.1019741296768188 time_taken: 0.05694150924682617\n",
      "Epoch 0: iteration 557/2501 train_loss: 1.1015279293060303 time_taken: 0.056676387786865234\n",
      "Epoch 0: iteration 558/2501 train_loss: 1.1010947227478027 time_taken: 0.05758929252624512\n",
      "Epoch 0: iteration 559/2501 train_loss: 1.1006081104278564 time_taken: 0.05714821815490723\n",
      "Epoch 0: iteration 560/2501 train_loss: 1.1001555919647217 time_taken: 0.05675339698791504\n",
      "Epoch 0: iteration 561/2501 train_loss: 1.099685788154602 time_taken: 0.05719113349914551\n",
      "Epoch 0: iteration 562/2501 train_loss: 1.0992257595062256 time_taken: 0.05683183670043945\n",
      "Epoch 0: iteration 563/2501 train_loss: 1.0987017154693604 time_taken: 0.057016611099243164\n",
      "Epoch 0: iteration 564/2501 train_loss: 1.0982364416122437 time_taken: 0.05718994140625\n",
      "Epoch 0: iteration 565/2501 train_loss: 1.0977449417114258 time_taken: 0.05677318572998047\n",
      "Epoch 0: iteration 566/2501 train_loss: 1.097204566001892 time_taken: 0.05738997459411621\n",
      "Epoch 0: iteration 567/2501 train_loss: 1.0967341661453247 time_taken: 0.05687665939331055\n",
      "Epoch 0: iteration 568/2501 train_loss: 1.0962172746658325 time_taken: 0.0565338134765625\n",
      "Epoch 0: iteration 569/2501 train_loss: 1.095775842666626 time_taken: 0.0565180778503418\n",
      "Epoch 0: iteration 570/2501 train_loss: 1.0953770875930786 time_taken: 0.056638240814208984\n",
      "Epoch 0: iteration 571/2501 train_loss: 1.0949565172195435 time_taken: 0.05710339546203613\n",
      "Epoch 0: iteration 572/2501 train_loss: 1.0945773124694824 time_taken: 0.056883811950683594\n",
      "Epoch 0: iteration 573/2501 train_loss: 1.0942364931106567 time_taken: 0.05731320381164551\n",
      "Epoch 0: iteration 574/2501 train_loss: 1.0938775539398193 time_taken: 0.05682873725891113\n",
      "Epoch 0: iteration 575/2501 train_loss: 1.093538522720337 time_taken: 0.056941986083984375\n",
      "Epoch 0: iteration 576/2501 train_loss: 1.093226432800293 time_taken: 0.05735468864440918\n",
      "Epoch 0: iteration 577/2501 train_loss: 1.0928248167037964 time_taken: 0.057234764099121094\n",
      "Epoch 0: iteration 578/2501 train_loss: 1.092417597770691 time_taken: 0.0572659969329834\n",
      "Epoch 0: iteration 579/2501 train_loss: 1.0920295715332031 time_taken: 0.056732177734375\n",
      "Epoch 0: iteration 580/2501 train_loss: 1.0916831493377686 time_taken: 0.056131839752197266\n",
      "Epoch 0: iteration 581/2501 train_loss: 1.0913422107696533 time_taken: 0.05650186538696289\n",
      "Epoch 0: iteration 582/2501 train_loss: 1.0909892320632935 time_taken: 0.05603313446044922\n",
      "Epoch 0: iteration 583/2501 train_loss: 1.0906685590744019 time_taken: 0.05699324607849121\n",
      "Epoch 0: iteration 584/2501 train_loss: 1.0903196334838867 time_taken: 0.05672574043273926\n",
      "Epoch 0: iteration 585/2501 train_loss: 1.0900758504867554 time_taken: 0.056738853454589844\n",
      "Epoch 0: iteration 586/2501 train_loss: 1.0897879600524902 time_taken: 0.05622458457946777\n",
      "Epoch 0: iteration 587/2501 train_loss: 1.0895919799804688 time_taken: 0.05663704872131348\n",
      "Epoch 0: iteration 588/2501 train_loss: 1.0893611907958984 time_taken: 0.05643129348754883\n",
      "Epoch 0: iteration 589/2501 train_loss: 1.089125394821167 time_taken: 0.056720733642578125\n",
      "Epoch 0: iteration 590/2501 train_loss: 1.0889030694961548 time_taken: 0.05666351318359375\n",
      "Epoch 0: iteration 591/2501 train_loss: 1.0887292623519897 time_taken: 0.057338714599609375\n",
      "Epoch 0: iteration 592/2501 train_loss: 1.0885529518127441 time_taken: 0.05716109275817871\n",
      "Epoch 0: iteration 593/2501 train_loss: 1.0884058475494385 time_taken: 0.05674386024475098\n",
      "Epoch 0: iteration 594/2501 train_loss: 1.0882240533828735 time_taken: 0.05627918243408203\n",
      "Epoch 0: iteration 595/2501 train_loss: 1.088058590888977 time_taken: 0.05640912055969238\n",
      "Epoch 0: iteration 596/2501 train_loss: 1.0879336595535278 time_taken: 0.05637955665588379\n",
      "Epoch 0: iteration 597/2501 train_loss: 1.0878034830093384 time_taken: 0.05633711814880371\n",
      "Epoch 0: iteration 598/2501 train_loss: 1.0876390933990479 time_taken: 0.0567169189453125\n",
      "Epoch 0: iteration 599/2501 train_loss: 1.0874130725860596 time_taken: 0.05591011047363281\n",
      "Epoch 0: iteration 600/2501 train_loss: 1.087222695350647 time_taken: 0.05617976188659668\n",
      "Epoch 0: iteration 601/2501 train_loss: 1.086979627609253 time_taken: 0.056015968322753906\n",
      "Epoch 0: iteration 602/2501 train_loss: 1.0867410898208618 time_taken: 0.056529998779296875\n",
      "Epoch 0: iteration 603/2501 train_loss: 1.0864689350128174 time_taken: 0.05660700798034668\n",
      "Epoch 0: iteration 604/2501 train_loss: 1.086160659790039 time_taken: 0.05703139305114746\n",
      "Epoch 0: iteration 605/2501 train_loss: 1.0858826637268066 time_taken: 0.056253910064697266\n",
      "Epoch 0: iteration 606/2501 train_loss: 1.08553946018219 time_taken: 0.05604219436645508\n",
      "Epoch 0: iteration 607/2501 train_loss: 1.0851627588272095 time_taken: 0.05678057670593262\n",
      "Epoch 0: iteration 608/2501 train_loss: 1.0848431587219238 time_taken: 0.05660676956176758\n",
      "Epoch 0: iteration 609/2501 train_loss: 1.0845208168029785 time_taken: 0.056205034255981445\n",
      "Epoch 0: iteration 610/2501 train_loss: 1.0841498374938965 time_taken: 0.05611109733581543\n",
      "Epoch 0: iteration 611/2501 train_loss: 1.0838104486465454 time_taken: 0.056284427642822266\n",
      "Epoch 0: iteration 612/2501 train_loss: 1.0833936929702759 time_taken: 0.05651497840881348\n",
      "Epoch 0: iteration 613/2501 train_loss: 1.0829769372940063 time_taken: 0.056001901626586914\n",
      "Epoch 0: iteration 614/2501 train_loss: 1.0825631618499756 time_taken: 0.05595207214355469\n",
      "Epoch 0: iteration 615/2501 train_loss: 1.0820809602737427 time_taken: 0.05594801902770996\n",
      "Epoch 0: iteration 616/2501 train_loss: 1.081636905670166 time_taken: 0.05586099624633789\n",
      "Epoch 0: iteration 617/2501 train_loss: 1.0811810493469238 time_taken: 0.056406497955322266\n",
      "Epoch 0: iteration 618/2501 train_loss: 1.0806729793548584 time_taken: 0.056189775466918945\n",
      "Epoch 0: iteration 619/2501 train_loss: 1.0801528692245483 time_taken: 0.056531429290771484\n",
      "Epoch 0: iteration 620/2501 train_loss: 1.0796372890472412 time_taken: 0.05614757537841797\n",
      "Epoch 0: iteration 621/2501 train_loss: 1.0791881084442139 time_taken: 0.05627775192260742\n",
      "Epoch 0: iteration 622/2501 train_loss: 1.0787123441696167 time_taken: 0.05618882179260254\n",
      "Epoch 0: iteration 623/2501 train_loss: 1.07830810546875 time_taken: 0.056139469146728516\n",
      "Epoch 0: iteration 624/2501 train_loss: 1.0778659582138062 time_taken: 0.05655550956726074\n",
      "Epoch 0: iteration 625/2501 train_loss: 1.0774052143096924 time_taken: 0.05672645568847656\n",
      "Epoch 0: iteration 626/2501 train_loss: 1.0770000219345093 time_taken: 0.05702376365661621\n",
      "Epoch 0: iteration 627/2501 train_loss: 1.0766063928604126 time_taken: 0.05685567855834961\n",
      "Epoch 0: iteration 628/2501 train_loss: 1.0762362480163574 time_taken: 0.05678057670593262\n",
      "Epoch 0: iteration 629/2501 train_loss: 1.0758788585662842 time_taken: 0.056722402572631836\n",
      "Epoch 0: iteration 630/2501 train_loss: 1.0755187273025513 time_taken: 0.056583404541015625\n",
      "Epoch 0: iteration 631/2501 train_loss: 1.0752531290054321 time_taken: 0.05755972862243652\n",
      "Epoch 0: iteration 632/2501 train_loss: 1.0749481916427612 time_taken: 0.05640268325805664\n",
      "Epoch 0: iteration 633/2501 train_loss: 1.074639081954956 time_taken: 0.0571444034576416\n",
      "Epoch 0: iteration 634/2501 train_loss: 1.0742435455322266 time_taken: 0.05842232704162598\n",
      "Epoch 0: iteration 635/2501 train_loss: 1.073859453201294 time_taken: 0.056406259536743164\n",
      "Epoch 0: iteration 636/2501 train_loss: 1.0734821557998657 time_taken: 0.05653548240661621\n",
      "Epoch 0: iteration 637/2501 train_loss: 1.0731093883514404 time_taken: 0.056122779846191406\n",
      "Epoch 0: iteration 638/2501 train_loss: 1.0726722478866577 time_taken: 0.05616426467895508\n",
      "Epoch 0: iteration 639/2501 train_loss: 1.0722278356552124 time_taken: 0.055940866470336914\n",
      "Epoch 0: iteration 640/2501 train_loss: 1.0717610120773315 time_taken: 0.05624079704284668\n",
      "Epoch 0: iteration 641/2501 train_loss: 1.0713098049163818 time_taken: 0.056035757064819336\n",
      "Epoch 0: iteration 642/2501 train_loss: 1.0708338022232056 time_taken: 0.05643582344055176\n",
      "Epoch 0: iteration 643/2501 train_loss: 1.0703755617141724 time_taken: 0.05639314651489258\n",
      "Epoch 0: iteration 644/2501 train_loss: 1.0698469877243042 time_taken: 0.056116580963134766\n",
      "Epoch 0: iteration 645/2501 train_loss: 1.0693676471710205 time_taken: 0.05652213096618652\n",
      "Epoch 0: iteration 646/2501 train_loss: 1.0689337253570557 time_taken: 0.056339263916015625\n",
      "Epoch 0: iteration 647/2501 train_loss: 1.0685619115829468 time_taken: 0.05654025077819824\n",
      "Epoch 0: iteration 648/2501 train_loss: 1.0681257247924805 time_taken: 0.05701255798339844\n",
      "Epoch 0: iteration 649/2501 train_loss: 1.0677331686019897 time_taken: 0.05944371223449707\n",
      "Epoch 0: iteration 650/2501 train_loss: 1.0672719478607178 time_taken: 0.0559840202331543\n",
      "Epoch 0: iteration 651/2501 train_loss: 1.066893458366394 time_taken: 0.05758929252624512\n",
      "Epoch 0: iteration 652/2501 train_loss: 1.0665197372436523 time_taken: 0.05626726150512695\n",
      "Epoch 0: iteration 653/2501 train_loss: 1.0661174058914185 time_taken: 0.058565616607666016\n",
      "Epoch 0: iteration 654/2501 train_loss: 1.0657200813293457 time_taken: 0.05586552619934082\n",
      "Epoch 0: iteration 655/2501 train_loss: 1.0653207302093506 time_taken: 0.05630683898925781\n",
      "Epoch 0: iteration 656/2501 train_loss: 1.0649759769439697 time_taken: 0.05586743354797363\n",
      "Epoch 0: iteration 657/2501 train_loss: 1.0646798610687256 time_taken: 0.05743288993835449\n",
      "Epoch 0: iteration 658/2501 train_loss: 1.0643556118011475 time_taken: 0.06148958206176758\n",
      "Epoch 0: iteration 659/2501 train_loss: 1.064011573791504 time_taken: 0.055986881256103516\n",
      "Epoch 0: iteration 660/2501 train_loss: 1.0637096166610718 time_taken: 0.05623912811279297\n",
      "Epoch 0: iteration 661/2501 train_loss: 1.063409447669983 time_taken: 0.0566256046295166\n",
      "Epoch 0: iteration 662/2501 train_loss: 1.0630836486816406 time_taken: 0.05643582344055176\n",
      "Epoch 0: iteration 663/2501 train_loss: 1.0627681016921997 time_taken: 0.05713915824890137\n",
      "Epoch 0: iteration 664/2501 train_loss: 1.0624412298202515 time_taken: 0.056268930435180664\n",
      "Epoch 0: iteration 665/2501 train_loss: 1.0621548891067505 time_taken: 0.0566716194152832\n",
      "Epoch 0: iteration 666/2501 train_loss: 1.0619416236877441 time_taken: 0.05632376670837402\n",
      "Epoch 0: iteration 667/2501 train_loss: 1.0616521835327148 time_taken: 0.05644822120666504\n",
      "Epoch 0: iteration 668/2501 train_loss: 1.0613739490509033 time_taken: 0.05607414245605469\n",
      "Epoch 0: iteration 669/2501 train_loss: 1.0610971450805664 time_taken: 0.056285858154296875\n",
      "Epoch 0: iteration 670/2501 train_loss: 1.060853362083435 time_taken: 0.05632901191711426\n",
      "Epoch 0: iteration 671/2501 train_loss: 1.0605852603912354 time_taken: 0.07132911682128906\n",
      "Epoch 0: iteration 672/2501 train_loss: 1.0603488683700562 time_taken: 0.0557408332824707\n",
      "Epoch 0: iteration 673/2501 train_loss: 1.060120940208435 time_taken: 0.05706167221069336\n",
      "Epoch 0: iteration 674/2501 train_loss: 1.059851884841919 time_taken: 0.05690503120422363\n",
      "Epoch 0: iteration 675/2501 train_loss: 1.059582233428955 time_taken: 0.05733609199523926\n",
      "Epoch 0: iteration 676/2501 train_loss: 1.0593678951263428 time_taken: 0.05625772476196289\n",
      "Epoch 0: iteration 677/2501 train_loss: 1.0591398477554321 time_taken: 0.06226611137390137\n",
      "Epoch 0: iteration 678/2501 train_loss: 1.0588979721069336 time_taken: 0.05592155456542969\n",
      "Epoch 0: iteration 679/2501 train_loss: 1.0586589574813843 time_taken: 0.05659198760986328\n",
      "Epoch 0: iteration 680/2501 train_loss: 1.0584533214569092 time_taken: 0.059639930725097656\n",
      "Epoch 0: iteration 681/2501 train_loss: 1.0582062005996704 time_taken: 0.05585360527038574\n",
      "Epoch 0: iteration 682/2501 train_loss: 1.0579907894134521 time_taken: 0.056427955627441406\n",
      "Epoch 0: iteration 683/2501 train_loss: 1.0577404499053955 time_taken: 0.05710339546203613\n",
      "Epoch 0: iteration 684/2501 train_loss: 1.0575306415557861 time_taken: 0.056676387786865234\n",
      "Epoch 0: iteration 685/2501 train_loss: 1.0573350191116333 time_taken: 0.05693411827087402\n",
      "Epoch 0: iteration 686/2501 train_loss: 1.0571244955062866 time_taken: 0.05772829055786133\n",
      "Epoch 0: iteration 687/2501 train_loss: 1.056904673576355 time_taken: 0.0567929744720459\n",
      "Epoch 0: iteration 688/2501 train_loss: 1.056664228439331 time_taken: 0.05782794952392578\n",
      "Epoch 0: iteration 689/2501 train_loss: 1.0564556121826172 time_taken: 0.056702375411987305\n",
      "Epoch 0: iteration 690/2501 train_loss: 1.056207537651062 time_taken: 0.05678725242614746\n",
      "Epoch 0: iteration 691/2501 train_loss: 1.0558960437774658 time_taken: 0.056943416595458984\n",
      "Epoch 0: iteration 692/2501 train_loss: 1.055594801902771 time_taken: 0.05701136589050293\n",
      "Epoch 0: iteration 693/2501 train_loss: 1.0553481578826904 time_taken: 0.05729365348815918\n",
      "Epoch 0: iteration 694/2501 train_loss: 1.055042028427124 time_taken: 0.05648088455200195\n",
      "Epoch 0: iteration 695/2501 train_loss: 1.0547288656234741 time_taken: 0.0560455322265625\n",
      "Epoch 0: iteration 696/2501 train_loss: 1.054377555847168 time_taken: 0.05687379837036133\n",
      "Epoch 0: iteration 697/2501 train_loss: 1.0540164709091187 time_taken: 0.056767940521240234\n",
      "Epoch 0: iteration 698/2501 train_loss: 1.0536319017410278 time_taken: 0.056955814361572266\n",
      "Epoch 0: iteration 699/2501 train_loss: 1.0532387495040894 time_taken: 0.055913686752319336\n",
      "Epoch 0: iteration 700/2501 train_loss: 1.0529195070266724 time_taken: 0.05663943290710449\n",
      "Epoch 0: iteration 701/2501 train_loss: 1.0526477098464966 time_taken: 0.05643153190612793\n",
      "Epoch 0: iteration 702/2501 train_loss: 1.0523314476013184 time_taken: 0.05664992332458496\n",
      "Epoch 0: iteration 703/2501 train_loss: 1.0520424842834473 time_taken: 0.05600905418395996\n",
      "Epoch 0: iteration 704/2501 train_loss: 1.0517393350601196 time_taken: 0.0565943717956543\n",
      "Epoch 0: iteration 705/2501 train_loss: 1.0514769554138184 time_taken: 0.05606508255004883\n",
      "Epoch 0: iteration 706/2501 train_loss: 1.0511746406555176 time_taken: 0.05654740333557129\n",
      "Epoch 0: iteration 707/2501 train_loss: 1.0509026050567627 time_taken: 0.05656242370605469\n",
      "Epoch 0: iteration 708/2501 train_loss: 1.0506471395492554 time_taken: 0.11163997650146484\n",
      "Epoch 0: iteration 709/2501 train_loss: 1.0504038333892822 time_taken: 0.0561065673828125\n",
      "Epoch 0: iteration 710/2501 train_loss: 1.0501693487167358 time_taken: 0.05633378028869629\n",
      "Epoch 0: iteration 711/2501 train_loss: 1.049891471862793 time_taken: 0.057297706604003906\n",
      "Epoch 0: iteration 712/2501 train_loss: 1.0496495962142944 time_taken: 0.056087493896484375\n",
      "Epoch 0: iteration 713/2501 train_loss: 1.0493956804275513 time_taken: 0.05596160888671875\n",
      "Epoch 0: iteration 714/2501 train_loss: 1.0491321086883545 time_taken: 0.05591845512390137\n",
      "Epoch 0: iteration 715/2501 train_loss: 1.0488866567611694 time_taken: 0.05789637565612793\n",
      "Epoch 0: iteration 716/2501 train_loss: 1.0486183166503906 time_taken: 0.05609774589538574\n",
      "Epoch 0: iteration 717/2501 train_loss: 1.0483044385910034 time_taken: 0.05587577819824219\n",
      "Epoch 0: iteration 718/2501 train_loss: 1.0480608940124512 time_taken: 0.05619359016418457\n",
      "Epoch 0: iteration 719/2501 train_loss: 1.0477898120880127 time_taken: 0.056501150131225586\n",
      "Epoch 0: iteration 720/2501 train_loss: 1.0475348234176636 time_taken: 0.05692863464355469\n",
      "Epoch 0: iteration 721/2501 train_loss: 1.0473203659057617 time_taken: 0.056810855865478516\n",
      "Epoch 0: iteration 722/2501 train_loss: 1.0471603870391846 time_taken: 0.05642127990722656\n",
      "Epoch 0: iteration 723/2501 train_loss: 1.046964406967163 time_taken: 0.0557863712310791\n",
      "Epoch 0: iteration 724/2501 train_loss: 1.0467438697814941 time_taken: 0.056433916091918945\n",
      "Epoch 0: iteration 725/2501 train_loss: 1.046505093574524 time_taken: 0.05663013458251953\n",
      "Epoch 0: iteration 726/2501 train_loss: 1.0462371110916138 time_taken: 0.06150412559509277\n",
      "Epoch 0: iteration 727/2501 train_loss: 1.0459537506103516 time_taken: 0.05641794204711914\n",
      "Epoch 0: iteration 728/2501 train_loss: 1.0456535816192627 time_taken: 0.05664324760437012\n",
      "Epoch 0: iteration 729/2501 train_loss: 1.045331358909607 time_taken: 0.05645322799682617\n",
      "Epoch 0: iteration 730/2501 train_loss: 1.045006513595581 time_taken: 0.056320905685424805\n",
      "Epoch 0: iteration 731/2501 train_loss: 1.0446624755859375 time_taken: 0.056112051010131836\n",
      "Epoch 0: iteration 732/2501 train_loss: 1.044312834739685 time_taken: 0.05637097358703613\n",
      "Epoch 0: iteration 733/2501 train_loss: 1.043971061706543 time_taken: 0.0561671257019043\n",
      "Epoch 0: iteration 734/2501 train_loss: 1.0436257123947144 time_taken: 0.05617403984069824\n",
      "Epoch 0: iteration 735/2501 train_loss: 1.043286919593811 time_taken: 0.05675005912780762\n",
      "Epoch 0: iteration 736/2501 train_loss: 1.042899489402771 time_taken: 0.05620288848876953\n",
      "Epoch 0: iteration 737/2501 train_loss: 1.0425902605056763 time_taken: 0.0562739372253418\n",
      "Epoch 0: iteration 738/2501 train_loss: 1.0422927141189575 time_taken: 0.05650687217712402\n",
      "Epoch 0: iteration 739/2501 train_loss: 1.0420316457748413 time_taken: 0.055999755859375\n",
      "Epoch 0: iteration 740/2501 train_loss: 1.0417665243148804 time_taken: 0.056171417236328125\n",
      "Epoch 0: iteration 741/2501 train_loss: 1.0415514707565308 time_taken: 0.055841922760009766\n",
      "Epoch 0: iteration 742/2501 train_loss: 1.0412683486938477 time_taken: 0.056432247161865234\n",
      "Epoch 0: iteration 743/2501 train_loss: 1.041000247001648 time_taken: 0.05579352378845215\n",
      "Epoch 0: iteration 744/2501 train_loss: 1.0406955480575562 time_taken: 0.05598044395446777\n",
      "Epoch 0: iteration 745/2501 train_loss: 1.0403835773468018 time_taken: 0.056281089782714844\n",
      "Epoch 0: iteration 746/2501 train_loss: 1.0400782823562622 time_taken: 0.05610322952270508\n",
      "Epoch 0: iteration 747/2501 train_loss: 1.0397857427597046 time_taken: 0.05611443519592285\n",
      "Epoch 0: iteration 748/2501 train_loss: 1.0394434928894043 time_taken: 0.05628848075866699\n",
      "Epoch 0: iteration 749/2501 train_loss: 1.039137601852417 time_taken: 0.057372331619262695\n",
      "Epoch 0: iteration 750/2501 train_loss: 1.0387901067733765 time_taken: 0.0562591552734375\n",
      "Epoch 0: iteration 751/2501 train_loss: 1.038485050201416 time_taken: 0.055994272232055664\n",
      "Epoch 0: iteration 752/2501 train_loss: 1.038160800933838 time_taken: 0.056536197662353516\n",
      "Epoch 0: iteration 753/2501 train_loss: 1.0378471612930298 time_taken: 0.0565190315246582\n",
      "Epoch 0: iteration 754/2501 train_loss: 1.0375176668167114 time_taken: 0.05608797073364258\n",
      "Epoch 0: iteration 755/2501 train_loss: 1.0372235774993896 time_taken: 0.0563356876373291\n",
      "Epoch 0: iteration 756/2501 train_loss: 1.036938190460205 time_taken: 0.05626344680786133\n",
      "Epoch 0: iteration 757/2501 train_loss: 1.0366387367248535 time_taken: 0.05655026435852051\n",
      "Epoch 0: iteration 758/2501 train_loss: 1.0363339185714722 time_taken: 0.05646848678588867\n",
      "Epoch 0: iteration 759/2501 train_loss: 1.0360934734344482 time_taken: 0.05645489692687988\n",
      "Epoch 0: iteration 760/2501 train_loss: 1.035911202430725 time_taken: 0.05689859390258789\n",
      "Epoch 0: iteration 761/2501 train_loss: 1.0356807708740234 time_taken: 0.05743908882141113\n",
      "Epoch 0: iteration 762/2501 train_loss: 1.0354046821594238 time_taken: 0.0612483024597168\n",
      "Epoch 0: iteration 763/2501 train_loss: 1.0351910591125488 time_taken: 0.056752681732177734\n",
      "Epoch 0: iteration 764/2501 train_loss: 1.0350100994110107 time_taken: 0.05679130554199219\n",
      "Epoch 0: iteration 765/2501 train_loss: 1.0348241329193115 time_taken: 0.05598282814025879\n",
      "Epoch 0: iteration 766/2501 train_loss: 1.0346518754959106 time_taken: 0.056154489517211914\n",
      "Epoch 0: iteration 767/2501 train_loss: 1.034426212310791 time_taken: 0.05600333213806152\n",
      "Epoch 0: iteration 768/2501 train_loss: 1.0341594219207764 time_taken: 0.05661821365356445\n",
      "Epoch 0: iteration 769/2501 train_loss: 1.0339915752410889 time_taken: 0.05733847618103027\n",
      "Epoch 0: iteration 770/2501 train_loss: 1.0338140726089478 time_taken: 0.06225466728210449\n",
      "Epoch 0: iteration 771/2501 train_loss: 1.0336661338806152 time_taken: 0.06345558166503906\n",
      "Epoch 0: iteration 772/2501 train_loss: 1.0334821939468384 time_taken: 0.0567324161529541\n",
      "Epoch 0: iteration 773/2501 train_loss: 1.033311128616333 time_taken: 0.056756019592285156\n",
      "Epoch 0: iteration 774/2501 train_loss: 1.0331599712371826 time_taken: 0.0563654899597168\n",
      "Epoch 0: iteration 775/2501 train_loss: 1.0330233573913574 time_taken: 0.057045936584472656\n",
      "Epoch 0: iteration 776/2501 train_loss: 1.032887578010559 time_taken: 0.05690312385559082\n",
      "Epoch 0: iteration 777/2501 train_loss: 1.0327367782592773 time_taken: 0.056363582611083984\n",
      "Epoch 0: iteration 778/2501 train_loss: 1.0325567722320557 time_taken: 0.057272911071777344\n",
      "Epoch 0: iteration 779/2501 train_loss: 1.0323522090911865 time_taken: 0.05700325965881348\n",
      "Epoch 0: iteration 780/2501 train_loss: 1.0321487188339233 time_taken: 0.0570836067199707\n",
      "Epoch 0: iteration 781/2501 train_loss: 1.0319690704345703 time_taken: 0.056737422943115234\n",
      "Epoch 0: iteration 782/2501 train_loss: 1.0317620038986206 time_taken: 0.05719280242919922\n",
      "Epoch 0: iteration 783/2501 train_loss: 1.0315512418746948 time_taken: 0.056894779205322266\n",
      "Epoch 0: iteration 784/2501 train_loss: 1.0313045978546143 time_taken: 0.05669879913330078\n",
      "Epoch 0: iteration 785/2501 train_loss: 1.0310983657836914 time_taken: 0.057424068450927734\n",
      "Epoch 0: iteration 786/2501 train_loss: 1.030877709388733 time_taken: 0.061925411224365234\n",
      "Epoch 0: iteration 787/2501 train_loss: 1.030626654624939 time_taken: 0.05711483955383301\n",
      "Epoch 0: iteration 788/2501 train_loss: 1.030422329902649 time_taken: 0.05659604072570801\n",
      "Epoch 0: iteration 789/2501 train_loss: 1.030195713043213 time_taken: 0.05707597732543945\n",
      "Epoch 0: iteration 790/2501 train_loss: 1.02999746799469 time_taken: 0.056964874267578125\n",
      "Epoch 0: iteration 791/2501 train_loss: 1.0298099517822266 time_taken: 0.06005358695983887\n",
      "Epoch 0: iteration 792/2501 train_loss: 1.0296162366867065 time_taken: 0.058109283447265625\n",
      "Epoch 0: iteration 793/2501 train_loss: 1.029444694519043 time_taken: 0.05728459358215332\n",
      "Epoch 0: iteration 794/2501 train_loss: 1.0292361974716187 time_taken: 0.056786537170410156\n",
      "Epoch 0: iteration 795/2501 train_loss: 1.0290822982788086 time_taken: 0.05671072006225586\n",
      "Epoch 0: iteration 796/2501 train_loss: 1.028924584388733 time_taken: 0.05663490295410156\n",
      "Epoch 0: iteration 797/2501 train_loss: 1.0287898778915405 time_taken: 0.057048797607421875\n",
      "Epoch 0: iteration 798/2501 train_loss: 1.0286351442337036 time_taken: 0.0566408634185791\n",
      "Epoch 0: iteration 799/2501 train_loss: 1.0284607410430908 time_taken: 0.056302547454833984\n",
      "Epoch 0: iteration 800/2501 train_loss: 1.0283364057540894 time_taken: 0.06671142578125\n",
      "Epoch 0: iteration 801/2501 train_loss: 1.0281838178634644 time_taken: 0.056734323501586914\n",
      "Epoch 0: iteration 802/2501 train_loss: 1.027974009513855 time_taken: 0.05635666847229004\n",
      "Epoch 0: iteration 803/2501 train_loss: 1.027748703956604 time_taken: 0.05654740333557129\n",
      "Epoch 0: iteration 804/2501 train_loss: 1.0275253057479858 time_taken: 0.05630230903625488\n",
      "Epoch 0: iteration 805/2501 train_loss: 1.0272886753082275 time_taken: 0.05656719207763672\n",
      "Epoch 0: iteration 806/2501 train_loss: 1.027055025100708 time_taken: 0.056580305099487305\n",
      "Epoch 0: iteration 807/2501 train_loss: 1.026800274848938 time_taken: 0.05620265007019043\n",
      "Epoch 0: iteration 808/2501 train_loss: 1.0266144275665283 time_taken: 0.056363582611083984\n",
      "Epoch 0: iteration 809/2501 train_loss: 1.0263826847076416 time_taken: 0.056427001953125\n",
      "Epoch 0: iteration 810/2501 train_loss: 1.0261127948760986 time_taken: 0.05642080307006836\n",
      "Epoch 0: iteration 811/2501 train_loss: 1.0258872509002686 time_taken: 0.056848764419555664\n",
      "Epoch 0: iteration 812/2501 train_loss: 1.0256913900375366 time_taken: 0.05645179748535156\n",
      "Epoch 0: iteration 813/2501 train_loss: 1.0254583358764648 time_taken: 0.05639791488647461\n",
      "Epoch 0: iteration 814/2501 train_loss: 1.025212287902832 time_taken: 0.057715654373168945\n",
      "Epoch 0: iteration 815/2501 train_loss: 1.0249429941177368 time_taken: 0.05819988250732422\n",
      "Epoch 0: iteration 816/2501 train_loss: 1.024723768234253 time_taken: 0.05763363838195801\n",
      "Epoch 0: iteration 817/2501 train_loss: 1.0244752168655396 time_taken: 0.056761980056762695\n",
      "Epoch 0: iteration 818/2501 train_loss: 1.0242457389831543 time_taken: 0.05755043029785156\n",
      "Epoch 0: iteration 819/2501 train_loss: 1.0240570306777954 time_taken: 0.05814409255981445\n",
      "Epoch 0: iteration 820/2501 train_loss: 1.023916482925415 time_taken: 0.05664682388305664\n",
      "Epoch 0: iteration 821/2501 train_loss: 1.0237361192703247 time_taken: 0.057188987731933594\n",
      "Epoch 0: iteration 822/2501 train_loss: 1.0235296487808228 time_taken: 0.05752825736999512\n",
      "Epoch 0: iteration 823/2501 train_loss: 1.0232839584350586 time_taken: 0.05868840217590332\n",
      "Epoch 0: iteration 824/2501 train_loss: 1.0230045318603516 time_taken: 0.057495832443237305\n",
      "Epoch 0: iteration 825/2501 train_loss: 1.0227482318878174 time_taken: 0.06182670593261719\n",
      "Epoch 0: iteration 826/2501 train_loss: 1.0224690437316895 time_taken: 0.05696916580200195\n",
      "Epoch 0: iteration 827/2501 train_loss: 1.0222357511520386 time_taken: 0.05780529975891113\n",
      "Epoch 0: iteration 828/2501 train_loss: 1.0219852924346924 time_taken: 0.05672192573547363\n",
      "Epoch 0: iteration 829/2501 train_loss: 1.0217843055725098 time_taken: 0.057218074798583984\n",
      "Epoch 0: iteration 830/2501 train_loss: 1.0215092897415161 time_taken: 0.05750155448913574\n",
      "Epoch 0: iteration 831/2501 train_loss: 1.0212514400482178 time_taken: 0.05785727500915527\n",
      "Epoch 0: iteration 832/2501 train_loss: 1.02095627784729 time_taken: 0.05707097053527832\n",
      "Epoch 0: iteration 833/2501 train_loss: 1.0206563472747803 time_taken: 0.05698728561401367\n",
      "Epoch 0: iteration 834/2501 train_loss: 1.020369052886963 time_taken: 0.05716204643249512\n",
      "Epoch 0: iteration 835/2501 train_loss: 1.0201106071472168 time_taken: 0.05699872970581055\n",
      "Epoch 0: iteration 836/2501 train_loss: 1.019813895225525 time_taken: 0.056494951248168945\n",
      "Epoch 0: iteration 837/2501 train_loss: 1.0194870233535767 time_taken: 0.05765080451965332\n",
      "Epoch 0: iteration 838/2501 train_loss: 1.0192008018493652 time_taken: 0.05669689178466797\n",
      "Epoch 0: iteration 839/2501 train_loss: 1.0189284086227417 time_taken: 0.056932687759399414\n",
      "Epoch 0: iteration 840/2501 train_loss: 1.0186121463775635 time_taken: 0.05664205551147461\n",
      "Epoch 0: iteration 841/2501 train_loss: 1.018301248550415 time_taken: 0.05688309669494629\n",
      "Epoch 0: iteration 842/2501 train_loss: 1.0179742574691772 time_taken: 0.05742669105529785\n",
      "Epoch 0: iteration 843/2501 train_loss: 1.0176481008529663 time_taken: 0.05722308158874512\n",
      "Epoch 0: iteration 844/2501 train_loss: 1.0173463821411133 time_taken: 0.0564723014831543\n",
      "Epoch 0: iteration 845/2501 train_loss: 1.017016887664795 time_taken: 0.056031227111816406\n",
      "Epoch 0: iteration 846/2501 train_loss: 1.0167127847671509 time_taken: 0.05634427070617676\n",
      "Epoch 0: iteration 847/2501 train_loss: 1.0163711309432983 time_taken: 0.05595135688781738\n",
      "Epoch 0: iteration 848/2501 train_loss: 1.016061544418335 time_taken: 0.05679154396057129\n",
      "Epoch 0: iteration 849/2501 train_loss: 1.0157326459884644 time_taken: 0.05669212341308594\n",
      "Epoch 0: iteration 850/2501 train_loss: 1.015406847000122 time_taken: 0.056732892990112305\n",
      "Epoch 0: iteration 851/2501 train_loss: 1.0150997638702393 time_taken: 0.05649614334106445\n",
      "Epoch 0: iteration 852/2501 train_loss: 1.0148026943206787 time_taken: 0.056221723556518555\n",
      "Epoch 0: iteration 853/2501 train_loss: 1.0144795179367065 time_taken: 0.0568082332611084\n",
      "Epoch 0: iteration 854/2501 train_loss: 1.0141693353652954 time_taken: 0.056038856506347656\n",
      "Epoch 0: iteration 855/2501 train_loss: 1.0138722658157349 time_taken: 0.061356544494628906\n",
      "Epoch 0: iteration 856/2501 train_loss: 1.0135794878005981 time_taken: 0.05645346641540527\n",
      "Epoch 0: iteration 857/2501 train_loss: 1.013279676437378 time_taken: 0.05599164962768555\n",
      "Epoch 0: iteration 858/2501 train_loss: 1.0129754543304443 time_taken: 0.0563352108001709\n",
      "Epoch 0: iteration 859/2501 train_loss: 1.012675404548645 time_taken: 0.05602765083312988\n",
      "Epoch 0: iteration 860/2501 train_loss: 1.012437105178833 time_taken: 0.05626487731933594\n",
      "Epoch 0: iteration 861/2501 train_loss: 1.0122140645980835 time_taken: 0.056791067123413086\n",
      "Epoch 0: iteration 862/2501 train_loss: 1.011989712715149 time_taken: 0.05820417404174805\n",
      "Epoch 0: iteration 863/2501 train_loss: 1.0117383003234863 time_taken: 0.05739307403564453\n",
      "Epoch 0: iteration 864/2501 train_loss: 1.0114854574203491 time_taken: 0.05782461166381836\n",
      "Epoch 0: iteration 865/2501 train_loss: 1.0112138986587524 time_taken: 0.05663776397705078\n",
      "Epoch 0: iteration 866/2501 train_loss: 1.0110044479370117 time_taken: 0.057099103927612305\n",
      "Epoch 0: iteration 867/2501 train_loss: 1.010769248008728 time_taken: 0.05657601356506348\n",
      "Epoch 0: iteration 868/2501 train_loss: 1.0105565786361694 time_taken: 0.05754590034484863\n",
      "Epoch 0: iteration 869/2501 train_loss: 1.0103375911712646 time_taken: 0.05697894096374512\n",
      "Epoch 0: iteration 870/2501 train_loss: 1.010117530822754 time_taken: 0.06529760360717773\n",
      "Epoch 0: iteration 871/2501 train_loss: 1.009954810142517 time_taken: 0.058197975158691406\n",
      "Epoch 0: iteration 872/2501 train_loss: 1.0097695589065552 time_taken: 0.057033538818359375\n",
      "Epoch 0: iteration 873/2501 train_loss: 1.009583830833435 time_taken: 0.05615711212158203\n",
      "Epoch 0: iteration 874/2501 train_loss: 1.0094064474105835 time_taken: 0.05585837364196777\n",
      "Epoch 0: iteration 875/2501 train_loss: 1.0092310905456543 time_taken: 0.05652046203613281\n",
      "Epoch 0: iteration 876/2501 train_loss: 1.0090292692184448 time_taken: 0.05673527717590332\n",
      "Epoch 0: iteration 877/2501 train_loss: 1.0088462829589844 time_taken: 0.05745673179626465\n",
      "Epoch 0: iteration 878/2501 train_loss: 1.0087260007858276 time_taken: 0.05698561668395996\n",
      "Epoch 0: iteration 879/2501 train_loss: 1.0085328817367554 time_taken: 0.056794166564941406\n",
      "Epoch 0: iteration 880/2501 train_loss: 1.0083222389221191 time_taken: 0.06068062782287598\n",
      "Epoch 0: iteration 881/2501 train_loss: 1.0081392526626587 time_taken: 0.05707526206970215\n",
      "Epoch 0: iteration 882/2501 train_loss: 1.0080183744430542 time_taken: 0.05660820007324219\n",
      "Epoch 0: iteration 883/2501 train_loss: 1.0079238414764404 time_taken: 0.057070255279541016\n",
      "Epoch 0: iteration 884/2501 train_loss: 1.0078668594360352 time_taken: 0.06218671798706055\n",
      "Epoch 0: iteration 885/2501 train_loss: 1.007828712463379 time_taken: 0.057451725006103516\n",
      "Epoch 0: iteration 886/2501 train_loss: 1.0078359842300415 time_taken: 0.056940317153930664\n",
      "Epoch 0: iteration 887/2501 train_loss: 1.0078579187393188 time_taken: 0.05661606788635254\n",
      "Epoch 0: iteration 888/2501 train_loss: 1.0078922510147095 time_taken: 0.05617237091064453\n",
      "Epoch 0: iteration 889/2501 train_loss: 1.0079712867736816 time_taken: 0.05670738220214844\n",
      "Epoch 0: iteration 890/2501 train_loss: 1.008046269416809 time_taken: 0.056207895278930664\n",
      "Epoch 0: iteration 891/2501 train_loss: 1.0081136226654053 time_taken: 0.056162357330322266\n",
      "Epoch 0: iteration 892/2501 train_loss: 1.008095145225525 time_taken: 0.057312965393066406\n",
      "Epoch 0: iteration 893/2501 train_loss: 1.0080724954605103 time_taken: 0.05613398551940918\n",
      "Epoch 0: iteration 894/2501 train_loss: 1.0080052614212036 time_taken: 0.05665779113769531\n",
      "Epoch 0: iteration 895/2501 train_loss: 1.007930874824524 time_taken: 0.056113243103027344\n",
      "Epoch 0: iteration 896/2501 train_loss: 1.0078213214874268 time_taken: 0.05638861656188965\n",
      "Epoch 0: iteration 897/2501 train_loss: 1.0077013969421387 time_taken: 0.056626319885253906\n",
      "Epoch 0: iteration 898/2501 train_loss: 1.007559061050415 time_taken: 0.056314945220947266\n",
      "Epoch 0: iteration 899/2501 train_loss: 1.0073829889297485 time_taken: 0.05767703056335449\n",
      "Epoch 0: iteration 900/2501 train_loss: 1.007206916809082 time_taken: 0.05611777305603027\n",
      "Epoch 0: iteration 901/2501 train_loss: 1.007049798965454 time_taken: 0.05614161491394043\n",
      "Epoch 0: iteration 902/2501 train_loss: 1.006892204284668 time_taken: 0.056944847106933594\n",
      "Epoch 0: iteration 903/2501 train_loss: 1.0066921710968018 time_taken: 0.056504011154174805\n",
      "Epoch 0: iteration 904/2501 train_loss: 1.0064857006072998 time_taken: 0.05641341209411621\n",
      "Epoch 0: iteration 905/2501 train_loss: 1.0062675476074219 time_taken: 0.06710195541381836\n",
      "Epoch 0: iteration 906/2501 train_loss: 1.006029725074768 time_taken: 0.05678200721740723\n",
      "Epoch 0: iteration 907/2501 train_loss: 1.0057839155197144 time_taken: 0.07815790176391602\n",
      "Epoch 0: iteration 908/2501 train_loss: 1.005582571029663 time_taken: 0.05656123161315918\n",
      "Epoch 0: iteration 909/2501 train_loss: 1.0053536891937256 time_taken: 0.05762481689453125\n",
      "Epoch 0: iteration 910/2501 train_loss: 1.005151629447937 time_taken: 0.05628466606140137\n",
      "Epoch 0: iteration 911/2501 train_loss: 1.004968285560608 time_taken: 0.057770729064941406\n",
      "Epoch 0: iteration 912/2501 train_loss: 1.0047744512557983 time_taken: 0.05661344528198242\n",
      "Epoch 0: iteration 913/2501 train_loss: 1.0046592950820923 time_taken: 0.06151175498962402\n",
      "Epoch 0: iteration 914/2501 train_loss: 1.004544734954834 time_taken: 0.056963205337524414\n",
      "Epoch 0: iteration 915/2501 train_loss: 1.0043964385986328 time_taken: 0.05678153038024902\n",
      "Epoch 0: iteration 916/2501 train_loss: 1.0042879581451416 time_taken: 0.05684971809387207\n",
      "Epoch 0: iteration 917/2501 train_loss: 1.004172682762146 time_taken: 0.05702567100524902\n",
      "Epoch 0: iteration 918/2501 train_loss: 1.0040619373321533 time_taken: 0.05638480186462402\n",
      "Epoch 0: iteration 919/2501 train_loss: 1.0039279460906982 time_taken: 0.05607748031616211\n",
      "Epoch 0: iteration 920/2501 train_loss: 1.0037798881530762 time_taken: 0.05651235580444336\n",
      "Epoch 0: iteration 921/2501 train_loss: 1.0036020278930664 time_taken: 0.05628156661987305\n",
      "Epoch 0: iteration 922/2501 train_loss: 1.0034171342849731 time_taken: 0.0566861629486084\n",
      "Epoch 0: iteration 923/2501 train_loss: 1.003219723701477 time_taken: 0.05659675598144531\n",
      "Epoch 0: iteration 924/2501 train_loss: 1.002983570098877 time_taken: 0.056624650955200195\n",
      "Epoch 0: iteration 925/2501 train_loss: 1.002746343612671 time_taken: 0.05716657638549805\n",
      "Epoch 0: iteration 926/2501 train_loss: 1.002492904663086 time_taken: 0.057985782623291016\n",
      "Epoch 0: iteration 927/2501 train_loss: 1.0022480487823486 time_taken: 0.05678868293762207\n",
      "Epoch 0: iteration 928/2501 train_loss: 1.0019869804382324 time_taken: 0.057184696197509766\n",
      "Epoch 0: iteration 929/2501 train_loss: 1.0017147064208984 time_taken: 0.05648350715637207\n",
      "Epoch 0: iteration 930/2501 train_loss: 1.0014275312423706 time_taken: 0.05676770210266113\n",
      "Epoch 0: iteration 931/2501 train_loss: 1.001137375831604 time_taken: 0.05754423141479492\n",
      "Epoch 0: iteration 932/2501 train_loss: 1.000856637954712 time_taken: 0.056981801986694336\n",
      "Epoch 0: iteration 933/2501 train_loss: 1.0005509853363037 time_taken: 0.06566524505615234\n",
      "Epoch 0: iteration 934/2501 train_loss: 1.0002601146697998 time_taken: 0.05640888214111328\n",
      "Epoch 0: iteration 935/2501 train_loss: 0.999963641166687 time_taken: 0.05661773681640625\n",
      "Epoch 0: iteration 936/2501 train_loss: 0.9996472001075745 time_taken: 0.057193756103515625\n",
      "Epoch 0: iteration 937/2501 train_loss: 0.9993475675582886 time_taken: 0.056498050689697266\n",
      "Epoch 0: iteration 938/2501 train_loss: 0.9990837574005127 time_taken: 0.056986093521118164\n",
      "Epoch 0: iteration 939/2501 train_loss: 0.9988165497779846 time_taken: 0.05647015571594238\n",
      "Epoch 0: iteration 940/2501 train_loss: 0.9985297322273254 time_taken: 0.05644702911376953\n",
      "Epoch 0: iteration 941/2501 train_loss: 0.9982527494430542 time_taken: 0.07150983810424805\n",
      "Epoch 0: iteration 942/2501 train_loss: 0.99795001745224 time_taken: 0.056906700134277344\n",
      "Epoch 0: iteration 943/2501 train_loss: 0.9976502656936646 time_taken: 0.0566403865814209\n",
      "Epoch 0: iteration 944/2501 train_loss: 0.9973350167274475 time_taken: 0.0566716194152832\n",
      "Epoch 0: iteration 945/2501 train_loss: 0.9970493316650391 time_taken: 0.05680251121520996\n",
      "Epoch 0: iteration 946/2501 train_loss: 0.9967657327651978 time_taken: 0.05663871765136719\n",
      "Epoch 0: iteration 947/2501 train_loss: 0.9965306520462036 time_taken: 0.056847572326660156\n",
      "Epoch 0: iteration 948/2501 train_loss: 0.9962871074676514 time_taken: 0.05678200721740723\n",
      "Epoch 0: iteration 949/2501 train_loss: 0.9960293769836426 time_taken: 0.05782675743103027\n",
      "Epoch 0: iteration 950/2501 train_loss: 0.9957685470581055 time_taken: 0.05702471733093262\n",
      "Epoch 0: iteration 951/2501 train_loss: 0.9955215454101562 time_taken: 0.05647706985473633\n",
      "Epoch 0: iteration 952/2501 train_loss: 0.9953017234802246 time_taken: 0.05728507041931152\n",
      "Epoch 0: iteration 953/2501 train_loss: 0.9950684309005737 time_taken: 0.05689120292663574\n",
      "Epoch 0: iteration 954/2501 train_loss: 0.9948585033416748 time_taken: 0.056945085525512695\n",
      "Epoch 0: iteration 955/2501 train_loss: 0.9946621060371399 time_taken: 0.056661128997802734\n",
      "Epoch 0: iteration 956/2501 train_loss: 0.9944660663604736 time_taken: 0.056455135345458984\n",
      "Epoch 0: iteration 957/2501 train_loss: 0.9942507743835449 time_taken: 0.05819249153137207\n",
      "Epoch 0: iteration 958/2501 train_loss: 0.9940022826194763 time_taken: 0.05720829963684082\n",
      "Epoch 0: iteration 959/2501 train_loss: 0.9937454462051392 time_taken: 0.05688667297363281\n",
      "Epoch 0: iteration 960/2501 train_loss: 0.9935066103935242 time_taken: 0.05677056312561035\n",
      "Epoch 0: iteration 961/2501 train_loss: 0.9932852387428284 time_taken: 0.05739259719848633\n",
      "Epoch 0: iteration 962/2501 train_loss: 0.9930588006973267 time_taken: 0.057276010513305664\n",
      "Epoch 0: iteration 963/2501 train_loss: 0.9928579926490784 time_taken: 0.05713653564453125\n",
      "Epoch 0: iteration 964/2501 train_loss: 0.9926466345787048 time_taken: 0.056984663009643555\n",
      "Epoch 0: iteration 965/2501 train_loss: 0.9924776554107666 time_taken: 0.05800747871398926\n",
      "Epoch 0: iteration 966/2501 train_loss: 0.9922859072685242 time_taken: 0.05739307403564453\n",
      "Epoch 0: iteration 967/2501 train_loss: 0.992072343826294 time_taken: 0.05754542350769043\n",
      "Epoch 0: iteration 968/2501 train_loss: 0.9918769598007202 time_taken: 0.057625770568847656\n",
      "Epoch 0: iteration 969/2501 train_loss: 0.9917265176773071 time_taken: 0.05716538429260254\n",
      "Epoch 0: iteration 970/2501 train_loss: 0.991601288318634 time_taken: 0.05709648132324219\n",
      "Epoch 0: iteration 971/2501 train_loss: 0.991482138633728 time_taken: 0.057144880294799805\n",
      "Epoch 0: iteration 972/2501 train_loss: 0.991374135017395 time_taken: 0.057442665100097656\n",
      "Epoch 0: iteration 973/2501 train_loss: 0.9913120865821838 time_taken: 0.05739712715148926\n",
      "Epoch 0: iteration 974/2501 train_loss: 0.9912903904914856 time_taken: 0.05673646926879883\n",
      "Epoch 0: iteration 975/2501 train_loss: 0.9912545084953308 time_taken: 0.05717921257019043\n",
      "Epoch 0: iteration 976/2501 train_loss: 0.9912233948707581 time_taken: 0.0568087100982666\n",
      "Epoch 0: iteration 977/2501 train_loss: 0.9911972284317017 time_taken: 0.05731773376464844\n",
      "Epoch 0: iteration 978/2501 train_loss: 0.9912126064300537 time_taken: 0.056723833084106445\n",
      "Epoch 0: iteration 979/2501 train_loss: 0.9912311434745789 time_taken: 0.05694174766540527\n",
      "Epoch 0: iteration 980/2501 train_loss: 0.9912531971931458 time_taken: 0.05704355239868164\n",
      "Epoch 0: iteration 981/2501 train_loss: 0.9912595152854919 time_taken: 0.05733466148376465\n",
      "Epoch 0: iteration 982/2501 train_loss: 0.9913132786750793 time_taken: 0.05717778205871582\n",
      "Epoch 0: iteration 983/2501 train_loss: 0.99139404296875 time_taken: 0.057761430740356445\n",
      "Epoch 0: iteration 984/2501 train_loss: 0.9914692044258118 time_taken: 0.057085514068603516\n",
      "Epoch 0: iteration 985/2501 train_loss: 0.9915657043457031 time_taken: 0.057703495025634766\n",
      "Epoch 0: iteration 986/2501 train_loss: 0.9916658997535706 time_taken: 0.05719304084777832\n",
      "Epoch 0: iteration 987/2501 train_loss: 0.9917120933532715 time_taken: 0.05679893493652344\n",
      "Epoch 0: iteration 988/2501 train_loss: 0.9917418956756592 time_taken: 0.056317806243896484\n",
      "Epoch 0: iteration 989/2501 train_loss: 0.9917340874671936 time_taken: 0.057334184646606445\n",
      "Epoch 0: iteration 990/2501 train_loss: 0.9917207956314087 time_taken: 0.0577850341796875\n",
      "Epoch 0: iteration 991/2501 train_loss: 0.9916918277740479 time_taken: 0.05658102035522461\n",
      "Epoch 0: iteration 992/2501 train_loss: 0.9916743636131287 time_taken: 0.05751466751098633\n",
      "Epoch 0: iteration 993/2501 train_loss: 0.9916397929191589 time_taken: 0.05713987350463867\n",
      "Epoch 0: iteration 994/2501 train_loss: 0.9915762543678284 time_taken: 0.05681204795837402\n",
      "Epoch 0: iteration 995/2501 train_loss: 0.9915544390678406 time_taken: 0.05631279945373535\n",
      "Epoch 0: iteration 996/2501 train_loss: 0.9915173053741455 time_taken: 0.0574803352355957\n",
      "Epoch 0: iteration 997/2501 train_loss: 0.9914441704750061 time_taken: 0.05700945854187012\n",
      "Epoch 0: iteration 998/2501 train_loss: 0.9913749098777771 time_taken: 0.06174015998840332\n",
      "Epoch 0: iteration 999/2501 train_loss: 0.9912683367729187 time_taken: 0.05763888359069824\n",
      "Epoch 0: iteration 1000/2501 train_loss: 0.9911360144615173 time_taken: 0.05719161033630371\n",
      "Epoch 0: iteration 1001/2501 train_loss: 0.9909976720809937 time_taken: 0.05663800239562988\n",
      "Epoch 0: iteration 1002/2501 train_loss: 0.9908435940742493 time_taken: 0.05706191062927246\n",
      "Epoch 0: iteration 1003/2501 train_loss: 0.9907050132751465 time_taken: 0.05672192573547363\n",
      "Epoch 0: iteration 1004/2501 train_loss: 0.9905553460121155 time_taken: 0.057016611099243164\n",
      "Epoch 0: iteration 1005/2501 train_loss: 0.9903868436813354 time_taken: 0.05736041069030762\n",
      "Epoch 0: iteration 1006/2501 train_loss: 0.9902858138084412 time_taken: 0.056447505950927734\n",
      "Epoch 0: iteration 1007/2501 train_loss: 0.990295946598053 time_taken: 0.05684924125671387\n",
      "Epoch 0: iteration 1008/2501 train_loss: 0.9903208613395691 time_taken: 0.056758880615234375\n",
      "Epoch 0: iteration 1009/2501 train_loss: 0.9901933670043945 time_taken: 0.05655932426452637\n",
      "Epoch 0: iteration 1010/2501 train_loss: 0.9900606870651245 time_taken: 0.07182908058166504\n",
      "Epoch 0: iteration 1011/2501 train_loss: 0.9899280071258545 time_taken: 0.056563377380371094\n",
      "Epoch 0: iteration 1012/2501 train_loss: 0.9897412061691284 time_taken: 0.05641317367553711\n",
      "Epoch 0: iteration 1013/2501 train_loss: 0.9895867109298706 time_taken: 0.05684995651245117\n",
      "Epoch 0: iteration 1014/2501 train_loss: 0.9893729090690613 time_taken: 0.056954145431518555\n",
      "Epoch 0: iteration 1015/2501 train_loss: 0.9891696572303772 time_taken: 0.056546688079833984\n",
      "Epoch 0: iteration 1016/2501 train_loss: 0.9890152812004089 time_taken: 0.056403160095214844\n",
      "Epoch 0: iteration 1017/2501 train_loss: 0.9888423681259155 time_taken: 0.0569300651550293\n",
      "Epoch 0: iteration 1018/2501 train_loss: 0.9886705875396729 time_taken: 0.056539058685302734\n",
      "Epoch 0: iteration 1019/2501 train_loss: 0.9885470271110535 time_taken: 0.05632185935974121\n",
      "Epoch 0: iteration 1020/2501 train_loss: 0.9883534908294678 time_taken: 0.05680537223815918\n",
      "Epoch 0: iteration 1021/2501 train_loss: 0.9881994128227234 time_taken: 0.057369232177734375\n",
      "Epoch 0: iteration 1022/2501 train_loss: 0.9880803823471069 time_taken: 0.05671429634094238\n",
      "Epoch 0: iteration 1023/2501 train_loss: 0.987937867641449 time_taken: 0.0569915771484375\n",
      "Epoch 0: iteration 1024/2501 train_loss: 0.9878162741661072 time_taken: 0.0564579963684082\n",
      "Epoch 0: iteration 1025/2501 train_loss: 0.9876814484596252 time_taken: 0.056163787841796875\n",
      "Epoch 0: iteration 1026/2501 train_loss: 0.9875337481498718 time_taken: 0.056676387786865234\n",
      "Epoch 0: iteration 1027/2501 train_loss: 0.9873890280723572 time_taken: 0.05667829513549805\n",
      "Epoch 0: iteration 1028/2501 train_loss: 0.9872376322746277 time_taken: 0.05622673034667969\n",
      "Epoch 0: iteration 1029/2501 train_loss: 0.987087607383728 time_taken: 0.05839109420776367\n",
      "Epoch 0: iteration 1030/2501 train_loss: 0.9869219064712524 time_taken: 0.056575775146484375\n",
      "Epoch 0: iteration 1031/2501 train_loss: 0.9867600798606873 time_taken: 0.05662417411804199\n",
      "Epoch 0: iteration 1032/2501 train_loss: 0.9866035580635071 time_taken: 0.05694127082824707\n",
      "Epoch 0: iteration 1033/2501 train_loss: 0.9864490628242493 time_taken: 0.0568394660949707\n",
      "Epoch 0: iteration 1034/2501 train_loss: 0.9862805604934692 time_taken: 0.05754232406616211\n",
      "Epoch 0: iteration 1035/2501 train_loss: 0.986133873462677 time_taken: 0.05714893341064453\n",
      "Epoch 0: iteration 1036/2501 train_loss: 0.9859822392463684 time_taken: 0.05642199516296387\n",
      "Epoch 0: iteration 1037/2501 train_loss: 0.9858093857765198 time_taken: 0.05679941177368164\n",
      "Epoch 0: iteration 1038/2501 train_loss: 0.9856457710266113 time_taken: 0.05740213394165039\n",
      "Epoch 0: iteration 1039/2501 train_loss: 0.9854824542999268 time_taken: 0.057006120681762695\n",
      "Epoch 0: iteration 1040/2501 train_loss: 0.9852921366691589 time_taken: 0.056395530700683594\n",
      "Epoch 0: iteration 1041/2501 train_loss: 0.9851447939872742 time_taken: 0.05661821365356445\n",
      "Epoch 0: iteration 1042/2501 train_loss: 0.9849798679351807 time_taken: 0.056351661682128906\n",
      "Epoch 0: iteration 1043/2501 train_loss: 0.9848100543022156 time_taken: 0.05656552314758301\n",
      "Epoch 0: iteration 1044/2501 train_loss: 0.9846533536911011 time_taken: 0.05677962303161621\n",
      "Epoch 0: iteration 1045/2501 train_loss: 0.9844653010368347 time_taken: 0.056478261947631836\n",
      "Epoch 0: iteration 1046/2501 train_loss: 0.9842982888221741 time_taken: 0.05656552314758301\n",
      "Epoch 0: iteration 1047/2501 train_loss: 0.9841446280479431 time_taken: 0.05701899528503418\n",
      "Epoch 0: iteration 1048/2501 train_loss: 0.9839706420898438 time_taken: 0.05717110633850098\n",
      "Epoch 0: iteration 1049/2501 train_loss: 0.983811616897583 time_taken: 0.0569005012512207\n",
      "Epoch 0: iteration 1050/2501 train_loss: 0.9836341142654419 time_taken: 0.05655837059020996\n",
      "Epoch 0: iteration 1051/2501 train_loss: 0.9834434390068054 time_taken: 0.05660724639892578\n",
      "Epoch 0: iteration 1052/2501 train_loss: 0.983259916305542 time_taken: 0.05736088752746582\n",
      "Epoch 0: iteration 1053/2501 train_loss: 0.9831025004386902 time_taken: 0.05685114860534668\n",
      "Epoch 0: iteration 1054/2501 train_loss: 0.9829246401786804 time_taken: 0.05697202682495117\n",
      "Epoch 0: iteration 1055/2501 train_loss: 0.9827863574028015 time_taken: 0.056588172912597656\n",
      "Epoch 0: iteration 1056/2501 train_loss: 0.9826617240905762 time_taken: 0.05649709701538086\n",
      "Epoch 0: iteration 1057/2501 train_loss: 0.9825215339660645 time_taken: 0.05691838264465332\n",
      "Epoch 0: iteration 1058/2501 train_loss: 0.9823448657989502 time_taken: 0.056975603103637695\n",
      "Epoch 0: iteration 1059/2501 train_loss: 0.9821921586990356 time_taken: 0.05665135383605957\n",
      "Epoch 0: iteration 1060/2501 train_loss: 0.9820051789283752 time_taken: 0.057270050048828125\n",
      "Epoch 0: iteration 1061/2501 train_loss: 0.9818528890609741 time_taken: 0.057016611099243164\n",
      "Epoch 0: iteration 1062/2501 train_loss: 0.9816799163818359 time_taken: 0.05636858940124512\n",
      "Epoch 0: iteration 1063/2501 train_loss: 0.981509804725647 time_taken: 0.057096242904663086\n",
      "Epoch 0: iteration 1064/2501 train_loss: 0.9813473224639893 time_taken: 0.05699920654296875\n",
      "Epoch 0: iteration 1065/2501 train_loss: 0.9811902642250061 time_taken: 0.05731368064880371\n",
      "Epoch 0: iteration 1066/2501 train_loss: 0.9810411334037781 time_taken: 0.05658221244812012\n",
      "Epoch 0: iteration 1067/2501 train_loss: 0.9808790683746338 time_taken: 0.056577205657958984\n",
      "Epoch 0: iteration 1068/2501 train_loss: 0.980731189250946 time_taken: 0.05681943893432617\n",
      "Epoch 0: iteration 1069/2501 train_loss: 0.9805833101272583 time_taken: 0.05637073516845703\n",
      "Epoch 0: iteration 1070/2501 train_loss: 0.9804703593254089 time_taken: 0.056793212890625\n",
      "Epoch 0: iteration 1071/2501 train_loss: 0.9803390502929688 time_taken: 0.05656862258911133\n",
      "Epoch 0: iteration 1072/2501 train_loss: 0.9801881909370422 time_taken: 0.05705761909484863\n",
      "Epoch 0: iteration 1073/2501 train_loss: 0.9800657033920288 time_taken: 0.05644083023071289\n",
      "Epoch 0: iteration 1074/2501 train_loss: 0.9799367785453796 time_taken: 0.05700826644897461\n",
      "Epoch 0: iteration 1075/2501 train_loss: 0.9797891974449158 time_taken: 0.057134389877319336\n",
      "Epoch 0: iteration 1076/2501 train_loss: 0.9796741008758545 time_taken: 0.056915998458862305\n",
      "Epoch 0: iteration 1077/2501 train_loss: 0.9795364737510681 time_taken: 0.05681324005126953\n",
      "Epoch 0: iteration 1078/2501 train_loss: 0.9793984889984131 time_taken: 0.05622291564941406\n",
      "Epoch 0: iteration 1079/2501 train_loss: 0.9792577624320984 time_taken: 0.05634450912475586\n",
      "Epoch 0: iteration 1080/2501 train_loss: 0.9791489243507385 time_taken: 0.05621194839477539\n",
      "Epoch 0: iteration 1081/2501 train_loss: 0.9790137410163879 time_taken: 0.05647706985473633\n",
      "Epoch 0: iteration 1082/2501 train_loss: 0.9789000749588013 time_taken: 0.05695605278015137\n",
      "Epoch 0: iteration 1083/2501 train_loss: 0.9787936806678772 time_taken: 0.05711936950683594\n",
      "Epoch 0: iteration 1084/2501 train_loss: 0.978689432144165 time_taken: 0.05627608299255371\n",
      "Epoch 0: iteration 1085/2501 train_loss: 0.9785833954811096 time_taken: 0.05663800239562988\n",
      "Epoch 0: iteration 1086/2501 train_loss: 0.9784673452377319 time_taken: 0.056349992752075195\n",
      "Epoch 0: iteration 1087/2501 train_loss: 0.978365957736969 time_taken: 0.05659747123718262\n",
      "Epoch 0: iteration 1088/2501 train_loss: 0.9782442450523376 time_taken: 0.05679059028625488\n",
      "Epoch 0: iteration 1089/2501 train_loss: 0.9780752658843994 time_taken: 0.05622553825378418\n",
      "Epoch 0: iteration 1090/2501 train_loss: 0.9779430627822876 time_taken: 0.05678248405456543\n",
      "Epoch 0: iteration 1091/2501 train_loss: 0.9777926206588745 time_taken: 0.05707550048828125\n",
      "Epoch 0: iteration 1092/2501 train_loss: 0.9776622653007507 time_taken: 0.05702614784240723\n",
      "Epoch 0: iteration 1093/2501 train_loss: 0.977482259273529 time_taken: 0.056288719177246094\n",
      "Epoch 0: iteration 1094/2501 train_loss: 0.9773202538490295 time_taken: 0.05676007270812988\n",
      "Epoch 0: iteration 1095/2501 train_loss: 0.9771496653556824 time_taken: 0.07146549224853516\n",
      "Epoch 0: iteration 1096/2501 train_loss: 0.9770035743713379 time_taken: 0.05694913864135742\n",
      "Epoch 0: iteration 1097/2501 train_loss: 0.9768692255020142 time_taken: 0.05668759346008301\n",
      "Epoch 0: iteration 1098/2501 train_loss: 0.976748526096344 time_taken: 0.06502771377563477\n",
      "Epoch 0: iteration 1099/2501 train_loss: 0.9766157865524292 time_taken: 0.05574989318847656\n",
      "Epoch 0: iteration 1100/2501 train_loss: 0.9765037298202515 time_taken: 0.05613541603088379\n",
      "Epoch 0: iteration 1101/2501 train_loss: 0.9763850569725037 time_taken: 0.0562746524810791\n",
      "Epoch 0: iteration 1102/2501 train_loss: 0.9762497544288635 time_taken: 0.056915283203125\n",
      "Epoch 0: iteration 1103/2501 train_loss: 0.9760997891426086 time_taken: 0.05655956268310547\n",
      "Epoch 0: iteration 1104/2501 train_loss: 0.9759135842323303 time_taken: 0.05644106864929199\n",
      "Epoch 0: iteration 1105/2501 train_loss: 0.9757251143455505 time_taken: 0.05682015419006348\n",
      "Epoch 0: iteration 1106/2501 train_loss: 0.9755462408065796 time_taken: 0.05736255645751953\n",
      "Epoch 0: iteration 1107/2501 train_loss: 0.9753813743591309 time_taken: 0.056690216064453125\n",
      "Epoch 0: iteration 1108/2501 train_loss: 0.9752129316329956 time_taken: 0.05621743202209473\n",
      "Epoch 0: iteration 1109/2501 train_loss: 0.9750546813011169 time_taken: 0.05658721923828125\n",
      "Epoch 0: iteration 1110/2501 train_loss: 0.974947452545166 time_taken: 0.05636477470397949\n",
      "Epoch 0: iteration 1111/2501 train_loss: 0.9748541712760925 time_taken: 0.05665445327758789\n",
      "Epoch 0: iteration 1112/2501 train_loss: 0.974747359752655 time_taken: 0.057135820388793945\n",
      "Epoch 0: iteration 1113/2501 train_loss: 0.9746567010879517 time_taken: 0.056110382080078125\n",
      "Epoch 0: iteration 1114/2501 train_loss: 0.9745766520500183 time_taken: 0.05677008628845215\n",
      "Epoch 0: iteration 1115/2501 train_loss: 0.9744866490364075 time_taken: 0.05620312690734863\n",
      "Epoch 0: iteration 1116/2501 train_loss: 0.9743989109992981 time_taken: 0.05673360824584961\n",
      "Epoch 0: iteration 1117/2501 train_loss: 0.9743281006813049 time_taken: 0.055975914001464844\n",
      "Epoch 0: iteration 1118/2501 train_loss: 0.9742656350135803 time_taken: 0.05672597885131836\n",
      "Epoch 0: iteration 1119/2501 train_loss: 0.974215030670166 time_taken: 0.056943416595458984\n",
      "Epoch 0: iteration 1120/2501 train_loss: 0.9741562604904175 time_taken: 0.05662250518798828\n",
      "Epoch 0: iteration 1121/2501 train_loss: 0.9741119742393494 time_taken: 0.05614066123962402\n",
      "Epoch 0: iteration 1122/2501 train_loss: 0.9740805625915527 time_taken: 0.057244300842285156\n",
      "Epoch 0: iteration 1123/2501 train_loss: 0.9740231037139893 time_taken: 0.05607342720031738\n",
      "Epoch 0: iteration 1124/2501 train_loss: 0.9739521741867065 time_taken: 0.05608391761779785\n",
      "Epoch 0: iteration 1125/2501 train_loss: 0.973874032497406 time_taken: 0.05582404136657715\n",
      "Epoch 0: iteration 1126/2501 train_loss: 0.9737851023674011 time_taken: 0.05651211738586426\n",
      "Epoch 0: iteration 1127/2501 train_loss: 0.9736953377723694 time_taken: 0.0563960075378418\n",
      "Epoch 0: iteration 1128/2501 train_loss: 0.973604679107666 time_taken: 0.057047128677368164\n",
      "Epoch 0: iteration 1129/2501 train_loss: 0.9735029935836792 time_taken: 0.05665469169616699\n",
      "Epoch 0: iteration 1130/2501 train_loss: 0.9734046459197998 time_taken: 0.05678725242614746\n",
      "Epoch 0: iteration 1131/2501 train_loss: 0.9733036160469055 time_taken: 0.056617021560668945\n",
      "Epoch 0: iteration 1132/2501 train_loss: 0.9731968641281128 time_taken: 0.0568087100982666\n",
      "Epoch 0: iteration 1133/2501 train_loss: 0.9730561375617981 time_taken: 0.05643773078918457\n",
      "Epoch 0: iteration 1134/2501 train_loss: 0.9729217886924744 time_taken: 0.05636429786682129\n",
      "Epoch 0: iteration 1135/2501 train_loss: 0.9728014469146729 time_taken: 0.056238651275634766\n",
      "Epoch 0: iteration 1136/2501 train_loss: 0.9727187156677246 time_taken: 0.056838035583496094\n",
      "Epoch 0: iteration 1137/2501 train_loss: 0.972629964351654 time_taken: 0.05717778205871582\n",
      "Epoch 0: iteration 1138/2501 train_loss: 0.9725329875946045 time_taken: 0.05705904960632324\n",
      "Epoch 0: iteration 1139/2501 train_loss: 0.9724467992782593 time_taken: 0.056899070739746094\n",
      "Epoch 0: iteration 1140/2501 train_loss: 0.9723632335662842 time_taken: 0.05695843696594238\n",
      "Epoch 0: iteration 1141/2501 train_loss: 0.9722760319709778 time_taken: 0.05648398399353027\n",
      "Epoch 0: iteration 1142/2501 train_loss: 0.972183108329773 time_taken: 0.05675029754638672\n",
      "Epoch 0: iteration 1143/2501 train_loss: 0.9720889925956726 time_taken: 0.05762434005737305\n",
      "Epoch 0: iteration 1144/2501 train_loss: 0.9719995260238647 time_taken: 0.05670046806335449\n",
      "Epoch 0: iteration 1145/2501 train_loss: 0.9719200730323792 time_taken: 0.05752134323120117\n",
      "Epoch 0: iteration 1146/2501 train_loss: 0.9718203544616699 time_taken: 0.05674481391906738\n",
      "Epoch 0: iteration 1147/2501 train_loss: 0.9717332720756531 time_taken: 0.05726146697998047\n",
      "Epoch 0: iteration 1148/2501 train_loss: 0.9716306328773499 time_taken: 0.0569608211517334\n",
      "Epoch 0: iteration 1149/2501 train_loss: 0.9715558290481567 time_taken: 0.05762839317321777\n",
      "Epoch 0: iteration 1150/2501 train_loss: 0.9714951515197754 time_taken: 0.0573267936706543\n",
      "Epoch 0: iteration 1151/2501 train_loss: 0.9714052677154541 time_taken: 0.05738472938537598\n",
      "Epoch 0: iteration 1152/2501 train_loss: 0.9713111519813538 time_taken: 0.05722856521606445\n",
      "Epoch 0: iteration 1153/2501 train_loss: 0.9712148904800415 time_taken: 0.05629849433898926\n",
      "Epoch 0: iteration 1154/2501 train_loss: 0.9711218476295471 time_taken: 0.0574641227722168\n",
      "Epoch 0: iteration 1155/2501 train_loss: 0.971034586429596 time_taken: 0.05705690383911133\n",
      "Epoch 0: iteration 1156/2501 train_loss: 0.9709639549255371 time_taken: 0.05740547180175781\n",
      "Epoch 0: iteration 1157/2501 train_loss: 0.9709234237670898 time_taken: 0.05698728561401367\n",
      "Epoch 0: iteration 1158/2501 train_loss: 0.9708648920059204 time_taken: 0.058087825775146484\n",
      "Epoch 0: iteration 1159/2501 train_loss: 0.9708282351493835 time_taken: 0.058526039123535156\n",
      "Epoch 0: iteration 1160/2501 train_loss: 0.9707712531089783 time_taken: 0.05734753608703613\n",
      "Epoch 0: iteration 1161/2501 train_loss: 0.9706649780273438 time_taken: 0.057488441467285156\n",
      "Epoch 0: iteration 1162/2501 train_loss: 0.9705623984336853 time_taken: 0.05737876892089844\n",
      "Epoch 0: iteration 1163/2501 train_loss: 0.9704551100730896 time_taken: 0.056668758392333984\n",
      "Epoch 0: iteration 1164/2501 train_loss: 0.9703323841094971 time_taken: 0.057097673416137695\n",
      "Epoch 0: iteration 1165/2501 train_loss: 0.9702306389808655 time_taken: 0.057134151458740234\n",
      "Epoch 0: iteration 1166/2501 train_loss: 0.9701688289642334 time_taken: 0.05657339096069336\n",
      "Epoch 0: iteration 1167/2501 train_loss: 0.9700709581375122 time_taken: 0.05665135383605957\n",
      "Epoch 0: iteration 1168/2501 train_loss: 0.9699802994728088 time_taken: 0.05762195587158203\n",
      "Epoch 0: iteration 1169/2501 train_loss: 0.9698782563209534 time_taken: 0.057090044021606445\n",
      "Epoch 0: iteration 1170/2501 train_loss: 0.9697884917259216 time_taken: 0.05713820457458496\n",
      "Epoch 0: iteration 1171/2501 train_loss: 0.9696932435035706 time_taken: 0.057061195373535156\n",
      "Epoch 0: iteration 1172/2501 train_loss: 0.9695842862129211 time_taken: 0.05656075477600098\n",
      "Epoch 0: iteration 1173/2501 train_loss: 0.9694715142250061 time_taken: 0.05804157257080078\n",
      "Epoch 0: iteration 1174/2501 train_loss: 0.9693824648857117 time_taken: 0.057100772857666016\n",
      "Epoch 0: iteration 1175/2501 train_loss: 0.9692646265029907 time_taken: 0.05647015571594238\n",
      "Epoch 0: iteration 1176/2501 train_loss: 0.9691774249076843 time_taken: 0.05753684043884277\n",
      "Epoch 0: iteration 1177/2501 train_loss: 0.9690957069396973 time_taken: 0.057497501373291016\n",
      "Epoch 0: iteration 1178/2501 train_loss: 0.9690076112747192 time_taken: 0.05679512023925781\n",
      "Epoch 0: iteration 1179/2501 train_loss: 0.9688661694526672 time_taken: 0.0566709041595459\n",
      "Epoch 0: iteration 1180/2501 train_loss: 0.9687371850013733 time_taken: 0.05731678009033203\n",
      "Epoch 0: iteration 1181/2501 train_loss: 0.9685941338539124 time_taken: 0.05654644966125488\n",
      "Epoch 0: iteration 1182/2501 train_loss: 0.9684519171714783 time_taken: 0.061409950256347656\n",
      "Epoch 0: iteration 1183/2501 train_loss: 0.9683024287223816 time_taken: 0.056291818618774414\n",
      "Epoch 0: iteration 1184/2501 train_loss: 0.9681615829467773 time_taken: 0.05617785453796387\n",
      "Epoch 0: iteration 1185/2501 train_loss: 0.9680147171020508 time_taken: 0.055846214294433594\n",
      "Epoch 0: iteration 1186/2501 train_loss: 0.9678383469581604 time_taken: 0.05639815330505371\n",
      "Epoch 0: iteration 1187/2501 train_loss: 0.9676847457885742 time_taken: 0.05614948272705078\n",
      "Epoch 0: iteration 1188/2501 train_loss: 0.967533528804779 time_taken: 0.056061744689941406\n",
      "Epoch 0: iteration 1189/2501 train_loss: 0.9674152135848999 time_taken: 0.05630993843078613\n",
      "Epoch 0: iteration 1190/2501 train_loss: 0.9672760367393494 time_taken: 0.05656552314758301\n",
      "Epoch 0: iteration 1191/2501 train_loss: 0.9671362638473511 time_taken: 0.05634498596191406\n",
      "Epoch 0: iteration 1192/2501 train_loss: 0.9669836163520813 time_taken: 0.0562899112701416\n",
      "Epoch 0: iteration 1193/2501 train_loss: 0.9668442010879517 time_taken: 0.05614066123962402\n",
      "Epoch 0: iteration 1194/2501 train_loss: 0.9667103290557861 time_taken: 0.05672287940979004\n",
      "Epoch 0: iteration 1195/2501 train_loss: 0.9665577411651611 time_taken: 0.05622434616088867\n",
      "Epoch 0: iteration 1196/2501 train_loss: 0.9664198756217957 time_taken: 0.056490421295166016\n",
      "Epoch 0: iteration 1197/2501 train_loss: 0.9662922024726868 time_taken: 0.05619454383850098\n",
      "Epoch 0: iteration 1198/2501 train_loss: 0.9661692976951599 time_taken: 0.056755781173706055\n",
      "Epoch 0: iteration 1199/2501 train_loss: 0.9660572409629822 time_taken: 0.056243181228637695\n",
      "Epoch 0: iteration 1200/2501 train_loss: 0.9659270644187927 time_taken: 0.05689263343811035\n",
      "Epoch 0: iteration 1201/2501 train_loss: 0.9658060073852539 time_taken: 0.057405710220336914\n",
      "Epoch 0: iteration 1202/2501 train_loss: 0.9656664729118347 time_taken: 0.056874990463256836\n",
      "Epoch 0: iteration 1203/2501 train_loss: 0.9655556678771973 time_taken: 0.05726790428161621\n",
      "Epoch 0: iteration 1204/2501 train_loss: 0.9654430747032166 time_taken: 0.05717587471008301\n",
      "Epoch 0: iteration 1205/2501 train_loss: 0.9653281569480896 time_taken: 0.056975603103637695\n",
      "Epoch 0: iteration 1206/2501 train_loss: 0.9652214646339417 time_taken: 0.057314157485961914\n",
      "Epoch 0: iteration 1207/2501 train_loss: 0.9651288986206055 time_taken: 0.06058001518249512\n",
      "Epoch 0: iteration 1208/2501 train_loss: 0.9650507569313049 time_taken: 0.056265830993652344\n",
      "Epoch 0: iteration 1209/2501 train_loss: 0.9649567604064941 time_taken: 0.05664968490600586\n",
      "Epoch 0: iteration 1210/2501 train_loss: 0.9648510217666626 time_taken: 0.05669546127319336\n",
      "Epoch 0: iteration 1211/2501 train_loss: 0.9647290110588074 time_taken: 0.05651402473449707\n",
      "Epoch 0: iteration 1212/2501 train_loss: 0.964592456817627 time_taken: 0.05669999122619629\n",
      "Epoch 0: iteration 1213/2501 train_loss: 0.9644688963890076 time_taken: 0.0566248893737793\n",
      "Epoch 0: iteration 1214/2501 train_loss: 0.964359700679779 time_taken: 0.056389808654785156\n",
      "Epoch 0: iteration 1215/2501 train_loss: 0.964287281036377 time_taken: 0.05634474754333496\n",
      "Epoch 0: iteration 1216/2501 train_loss: 0.9642168283462524 time_taken: 0.05726790428161621\n",
      "Epoch 0: iteration 1217/2501 train_loss: 0.9641376733779907 time_taken: 0.056839704513549805\n",
      "Epoch 0: iteration 1218/2501 train_loss: 0.9640598297119141 time_taken: 0.056976318359375\n",
      "Epoch 0: iteration 1219/2501 train_loss: 0.9639794230461121 time_taken: 0.05688667297363281\n",
      "Epoch 0: iteration 1220/2501 train_loss: 0.9638881087303162 time_taken: 0.05662870407104492\n",
      "Epoch 0: iteration 1221/2501 train_loss: 0.9638014435768127 time_taken: 0.056745290756225586\n",
      "Epoch 0: iteration 1222/2501 train_loss: 0.9636946320533752 time_taken: 0.05646514892578125\n",
      "Epoch 0: iteration 1223/2501 train_loss: 0.9635542035102844 time_taken: 0.0565946102142334\n",
      "Epoch 0: iteration 1224/2501 train_loss: 0.9634442925453186 time_taken: 0.056546926498413086\n",
      "Epoch 0: iteration 1225/2501 train_loss: 0.9633116722106934 time_taken: 0.05682516098022461\n",
      "Epoch 0: iteration 1226/2501 train_loss: 0.9631943702697754 time_taken: 0.056688547134399414\n",
      "Epoch 0: iteration 1227/2501 train_loss: 0.9630430340766907 time_taken: 0.05650162696838379\n",
      "Epoch 0: iteration 1228/2501 train_loss: 0.96293044090271 time_taken: 0.05690455436706543\n",
      "Epoch 0: iteration 1229/2501 train_loss: 0.9628387093544006 time_taken: 0.056456565856933594\n",
      "Epoch 0: iteration 1230/2501 train_loss: 0.9627282023429871 time_taken: 0.05689835548400879\n",
      "Epoch 0: iteration 1231/2501 train_loss: 0.9626212120056152 time_taken: 0.11205101013183594\n",
      "Epoch 0: iteration 1232/2501 train_loss: 0.9625085592269897 time_taken: 0.05672264099121094\n",
      "Epoch 0: iteration 1233/2501 train_loss: 0.9624195694923401 time_taken: 0.057428598403930664\n",
      "Epoch 0: iteration 1234/2501 train_loss: 0.9623199105262756 time_taken: 0.05720019340515137\n",
      "Epoch 0: iteration 1235/2501 train_loss: 0.9622268676757812 time_taken: 0.05719494819641113\n",
      "Epoch 0: iteration 1236/2501 train_loss: 0.9621275067329407 time_taken: 0.05659842491149902\n",
      "Epoch 0: iteration 1237/2501 train_loss: 0.9620289206504822 time_taken: 0.05651402473449707\n",
      "Epoch 0: iteration 1238/2501 train_loss: 0.9619395732879639 time_taken: 0.05686330795288086\n",
      "Epoch 0: iteration 1239/2501 train_loss: 0.9618521332740784 time_taken: 0.05666160583496094\n",
      "Epoch 0: iteration 1240/2501 train_loss: 0.9617686867713928 time_taken: 0.05708122253417969\n",
      "Epoch 0: iteration 1241/2501 train_loss: 0.9616661071777344 time_taken: 0.057831764221191406\n",
      "Epoch 0: iteration 1242/2501 train_loss: 0.961571216583252 time_taken: 0.05863833427429199\n",
      "Epoch 0: iteration 1243/2501 train_loss: 0.9614694714546204 time_taken: 0.05677485466003418\n",
      "Epoch 0: iteration 1244/2501 train_loss: 0.961385190486908 time_taken: 0.057085514068603516\n",
      "Epoch 0: iteration 1245/2501 train_loss: 0.9612788558006287 time_taken: 0.05655407905578613\n",
      "Epoch 0: iteration 1246/2501 train_loss: 0.9611846804618835 time_taken: 0.05617189407348633\n",
      "Epoch 0: iteration 1247/2501 train_loss: 0.9610781669616699 time_taken: 0.05792689323425293\n",
      "Epoch 0: iteration 1248/2501 train_loss: 0.960978627204895 time_taken: 0.056302547454833984\n",
      "Epoch 0: iteration 1249/2501 train_loss: 0.9609038829803467 time_taken: 0.05659198760986328\n",
      "Epoch 0: iteration 1250/2501 train_loss: 0.9608204960823059 time_taken: 0.05780196189880371\n",
      "Epoch 0: iteration 1251/2501 train_loss: 0.960735559463501 time_taken: 0.05697917938232422\n",
      "Epoch 0: iteration 1252/2501 train_loss: 0.9606439471244812 time_taken: 0.05671072006225586\n",
      "Epoch 0: iteration 1253/2501 train_loss: 0.96056067943573 time_taken: 0.05680727958679199\n",
      "Epoch 0: iteration 1254/2501 train_loss: 0.9604549407958984 time_taken: 0.05654788017272949\n",
      "Epoch 0: iteration 1255/2501 train_loss: 0.9603469967842102 time_taken: 0.05671048164367676\n",
      "Epoch 0: iteration 1256/2501 train_loss: 0.9602077007293701 time_taken: 0.05639386177062988\n",
      "Epoch 0: iteration 1257/2501 train_loss: 0.9600494503974915 time_taken: 0.056723594665527344\n",
      "Epoch 0: iteration 1258/2501 train_loss: 0.959892988204956 time_taken: 0.056478023529052734\n",
      "Epoch 0: iteration 1259/2501 train_loss: 0.9597358107566833 time_taken: 0.056366682052612305\n",
      "Epoch 0: iteration 1260/2501 train_loss: 0.959547221660614 time_taken: 0.056034088134765625\n",
      "Epoch 0: iteration 1261/2501 train_loss: 0.9593774080276489 time_taken: 0.09172320365905762\n",
      "Epoch 0: iteration 1262/2501 train_loss: 0.9591953754425049 time_taken: 0.05589747428894043\n",
      "Epoch 0: iteration 1263/2501 train_loss: 0.9590336084365845 time_taken: 0.06752991676330566\n",
      "Epoch 0: iteration 1264/2501 train_loss: 0.9588369131088257 time_taken: 0.0569918155670166\n",
      "Epoch 0: iteration 1265/2501 train_loss: 0.9586607813835144 time_taken: 0.05739641189575195\n",
      "Epoch 0: iteration 1266/2501 train_loss: 0.9584859609603882 time_taken: 0.05737948417663574\n",
      "Epoch 0: iteration 1267/2501 train_loss: 0.9582704305648804 time_taken: 0.05628371238708496\n",
      "Epoch 0: iteration 1268/2501 train_loss: 0.958060622215271 time_taken: 0.057041168212890625\n",
      "Epoch 0: iteration 1269/2501 train_loss: 0.9578595757484436 time_taken: 0.05642867088317871\n",
      "Epoch 0: iteration 1270/2501 train_loss: 0.9576494693756104 time_taken: 0.0569310188293457\n",
      "Epoch 0: iteration 1271/2501 train_loss: 0.9574844241142273 time_taken: 0.056550025939941406\n",
      "Epoch 0: iteration 1272/2501 train_loss: 0.9572990536689758 time_taken: 0.05638432502746582\n",
      "Epoch 0: iteration 1273/2501 train_loss: 0.9571117162704468 time_taken: 0.056792497634887695\n",
      "Epoch 0: iteration 1274/2501 train_loss: 0.9569330215454102 time_taken: 0.056607961654663086\n",
      "Epoch 0: iteration 1275/2501 train_loss: 0.9568018317222595 time_taken: 0.057074785232543945\n",
      "Epoch 0: iteration 1276/2501 train_loss: 0.9566615223884583 time_taken: 0.05605053901672363\n",
      "Epoch 0: iteration 1277/2501 train_loss: 0.9565298557281494 time_taken: 0.05701279640197754\n",
      "Epoch 0: iteration 1278/2501 train_loss: 0.9563989639282227 time_taken: 0.056534528732299805\n",
      "Epoch 0: iteration 1279/2501 train_loss: 0.9562616348266602 time_taken: 0.05702710151672363\n",
      "Epoch 0: iteration 1280/2501 train_loss: 0.9561336636543274 time_taken: 0.05631566047668457\n",
      "Epoch 0: iteration 1281/2501 train_loss: 0.9559818506240845 time_taken: 0.05711174011230469\n",
      "Epoch 0: iteration 1282/2501 train_loss: 0.9558265209197998 time_taken: 0.05649685859680176\n",
      "Epoch 0: iteration 1283/2501 train_loss: 0.9556755423545837 time_taken: 0.05640864372253418\n",
      "Epoch 0: iteration 1284/2501 train_loss: 0.95551997423172 time_taken: 0.05607414245605469\n",
      "Epoch 0: iteration 1285/2501 train_loss: 0.9553400874137878 time_taken: 0.05692625045776367\n",
      "Epoch 0: iteration 1286/2501 train_loss: 0.9551804661750793 time_taken: 0.05705976486206055\n",
      "Epoch 0: iteration 1287/2501 train_loss: 0.9549909234046936 time_taken: 0.05701756477355957\n",
      "Epoch 0: iteration 1288/2501 train_loss: 0.954805314540863 time_taken: 0.05706644058227539\n",
      "Epoch 0: iteration 1289/2501 train_loss: 0.9546310901641846 time_taken: 0.05704545974731445\n",
      "Epoch 0: iteration 1290/2501 train_loss: 0.9544510245323181 time_taken: 0.0565335750579834\n",
      "Epoch 0: iteration 1291/2501 train_loss: 0.9542606472969055 time_taken: 0.057085514068603516\n",
      "Epoch 0: iteration 1292/2501 train_loss: 0.9540985226631165 time_taken: 0.06420707702636719\n",
      "Epoch 0: iteration 1293/2501 train_loss: 0.9539341926574707 time_taken: 0.0567011833190918\n",
      "Epoch 0: iteration 1294/2501 train_loss: 0.9537648558616638 time_taken: 0.056554555892944336\n",
      "Epoch 0: iteration 1295/2501 train_loss: 0.9536564350128174 time_taken: 0.056128501892089844\n",
      "Epoch 0: iteration 1296/2501 train_loss: 0.9535357356071472 time_taken: 0.0561065673828125\n",
      "Epoch 0: iteration 1297/2501 train_loss: 0.9534124732017517 time_taken: 0.06078171730041504\n",
      "Epoch 0: iteration 1298/2501 train_loss: 0.9532926678657532 time_taken: 0.05620527267456055\n",
      "Epoch 0: iteration 1299/2501 train_loss: 0.9531879425048828 time_taken: 0.0570368766784668\n",
      "Epoch 0: iteration 1300/2501 train_loss: 0.953089714050293 time_taken: 0.05628013610839844\n",
      "Epoch 0: iteration 1301/2501 train_loss: 0.9529988169670105 time_taken: 0.06208372116088867\n",
      "Epoch 0: iteration 1302/2501 train_loss: 0.9529157280921936 time_taken: 0.05625128746032715\n",
      "Epoch 0: iteration 1303/2501 train_loss: 0.9528237581253052 time_taken: 0.05696392059326172\n",
      "Epoch 0: iteration 1304/2501 train_loss: 0.9527234435081482 time_taken: 0.06154036521911621\n",
      "Epoch 0: iteration 1305/2501 train_loss: 0.9525998830795288 time_taken: 0.05634331703186035\n",
      "Epoch 0: iteration 1306/2501 train_loss: 0.952462375164032 time_taken: 0.05675649642944336\n",
      "Epoch 0: iteration 1307/2501 train_loss: 0.9523299336433411 time_taken: 0.056592464447021484\n",
      "Epoch 0: iteration 1308/2501 train_loss: 0.95222407579422 time_taken: 0.05609750747680664\n",
      "Epoch 0: iteration 1309/2501 train_loss: 0.9521246552467346 time_taken: 0.05730867385864258\n",
      "Epoch 0: iteration 1310/2501 train_loss: 0.9520225524902344 time_taken: 0.05658602714538574\n",
      "Epoch 0: iteration 1311/2501 train_loss: 0.9518862366676331 time_taken: 0.05696749687194824\n",
      "Epoch 0: iteration 1312/2501 train_loss: 0.9517616033554077 time_taken: 0.05676603317260742\n",
      "Epoch 0: iteration 1313/2501 train_loss: 0.9516781568527222 time_taken: 0.05681157112121582\n",
      "Epoch 0: iteration 1314/2501 train_loss: 0.9515945911407471 time_taken: 0.0569765567779541\n",
      "Epoch 0: iteration 1315/2501 train_loss: 0.9514955878257751 time_taken: 0.057093143463134766\n",
      "Epoch 0: iteration 1316/2501 train_loss: 0.9513749480247498 time_taken: 0.056508779525756836\n",
      "Epoch 0: iteration 1317/2501 train_loss: 0.951261043548584 time_taken: 0.05685114860534668\n",
      "Epoch 0: iteration 1318/2501 train_loss: 0.9511268138885498 time_taken: 0.05718111991882324\n",
      "Epoch 0: iteration 1319/2501 train_loss: 0.9510220885276794 time_taken: 0.05697488784790039\n",
      "Epoch 0: iteration 1320/2501 train_loss: 0.9508746266365051 time_taken: 0.05694079399108887\n",
      "Epoch 0: iteration 1321/2501 train_loss: 0.9507511854171753 time_taken: 0.05678820610046387\n",
      "Epoch 0: iteration 1322/2501 train_loss: 0.9506576657295227 time_taken: 0.05700039863586426\n",
      "Epoch 0: iteration 1323/2501 train_loss: 0.950715959072113 time_taken: 0.05659151077270508\n",
      "Epoch 0: iteration 1324/2501 train_loss: 0.9511046409606934 time_taken: 0.056389570236206055\n",
      "Epoch 0: iteration 1325/2501 train_loss: 0.9511030316352844 time_taken: 0.05619454383850098\n",
      "Epoch 0: iteration 1326/2501 train_loss: 0.9509961009025574 time_taken: 0.05654621124267578\n",
      "Epoch 0: iteration 1327/2501 train_loss: 0.9509559273719788 time_taken: 0.05646514892578125\n",
      "Epoch 0: iteration 1328/2501 train_loss: 0.9508331418037415 time_taken: 0.0567471981048584\n",
      "Epoch 0: iteration 1329/2501 train_loss: 0.950702965259552 time_taken: 0.056746482849121094\n",
      "Epoch 0: iteration 1330/2501 train_loss: 0.9506120681762695 time_taken: 0.05638909339904785\n",
      "Epoch 0: iteration 1331/2501 train_loss: 0.9504517316818237 time_taken: 0.05664539337158203\n",
      "Epoch 0: iteration 1332/2501 train_loss: 0.950323224067688 time_taken: 0.0566248893737793\n",
      "Epoch 0: iteration 1333/2501 train_loss: 0.9502180218696594 time_taken: 0.056557416915893555\n",
      "Epoch 0: iteration 1334/2501 train_loss: 0.9501066207885742 time_taken: 0.056424617767333984\n",
      "Epoch 0: iteration 1335/2501 train_loss: 0.9499689936637878 time_taken: 0.05626058578491211\n",
      "Epoch 0: iteration 1336/2501 train_loss: 0.9498203992843628 time_taken: 0.057090044021606445\n",
      "Epoch 0: iteration 1337/2501 train_loss: 0.9496580362319946 time_taken: 0.05627274513244629\n",
      "Epoch 0: iteration 1338/2501 train_loss: 0.9495323300361633 time_taken: 0.0567474365234375\n",
      "Epoch 0: iteration 1339/2501 train_loss: 0.9493837356567383 time_taken: 0.05631065368652344\n",
      "Epoch 0: iteration 1340/2501 train_loss: 0.9492391347885132 time_taken: 0.05605483055114746\n",
      "Epoch 0: iteration 1341/2501 train_loss: 0.9491399526596069 time_taken: 0.05643105506896973\n",
      "Epoch 0: iteration 1342/2501 train_loss: 0.9490208625793457 time_taken: 0.056523799896240234\n",
      "Epoch 0: iteration 1343/2501 train_loss: 0.9489333033561707 time_taken: 0.056588172912597656\n",
      "Epoch 0: iteration 1344/2501 train_loss: 0.948830783367157 time_taken: 0.055992841720581055\n",
      "Epoch 0: iteration 1345/2501 train_loss: 0.9487351179122925 time_taken: 0.05667304992675781\n",
      "Epoch 0: iteration 1346/2501 train_loss: 0.9486567974090576 time_taken: 0.056452035903930664\n",
      "Epoch 0: iteration 1347/2501 train_loss: 0.948611319065094 time_taken: 0.056731462478637695\n",
      "Epoch 0: iteration 1348/2501 train_loss: 0.9485529065132141 time_taken: 0.05675649642944336\n",
      "Epoch 0: iteration 1349/2501 train_loss: 0.9484421014785767 time_taken: 0.05661273002624512\n",
      "Epoch 0: iteration 1350/2501 train_loss: 0.9483528733253479 time_taken: 0.056976318359375\n",
      "Epoch 0: iteration 1351/2501 train_loss: 0.9482565522193909 time_taken: 0.05648303031921387\n",
      "Epoch 0: iteration 1352/2501 train_loss: 0.9481666088104248 time_taken: 0.0560765266418457\n",
      "Epoch 0: iteration 1353/2501 train_loss: 0.9480910897254944 time_taken: 0.05721306800842285\n",
      "Epoch 0: iteration 1354/2501 train_loss: 0.9480431079864502 time_taken: 0.0571904182434082\n",
      "Epoch 0: iteration 1355/2501 train_loss: 0.9479720592498779 time_taken: 0.056867122650146484\n",
      "Epoch 0: iteration 1356/2501 train_loss: 0.9479114413261414 time_taken: 0.056804656982421875\n",
      "Epoch 0: iteration 1357/2501 train_loss: 0.9478535652160645 time_taken: 0.0561366081237793\n",
      "Epoch 0: iteration 1358/2501 train_loss: 0.9477987885475159 time_taken: 0.1043097972869873\n",
      "Epoch 0: iteration 1359/2501 train_loss: 0.9477151036262512 time_taken: 0.05665946006774902\n",
      "Epoch 0: iteration 1360/2501 train_loss: 0.9476421475410461 time_taken: 0.05768585205078125\n",
      "Epoch 0: iteration 1361/2501 train_loss: 0.9475667476654053 time_taken: 0.057061195373535156\n",
      "Epoch 0: iteration 1362/2501 train_loss: 0.9474629163742065 time_taken: 0.05657601356506348\n",
      "Epoch 0: iteration 1363/2501 train_loss: 0.9473705291748047 time_taken: 0.05642104148864746\n",
      "Epoch 0: iteration 1364/2501 train_loss: 0.9472751021385193 time_taken: 0.056375741958618164\n",
      "Epoch 0: iteration 1365/2501 train_loss: 0.9471702575683594 time_taken: 0.056870460510253906\n",
      "Epoch 0: iteration 1366/2501 train_loss: 0.947066068649292 time_taken: 0.056645870208740234\n",
      "Epoch 0: iteration 1367/2501 train_loss: 0.9469646215438843 time_taken: 0.0564572811126709\n",
      "Epoch 0: iteration 1368/2501 train_loss: 0.9468647241592407 time_taken: 0.05688118934631348\n",
      "Epoch 0: iteration 1369/2501 train_loss: 0.9467731714248657 time_taken: 0.0566411018371582\n",
      "Epoch 0: iteration 1370/2501 train_loss: 0.9466665983200073 time_taken: 0.056591033935546875\n",
      "Epoch 0: iteration 1371/2501 train_loss: 0.9466015100479126 time_taken: 0.05651092529296875\n",
      "Epoch 0: iteration 1372/2501 train_loss: 0.9465224742889404 time_taken: 0.05737018585205078\n",
      "Epoch 0: iteration 1373/2501 train_loss: 0.94644695520401 time_taken: 0.056940555572509766\n",
      "Epoch 0: iteration 1374/2501 train_loss: 0.9463965892791748 time_taken: 0.05686688423156738\n",
      "Epoch 0: iteration 1375/2501 train_loss: 0.9463406205177307 time_taken: 0.05730295181274414\n",
      "Epoch 0: iteration 1376/2501 train_loss: 0.9462743401527405 time_taken: 0.05700373649597168\n",
      "Epoch 0: iteration 1377/2501 train_loss: 0.9462522864341736 time_taken: 0.05690813064575195\n",
      "Epoch 0: iteration 1378/2501 train_loss: 0.9462452530860901 time_taken: 0.057042837142944336\n",
      "Epoch 0: iteration 1379/2501 train_loss: 0.9462680220603943 time_taken: 0.056952476501464844\n",
      "Epoch 0: iteration 1380/2501 train_loss: 0.946281373500824 time_taken: 0.05681467056274414\n",
      "Epoch 0: iteration 1381/2501 train_loss: 0.946291446685791 time_taken: 0.0571894645690918\n",
      "Epoch 0: iteration 1382/2501 train_loss: 0.9463191628456116 time_taken: 0.05705070495605469\n",
      "Epoch 0: iteration 1383/2501 train_loss: 0.9463229179382324 time_taken: 0.05684232711791992\n",
      "Epoch 0: iteration 1384/2501 train_loss: 0.946312427520752 time_taken: 0.05703997611999512\n",
      "Epoch 0: iteration 1385/2501 train_loss: 0.946301281452179 time_taken: 0.05667424201965332\n",
      "Epoch 0: iteration 1386/2501 train_loss: 0.9462615847587585 time_taken: 0.05662369728088379\n",
      "Epoch 0: iteration 1387/2501 train_loss: 0.9462304711341858 time_taken: 0.057102203369140625\n",
      "Epoch 0: iteration 1388/2501 train_loss: 0.9461991786956787 time_taken: 0.056670188903808594\n",
      "Epoch 0: iteration 1389/2501 train_loss: 0.9461658596992493 time_taken: 0.05662178993225098\n",
      "Epoch 0: iteration 1390/2501 train_loss: 0.9461268186569214 time_taken: 0.056499481201171875\n",
      "Epoch 0: iteration 1391/2501 train_loss: 0.9460819959640503 time_taken: 0.0567781925201416\n",
      "Epoch 0: iteration 1392/2501 train_loss: 0.9460193514823914 time_taken: 0.05636167526245117\n",
      "Epoch 0: iteration 1393/2501 train_loss: 0.9459575414657593 time_taken: 0.056412696838378906\n",
      "Epoch 0: iteration 1394/2501 train_loss: 0.9458942413330078 time_taken: 0.05710864067077637\n",
      "Epoch 0: iteration 1395/2501 train_loss: 0.9458122253417969 time_taken: 0.05646634101867676\n",
      "Epoch 0: iteration 1396/2501 train_loss: 0.9457439184188843 time_taken: 0.05597496032714844\n",
      "Epoch 0: iteration 1397/2501 train_loss: 0.9456587433815002 time_taken: 0.05706906318664551\n",
      "Epoch 0: iteration 1398/2501 train_loss: 0.9456159472465515 time_taken: 0.0567774772644043\n",
      "Epoch 0: iteration 1399/2501 train_loss: 0.9455557465553284 time_taken: 0.0566251277923584\n",
      "Epoch 0: iteration 1400/2501 train_loss: 0.9454959034919739 time_taken: 0.05667567253112793\n",
      "Epoch 0: iteration 1401/2501 train_loss: 0.9454073905944824 time_taken: 0.056363821029663086\n",
      "Epoch 0: iteration 1402/2501 train_loss: 0.9453181624412537 time_taken: 0.056406259536743164\n",
      "Epoch 0: iteration 1403/2501 train_loss: 0.9452383518218994 time_taken: 0.056084394454956055\n",
      "Epoch 0: iteration 1404/2501 train_loss: 0.9451503753662109 time_taken: 0.056414127349853516\n",
      "Epoch 0: iteration 1405/2501 train_loss: 0.9450759291648865 time_taken: 0.056504249572753906\n",
      "Epoch 0: iteration 1406/2501 train_loss: 0.9449870586395264 time_taken: 0.057126760482788086\n",
      "Epoch 0: iteration 1407/2501 train_loss: 0.9448916912078857 time_taken: 0.056937456130981445\n",
      "Epoch 0: iteration 1408/2501 train_loss: 0.9448003172874451 time_taken: 0.05640840530395508\n",
      "Epoch 0: iteration 1409/2501 train_loss: 0.9447070956230164 time_taken: 0.056328535079956055\n",
      "Epoch 0: iteration 1410/2501 train_loss: 0.944598913192749 time_taken: 0.05664372444152832\n",
      "Epoch 0: iteration 1411/2501 train_loss: 0.9444823861122131 time_taken: 0.05693507194519043\n",
      "Epoch 0: iteration 1412/2501 train_loss: 0.9443612694740295 time_taken: 0.05690741539001465\n",
      "Epoch 0: iteration 1413/2501 train_loss: 0.9442328810691833 time_taken: 0.05639815330505371\n",
      "Epoch 0: iteration 1414/2501 train_loss: 0.9441137909889221 time_taken: 0.05719757080078125\n",
      "Epoch 0: iteration 1415/2501 train_loss: 0.9440131187438965 time_taken: 0.05681753158569336\n",
      "Epoch 0: iteration 1416/2501 train_loss: 0.9439109563827515 time_taken: 0.05626988410949707\n",
      "Epoch 0: iteration 1417/2501 train_loss: 0.9437997341156006 time_taken: 0.05656027793884277\n",
      "Epoch 0: iteration 1418/2501 train_loss: 0.9436907172203064 time_taken: 0.05639982223510742\n",
      "Epoch 0: iteration 1419/2501 train_loss: 0.9435983300209045 time_taken: 0.0566105842590332\n",
      "Epoch 0: iteration 1420/2501 train_loss: 0.9434959888458252 time_taken: 0.057047128677368164\n",
      "Epoch 0: iteration 1421/2501 train_loss: 0.9434362649917603 time_taken: 0.05631303787231445\n",
      "Epoch 0: iteration 1422/2501 train_loss: 0.9433632493019104 time_taken: 0.05657196044921875\n",
      "Epoch 0: iteration 1423/2501 train_loss: 0.9432766437530518 time_taken: 0.05675363540649414\n",
      "Epoch 0: iteration 1424/2501 train_loss: 0.9432090520858765 time_taken: 0.0563204288482666\n",
      "Epoch 0: iteration 1425/2501 train_loss: 0.9431429505348206 time_taken: 0.05751609802246094\n",
      "Epoch 0: iteration 1426/2501 train_loss: 0.9430886507034302 time_taken: 0.05647015571594238\n",
      "Epoch 0: iteration 1427/2501 train_loss: 0.9430168271064758 time_taken: 0.05671095848083496\n",
      "Epoch 0: iteration 1428/2501 train_loss: 0.9429131150245667 time_taken: 0.05742025375366211\n",
      "Epoch 0: iteration 1429/2501 train_loss: 0.942834198474884 time_taken: 0.05631566047668457\n",
      "Epoch 0: iteration 1430/2501 train_loss: 0.9427307844161987 time_taken: 0.05664491653442383\n",
      "Epoch 0: iteration 1431/2501 train_loss: 0.9426255226135254 time_taken: 0.057503700256347656\n",
      "Epoch 0: iteration 1432/2501 train_loss: 0.9425066709518433 time_taken: 0.05698990821838379\n",
      "Epoch 0: iteration 1433/2501 train_loss: 0.9423761963844299 time_taken: 0.05702042579650879\n",
      "Epoch 0: iteration 1434/2501 train_loss: 0.9422624707221985 time_taken: 0.05750584602355957\n",
      "Epoch 0: iteration 1435/2501 train_loss: 0.9421869516372681 time_taken: 0.057309627532958984\n",
      "Epoch 0: iteration 1436/2501 train_loss: 0.9421437978744507 time_taken: 0.056722402572631836\n",
      "Epoch 0: iteration 1437/2501 train_loss: 0.9420962333679199 time_taken: 0.056298255920410156\n",
      "Epoch 0: iteration 1438/2501 train_loss: 0.9420596361160278 time_taken: 0.056665658950805664\n",
      "Epoch 0: iteration 1439/2501 train_loss: 0.9420039653778076 time_taken: 0.05676150321960449\n",
      "Epoch 0: iteration 1440/2501 train_loss: 0.9419337511062622 time_taken: 0.05740237236022949\n",
      "Epoch 0: iteration 1441/2501 train_loss: 0.941879391670227 time_taken: 0.05722546577453613\n",
      "Epoch 0: iteration 1442/2501 train_loss: 0.941821277141571 time_taken: 0.05732297897338867\n",
      "Epoch 0: iteration 1443/2501 train_loss: 0.9417481422424316 time_taken: 0.05705142021179199\n",
      "Epoch 0: iteration 1444/2501 train_loss: 0.9416795969009399 time_taken: 0.0574038028717041\n",
      "Epoch 0: iteration 1445/2501 train_loss: 0.941615104675293 time_taken: 0.056073665618896484\n",
      "Epoch 0: iteration 1446/2501 train_loss: 0.9415343999862671 time_taken: 0.05623793601989746\n",
      "Epoch 0: iteration 1447/2501 train_loss: 0.9414424300193787 time_taken: 0.05608415603637695\n",
      "Epoch 0: iteration 1448/2501 train_loss: 0.9413431286811829 time_taken: 0.05724763870239258\n",
      "Epoch 0: iteration 1449/2501 train_loss: 0.9412533044815063 time_taken: 0.05690932273864746\n",
      "Epoch 0: iteration 1450/2501 train_loss: 0.9411382079124451 time_taken: 0.05672931671142578\n",
      "Epoch 0: iteration 1451/2501 train_loss: 0.9410369992256165 time_taken: 0.05691027641296387\n",
      "Epoch 0: iteration 1452/2501 train_loss: 0.9409651756286621 time_taken: 0.05672121047973633\n",
      "Epoch 0: iteration 1453/2501 train_loss: 0.9408924579620361 time_taken: 0.05619454383850098\n",
      "Epoch 0: iteration 1454/2501 train_loss: 0.9408275485038757 time_taken: 0.05625271797180176\n",
      "Epoch 0: iteration 1455/2501 train_loss: 0.9407880306243896 time_taken: 0.05652928352355957\n",
      "Epoch 0: iteration 1456/2501 train_loss: 0.9407392740249634 time_taken: 0.056847572326660156\n",
      "Epoch 0: iteration 1457/2501 train_loss: 0.940667450428009 time_taken: 0.05806159973144531\n",
      "Epoch 0: iteration 1458/2501 train_loss: 0.9406148195266724 time_taken: 0.056882381439208984\n",
      "Epoch 0: iteration 1459/2501 train_loss: 0.940566897392273 time_taken: 0.05660605430603027\n",
      "Epoch 0: iteration 1460/2501 train_loss: 0.9405190348625183 time_taken: 0.05673813819885254\n",
      "Epoch 0: iteration 1461/2501 train_loss: 0.9404758810997009 time_taken: 0.05675339698791504\n",
      "Epoch 0: iteration 1462/2501 train_loss: 0.9404248595237732 time_taken: 0.05623650550842285\n",
      "Epoch 0: iteration 1463/2501 train_loss: 0.9403383135795593 time_taken: 0.05759119987487793\n",
      "Epoch 0: iteration 1464/2501 train_loss: 0.9402526021003723 time_taken: 0.05631136894226074\n",
      "Epoch 0: iteration 1465/2501 train_loss: 0.9401693940162659 time_taken: 0.05663347244262695\n",
      "Epoch 0: iteration 1466/2501 train_loss: 0.9400983452796936 time_taken: 0.05669808387756348\n",
      "Epoch 0: iteration 1467/2501 train_loss: 0.9400098323822021 time_taken: 0.05653810501098633\n",
      "Epoch 0: iteration 1468/2501 train_loss: 0.9399184584617615 time_taken: 0.05642342567443848\n",
      "Epoch 0: iteration 1469/2501 train_loss: 0.9398332238197327 time_taken: 0.06204819679260254\n",
      "Epoch 0: iteration 1470/2501 train_loss: 0.9397174119949341 time_taken: 0.05628323554992676\n",
      "Epoch 0: iteration 1471/2501 train_loss: 0.9396209120750427 time_taken: 0.05670571327209473\n",
      "Epoch 0: iteration 1472/2501 train_loss: 0.9395329356193542 time_taken: 0.056509971618652344\n",
      "Epoch 0: iteration 1473/2501 train_loss: 0.9394631385803223 time_taken: 0.05684208869934082\n",
      "Epoch 0: iteration 1474/2501 train_loss: 0.9393882155418396 time_taken: 0.05649447441101074\n",
      "Epoch 0: iteration 1475/2501 train_loss: 0.939319908618927 time_taken: 0.05680084228515625\n",
      "Epoch 0: iteration 1476/2501 train_loss: 0.9392576813697815 time_taken: 0.056578636169433594\n",
      "Epoch 0: iteration 1477/2501 train_loss: 0.9392121434211731 time_taken: 0.05705666542053223\n",
      "Epoch 0: iteration 1478/2501 train_loss: 0.9392012357711792 time_taken: 0.05644702911376953\n",
      "Epoch 0: iteration 1479/2501 train_loss: 0.9391612410545349 time_taken: 0.05694127082824707\n",
      "Epoch 0: iteration 1480/2501 train_loss: 0.9391410946846008 time_taken: 0.05673527717590332\n",
      "Epoch 0: iteration 1481/2501 train_loss: 0.9391288161277771 time_taken: 0.0564732551574707\n",
      "Epoch 0: iteration 1482/2501 train_loss: 0.9391186237335205 time_taken: 0.05690646171569824\n",
      "Epoch 0: iteration 1483/2501 train_loss: 0.9390977621078491 time_taken: 0.05781888961791992\n",
      "Epoch 0: iteration 1484/2501 train_loss: 0.9390464425086975 time_taken: 0.05654716491699219\n",
      "Epoch 0: iteration 1485/2501 train_loss: 0.9389976859092712 time_taken: 0.05655360221862793\n",
      "Epoch 0: iteration 1486/2501 train_loss: 0.9389252662658691 time_taken: 0.05700206756591797\n",
      "Epoch 0: iteration 1487/2501 train_loss: 0.9388417601585388 time_taken: 0.05665779113769531\n",
      "Epoch 0: iteration 1488/2501 train_loss: 0.938764214515686 time_taken: 0.05687308311462402\n",
      "Epoch 0: iteration 1489/2501 train_loss: 0.9386729598045349 time_taken: 0.05735278129577637\n",
      "Epoch 0: iteration 1490/2501 train_loss: 0.9385766983032227 time_taken: 0.05665779113769531\n",
      "Epoch 0: iteration 1491/2501 train_loss: 0.938488781452179 time_taken: 0.05656886100769043\n",
      "Epoch 0: iteration 1492/2501 train_loss: 0.9383859634399414 time_taken: 0.05662870407104492\n",
      "Epoch 0: iteration 1493/2501 train_loss: 0.9382786750793457 time_taken: 0.057155609130859375\n",
      "Epoch 0: iteration 1494/2501 train_loss: 0.9381651282310486 time_taken: 0.05666542053222656\n",
      "Epoch 0: iteration 1495/2501 train_loss: 0.9380700588226318 time_taken: 0.05630040168762207\n",
      "Epoch 0: iteration 1496/2501 train_loss: 0.9379615187644958 time_taken: 0.05634021759033203\n",
      "Epoch 0: iteration 1497/2501 train_loss: 0.937877357006073 time_taken: 0.056121826171875\n",
      "Epoch 0: iteration 1498/2501 train_loss: 0.93779456615448 time_taken: 0.05631422996520996\n",
      "Epoch 0: iteration 1499/2501 train_loss: 0.9376978278160095 time_taken: 0.05643439292907715\n",
      "Epoch 0: iteration 1500/2501 train_loss: 0.9375832080841064 time_taken: 0.056047677993774414\n",
      "Epoch 0: iteration 1501/2501 train_loss: 0.9374819397926331 time_taken: 0.05633258819580078\n",
      "Epoch 0: iteration 1502/2501 train_loss: 0.9373944997787476 time_taken: 0.05591607093811035\n",
      "Epoch 0: iteration 1503/2501 train_loss: 0.9372865557670593 time_taken: 0.05610775947570801\n",
      "Epoch 0: iteration 1504/2501 train_loss: 0.9371745586395264 time_taken: 0.05720329284667969\n",
      "Epoch 0: iteration 1505/2501 train_loss: 0.9370894432067871 time_taken: 0.056940555572509766\n",
      "Epoch 0: iteration 1506/2501 train_loss: 0.9370315074920654 time_taken: 0.05714702606201172\n",
      "Epoch 0: iteration 1507/2501 train_loss: 0.9369423985481262 time_taken: 0.05686044692993164\n",
      "Epoch 0: iteration 1508/2501 train_loss: 0.9368494153022766 time_taken: 0.056342363357543945\n",
      "Epoch 0: iteration 1509/2501 train_loss: 0.9367607831954956 time_taken: 0.05658721923828125\n",
      "Epoch 0: iteration 1510/2501 train_loss: 0.9366686344146729 time_taken: 0.057211875915527344\n",
      "Epoch 0: iteration 1511/2501 train_loss: 0.936590850353241 time_taken: 0.0571901798248291\n",
      "Epoch 0: iteration 1512/2501 train_loss: 0.9365234971046448 time_taken: 0.057233572006225586\n",
      "Epoch 0: iteration 1513/2501 train_loss: 0.9364758133888245 time_taken: 0.0565485954284668\n",
      "Epoch 0: iteration 1514/2501 train_loss: 0.936426043510437 time_taken: 0.0560154914855957\n",
      "Epoch 0: iteration 1515/2501 train_loss: 0.9363529086112976 time_taken: 0.05626940727233887\n",
      "Epoch 0: iteration 1516/2501 train_loss: 0.9362720251083374 time_taken: 0.07547593116760254\n",
      "Epoch 0: iteration 1517/2501 train_loss: 0.9361756443977356 time_taken: 0.06596088409423828\n",
      "Epoch 0: iteration 1518/2501 train_loss: 0.9360783696174622 time_taken: 0.056913137435913086\n",
      "Epoch 0: iteration 1519/2501 train_loss: 0.9359963536262512 time_taken: 0.05666637420654297\n",
      "Epoch 0: iteration 1520/2501 train_loss: 0.935931384563446 time_taken: 0.05700230598449707\n",
      "Epoch 0: iteration 1521/2501 train_loss: 0.9358472228050232 time_taken: 0.056432485580444336\n",
      "Epoch 0: iteration 1522/2501 train_loss: 0.9357505440711975 time_taken: 0.05647897720336914\n",
      "Epoch 0: iteration 1523/2501 train_loss: 0.9356167912483215 time_taken: 0.05652499198913574\n",
      "Epoch 0: iteration 1524/2501 train_loss: 0.9354835748672485 time_taken: 0.05632328987121582\n",
      "Epoch 0: iteration 1525/2501 train_loss: 0.9353513717651367 time_taken: 0.05633878707885742\n",
      "Epoch 0: iteration 1526/2501 train_loss: 0.9352040886878967 time_taken: 0.05652046203613281\n",
      "Epoch 0: iteration 1527/2501 train_loss: 0.9350533485412598 time_taken: 0.0564882755279541\n",
      "Epoch 0: iteration 1528/2501 train_loss: 0.9348986148834229 time_taken: 0.05623960494995117\n",
      "Epoch 0: iteration 1529/2501 train_loss: 0.9347414374351501 time_taken: 0.056281328201293945\n",
      "Epoch 0: iteration 1530/2501 train_loss: 0.9345663785934448 time_taken: 0.05611371994018555\n",
      "Epoch 0: iteration 1531/2501 train_loss: 0.9343794584274292 time_taken: 0.05639839172363281\n",
      "Epoch 0: iteration 1532/2501 train_loss: 0.9342073798179626 time_taken: 0.055899858474731445\n",
      "Epoch 0: iteration 1533/2501 train_loss: 0.9340289831161499 time_taken: 0.055856943130493164\n",
      "Epoch 0: iteration 1534/2501 train_loss: 0.9338771104812622 time_taken: 0.05654168128967285\n",
      "Epoch 0: iteration 1535/2501 train_loss: 0.9337260723114014 time_taken: 0.05626702308654785\n",
      "Epoch 0: iteration 1536/2501 train_loss: 0.9335901141166687 time_taken: 0.05631113052368164\n",
      "Epoch 0: iteration 1537/2501 train_loss: 0.9334702491760254 time_taken: 0.0564119815826416\n",
      "Epoch 0: iteration 1538/2501 train_loss: 0.93333500623703 time_taken: 0.05575418472290039\n",
      "Epoch 0: iteration 1539/2501 train_loss: 0.9332156777381897 time_taken: 0.05691695213317871\n",
      "Epoch 0: iteration 1540/2501 train_loss: 0.9330893158912659 time_taken: 0.05705070495605469\n",
      "Epoch 0: iteration 1541/2501 train_loss: 0.9329880475997925 time_taken: 0.06214332580566406\n",
      "Epoch 0: iteration 1542/2501 train_loss: 0.9328929781913757 time_taken: 0.05623197555541992\n",
      "Epoch 0: iteration 1543/2501 train_loss: 0.9328060746192932 time_taken: 0.05662822723388672\n",
      "Epoch 0: iteration 1544/2501 train_loss: 0.9327303171157837 time_taken: 0.05661749839782715\n",
      "Epoch 0: iteration 1545/2501 train_loss: 0.9326579570770264 time_taken: 0.057434797286987305\n",
      "Epoch 0: iteration 1546/2501 train_loss: 0.9325783848762512 time_taken: 0.05756187438964844\n",
      "Epoch 0: iteration 1547/2501 train_loss: 0.9325046539306641 time_taken: 0.056557416915893555\n",
      "Epoch 0: iteration 1548/2501 train_loss: 0.9324322938919067 time_taken: 0.05641341209411621\n",
      "Epoch 0: iteration 1549/2501 train_loss: 0.9323784708976746 time_taken: 0.05614042282104492\n",
      "Epoch 0: iteration 1550/2501 train_loss: 0.9323160648345947 time_taken: 0.0559844970703125\n",
      "Epoch 0: iteration 1551/2501 train_loss: 0.932223379611969 time_taken: 0.05619049072265625\n",
      "Epoch 0: iteration 1552/2501 train_loss: 0.9321417212486267 time_taken: 0.05623173713684082\n",
      "Epoch 0: iteration 1553/2501 train_loss: 0.9320805668830872 time_taken: 0.056165218353271484\n",
      "Epoch 0: iteration 1554/2501 train_loss: 0.9319794178009033 time_taken: 0.05604124069213867\n",
      "Epoch 0: iteration 1555/2501 train_loss: 0.9318965077400208 time_taken: 0.055963993072509766\n",
      "Epoch 0: iteration 1556/2501 train_loss: 0.9318144917488098 time_taken: 0.05928683280944824\n",
      "Epoch 0: iteration 1557/2501 train_loss: 0.9317322373390198 time_taken: 0.05606269836425781\n",
      "Epoch 0: iteration 1558/2501 train_loss: 0.931648313999176 time_taken: 0.056897878646850586\n",
      "Epoch 0: iteration 1559/2501 train_loss: 0.9315571188926697 time_taken: 0.055989980697631836\n",
      "Epoch 0: iteration 1560/2501 train_loss: 0.9314740300178528 time_taken: 0.05643057823181152\n",
      "Epoch 0: iteration 1561/2501 train_loss: 0.9313874244689941 time_taken: 0.056082963943481445\n",
      "Epoch 0: iteration 1562/2501 train_loss: 0.9313051104545593 time_taken: 0.06143355369567871\n",
      "Epoch 0: iteration 1563/2501 train_loss: 0.9312369227409363 time_taken: 0.0582427978515625\n",
      "Epoch 0: iteration 1564/2501 train_loss: 0.9311485886573792 time_taken: 0.05697798728942871\n",
      "Epoch 0: iteration 1565/2501 train_loss: 0.9310582280158997 time_taken: 0.05744361877441406\n",
      "Epoch 0: iteration 1566/2501 train_loss: 0.930979311466217 time_taken: 0.05709958076477051\n",
      "Epoch 0: iteration 1567/2501 train_loss: 0.9308927655220032 time_taken: 0.05697512626647949\n",
      "Epoch 0: iteration 1568/2501 train_loss: 0.9308261275291443 time_taken: 0.057198524475097656\n",
      "Epoch 0: iteration 1569/2501 train_loss: 0.9307595491409302 time_taken: 0.05684041976928711\n",
      "Epoch 0: iteration 1570/2501 train_loss: 0.9306941628456116 time_taken: 0.05746197700500488\n",
      "Epoch 0: iteration 1571/2501 train_loss: 0.9306215047836304 time_taken: 0.05692315101623535\n",
      "Epoch 0: iteration 1572/2501 train_loss: 0.9305437803268433 time_taken: 0.05715441703796387\n",
      "Epoch 0: iteration 1573/2501 train_loss: 0.9304720163345337 time_taken: 0.05650496482849121\n",
      "Epoch 0: iteration 1574/2501 train_loss: 0.9304035902023315 time_taken: 0.05641460418701172\n",
      "Epoch 0: iteration 1575/2501 train_loss: 0.9303234219551086 time_taken: 0.05658674240112305\n",
      "Epoch 0: iteration 1576/2501 train_loss: 0.9302744269371033 time_taken: 0.05664682388305664\n",
      "Epoch 0: iteration 1577/2501 train_loss: 0.930250883102417 time_taken: 0.056525468826293945\n",
      "Epoch 0: iteration 1578/2501 train_loss: 0.9302367568016052 time_taken: 0.05685591697692871\n",
      "Epoch 0: iteration 1579/2501 train_loss: 0.9302399158477783 time_taken: 0.057045936584472656\n",
      "Epoch 0: iteration 1580/2501 train_loss: 0.9302456378936768 time_taken: 0.056531429290771484\n",
      "Epoch 0: iteration 1581/2501 train_loss: 0.9302375316619873 time_taken: 0.05730795860290527\n",
      "Epoch 0: iteration 1582/2501 train_loss: 0.9302268028259277 time_taken: 0.056845903396606445\n",
      "Epoch 0: iteration 1583/2501 train_loss: 0.930199921131134 time_taken: 0.05651235580444336\n",
      "Epoch 0: iteration 1584/2501 train_loss: 0.9301779866218567 time_taken: 0.07170629501342773\n",
      "Epoch 0: iteration 1585/2501 train_loss: 0.9301419854164124 time_taken: 0.05653047561645508\n",
      "Epoch 0: iteration 1586/2501 train_loss: 0.9300824999809265 time_taken: 0.05658364295959473\n",
      "Epoch 0: iteration 1587/2501 train_loss: 0.9300436973571777 time_taken: 0.05703473091125488\n",
      "Epoch 0: iteration 1588/2501 train_loss: 0.9300169348716736 time_taken: 0.05706477165222168\n",
      "Epoch 0: iteration 1589/2501 train_loss: 0.9299647212028503 time_taken: 0.056461334228515625\n",
      "Epoch 0: iteration 1590/2501 train_loss: 0.9299294352531433 time_taken: 0.05685782432556152\n",
      "Epoch 0: iteration 1591/2501 train_loss: 0.9299083948135376 time_taken: 0.05663323402404785\n",
      "Epoch 0: iteration 1592/2501 train_loss: 0.9298726916313171 time_taken: 0.05671811103820801\n",
      "Epoch 0: iteration 1593/2501 train_loss: 0.9298494458198547 time_taken: 0.056825876235961914\n",
      "Epoch 0: iteration 1594/2501 train_loss: 0.929823100566864 time_taken: 0.05672097206115723\n",
      "Epoch 0: iteration 1595/2501 train_loss: 0.9298104643821716 time_taken: 0.05730915069580078\n",
      "Epoch 0: iteration 1596/2501 train_loss: 0.9297806620597839 time_taken: 0.056733131408691406\n",
      "Epoch 0: iteration 1597/2501 train_loss: 0.9297865629196167 time_taken: 0.05698370933532715\n",
      "Epoch 0: iteration 1598/2501 train_loss: 0.9297794103622437 time_taken: 0.05691790580749512\n",
      "Epoch 0: iteration 1599/2501 train_loss: 0.9297531247138977 time_taken: 0.05640125274658203\n",
      "Epoch 0: iteration 1600/2501 train_loss: 0.9297235012054443 time_taken: 0.05635428428649902\n",
      "Epoch 0: iteration 1601/2501 train_loss: 0.9296746253967285 time_taken: 0.05659651756286621\n",
      "Epoch 0: iteration 1602/2501 train_loss: 0.9296107888221741 time_taken: 0.05695199966430664\n",
      "Epoch 0: iteration 1603/2501 train_loss: 0.9295737147331238 time_taken: 0.05681276321411133\n",
      "Epoch 0: iteration 1604/2501 train_loss: 0.929529070854187 time_taken: 0.057225704193115234\n",
      "Epoch 0: iteration 1605/2501 train_loss: 0.9294771552085876 time_taken: 0.05691814422607422\n",
      "Epoch 0: iteration 1606/2501 train_loss: 0.9294093251228333 time_taken: 0.05720353126525879\n",
      "Epoch 0: iteration 1607/2501 train_loss: 0.9293512105941772 time_taken: 0.056838274002075195\n",
      "Epoch 0: iteration 1608/2501 train_loss: 0.9292974472045898 time_taken: 0.056719064712524414\n",
      "Epoch 0: iteration 1609/2501 train_loss: 0.9292089343070984 time_taken: 0.05692148208618164\n",
      "Epoch 0: iteration 1610/2501 train_loss: 0.9290996789932251 time_taken: 0.05614829063415527\n",
      "Epoch 0: iteration 1611/2501 train_loss: 0.9290291666984558 time_taken: 0.056146860122680664\n",
      "Epoch 0: iteration 1612/2501 train_loss: 0.9289958477020264 time_taken: 0.05741310119628906\n",
      "Epoch 0: iteration 1613/2501 train_loss: 0.9289576411247253 time_taken: 0.09907674789428711\n",
      "Epoch 0: iteration 1614/2501 train_loss: 0.9289294481277466 time_taken: 0.05670881271362305\n",
      "Epoch 0: iteration 1615/2501 train_loss: 0.9289200901985168 time_taken: 0.05588102340698242\n",
      "Epoch 0: iteration 1616/2501 train_loss: 0.9288629293441772 time_taken: 0.055854082107543945\n",
      "Epoch 0: iteration 1617/2501 train_loss: 0.928805410861969 time_taken: 0.05680680274963379\n",
      "Epoch 0: iteration 1618/2501 train_loss: 0.9287340641021729 time_taken: 0.05734395980834961\n",
      "Epoch 0: iteration 1619/2501 train_loss: 0.9286504983901978 time_taken: 0.05660510063171387\n",
      "Epoch 0: iteration 1620/2501 train_loss: 0.9285609126091003 time_taken: 0.05588364601135254\n",
      "Epoch 0: iteration 1621/2501 train_loss: 0.9284791350364685 time_taken: 0.05633687973022461\n",
      "Epoch 0: iteration 1622/2501 train_loss: 0.9284093976020813 time_taken: 0.056928157806396484\n",
      "Epoch 0: iteration 1623/2501 train_loss: 0.9283551573753357 time_taken: 0.05632925033569336\n",
      "Epoch 0: iteration 1624/2501 train_loss: 0.9282950758934021 time_taken: 0.056139230728149414\n",
      "Epoch 0: iteration 1625/2501 train_loss: 0.9282112717628479 time_taken: 0.05709958076477051\n",
      "Epoch 0: iteration 1626/2501 train_loss: 0.9281217455863953 time_taken: 0.05647110939025879\n",
      "Epoch 0: iteration 1627/2501 train_loss: 0.928016185760498 time_taken: 0.056915998458862305\n",
      "Epoch 0: iteration 1628/2501 train_loss: 0.9279078245162964 time_taken: 0.05671048164367676\n",
      "Epoch 0: iteration 1629/2501 train_loss: 0.9277749061584473 time_taken: 0.05636000633239746\n",
      "Epoch 0: iteration 1630/2501 train_loss: 0.9276529550552368 time_taken: 0.056077003479003906\n",
      "Epoch 0: iteration 1631/2501 train_loss: 0.9275335669517517 time_taken: 0.056238651275634766\n",
      "Epoch 0: iteration 1632/2501 train_loss: 0.9274078011512756 time_taken: 0.05597209930419922\n",
      "Epoch 0: iteration 1633/2501 train_loss: 0.9273002743721008 time_taken: 0.05636286735534668\n",
      "Epoch 0: iteration 1634/2501 train_loss: 0.9272171258926392 time_taken: 0.056726694107055664\n",
      "Epoch 0: iteration 1635/2501 train_loss: 0.9271370768547058 time_taken: 0.05669522285461426\n",
      "Epoch 0: iteration 1636/2501 train_loss: 0.927063524723053 time_taken: 0.05719327926635742\n",
      "Epoch 0: iteration 1637/2501 train_loss: 0.9270021319389343 time_taken: 0.05638432502746582\n",
      "Epoch 0: iteration 1638/2501 train_loss: 0.9269360303878784 time_taken: 0.0560758113861084\n",
      "Epoch 0: iteration 1639/2501 train_loss: 0.926872193813324 time_taken: 0.056234121322631836\n",
      "Epoch 0: iteration 1640/2501 train_loss: 0.9268049001693726 time_taken: 0.05717206001281738\n",
      "Epoch 0: iteration 1641/2501 train_loss: 0.9267264604568481 time_taken: 0.05648350715637207\n",
      "Epoch 0: iteration 1642/2501 train_loss: 0.9266581535339355 time_taken: 0.055951833724975586\n",
      "Epoch 0: iteration 1643/2501 train_loss: 0.9265891909599304 time_taken: 0.056479692459106445\n",
      "Epoch 0: iteration 1644/2501 train_loss: 0.9265224933624268 time_taken: 0.05633711814880371\n",
      "Epoch 0: iteration 1645/2501 train_loss: 0.9264593124389648 time_taken: 0.05644702911376953\n",
      "Epoch 0: iteration 1646/2501 train_loss: 0.9263936877250671 time_taken: 0.056183815002441406\n",
      "Epoch 0: iteration 1647/2501 train_loss: 0.9263376593589783 time_taken: 0.05606484413146973\n",
      "Epoch 0: iteration 1648/2501 train_loss: 0.9262783527374268 time_taken: 0.056157827377319336\n",
      "Epoch 0: iteration 1649/2501 train_loss: 0.9262133836746216 time_taken: 0.05670762062072754\n",
      "Epoch 0: iteration 1650/2501 train_loss: 0.9261581897735596 time_taken: 0.05590248107910156\n",
      "Epoch 0: iteration 1651/2501 train_loss: 0.926096498966217 time_taken: 0.05656075477600098\n",
      "Epoch 0: iteration 1652/2501 train_loss: 0.9260334372520447 time_taken: 0.05607342720031738\n",
      "Epoch 0: iteration 1653/2501 train_loss: 0.9259897470474243 time_taken: 0.0564265251159668\n",
      "Epoch 0: iteration 1654/2501 train_loss: 0.9259405136108398 time_taken: 0.056622982025146484\n",
      "Epoch 0: iteration 1655/2501 train_loss: 0.9258939027786255 time_taken: 0.0565183162689209\n",
      "Epoch 0: iteration 1656/2501 train_loss: 0.9258564710617065 time_taken: 0.056319236755371094\n",
      "Epoch 0: iteration 1657/2501 train_loss: 0.9257953763008118 time_taken: 0.05648469924926758\n",
      "Epoch 0: iteration 1658/2501 train_loss: 0.9257434010505676 time_taken: 0.05717206001281738\n",
      "Epoch 0: iteration 1659/2501 train_loss: 0.9256982803344727 time_taken: 0.05592060089111328\n",
      "Epoch 0: iteration 1660/2501 train_loss: 0.9256419539451599 time_taken: 0.05654430389404297\n",
      "Epoch 0: iteration 1661/2501 train_loss: 0.9255743026733398 time_taken: 0.05582380294799805\n",
      "Epoch 0: iteration 1662/2501 train_loss: 0.9255234003067017 time_taken: 0.056711435317993164\n",
      "Epoch 0: iteration 1663/2501 train_loss: 0.9254544973373413 time_taken: 0.05714917182922363\n",
      "Epoch 0: iteration 1664/2501 train_loss: 0.9253982305526733 time_taken: 0.056775808334350586\n",
      "Epoch 0: iteration 1665/2501 train_loss: 0.9253296256065369 time_taken: 0.05656623840332031\n",
      "Epoch 0: iteration 1666/2501 train_loss: 0.9252827763557434 time_taken: 0.05648994445800781\n",
      "Epoch 0: iteration 1667/2501 train_loss: 0.9252133965492249 time_taken: 0.05741310119628906\n",
      "Epoch 0: iteration 1668/2501 train_loss: 0.9251652956008911 time_taken: 0.05667519569396973\n",
      "Epoch 0: iteration 1669/2501 train_loss: 0.9251338243484497 time_taken: 0.0572047233581543\n",
      "Epoch 0: iteration 1670/2501 train_loss: 0.92510586977005 time_taken: 0.0563967227935791\n",
      "Epoch 0: iteration 1671/2501 train_loss: 0.9250887036323547 time_taken: 0.05675077438354492\n",
      "Epoch 0: iteration 1672/2501 train_loss: 0.9250994920730591 time_taken: 0.056910037994384766\n",
      "Epoch 0: iteration 1673/2501 train_loss: 0.9251183271408081 time_taken: 0.05690145492553711\n",
      "Epoch 0: iteration 1674/2501 train_loss: 0.925136148929596 time_taken: 0.05650663375854492\n",
      "Epoch 0: iteration 1675/2501 train_loss: 0.9251906871795654 time_taken: 0.056099653244018555\n",
      "Epoch 0: iteration 1676/2501 train_loss: 0.925277054309845 time_taken: 0.05610775947570801\n",
      "Epoch 0: iteration 1677/2501 train_loss: 0.9253844618797302 time_taken: 0.057730913162231445\n",
      "Epoch 0: iteration 1678/2501 train_loss: 0.9254897832870483 time_taken: 0.055689096450805664\n",
      "Epoch 0: iteration 1679/2501 train_loss: 0.9256229400634766 time_taken: 0.05651998519897461\n",
      "Epoch 0: iteration 1680/2501 train_loss: 0.9257726669311523 time_taken: 0.056043148040771484\n",
      "Epoch 0: iteration 1681/2501 train_loss: 0.9259199500083923 time_taken: 0.05646777153015137\n",
      "Epoch 0: iteration 1682/2501 train_loss: 0.9260743260383606 time_taken: 0.057225942611694336\n",
      "Epoch 0: iteration 1683/2501 train_loss: 0.9262557625770569 time_taken: 0.056366920471191406\n",
      "Epoch 0: iteration 1684/2501 train_loss: 0.926455557346344 time_taken: 0.05620002746582031\n",
      "Epoch 0: iteration 1685/2501 train_loss: 0.926645815372467 time_taken: 0.05649566650390625\n",
      "Epoch 0: iteration 1686/2501 train_loss: 0.9268397092819214 time_taken: 0.05604219436645508\n",
      "Epoch 0: iteration 1687/2501 train_loss: 0.927024781703949 time_taken: 0.05635881423950195\n",
      "Epoch 0: iteration 1688/2501 train_loss: 0.9271709322929382 time_taken: 0.05629134178161621\n",
      "Epoch 0: iteration 1689/2501 train_loss: 0.9273044466972351 time_taken: 0.05614137649536133\n",
      "Epoch 0: iteration 1690/2501 train_loss: 0.9274282455444336 time_taken: 0.056171417236328125\n",
      "Epoch 0: iteration 1691/2501 train_loss: 0.9275557994842529 time_taken: 0.05639004707336426\n",
      "Epoch 0: iteration 1692/2501 train_loss: 0.9276424646377563 time_taken: 0.055877685546875\n",
      "Epoch 0: iteration 1693/2501 train_loss: 0.9277217388153076 time_taken: 0.0570673942565918\n",
      "Epoch 0: iteration 1694/2501 train_loss: 0.9277811646461487 time_taken: 0.05645132064819336\n",
      "Epoch 0: iteration 1695/2501 train_loss: 0.9278408288955688 time_taken: 0.056550025939941406\n",
      "Epoch 0: iteration 1696/2501 train_loss: 0.9279133677482605 time_taken: 0.05704832077026367\n",
      "Epoch 0: iteration 1697/2501 train_loss: 0.927979588508606 time_taken: 0.05659317970275879\n",
      "Epoch 0: iteration 1698/2501 train_loss: 0.9280366897583008 time_taken: 0.056730031967163086\n",
      "Epoch 0: iteration 1699/2501 train_loss: 0.9280861020088196 time_taken: 0.056716203689575195\n",
      "Epoch 0: iteration 1700/2501 train_loss: 0.9281325936317444 time_taken: 0.05699872970581055\n",
      "Epoch 0: iteration 1701/2501 train_loss: 0.9281867742538452 time_taken: 0.05694890022277832\n",
      "Epoch 0: iteration 1702/2501 train_loss: 0.9282403588294983 time_taken: 0.05607748031616211\n",
      "Epoch 0: iteration 1703/2501 train_loss: 0.9282569885253906 time_taken: 0.05656290054321289\n",
      "Epoch 0: iteration 1704/2501 train_loss: 0.9282892942428589 time_taken: 0.056622982025146484\n",
      "Epoch 0: iteration 1705/2501 train_loss: 0.9282880425453186 time_taken: 0.05638837814331055\n",
      "Epoch 0: iteration 1706/2501 train_loss: 0.9282732605934143 time_taken: 0.056462764739990234\n",
      "Epoch 0: iteration 1707/2501 train_loss: 0.9282494783401489 time_taken: 0.05632376670837402\n",
      "Epoch 0: iteration 1708/2501 train_loss: 0.9282160997390747 time_taken: 0.05672740936279297\n",
      "Epoch 0: iteration 1709/2501 train_loss: 0.9282103776931763 time_taken: 0.05654644966125488\n",
      "Epoch 0: iteration 1710/2501 train_loss: 0.9281830787658691 time_taken: 0.056465864181518555\n",
      "Epoch 0: iteration 1711/2501 train_loss: 0.9281560778617859 time_taken: 0.0558624267578125\n",
      "Epoch 0: iteration 1712/2501 train_loss: 0.9281234741210938 time_taken: 0.056615591049194336\n",
      "Epoch 0: iteration 1713/2501 train_loss: 0.9280722141265869 time_taken: 0.05645346641540527\n",
      "Epoch 0: iteration 1714/2501 train_loss: 0.9280260801315308 time_taken: 0.056455135345458984\n",
      "Epoch 0: iteration 1715/2501 train_loss: 0.9279839396476746 time_taken: 0.06044340133666992\n",
      "Epoch 0: iteration 1716/2501 train_loss: 0.9279356598854065 time_taken: 0.05647754669189453\n",
      "Epoch 0: iteration 1717/2501 train_loss: 0.9278978705406189 time_taken: 0.05648159980773926\n",
      "Epoch 0: iteration 1718/2501 train_loss: 0.9278355240821838 time_taken: 0.05589890480041504\n",
      "Epoch 0: iteration 1719/2501 train_loss: 0.927778422832489 time_taken: 0.056482553482055664\n",
      "Epoch 0: iteration 1720/2501 train_loss: 0.9277336597442627 time_taken: 0.05632758140563965\n",
      "Epoch 0: iteration 1721/2501 train_loss: 0.9276831150054932 time_taken: 0.056661367416381836\n",
      "Epoch 0: iteration 1722/2501 train_loss: 0.927641749382019 time_taken: 0.05652499198913574\n",
      "Epoch 0: iteration 1723/2501 train_loss: 0.9275832176208496 time_taken: 0.05635881423950195\n",
      "Epoch 0: iteration 1724/2501 train_loss: 0.9275305867195129 time_taken: 0.05652117729187012\n",
      "Epoch 0: iteration 1725/2501 train_loss: 0.9274795055389404 time_taken: 0.055948734283447266\n",
      "Epoch 0: iteration 1726/2501 train_loss: 0.9274169206619263 time_taken: 0.05583810806274414\n",
      "Epoch 0: iteration 1727/2501 train_loss: 0.9273589849472046 time_taken: 0.05665111541748047\n",
      "Epoch 0: iteration 1728/2501 train_loss: 0.9273162484169006 time_taken: 0.05698728561401367\n",
      "Epoch 0: iteration 1729/2501 train_loss: 0.9272527694702148 time_taken: 0.056502342224121094\n",
      "Epoch 0: iteration 1730/2501 train_loss: 0.927203893661499 time_taken: 0.05667734146118164\n",
      "Epoch 0: iteration 1731/2501 train_loss: 0.9271625876426697 time_taken: 0.05663132667541504\n",
      "Epoch 0: iteration 1732/2501 train_loss: 0.9271144270896912 time_taken: 0.05648398399353027\n",
      "Epoch 0: iteration 1733/2501 train_loss: 0.9270728230476379 time_taken: 0.05688834190368652\n",
      "Epoch 0: iteration 1734/2501 train_loss: 0.9270226955413818 time_taken: 0.05639076232910156\n",
      "Epoch 0: iteration 1735/2501 train_loss: 0.9269894361495972 time_taken: 0.057404279708862305\n",
      "Epoch 0: iteration 1736/2501 train_loss: 0.9269341826438904 time_taken: 0.05607414245605469\n",
      "Epoch 0: iteration 1737/2501 train_loss: 0.926879346370697 time_taken: 0.05697298049926758\n",
      "Epoch 0: iteration 1738/2501 train_loss: 0.9268313646316528 time_taken: 0.05687713623046875\n",
      "Epoch 0: iteration 1739/2501 train_loss: 0.9267875552177429 time_taken: 0.05759119987487793\n",
      "Epoch 0: iteration 1740/2501 train_loss: 0.9267412424087524 time_taken: 0.05662965774536133\n",
      "Epoch 0: iteration 1741/2501 train_loss: 0.9266918897628784 time_taken: 0.05707287788391113\n",
      "Epoch 0: iteration 1742/2501 train_loss: 0.9266549348831177 time_taken: 0.05687594413757324\n",
      "Epoch 0: iteration 1743/2501 train_loss: 0.9266181588172913 time_taken: 0.06458854675292969\n",
      "Epoch 0: iteration 1744/2501 train_loss: 0.9265782237052917 time_taken: 0.05675959587097168\n",
      "Epoch 0: iteration 1745/2501 train_loss: 0.926544725894928 time_taken: 0.05680370330810547\n",
      "Epoch 0: iteration 1746/2501 train_loss: 0.9265259504318237 time_taken: 0.05669260025024414\n",
      "Epoch 0: iteration 1747/2501 train_loss: 0.9265120029449463 time_taken: 0.05686616897583008\n",
      "Epoch 0: iteration 1748/2501 train_loss: 0.9264987111091614 time_taken: 0.0576479434967041\n",
      "Epoch 0: iteration 1749/2501 train_loss: 0.926487386226654 time_taken: 0.05672860145568848\n",
      "Epoch 0: iteration 1750/2501 train_loss: 0.9264843463897705 time_taken: 0.056915998458862305\n",
      "Epoch 0: iteration 1751/2501 train_loss: 0.9265020489692688 time_taken: 0.05697369575500488\n",
      "Epoch 0: iteration 1752/2501 train_loss: 0.9265120029449463 time_taken: 0.05685305595397949\n",
      "Epoch 0: iteration 1753/2501 train_loss: 0.9265409111976624 time_taken: 0.056546926498413086\n",
      "Epoch 0: iteration 1754/2501 train_loss: 0.9265521764755249 time_taken: 0.05652642250061035\n",
      "Epoch 0: iteration 1755/2501 train_loss: 0.9265817999839783 time_taken: 0.05649280548095703\n",
      "Epoch 0: iteration 1756/2501 train_loss: 0.9266226887702942 time_taken: 0.05724740028381348\n",
      "Epoch 0: iteration 1757/2501 train_loss: 0.9266602396965027 time_taken: 0.05648970603942871\n",
      "Epoch 0: iteration 1758/2501 train_loss: 0.9266924262046814 time_taken: 0.056615352630615234\n",
      "Epoch 0: iteration 1759/2501 train_loss: 0.9267174005508423 time_taken: 0.0561833381652832\n",
      "Epoch 0: iteration 1760/2501 train_loss: 0.9267368316650391 time_taken: 0.05619478225708008\n",
      "Epoch 0: iteration 1761/2501 train_loss: 0.9267455339431763 time_taken: 0.057211875915527344\n",
      "Epoch 0: iteration 1762/2501 train_loss: 0.9267368316650391 time_taken: 0.056371212005615234\n",
      "Epoch 0: iteration 1763/2501 train_loss: 0.9267194271087646 time_taken: 0.05648994445800781\n",
      "Epoch 0: iteration 1764/2501 train_loss: 0.926679790019989 time_taken: 0.05650520324707031\n",
      "Epoch 0: iteration 1765/2501 train_loss: 0.9266198873519897 time_taken: 0.056275129318237305\n",
      "Epoch 0: iteration 1766/2501 train_loss: 0.9265697598457336 time_taken: 0.056189775466918945\n",
      "Epoch 0: iteration 1767/2501 train_loss: 0.926521897315979 time_taken: 0.05654096603393555\n",
      "Epoch 0: iteration 1768/2501 train_loss: 0.9264585971832275 time_taken: 0.05713844299316406\n",
      "Epoch 0: iteration 1769/2501 train_loss: 0.9263979196548462 time_taken: 0.056348562240600586\n",
      "Epoch 0: iteration 1770/2501 train_loss: 0.9263524413108826 time_taken: 0.0567784309387207\n",
      "Epoch 0: iteration 1771/2501 train_loss: 0.9262992739677429 time_taken: 0.05657458305358887\n",
      "Epoch 0: iteration 1772/2501 train_loss: 0.9262428879737854 time_taken: 0.05691409111022949\n",
      "Epoch 0: iteration 1773/2501 train_loss: 0.9261835217475891 time_taken: 0.05653667449951172\n",
      "Epoch 0: iteration 1774/2501 train_loss: 0.9261059165000916 time_taken: 0.05609011650085449\n",
      "Epoch 0: iteration 1775/2501 train_loss: 0.9260214567184448 time_taken: 0.05652046203613281\n",
      "Epoch 0: iteration 1776/2501 train_loss: 0.9259408712387085 time_taken: 0.05710196495056152\n",
      "Epoch 0: iteration 1777/2501 train_loss: 0.9258663058280945 time_taken: 0.05677151679992676\n",
      "Epoch 0: iteration 1778/2501 train_loss: 0.9257844686508179 time_taken: 0.056473493576049805\n",
      "Epoch 0: iteration 1779/2501 train_loss: 0.9257009625434875 time_taken: 0.05666160583496094\n",
      "Epoch 0: iteration 1780/2501 train_loss: 0.9256317019462585 time_taken: 0.05645585060119629\n",
      "Epoch 0: iteration 1781/2501 train_loss: 0.9255471229553223 time_taken: 0.057428836822509766\n",
      "Epoch 0: iteration 1782/2501 train_loss: 0.9254536032676697 time_taken: 0.05640268325805664\n",
      "Epoch 0: iteration 1783/2501 train_loss: 0.9253790974617004 time_taken: 0.0563817024230957\n",
      "Epoch 0: iteration 1784/2501 train_loss: 0.9253185987472534 time_taken: 0.0567631721496582\n",
      "Epoch 0: iteration 1785/2501 train_loss: 0.9252318143844604 time_taken: 0.05626487731933594\n",
      "Epoch 0: iteration 1786/2501 train_loss: 0.9251499176025391 time_taken: 0.05633687973022461\n",
      "Epoch 0: iteration 1787/2501 train_loss: 0.9250737428665161 time_taken: 0.05594611167907715\n",
      "Epoch 0: iteration 1788/2501 train_loss: 0.9250103831291199 time_taken: 0.056704044342041016\n",
      "Epoch 0: iteration 1789/2501 train_loss: 0.9249540567398071 time_taken: 0.05619001388549805\n",
      "Epoch 0: iteration 1790/2501 train_loss: 0.9249115586280823 time_taken: 0.05680108070373535\n",
      "Epoch 0: iteration 1791/2501 train_loss: 0.9248781800270081 time_taken: 0.05681443214416504\n",
      "Epoch 0: iteration 1792/2501 train_loss: 0.9248509407043457 time_taken: 0.05661416053771973\n",
      "Epoch 0: iteration 1793/2501 train_loss: 0.9248384237289429 time_taken: 0.056176185607910156\n",
      "Epoch 0: iteration 1794/2501 train_loss: 0.9248180389404297 time_taken: 0.05662035942077637\n",
      "Epoch 0: iteration 1795/2501 train_loss: 0.9248135685920715 time_taken: 0.056842803955078125\n",
      "Epoch 0: iteration 1796/2501 train_loss: 0.9248111844062805 time_taken: 0.05617666244506836\n",
      "Epoch 0: iteration 1797/2501 train_loss: 0.9248189926147461 time_taken: 0.05660653114318848\n",
      "Epoch 0: iteration 1798/2501 train_loss: 0.9248204827308655 time_taken: 0.05662727355957031\n",
      "Epoch 0: iteration 1799/2501 train_loss: 0.9248143434524536 time_taken: 0.05684399604797363\n",
      "Epoch 0: iteration 1800/2501 train_loss: 0.9248075485229492 time_taken: 0.05623173713684082\n",
      "Epoch 0: iteration 1801/2501 train_loss: 0.9247877597808838 time_taken: 0.061528682708740234\n",
      "Epoch 0: iteration 1802/2501 train_loss: 0.9247554540634155 time_taken: 0.0566253662109375\n",
      "Epoch 0: iteration 1803/2501 train_loss: 0.9247167706489563 time_taken: 0.056633949279785156\n",
      "Epoch 0: iteration 1804/2501 train_loss: 0.9246912002563477 time_taken: 0.057329416275024414\n",
      "Epoch 0: iteration 1805/2501 train_loss: 0.9246588349342346 time_taken: 0.05658292770385742\n",
      "Epoch 0: iteration 1806/2501 train_loss: 0.9246242642402649 time_taken: 0.0563960075378418\n",
      "Epoch 0: iteration 1807/2501 train_loss: 0.9245889782905579 time_taken: 0.05653047561645508\n",
      "Epoch 0: iteration 1808/2501 train_loss: 0.9245305061340332 time_taken: 0.056954383850097656\n",
      "Epoch 0: iteration 1809/2501 train_loss: 0.9244652986526489 time_taken: 0.05671286582946777\n",
      "Epoch 0: iteration 1810/2501 train_loss: 0.9243905544281006 time_taken: 0.05723142623901367\n",
      "Epoch 0: iteration 1811/2501 train_loss: 0.9243230223655701 time_taken: 0.05682182312011719\n",
      "Epoch 0: iteration 1812/2501 train_loss: 0.924252450466156 time_taken: 0.056067705154418945\n",
      "Epoch 0: iteration 1813/2501 train_loss: 0.9241870641708374 time_taken: 0.056548357009887695\n",
      "Epoch 0: iteration 1814/2501 train_loss: 0.9241092801094055 time_taken: 0.056751251220703125\n",
      "Epoch 0: iteration 1815/2501 train_loss: 0.9240168333053589 time_taken: 0.05709123611450195\n",
      "Epoch 0: iteration 1816/2501 train_loss: 0.9239300489425659 time_taken: 0.056900978088378906\n",
      "Epoch 0: iteration 1817/2501 train_loss: 0.9238686561584473 time_taken: 0.05764460563659668\n",
      "Epoch 0: iteration 1818/2501 train_loss: 0.9237989187240601 time_taken: 0.05684542655944824\n",
      "Epoch 0: iteration 1819/2501 train_loss: 0.9237259030342102 time_taken: 0.05698204040527344\n",
      "Epoch 0: iteration 1820/2501 train_loss: 0.9236621856689453 time_taken: 0.056864023208618164\n",
      "Epoch 0: iteration 1821/2501 train_loss: 0.9235922694206238 time_taken: 0.0570833683013916\n",
      "Epoch 0: iteration 1822/2501 train_loss: 0.9235190749168396 time_taken: 0.057279348373413086\n",
      "Epoch 0: iteration 1823/2501 train_loss: 0.9234564304351807 time_taken: 0.05696225166320801\n",
      "Epoch 0: iteration 1824/2501 train_loss: 0.9233987927436829 time_taken: 0.05637788772583008\n",
      "Epoch 0: iteration 1825/2501 train_loss: 0.9233419895172119 time_taken: 0.05708122253417969\n",
      "Epoch 0: iteration 1826/2501 train_loss: 0.923288106918335 time_taken: 0.057306528091430664\n",
      "Epoch 0: iteration 1827/2501 train_loss: 0.9232441782951355 time_taken: 0.056783199310302734\n",
      "Epoch 0: iteration 1828/2501 train_loss: 0.923207700252533 time_taken: 0.0564570426940918\n",
      "Epoch 0: iteration 1829/2501 train_loss: 0.9231708645820618 time_taken: 0.05661463737487793\n",
      "Epoch 0: iteration 1830/2501 train_loss: 0.9231432676315308 time_taken: 0.056241512298583984\n",
      "Epoch 0: iteration 1831/2501 train_loss: 0.9231134653091431 time_taken: 0.0568079948425293\n",
      "Epoch 0: iteration 1832/2501 train_loss: 0.9231044054031372 time_taken: 0.056594133377075195\n",
      "Epoch 0: iteration 1833/2501 train_loss: 0.9230901002883911 time_taken: 0.05693531036376953\n",
      "Epoch 0: iteration 1834/2501 train_loss: 0.9230548739433289 time_taken: 0.05592226982116699\n",
      "Epoch 0: iteration 1835/2501 train_loss: 0.9230347275733948 time_taken: 0.0566554069519043\n",
      "Epoch 0: iteration 1836/2501 train_loss: 0.9230165481567383 time_taken: 0.056809425354003906\n",
      "Epoch 0: iteration 1837/2501 train_loss: 0.9229865074157715 time_taken: 0.057227373123168945\n",
      "Epoch 0: iteration 1838/2501 train_loss: 0.9229783415794373 time_taken: 0.056766510009765625\n",
      "Epoch 0: iteration 1839/2501 train_loss: 0.9229524731636047 time_taken: 0.057630300521850586\n",
      "Epoch 0: iteration 1840/2501 train_loss: 0.9229216575622559 time_taken: 0.05650472640991211\n",
      "Epoch 0: iteration 1841/2501 train_loss: 0.9228871464729309 time_taken: 0.056288719177246094\n",
      "Epoch 0: iteration 1842/2501 train_loss: 0.9228706955909729 time_taken: 0.05637097358703613\n",
      "Epoch 0: iteration 1843/2501 train_loss: 0.9228336215019226 time_taken: 0.05720233917236328\n",
      "Epoch 0: iteration 1844/2501 train_loss: 0.9227946996688843 time_taken: 0.05706000328063965\n",
      "Epoch 0: iteration 1845/2501 train_loss: 0.922761082649231 time_taken: 0.05667710304260254\n",
      "Epoch 0: iteration 1846/2501 train_loss: 0.9227123260498047 time_taken: 0.05634808540344238\n",
      "Epoch 0: iteration 1847/2501 train_loss: 0.9226776957511902 time_taken: 0.05672287940979004\n",
      "Epoch 0: iteration 1848/2501 train_loss: 0.9226324558258057 time_taken: 0.056868553161621094\n",
      "Epoch 0: iteration 1849/2501 train_loss: 0.9225887060165405 time_taken: 0.05675935745239258\n",
      "Epoch 0: iteration 1850/2501 train_loss: 0.9225574135780334 time_taken: 0.05734443664550781\n",
      "Epoch 0: iteration 1851/2501 train_loss: 0.9225146770477295 time_taken: 0.05697298049926758\n",
      "Epoch 0: iteration 1852/2501 train_loss: 0.9224717020988464 time_taken: 0.057909250259399414\n",
      "Epoch 0: iteration 1853/2501 train_loss: 0.9224314093589783 time_taken: 0.05655479431152344\n",
      "Epoch 0: iteration 1854/2501 train_loss: 0.9224016666412354 time_taken: 0.06043362617492676\n",
      "Epoch 0: iteration 1855/2501 train_loss: 0.9223681092262268 time_taken: 0.05596637725830078\n",
      "Epoch 0: iteration 1856/2501 train_loss: 0.9223191738128662 time_taken: 0.05600881576538086\n",
      "Epoch 0: iteration 1857/2501 train_loss: 0.9222952127456665 time_taken: 0.05633401870727539\n",
      "Epoch 0: iteration 1858/2501 train_loss: 0.9222736954689026 time_taken: 0.05728602409362793\n",
      "Epoch 0: iteration 1859/2501 train_loss: 0.9222399592399597 time_taken: 0.056917667388916016\n",
      "Epoch 0: iteration 1860/2501 train_loss: 0.922187089920044 time_taken: 0.056986093521118164\n",
      "Epoch 0: iteration 1861/2501 train_loss: 0.9221276640892029 time_taken: 0.05674314498901367\n",
      "Epoch 0: iteration 1862/2501 train_loss: 0.9220683574676514 time_taken: 0.05721163749694824\n",
      "Epoch 0: iteration 1863/2501 train_loss: 0.9219919443130493 time_taken: 0.056920766830444336\n",
      "Epoch 0: iteration 1864/2501 train_loss: 0.9219192266464233 time_taken: 0.05708670616149902\n",
      "Epoch 0: iteration 1865/2501 train_loss: 0.9218365550041199 time_taken: 0.05707597732543945\n",
      "Epoch 0: iteration 1866/2501 train_loss: 0.9217638969421387 time_taken: 0.057233572006225586\n",
      "Epoch 0: iteration 1867/2501 train_loss: 0.9216996431350708 time_taken: 0.057457685470581055\n",
      "Epoch 0: iteration 1868/2501 train_loss: 0.921637237071991 time_taken: 0.05680656433105469\n",
      "Epoch 0: iteration 1869/2501 train_loss: 0.9215617179870605 time_taken: 0.0571901798248291\n",
      "Epoch 0: iteration 1870/2501 train_loss: 0.9215041399002075 time_taken: 0.05691051483154297\n",
      "Epoch 0: iteration 1871/2501 train_loss: 0.921447217464447 time_taken: 0.05679202079772949\n",
      "Epoch 0: iteration 1872/2501 train_loss: 0.9213870167732239 time_taken: 0.05668997764587402\n",
      "Epoch 0: iteration 1873/2501 train_loss: 0.9213318824768066 time_taken: 0.05715751647949219\n",
      "Epoch 0: iteration 1874/2501 train_loss: 0.9212800860404968 time_taken: 0.058270931243896484\n",
      "Epoch 0: iteration 1875/2501 train_loss: 0.9212363362312317 time_taken: 0.05690431594848633\n",
      "Epoch 0: iteration 1876/2501 train_loss: 0.9212003350257874 time_taken: 0.05681109428405762\n",
      "Epoch 0: iteration 1877/2501 train_loss: 0.9211432337760925 time_taken: 0.06998014450073242\n",
      "Epoch 0: iteration 1878/2501 train_loss: 0.9211007952690125 time_taken: 0.07154583930969238\n",
      "Epoch 0: iteration 1879/2501 train_loss: 0.9210394024848938 time_taken: 0.08194780349731445\n",
      "Epoch 0: iteration 1880/2501 train_loss: 0.9209750294685364 time_taken: 0.05646514892578125\n",
      "Epoch 0: iteration 1881/2501 train_loss: 0.9209060668945312 time_taken: 0.056986093521118164\n",
      "Epoch 0: iteration 1882/2501 train_loss: 0.9208490252494812 time_taken: 0.05681133270263672\n",
      "Epoch 0: iteration 1883/2501 train_loss: 0.9207862615585327 time_taken: 0.05701851844787598\n",
      "Epoch 0: iteration 1884/2501 train_loss: 0.9207397699356079 time_taken: 0.05734109878540039\n",
      "Epoch 0: iteration 1885/2501 train_loss: 0.9206792116165161 time_taken: 0.05649685859680176\n",
      "Epoch 0: iteration 1886/2501 train_loss: 0.9206224083900452 time_taken: 0.05684924125671387\n",
      "Epoch 0: iteration 1887/2501 train_loss: 0.9205542206764221 time_taken: 0.056575775146484375\n",
      "Epoch 0: iteration 1888/2501 train_loss: 0.9204915165901184 time_taken: 0.056853532791137695\n",
      "Epoch 0: iteration 1889/2501 train_loss: 0.9204370379447937 time_taken: 0.057250261306762695\n",
      "Epoch 0: iteration 1890/2501 train_loss: 0.9203702211380005 time_taken: 0.05775809288024902\n",
      "Epoch 0: iteration 1891/2501 train_loss: 0.920307993888855 time_taken: 0.0568234920501709\n",
      "Epoch 0: iteration 1892/2501 train_loss: 0.9202454090118408 time_taken: 0.056860923767089844\n",
      "Epoch 0: iteration 1893/2501 train_loss: 0.9201893210411072 time_taken: 0.05677342414855957\n",
      "Epoch 0: iteration 1894/2501 train_loss: 0.9201705455780029 time_taken: 0.05620455741882324\n",
      "Epoch 0: iteration 1895/2501 train_loss: 0.9201773405075073 time_taken: 0.05691194534301758\n",
      "Epoch 0: iteration 1896/2501 train_loss: 0.9201525449752808 time_taken: 0.05618691444396973\n",
      "Epoch 0: iteration 1897/2501 train_loss: 0.9201313853263855 time_taken: 0.05701327323913574\n",
      "Epoch 0: iteration 1898/2501 train_loss: 0.9200969934463501 time_taken: 0.05708169937133789\n",
      "Epoch 0: iteration 1899/2501 train_loss: 0.9200751185417175 time_taken: 0.05739879608154297\n",
      "Epoch 0: iteration 1900/2501 train_loss: 0.92005455493927 time_taken: 0.05672454833984375\n",
      "Epoch 0: iteration 1901/2501 train_loss: 0.9200074672698975 time_taken: 0.05647706985473633\n",
      "Epoch 0: iteration 1902/2501 train_loss: 0.919971764087677 time_taken: 0.056867122650146484\n",
      "Epoch 0: iteration 1903/2501 train_loss: 0.9199261665344238 time_taken: 0.057366132736206055\n",
      "Epoch 0: iteration 1904/2501 train_loss: 0.9198838472366333 time_taken: 0.056919097900390625\n",
      "Epoch 0: iteration 1905/2501 train_loss: 0.9198366403579712 time_taken: 0.056939125061035156\n",
      "Epoch 0: iteration 1906/2501 train_loss: 0.9197928309440613 time_taken: 0.05688118934631348\n",
      "Epoch 0: iteration 1907/2501 train_loss: 0.9197623133659363 time_taken: 0.05680441856384277\n",
      "Epoch 0: iteration 1908/2501 train_loss: 0.9197329878807068 time_taken: 0.056821346282958984\n",
      "Epoch 0: iteration 1909/2501 train_loss: 0.9197006225585938 time_taken: 0.056793928146362305\n",
      "Epoch 0: iteration 1910/2501 train_loss: 0.9196610450744629 time_taken: 0.05649685859680176\n",
      "Epoch 0: iteration 1911/2501 train_loss: 0.9196186661720276 time_taken: 0.05649161338806152\n",
      "Epoch 0: iteration 1912/2501 train_loss: 0.9195782542228699 time_taken: 0.05678987503051758\n",
      "Epoch 0: iteration 1913/2501 train_loss: 0.9195375442504883 time_taken: 0.05623197555541992\n",
      "Epoch 0: iteration 1914/2501 train_loss: 0.919491708278656 time_taken: 0.05710148811340332\n",
      "Epoch 0: iteration 1915/2501 train_loss: 0.9194480180740356 time_taken: 0.05669403076171875\n",
      "Epoch 0: iteration 1916/2501 train_loss: 0.91941237449646 time_taken: 0.05644369125366211\n",
      "Epoch 0: iteration 1917/2501 train_loss: 0.9193647503852844 time_taken: 0.05631399154663086\n",
      "Epoch 0: iteration 1918/2501 train_loss: 0.919310986995697 time_taken: 0.05782508850097656\n",
      "Epoch 0: iteration 1919/2501 train_loss: 0.9192602038383484 time_taken: 0.056439876556396484\n",
      "Epoch 0: iteration 1920/2501 train_loss: 0.9192243218421936 time_taken: 0.05652618408203125\n",
      "Epoch 0: iteration 1921/2501 train_loss: 0.9191978573799133 time_taken: 0.05668187141418457\n",
      "Epoch 0: iteration 1922/2501 train_loss: 0.9191750288009644 time_taken: 0.05639910697937012\n",
      "Epoch 0: iteration 1923/2501 train_loss: 0.9191709160804749 time_taken: 0.05641365051269531\n",
      "Epoch 0: iteration 1924/2501 train_loss: 0.919169545173645 time_taken: 0.05681157112121582\n",
      "Epoch 0: iteration 1925/2501 train_loss: 0.9191569685935974 time_taken: 0.05683302879333496\n",
      "Epoch 0: iteration 1926/2501 train_loss: 0.9191422462463379 time_taken: 0.05688667297363281\n",
      "Epoch 0: iteration 1927/2501 train_loss: 0.9191150069236755 time_taken: 0.056531667709350586\n",
      "Epoch 0: iteration 1928/2501 train_loss: 0.9190839529037476 time_taken: 0.056722402572631836\n",
      "Epoch 0: iteration 1929/2501 train_loss: 0.9190550446510315 time_taken: 0.05623173713684082\n",
      "Epoch 0: iteration 1930/2501 train_loss: 0.9190271496772766 time_taken: 0.0560450553894043\n",
      "Epoch 0: iteration 1931/2501 train_loss: 0.9190170168876648 time_taken: 0.05730175971984863\n",
      "Epoch 0: iteration 1932/2501 train_loss: 0.9190030097961426 time_taken: 0.05669093132019043\n",
      "Epoch 0: iteration 1933/2501 train_loss: 0.9190042018890381 time_taken: 0.05692243576049805\n",
      "Epoch 0: iteration 1934/2501 train_loss: 0.9190028309822083 time_taken: 0.05641746520996094\n",
      "Epoch 0: iteration 1935/2501 train_loss: 0.9189867973327637 time_taken: 0.05650782585144043\n",
      "Epoch 0: iteration 1936/2501 train_loss: 0.9189573526382446 time_taken: 0.0561063289642334\n",
      "Epoch 0: iteration 1937/2501 train_loss: 0.9189110994338989 time_taken: 0.05633831024169922\n",
      "Epoch 0: iteration 1938/2501 train_loss: 0.9188445210456848 time_taken: 0.05636477470397949\n",
      "Epoch 0: iteration 1939/2501 train_loss: 0.9187756776809692 time_taken: 0.05649423599243164\n",
      "Epoch 0: iteration 1940/2501 train_loss: 0.9187284708023071 time_taken: 0.056128501892089844\n",
      "Epoch 0: iteration 1941/2501 train_loss: 0.9186640977859497 time_taken: 0.05614042282104492\n",
      "Epoch 0: iteration 1942/2501 train_loss: 0.9185911417007446 time_taken: 0.05672597885131836\n",
      "Epoch 0: iteration 1943/2501 train_loss: 0.9185097813606262 time_taken: 0.05657386779785156\n",
      "Epoch 0: iteration 1944/2501 train_loss: 0.9184284806251526 time_taken: 0.07157731056213379\n",
      "Epoch 0: iteration 1945/2501 train_loss: 0.9183303117752075 time_taken: 0.05590081214904785\n",
      "Epoch 0: iteration 1946/2501 train_loss: 0.9182361364364624 time_taken: 0.0561976432800293\n",
      "Epoch 0: iteration 1947/2501 train_loss: 0.9181426167488098 time_taken: 0.05620002746582031\n",
      "Epoch 0: iteration 1948/2501 train_loss: 0.9180432558059692 time_taken: 0.056212425231933594\n",
      "Epoch 0: iteration 1949/2501 train_loss: 0.9179498553276062 time_taken: 0.05647540092468262\n",
      "Epoch 0: iteration 1950/2501 train_loss: 0.9178540110588074 time_taken: 0.05649304389953613\n",
      "Epoch 0: iteration 1951/2501 train_loss: 0.9177677631378174 time_taken: 0.05634617805480957\n",
      "Epoch 0: iteration 1952/2501 train_loss: 0.9176795482635498 time_taken: 0.05661463737487793\n",
      "Epoch 0: iteration 1953/2501 train_loss: 0.917599081993103 time_taken: 0.05661129951477051\n",
      "Epoch 0: iteration 1954/2501 train_loss: 0.9175323843955994 time_taken: 0.05687141418457031\n",
      "Epoch 0: iteration 1955/2501 train_loss: 0.917451024055481 time_taken: 0.05687355995178223\n",
      "Epoch 0: iteration 1956/2501 train_loss: 0.9173863530158997 time_taken: 0.05751347541809082\n",
      "Epoch 0: iteration 1957/2501 train_loss: 0.9173077940940857 time_taken: 0.05659914016723633\n",
      "Epoch 0: iteration 1958/2501 train_loss: 0.9172330498695374 time_taken: 0.05623745918273926\n",
      "Epoch 0: iteration 1959/2501 train_loss: 0.9171580672264099 time_taken: 0.05610537528991699\n",
      "Epoch 0: iteration 1960/2501 train_loss: 0.9170800447463989 time_taken: 0.056256771087646484\n",
      "Epoch 0: iteration 1961/2501 train_loss: 0.9169941544532776 time_taken: 0.05682516098022461\n",
      "Epoch 0: iteration 1962/2501 train_loss: 0.916900634765625 time_taken: 0.0571286678314209\n",
      "Epoch 0: iteration 1963/2501 train_loss: 0.9168190956115723 time_taken: 0.05626058578491211\n",
      "Epoch 0: iteration 1964/2501 train_loss: 0.9167422652244568 time_taken: 0.05655670166015625\n",
      "Epoch 0: iteration 1965/2501 train_loss: 0.9166628122329712 time_taken: 0.05683135986328125\n",
      "Epoch 0: iteration 1966/2501 train_loss: 0.916578471660614 time_taken: 0.05642199516296387\n",
      "Epoch 0: iteration 1967/2501 train_loss: 0.9164829850196838 time_taken: 0.05647087097167969\n",
      "Epoch 0: iteration 1968/2501 train_loss: 0.9164025783538818 time_taken: 0.057091712951660156\n",
      "Epoch 0: iteration 1969/2501 train_loss: 0.9163210988044739 time_taken: 0.05621194839477539\n",
      "Epoch 0: iteration 1970/2501 train_loss: 0.9162423610687256 time_taken: 0.05677461624145508\n",
      "Epoch 0: iteration 1971/2501 train_loss: 0.9161542057991028 time_taken: 0.05621647834777832\n",
      "Epoch 0: iteration 1972/2501 train_loss: 0.9160885214805603 time_taken: 0.05687069892883301\n",
      "Epoch 0: iteration 1973/2501 train_loss: 0.9160129427909851 time_taken: 0.056681156158447266\n",
      "Epoch 0: iteration 1974/2501 train_loss: 0.9159514904022217 time_taken: 0.05647635459899902\n",
      "Epoch 0: iteration 1975/2501 train_loss: 0.9159044623374939 time_taken: 0.057492733001708984\n",
      "Epoch 0: iteration 1976/2501 train_loss: 0.9158512949943542 time_taken: 0.05665254592895508\n",
      "Epoch 0: iteration 1977/2501 train_loss: 0.9157954454421997 time_taken: 0.056488990783691406\n",
      "Epoch 0: iteration 1978/2501 train_loss: 0.915736198425293 time_taken: 0.05642843246459961\n",
      "Epoch 0: iteration 1979/2501 train_loss: 0.91568922996521 time_taken: 0.05611109733581543\n",
      "Epoch 0: iteration 1980/2501 train_loss: 0.9156169295310974 time_taken: 0.056997060775756836\n",
      "Epoch 0: iteration 1981/2501 train_loss: 0.9155568480491638 time_taken: 0.05685091018676758\n",
      "Epoch 0: iteration 1982/2501 train_loss: 0.915485680103302 time_taken: 0.05715656280517578\n",
      "Epoch 0: iteration 1983/2501 train_loss: 0.9154396057128906 time_taken: 0.05738377571105957\n",
      "Epoch 0: iteration 1984/2501 train_loss: 0.9153974056243896 time_taken: 0.056444406509399414\n",
      "Epoch 0: iteration 1985/2501 train_loss: 0.9153327941894531 time_taken: 0.05679821968078613\n",
      "Epoch 0: iteration 1986/2501 train_loss: 0.9152774214744568 time_taken: 0.05724692344665527\n",
      "Epoch 0: iteration 1987/2501 train_loss: 0.9152143001556396 time_taken: 0.057120561599731445\n",
      "Epoch 0: iteration 1988/2501 train_loss: 0.9151367545127869 time_taken: 0.056208133697509766\n",
      "Epoch 0: iteration 1989/2501 train_loss: 0.9150553941726685 time_taken: 0.05670809745788574\n",
      "Epoch 0: iteration 1990/2501 train_loss: 0.9149711728096008 time_taken: 0.05633258819580078\n",
      "Epoch 0: iteration 1991/2501 train_loss: 0.9148745536804199 time_taken: 0.056670188903808594\n",
      "Epoch 0: iteration 1992/2501 train_loss: 0.9147821068763733 time_taken: 0.05676412582397461\n",
      "Epoch 0: iteration 1993/2501 train_loss: 0.9147205948829651 time_taken: 0.05631113052368164\n",
      "Epoch 0: iteration 1994/2501 train_loss: 0.9146689176559448 time_taken: 0.056908369064331055\n",
      "Epoch 0: iteration 1995/2501 train_loss: 0.914604902267456 time_taken: 0.05679178237915039\n",
      "Epoch 0: iteration 1996/2501 train_loss: 0.9145374894142151 time_taken: 0.05684161186218262\n",
      "Epoch 0: iteration 1997/2501 train_loss: 0.9144716858863831 time_taken: 0.05697917938232422\n",
      "Epoch 0: iteration 1998/2501 train_loss: 0.9144102931022644 time_taken: 0.05696582794189453\n",
      "Epoch 0: iteration 1999/2501 train_loss: 0.9143531322479248 time_taken: 0.05617260932922363\n",
      "Epoch 0: iteration 2000/2501 train_loss: 0.9142778515815735 time_taken: 0.05702018737792969\n",
      "Epoch 0: iteration 2001/2501 train_loss: 0.9142084717750549 time_taken: 0.05692911148071289\n",
      "Epoch 0: iteration 2002/2501 train_loss: 0.9141260385513306 time_taken: 0.05632185935974121\n",
      "Epoch 0: iteration 2003/2501 train_loss: 0.9140406847000122 time_taken: 0.05707859992980957\n",
      "Epoch 0: iteration 2004/2501 train_loss: 0.9139695763587952 time_taken: 0.05670285224914551\n",
      "Epoch 0: iteration 2005/2501 train_loss: 0.913894772529602 time_taken: 0.056500911712646484\n",
      "Epoch 0: iteration 2006/2501 train_loss: 0.9138261079788208 time_taken: 0.05649232864379883\n",
      "Epoch 0: iteration 2007/2501 train_loss: 0.9137609601020813 time_taken: 0.05647921562194824\n",
      "Epoch 0: iteration 2008/2501 train_loss: 0.913706362247467 time_taken: 0.0566713809967041\n",
      "Epoch 0: iteration 2009/2501 train_loss: 0.9136553406715393 time_taken: 0.05624675750732422\n",
      "Epoch 0: iteration 2010/2501 train_loss: 0.9136154055595398 time_taken: 0.056986093521118164\n",
      "Epoch 0: iteration 2011/2501 train_loss: 0.9135902523994446 time_taken: 0.05654430389404297\n",
      "Epoch 0: iteration 2012/2501 train_loss: 0.9135565161705017 time_taken: 0.056054115295410156\n",
      "Epoch 0: iteration 2013/2501 train_loss: 0.9135364890098572 time_taken: 0.05737757682800293\n",
      "Epoch 0: iteration 2014/2501 train_loss: 0.913508415222168 time_taken: 0.05731821060180664\n",
      "Epoch 0: iteration 2015/2501 train_loss: 0.9134724140167236 time_taken: 0.05715441703796387\n",
      "Epoch 0: iteration 2016/2501 train_loss: 0.913429319858551 time_taken: 0.05685615539550781\n",
      "Epoch 0: iteration 2017/2501 train_loss: 0.9134042263031006 time_taken: 0.056787967681884766\n",
      "Epoch 0: iteration 2018/2501 train_loss: 0.9133805632591248 time_taken: 0.05734515190124512\n",
      "Epoch 0: iteration 2019/2501 train_loss: 0.9133351445198059 time_taken: 0.05634307861328125\n",
      "Epoch 0: iteration 2020/2501 train_loss: 0.9133031368255615 time_taken: 0.057656288146972656\n",
      "Epoch 0: iteration 2021/2501 train_loss: 0.9132704138755798 time_taken: 0.056640625\n",
      "Epoch 0: iteration 2022/2501 train_loss: 0.9132301211357117 time_taken: 0.05717897415161133\n",
      "Epoch 0: iteration 2023/2501 train_loss: 0.9131771922111511 time_taken: 0.056435346603393555\n",
      "Epoch 0: iteration 2024/2501 train_loss: 0.9131273627281189 time_taken: 0.057669878005981445\n",
      "Epoch 0: iteration 2025/2501 train_loss: 0.9130733609199524 time_taken: 0.057698965072631836\n",
      "Epoch 0: iteration 2026/2501 train_loss: 0.9130210280418396 time_taken: 0.056973934173583984\n",
      "Epoch 0: iteration 2027/2501 train_loss: 0.912971556186676 time_taken: 0.05679488182067871\n",
      "Epoch 0: iteration 2028/2501 train_loss: 0.9129155278205872 time_taken: 0.05661416053771973\n",
      "Epoch 0: iteration 2029/2501 train_loss: 0.9128773212432861 time_taken: 0.05653023719787598\n",
      "Epoch 0: iteration 2030/2501 train_loss: 0.9128360152244568 time_taken: 0.05654716491699219\n",
      "Epoch 0: iteration 2031/2501 train_loss: 0.9128026366233826 time_taken: 0.05634737014770508\n",
      "Epoch 0: iteration 2032/2501 train_loss: 0.9127795100212097 time_taken: 0.0566859245300293\n",
      "Epoch 0: iteration 2033/2501 train_loss: 0.9127511382102966 time_taken: 0.05756425857543945\n",
      "Epoch 0: iteration 2034/2501 train_loss: 0.9127301573753357 time_taken: 0.05734610557556152\n",
      "Epoch 0: iteration 2035/2501 train_loss: 0.9127159714698792 time_taken: 0.05677032470703125\n",
      "Epoch 0: iteration 2036/2501 train_loss: 0.9126984477043152 time_taken: 0.05705595016479492\n",
      "Epoch 0: iteration 2037/2501 train_loss: 0.9126958847045898 time_taken: 0.057219505310058594\n",
      "Epoch 0: iteration 2038/2501 train_loss: 0.9126833081245422 time_taken: 0.05679965019226074\n",
      "Epoch 0: iteration 2039/2501 train_loss: 0.91267329454422 time_taken: 0.05654478073120117\n",
      "Epoch 0: iteration 2040/2501 train_loss: 0.912667453289032 time_taken: 0.07277250289916992\n",
      "Epoch 0: iteration 2041/2501 train_loss: 0.9126827716827393 time_taken: 0.11178112030029297\n",
      "Epoch 0: iteration 2042/2501 train_loss: 0.9126858115196228 time_taken: 0.056421518325805664\n",
      "Epoch 0: iteration 2043/2501 train_loss: 0.9126853346824646 time_taken: 0.056023359298706055\n",
      "Epoch 0: iteration 2044/2501 train_loss: 0.9126608371734619 time_taken: 0.05627274513244629\n",
      "Epoch 0: iteration 2045/2501 train_loss: 0.9126399755477905 time_taken: 0.056534528732299805\n",
      "Epoch 0: iteration 2046/2501 train_loss: 0.9125967621803284 time_taken: 0.05721783638000488\n",
      "Epoch 0: iteration 2047/2501 train_loss: 0.912554144859314 time_taken: 0.05691361427307129\n",
      "Epoch 0: iteration 2048/2501 train_loss: 0.912499725818634 time_taken: 0.056676626205444336\n",
      "Epoch 0: iteration 2049/2501 train_loss: 0.9124639630317688 time_taken: 0.056672096252441406\n",
      "Epoch 0: iteration 2050/2501 train_loss: 0.9124224185943604 time_taken: 0.05721449851989746\n",
      "Epoch 0: iteration 2051/2501 train_loss: 0.9123892188072205 time_taken: 0.05621004104614258\n",
      "Epoch 0: iteration 2052/2501 train_loss: 0.9123542308807373 time_taken: 0.056919097900390625\n",
      "Epoch 0: iteration 2053/2501 train_loss: 0.9123010039329529 time_taken: 0.05643343925476074\n",
      "Epoch 0: iteration 2054/2501 train_loss: 0.9122421145439148 time_taken: 0.05704164505004883\n",
      "Epoch 0: iteration 2055/2501 train_loss: 0.9121875762939453 time_taken: 0.05680584907531738\n",
      "Epoch 0: iteration 2056/2501 train_loss: 0.9121400713920593 time_taken: 0.05640435218811035\n",
      "Epoch 0: iteration 2057/2501 train_loss: 0.912091076374054 time_taken: 0.05639481544494629\n",
      "Epoch 0: iteration 2058/2501 train_loss: 0.9120272397994995 time_taken: 0.0565037727355957\n",
      "Epoch 0: iteration 2059/2501 train_loss: 0.9119660258293152 time_taken: 0.06317377090454102\n",
      "Epoch 0: iteration 2060/2501 train_loss: 0.9119014739990234 time_taken: 0.05643272399902344\n",
      "Epoch 0: iteration 2061/2501 train_loss: 0.9118282794952393 time_taken: 0.056490421295166016\n",
      "Epoch 0: iteration 2062/2501 train_loss: 0.9117687940597534 time_taken: 0.05644392967224121\n",
      "Epoch 0: iteration 2063/2501 train_loss: 0.9117432832717896 time_taken: 0.05600380897521973\n",
      "Epoch 0: iteration 2064/2501 train_loss: 0.9117163419723511 time_taken: 0.05632209777832031\n",
      "Epoch 0: iteration 2065/2501 train_loss: 0.9116989374160767 time_taken: 0.05613899230957031\n",
      "Epoch 0: iteration 2066/2501 train_loss: 0.9116846323013306 time_taken: 0.05629754066467285\n",
      "Epoch 0: iteration 2067/2501 train_loss: 0.9116557240486145 time_taken: 0.05647158622741699\n",
      "Epoch 0: iteration 2068/2501 train_loss: 0.9116247892379761 time_taken: 0.05620980262756348\n",
      "Epoch 0: iteration 2069/2501 train_loss: 0.9115784764289856 time_taken: 0.0559844970703125\n",
      "Epoch 0: iteration 2070/2501 train_loss: 0.9115351438522339 time_taken: 0.05583071708679199\n",
      "Epoch 0: iteration 2071/2501 train_loss: 0.911490797996521 time_taken: 0.05652904510498047\n",
      "Epoch 0: iteration 2072/2501 train_loss: 0.9114406704902649 time_taken: 0.05743002891540527\n",
      "Epoch 0: iteration 2073/2501 train_loss: 0.9113740921020508 time_taken: 0.05718803405761719\n",
      "Epoch 0: iteration 2074/2501 train_loss: 0.9113156795501709 time_taken: 0.05668020248413086\n",
      "Epoch 0: iteration 2075/2501 train_loss: 0.9112493991851807 time_taken: 0.05719470977783203\n",
      "Epoch 0: iteration 2076/2501 train_loss: 0.9111906290054321 time_taken: 0.057511091232299805\n",
      "Epoch 0: iteration 2077/2501 train_loss: 0.9111335277557373 time_taken: 0.05759072303771973\n",
      "Epoch 0: iteration 2078/2501 train_loss: 0.9110793471336365 time_taken: 0.057936668395996094\n",
      "Epoch 0: iteration 2079/2501 train_loss: 0.9110236763954163 time_taken: 0.05771231651306152\n",
      "Epoch 0: iteration 2080/2501 train_loss: 0.910971462726593 time_taken: 0.05709981918334961\n",
      "Epoch 0: iteration 2081/2501 train_loss: 0.9109093546867371 time_taken: 0.05693840980529785\n",
      "Epoch 0: iteration 2082/2501 train_loss: 0.9108759760856628 time_taken: 0.05666708946228027\n",
      "Epoch 0: iteration 2083/2501 train_loss: 0.9108375906944275 time_taken: 0.057060956954956055\n",
      "Epoch 0: iteration 2084/2501 train_loss: 0.9107860922813416 time_taken: 0.05705690383911133\n",
      "Epoch 0: iteration 2085/2501 train_loss: 0.9107153415679932 time_taken: 0.0575406551361084\n",
      "Epoch 0: iteration 2086/2501 train_loss: 0.9106557369232178 time_taken: 0.05666208267211914\n",
      "Epoch 0: iteration 2087/2501 train_loss: 0.9105995893478394 time_taken: 0.056775808334350586\n",
      "Epoch 0: iteration 2088/2501 train_loss: 0.9105371832847595 time_taken: 0.062497854232788086\n",
      "Epoch 0: iteration 2089/2501 train_loss: 0.9104716181755066 time_taken: 0.05687427520751953\n",
      "Epoch 0: iteration 2090/2501 train_loss: 0.9104105234146118 time_taken: 0.05678868293762207\n",
      "Epoch 0: iteration 2091/2501 train_loss: 0.9103441834449768 time_taken: 0.05713534355163574\n",
      "Epoch 0: iteration 2092/2501 train_loss: 0.9102863669395447 time_taken: 0.057147979736328125\n",
      "Epoch 0: iteration 2093/2501 train_loss: 0.9102063775062561 time_taken: 0.057355403900146484\n",
      "Epoch 0: iteration 2094/2501 train_loss: 0.9101357460021973 time_taken: 0.05772280693054199\n",
      "Epoch 0: iteration 2095/2501 train_loss: 0.9100644588470459 time_taken: 0.05695509910583496\n",
      "Epoch 0: iteration 2096/2501 train_loss: 0.9100019335746765 time_taken: 0.05715322494506836\n",
      "Epoch 0: iteration 2097/2501 train_loss: 0.9099352359771729 time_taken: 0.0568845272064209\n",
      "Epoch 0: iteration 2098/2501 train_loss: 0.9098738431930542 time_taken: 0.05705070495605469\n",
      "Epoch 0: iteration 2099/2501 train_loss: 0.9098085761070251 time_taken: 0.05698370933532715\n",
      "Epoch 0: iteration 2100/2501 train_loss: 0.9097476005554199 time_taken: 0.0571291446685791\n",
      "Epoch 0: iteration 2101/2501 train_loss: 0.9097067713737488 time_taken: 0.05697774887084961\n",
      "Epoch 0: iteration 2102/2501 train_loss: 0.9096553325653076 time_taken: 0.05697369575500488\n",
      "Epoch 0: iteration 2103/2501 train_loss: 0.9096112847328186 time_taken: 0.0569920539855957\n",
      "Epoch 0: iteration 2104/2501 train_loss: 0.909553587436676 time_taken: 0.05716729164123535\n",
      "Epoch 0: iteration 2105/2501 train_loss: 0.9094818234443665 time_taken: 0.05663347244262695\n",
      "Epoch 0: iteration 2106/2501 train_loss: 0.9094089269638062 time_taken: 0.05694842338562012\n",
      "Epoch 0: iteration 2107/2501 train_loss: 0.9093568325042725 time_taken: 0.08049750328063965\n",
      "Epoch 0: iteration 2108/2501 train_loss: 0.9092944264411926 time_taken: 0.07073521614074707\n",
      "Epoch 0: iteration 2109/2501 train_loss: 0.9092205166816711 time_taken: 0.05743575096130371\n",
      "Epoch 0: iteration 2110/2501 train_loss: 0.909147322177887 time_taken: 0.05670499801635742\n",
      "Epoch 0: iteration 2111/2501 train_loss: 0.9090863466262817 time_taken: 0.05675339698791504\n",
      "Epoch 0: iteration 2112/2501 train_loss: 0.9090076088905334 time_taken: 0.056305885314941406\n",
      "Epoch 0: iteration 2113/2501 train_loss: 0.9089426398277283 time_taken: 0.056696414947509766\n",
      "Epoch 0: iteration 2114/2501 train_loss: 0.9088847637176514 time_taken: 0.05602908134460449\n",
      "Epoch 0: iteration 2115/2501 train_loss: 0.9088377952575684 time_taken: 0.05606961250305176\n",
      "Epoch 0: iteration 2116/2501 train_loss: 0.9088099598884583 time_taken: 0.056438446044921875\n",
      "Epoch 0: iteration 2117/2501 train_loss: 0.9087581634521484 time_taken: 0.056218862533569336\n",
      "Epoch 0: iteration 2118/2501 train_loss: 0.9087033867835999 time_taken: 0.05620884895324707\n",
      "Epoch 0: iteration 2119/2501 train_loss: 0.908646285533905 time_taken: 0.05628180503845215\n",
      "Epoch 0: iteration 2120/2501 train_loss: 0.9085784554481506 time_taken: 0.05699419975280762\n",
      "Epoch 0: iteration 2121/2501 train_loss: 0.9085250496864319 time_taken: 0.05710649490356445\n",
      "Epoch 0: iteration 2122/2501 train_loss: 0.9084800481796265 time_taken: 0.05663180351257324\n",
      "Epoch 0: iteration 2123/2501 train_loss: 0.9084298014640808 time_taken: 0.057238101959228516\n",
      "Epoch 0: iteration 2124/2501 train_loss: 0.9083966612815857 time_taken: 0.05698442459106445\n",
      "Epoch 0: iteration 2125/2501 train_loss: 0.9083471894264221 time_taken: 0.057100772857666016\n",
      "Epoch 0: iteration 2126/2501 train_loss: 0.9083152413368225 time_taken: 0.05724668502807617\n",
      "Epoch 0: iteration 2127/2501 train_loss: 0.9082663059234619 time_taken: 0.05691885948181152\n",
      "Epoch 0: iteration 2128/2501 train_loss: 0.9082134962081909 time_taken: 0.0571749210357666\n",
      "Epoch 0: iteration 2129/2501 train_loss: 0.9081674814224243 time_taken: 0.05841779708862305\n",
      "Epoch 0: iteration 2130/2501 train_loss: 0.908123791217804 time_taken: 0.05769491195678711\n",
      "Epoch 0: iteration 2131/2501 train_loss: 0.9080716371536255 time_taken: 0.056699275970458984\n",
      "Epoch 0: iteration 2132/2501 train_loss: 0.9080368876457214 time_taken: 0.0565180778503418\n",
      "Epoch 0: iteration 2133/2501 train_loss: 0.9079996347427368 time_taken: 0.057272911071777344\n",
      "Epoch 0: iteration 2134/2501 train_loss: 0.9079669713973999 time_taken: 0.056594133377075195\n",
      "Epoch 0: iteration 2135/2501 train_loss: 0.9079458117485046 time_taken: 0.05678391456604004\n",
      "Epoch 0: iteration 2136/2501 train_loss: 0.907913863658905 time_taken: 0.0568699836730957\n",
      "Epoch 0: iteration 2137/2501 train_loss: 0.9078854918479919 time_taken: 0.05715179443359375\n",
      "Epoch 0: iteration 2138/2501 train_loss: 0.9078711867332458 time_taken: 0.056539297103881836\n",
      "Epoch 0: iteration 2139/2501 train_loss: 0.9078483581542969 time_taken: 0.05602598190307617\n",
      "Epoch 0: iteration 2140/2501 train_loss: 0.9078414440155029 time_taken: 0.056260108947753906\n",
      "Epoch 0: iteration 2141/2501 train_loss: 0.9078138470649719 time_taken: 0.0560452938079834\n",
      "Epoch 0: iteration 2142/2501 train_loss: 0.9078115820884705 time_taken: 0.056087493896484375\n",
      "Epoch 0: iteration 2143/2501 train_loss: 0.9078004956245422 time_taken: 0.05632376670837402\n",
      "Epoch 0: iteration 2144/2501 train_loss: 0.9077970385551453 time_taken: 0.05617856979370117\n",
      "Epoch 0: iteration 2145/2501 train_loss: 0.9077751636505127 time_taken: 0.05707263946533203\n",
      "Epoch 0: iteration 2146/2501 train_loss: 0.9077610373497009 time_taken: 0.05710005760192871\n",
      "Epoch 0: iteration 2147/2501 train_loss: 0.9077605605125427 time_taken: 0.05621838569641113\n",
      "Epoch 0: iteration 2148/2501 train_loss: 0.9077416062355042 time_taken: 0.05666160583496094\n",
      "Epoch 0: iteration 2149/2501 train_loss: 0.9077251553535461 time_taken: 0.057238101959228516\n",
      "Epoch 0: iteration 2150/2501 train_loss: 0.9077082872390747 time_taken: 0.05700349807739258\n",
      "Epoch 0: iteration 2151/2501 train_loss: 0.9077053070068359 time_taken: 0.05666542053222656\n",
      "Epoch 0: iteration 2152/2501 train_loss: 0.9077073335647583 time_taken: 0.05675792694091797\n",
      "Epoch 0: iteration 2153/2501 train_loss: 0.9077083468437195 time_taken: 0.05688023567199707\n",
      "Epoch 0: iteration 2154/2501 train_loss: 0.907715916633606 time_taken: 0.0567171573638916\n",
      "Epoch 0: iteration 2155/2501 train_loss: 0.9077244997024536 time_taken: 0.05662655830383301\n",
      "Epoch 0: iteration 2156/2501 train_loss: 0.9077210426330566 time_taken: 0.056694984436035156\n",
      "Epoch 0: iteration 2157/2501 train_loss: 0.9077085852622986 time_taken: 0.056578636169433594\n",
      "Epoch 0: iteration 2158/2501 train_loss: 0.907708466053009 time_taken: 0.0562138557434082\n",
      "Epoch 0: iteration 2159/2501 train_loss: 0.9077362418174744 time_taken: 0.05665922164916992\n",
      "Epoch 0: iteration 2160/2501 train_loss: 0.9077752828598022 time_taken: 0.05683135986328125\n",
      "Epoch 0: iteration 2161/2501 train_loss: 0.9077945947647095 time_taken: 0.05633854866027832\n",
      "Epoch 0: iteration 2162/2501 train_loss: 0.9078149199485779 time_taken: 0.05608940124511719\n",
      "Epoch 0: iteration 2163/2501 train_loss: 0.9078083634376526 time_taken: 0.05704331398010254\n",
      "Epoch 0: iteration 2164/2501 train_loss: 0.9077966809272766 time_taken: 0.056165456771850586\n",
      "Epoch 0: iteration 2165/2501 train_loss: 0.907775342464447 time_taken: 0.0561671257019043\n",
      "Epoch 0: iteration 2166/2501 train_loss: 0.9077723026275635 time_taken: 0.05608677864074707\n",
      "Epoch 0: iteration 2167/2501 train_loss: 0.9077622890472412 time_taken: 0.05663180351257324\n",
      "Epoch 0: iteration 2168/2501 train_loss: 0.907737672328949 time_taken: 0.056154727935791016\n",
      "Epoch 0: iteration 2169/2501 train_loss: 0.9077130556106567 time_taken: 0.05607914924621582\n",
      "Epoch 0: iteration 2170/2501 train_loss: 0.9076682329177856 time_taken: 0.0563807487487793\n",
      "Epoch 0: iteration 2171/2501 train_loss: 0.9076139330863953 time_taken: 0.05597352981567383\n",
      "Epoch 0: iteration 2172/2501 train_loss: 0.9075619578361511 time_taken: 0.05620718002319336\n",
      "Epoch 0: iteration 2173/2501 train_loss: 0.9075077176094055 time_taken: 0.056618452072143555\n",
      "Epoch 0: iteration 2174/2501 train_loss: 0.9074434041976929 time_taken: 0.056437015533447266\n",
      "Epoch 0: iteration 2175/2501 train_loss: 0.9073843359947205 time_taken: 0.056267738342285156\n",
      "Epoch 0: iteration 2176/2501 train_loss: 0.9073114395141602 time_taken: 0.0564730167388916\n",
      "Epoch 0: iteration 2177/2501 train_loss: 0.9072405099868774 time_taken: 0.05620908737182617\n",
      "Epoch 0: iteration 2178/2501 train_loss: 0.9071677327156067 time_taken: 0.05743598937988281\n",
      "Epoch 0: iteration 2179/2501 train_loss: 0.9070975184440613 time_taken: 0.05653095245361328\n",
      "Epoch 0: iteration 2180/2501 train_loss: 0.907016932964325 time_taken: 0.05994296073913574\n",
      "Epoch 0: iteration 2181/2501 train_loss: 0.9069377183914185 time_taken: 0.056302547454833984\n",
      "Epoch 0: iteration 2182/2501 train_loss: 0.9068928956985474 time_taken: 0.05681490898132324\n",
      "Epoch 0: iteration 2183/2501 train_loss: 0.9069128632545471 time_taken: 0.05695319175720215\n",
      "Epoch 0: iteration 2184/2501 train_loss: 0.9070205688476562 time_taken: 0.05797266960144043\n",
      "Epoch 0: iteration 2185/2501 train_loss: 0.9069947600364685 time_taken: 0.056668758392333984\n",
      "Epoch 0: iteration 2186/2501 train_loss: 0.9070212244987488 time_taken: 0.057660818099975586\n",
      "Epoch 0: iteration 2187/2501 train_loss: 0.9070075154304504 time_taken: 0.05681586265563965\n",
      "Epoch 0: iteration 2188/2501 train_loss: 0.9070248007774353 time_taken: 0.056813955307006836\n",
      "Epoch 0: iteration 2189/2501 train_loss: 0.9070062041282654 time_taken: 0.05597853660583496\n",
      "Epoch 0: iteration 2190/2501 train_loss: 0.9070218801498413 time_taken: 0.05717873573303223\n",
      "Epoch 0: iteration 2191/2501 train_loss: 0.9069891571998596 time_taken: 0.05675649642944336\n",
      "Epoch 0: iteration 2192/2501 train_loss: 0.9069582223892212 time_taken: 0.05652880668640137\n",
      "Epoch 0: iteration 2193/2501 train_loss: 0.9069095849990845 time_taken: 0.05633950233459473\n",
      "Epoch 0: iteration 2194/2501 train_loss: 0.9068288207054138 time_taken: 0.05705428123474121\n",
      "Epoch 0: iteration 2195/2501 train_loss: 0.9067535400390625 time_taken: 0.05707597732543945\n",
      "Epoch 0: iteration 2196/2501 train_loss: 0.9066545367240906 time_taken: 0.05663275718688965\n",
      "Epoch 0: iteration 2197/2501 train_loss: 0.906559944152832 time_taken: 0.05733537673950195\n",
      "Epoch 0: iteration 2198/2501 train_loss: 0.9064523577690125 time_taken: 0.05701017379760742\n",
      "Epoch 0: iteration 2199/2501 train_loss: 0.9063507914543152 time_taken: 0.05697011947631836\n",
      "Epoch 0: iteration 2200/2501 train_loss: 0.9062415361404419 time_taken: 0.057190656661987305\n",
      "Epoch 0: iteration 2201/2501 train_loss: 0.9061203598976135 time_taken: 0.0568695068359375\n",
      "Epoch 0: iteration 2202/2501 train_loss: 0.9060093760490417 time_taken: 0.05728268623352051\n",
      "Epoch 0: iteration 2203/2501 train_loss: 0.9058749675750732 time_taken: 0.05784177780151367\n",
      "Epoch 0: iteration 2204/2501 train_loss: 0.9057567119598389 time_taken: 0.05669903755187988\n",
      "Epoch 0: iteration 2205/2501 train_loss: 0.905646800994873 time_taken: 0.057335615158081055\n",
      "Epoch 0: iteration 2206/2501 train_loss: 0.9055271744728088 time_taken: 0.05629539489746094\n",
      "Epoch 0: iteration 2207/2501 train_loss: 0.905418872833252 time_taken: 0.056472063064575195\n",
      "Epoch 0: iteration 2208/2501 train_loss: 0.9053190350532532 time_taken: 0.05657243728637695\n",
      "Epoch 0: iteration 2209/2501 train_loss: 0.9052176475524902 time_taken: 0.056937217712402344\n",
      "Epoch 0: iteration 2210/2501 train_loss: 0.9051333665847778 time_taken: 0.05663037300109863\n",
      "Epoch 0: iteration 2211/2501 train_loss: 0.9050634503364563 time_taken: 0.05744457244873047\n",
      "Epoch 0: iteration 2212/2501 train_loss: 0.9050052762031555 time_taken: 0.05664181709289551\n",
      "Epoch 0: iteration 2213/2501 train_loss: 0.9049692153930664 time_taken: 0.05758523941040039\n",
      "Epoch 0: iteration 2214/2501 train_loss: 0.9049347639083862 time_taken: 0.0677635669708252\n",
      "Epoch 0: iteration 2215/2501 train_loss: 0.9049023389816284 time_taken: 0.05698537826538086\n",
      "Epoch 0: iteration 2216/2501 train_loss: 0.9048699736595154 time_taken: 0.05715060234069824\n",
      "Epoch 0: iteration 2217/2501 train_loss: 0.9048370122909546 time_taken: 0.056529998779296875\n",
      "Epoch 0: iteration 2218/2501 train_loss: 0.9048255085945129 time_taken: 0.05628323554992676\n",
      "Epoch 0: iteration 2219/2501 train_loss: 0.9048153162002563 time_taken: 0.056221723556518555\n",
      "Epoch 0: iteration 2220/2501 train_loss: 0.9047821760177612 time_taken: 0.05652666091918945\n",
      "Epoch 0: iteration 2221/2501 train_loss: 0.9047428965568542 time_taken: 0.056249380111694336\n",
      "Epoch 0: iteration 2222/2501 train_loss: 0.9047178626060486 time_taken: 0.056285858154296875\n",
      "Epoch 0: iteration 2223/2501 train_loss: 0.9046998023986816 time_taken: 0.05668330192565918\n",
      "Epoch 0: iteration 2224/2501 train_loss: 0.9046768546104431 time_taken: 0.05626726150512695\n",
      "Epoch 0: iteration 2225/2501 train_loss: 0.9046551585197449 time_taken: 0.05730724334716797\n",
      "Epoch 0: iteration 2226/2501 train_loss: 0.9046359062194824 time_taken: 0.056952476501464844\n",
      "Epoch 0: iteration 2227/2501 train_loss: 0.9046136736869812 time_taken: 0.05699419975280762\n",
      "Epoch 0: iteration 2228/2501 train_loss: 0.9046118855476379 time_taken: 0.057476043701171875\n",
      "Epoch 0: iteration 2229/2501 train_loss: 0.9045981764793396 time_taken: 0.05696845054626465\n",
      "Epoch 0: iteration 2230/2501 train_loss: 0.9045835733413696 time_taken: 0.05739927291870117\n",
      "Epoch 0: iteration 2231/2501 train_loss: 0.9045588374137878 time_taken: 0.05632209777832031\n",
      "Epoch 0: iteration 2232/2501 train_loss: 0.9045501351356506 time_taken: 0.05683422088623047\n",
      "Epoch 0: iteration 2233/2501 train_loss: 0.9045368432998657 time_taken: 0.056793212890625\n",
      "Epoch 0: iteration 2234/2501 train_loss: 0.9045066237449646 time_taken: 0.057088375091552734\n",
      "Epoch 0: iteration 2235/2501 train_loss: 0.9044789671897888 time_taken: 0.05722975730895996\n",
      "Epoch 0: iteration 2236/2501 train_loss: 0.904455304145813 time_taken: 0.05665397644042969\n",
      "Epoch 0: iteration 2237/2501 train_loss: 0.9044220447540283 time_taken: 0.05718255043029785\n",
      "Epoch 0: iteration 2238/2501 train_loss: 0.9043954610824585 time_taken: 0.05625104904174805\n",
      "Epoch 0: iteration 2239/2501 train_loss: 0.9043802618980408 time_taken: 0.05656099319458008\n",
      "Epoch 0: iteration 2240/2501 train_loss: 0.9043692350387573 time_taken: 0.05644989013671875\n",
      "Epoch 0: iteration 2241/2501 train_loss: 0.9043570756912231 time_taken: 0.0562591552734375\n",
      "Epoch 0: iteration 2242/2501 train_loss: 0.9043551087379456 time_taken: 0.0569610595703125\n",
      "Epoch 0: iteration 2243/2501 train_loss: 0.9043307900428772 time_taken: 0.057086944580078125\n",
      "Epoch 0: iteration 2244/2501 train_loss: 0.904302179813385 time_taken: 0.05655622482299805\n",
      "Epoch 0: iteration 2245/2501 train_loss: 0.9042819142341614 time_taken: 0.05680418014526367\n",
      "Epoch 0: iteration 2246/2501 train_loss: 0.9042847752571106 time_taken: 0.05648183822631836\n",
      "Epoch 0: iteration 2247/2501 train_loss: 0.9042660593986511 time_taken: 0.05698204040527344\n",
      "Epoch 0: iteration 2248/2501 train_loss: 0.9042519927024841 time_taken: 0.05630016326904297\n",
      "Epoch 0: iteration 2249/2501 train_loss: 0.904253363609314 time_taken: 0.0563352108001709\n",
      "Epoch 0: iteration 2250/2501 train_loss: 0.9042497873306274 time_taken: 0.05614304542541504\n",
      "Epoch 0: iteration 2251/2501 train_loss: 0.9042359590530396 time_taken: 0.0561985969543457\n",
      "Epoch 0: iteration 2252/2501 train_loss: 0.9042266607284546 time_taken: 0.05612444877624512\n",
      "Epoch 0: iteration 2253/2501 train_loss: 0.9042247533798218 time_taken: 0.05612659454345703\n",
      "Epoch 0: iteration 2254/2501 train_loss: 0.9042196273803711 time_taken: 0.05733680725097656\n",
      "Epoch 0: iteration 2255/2501 train_loss: 0.9042173027992249 time_taken: 0.05624580383300781\n",
      "Epoch 0: iteration 2256/2501 train_loss: 0.9042187929153442 time_taken: 0.05650591850280762\n",
      "Epoch 0: iteration 2257/2501 train_loss: 0.9042201638221741 time_taken: 0.05711245536804199\n",
      "Epoch 0: iteration 2258/2501 train_loss: 0.9042225480079651 time_taken: 0.05659627914428711\n",
      "Epoch 0: iteration 2259/2501 train_loss: 0.9042192101478577 time_taken: 0.056440114974975586\n",
      "Epoch 0: iteration 2260/2501 train_loss: 0.9042220115661621 time_taken: 0.056036949157714844\n",
      "Epoch 0: iteration 2261/2501 train_loss: 0.9042321443557739 time_taken: 0.05656790733337402\n",
      "Epoch 0: iteration 2262/2501 train_loss: 0.9042395353317261 time_taken: 0.056551218032836914\n",
      "Epoch 0: iteration 2263/2501 train_loss: 0.9042423963546753 time_taken: 0.05691075325012207\n",
      "Epoch 0: iteration 2264/2501 train_loss: 0.9042631387710571 time_taken: 0.0565950870513916\n",
      "Epoch 0: iteration 2265/2501 train_loss: 0.9042851328849792 time_taken: 0.0559999942779541\n",
      "Epoch 0: iteration 2266/2501 train_loss: 0.9043068885803223 time_taken: 0.05629730224609375\n",
      "Epoch 0: iteration 2267/2501 train_loss: 0.904322624206543 time_taken: 0.05684542655944824\n",
      "Epoch 0: iteration 2268/2501 train_loss: 0.9043293595314026 time_taken: 0.05605435371398926\n",
      "Epoch 0: iteration 2269/2501 train_loss: 0.9043304324150085 time_taken: 0.05638241767883301\n",
      "Epoch 0: iteration 2270/2501 train_loss: 0.904331386089325 time_taken: 0.056333065032958984\n",
      "Epoch 0: iteration 2271/2501 train_loss: 0.904326319694519 time_taken: 0.056482553482055664\n",
      "Epoch 0: iteration 2272/2501 train_loss: 0.9043108224868774 time_taken: 0.05624532699584961\n",
      "Epoch 0: iteration 2273/2501 train_loss: 0.9042933583259583 time_taken: 0.05613422393798828\n",
      "Epoch 0: iteration 2274/2501 train_loss: 0.9042667150497437 time_taken: 0.05643415451049805\n",
      "Epoch 0: iteration 2275/2501 train_loss: 0.904238224029541 time_taken: 0.05672121047973633\n",
      "Epoch 0: iteration 2276/2501 train_loss: 0.9042215943336487 time_taken: 0.0561976432800293\n",
      "Epoch 0: iteration 2277/2501 train_loss: 0.9042027592658997 time_taken: 0.055975914001464844\n",
      "Epoch 0: iteration 2278/2501 train_loss: 0.9041704535484314 time_taken: 0.05652213096618652\n",
      "Epoch 0: iteration 2279/2501 train_loss: 0.9041550755500793 time_taken: 0.05598902702331543\n",
      "Epoch 0: iteration 2280/2501 train_loss: 0.904132604598999 time_taken: 0.05614757537841797\n",
      "Epoch 0: iteration 2281/2501 train_loss: 0.9041137099266052 time_taken: 0.05617880821228027\n",
      "Epoch 0: iteration 2282/2501 train_loss: 0.9040871858596802 time_taken: 0.05675077438354492\n",
      "Epoch 0: iteration 2283/2501 train_loss: 0.9040574431419373 time_taken: 0.0563359260559082\n",
      "Epoch 0: iteration 2284/2501 train_loss: 0.9040266871452332 time_taken: 0.05702614784240723\n",
      "Epoch 0: iteration 2285/2501 train_loss: 0.9039994478225708 time_taken: 0.05635523796081543\n",
      "Epoch 0: iteration 2286/2501 train_loss: 0.9039751291275024 time_taken: 0.05666708946228027\n",
      "Epoch 0: iteration 2287/2501 train_loss: 0.9039620161056519 time_taken: 0.056731224060058594\n",
      "Epoch 0: iteration 2288/2501 train_loss: 0.9039509892463684 time_taken: 0.05630326271057129\n",
      "Epoch 0: iteration 2289/2501 train_loss: 0.9039466381072998 time_taken: 0.05669999122619629\n",
      "Epoch 0: iteration 2290/2501 train_loss: 0.9039506316184998 time_taken: 0.05625629425048828\n",
      "Epoch 0: iteration 2291/2501 train_loss: 0.9039535522460938 time_taken: 0.05696249008178711\n",
      "Epoch 0: iteration 2292/2501 train_loss: 0.9039682149887085 time_taken: 0.05721855163574219\n",
      "Epoch 0: iteration 2293/2501 train_loss: 0.9039826989173889 time_taken: 0.05623817443847656\n",
      "Epoch 0: iteration 2294/2501 train_loss: 0.9039818644523621 time_taken: 0.05706000328063965\n",
      "Epoch 0: iteration 2295/2501 train_loss: 0.9039910435676575 time_taken: 0.05637025833129883\n",
      "Epoch 0: iteration 2296/2501 train_loss: 0.903985857963562 time_taken: 0.056366682052612305\n",
      "Epoch 0: iteration 2297/2501 train_loss: 0.9039747714996338 time_taken: 0.05639910697937012\n",
      "Epoch 0: iteration 2298/2501 train_loss: 0.9039565324783325 time_taken: 0.05642843246459961\n",
      "Epoch 0: iteration 2299/2501 train_loss: 0.9039226174354553 time_taken: 0.05660080909729004\n",
      "Epoch 0: iteration 2300/2501 train_loss: 0.9039081335067749 time_taken: 0.05628681182861328\n",
      "Epoch 0: iteration 2301/2501 train_loss: 0.9038853645324707 time_taken: 0.05631375312805176\n",
      "Epoch 0: iteration 2302/2501 train_loss: 0.903859555721283 time_taken: 0.05664968490600586\n",
      "Epoch 0: iteration 2303/2501 train_loss: 0.9038248062133789 time_taken: 0.0562748908996582\n",
      "Epoch 0: iteration 2304/2501 train_loss: 0.9037922024726868 time_taken: 0.05761146545410156\n",
      "Epoch 0: iteration 2305/2501 train_loss: 0.9037529230117798 time_taken: 0.058240652084350586\n",
      "Epoch 0: iteration 2306/2501 train_loss: 0.9037097692489624 time_taken: 0.05698728561401367\n",
      "Epoch 0: iteration 2307/2501 train_loss: 0.9036546945571899 time_taken: 0.05733299255371094\n",
      "Epoch 0: iteration 2308/2501 train_loss: 0.9036182761192322 time_taken: 0.056198835372924805\n",
      "Epoch 0: iteration 2309/2501 train_loss: 0.9035868644714355 time_taken: 0.057260990142822266\n",
      "Epoch 0: iteration 2310/2501 train_loss: 0.9035549163818359 time_taken: 0.05660223960876465\n",
      "Epoch 0: iteration 2311/2501 train_loss: 0.9035282135009766 time_taken: 0.05650806427001953\n",
      "Epoch 0: iteration 2312/2501 train_loss: 0.90351802110672 time_taken: 0.0568692684173584\n",
      "Epoch 0: iteration 2313/2501 train_loss: 0.9035081267356873 time_taken: 0.05652666091918945\n",
      "Epoch 0: iteration 2314/2501 train_loss: 0.9034897089004517 time_taken: 0.0566403865814209\n",
      "Epoch 0: iteration 2315/2501 train_loss: 0.9034590125083923 time_taken: 0.05675697326660156\n",
      "Epoch 0: iteration 2316/2501 train_loss: 0.9034230709075928 time_taken: 0.056154727935791016\n",
      "Epoch 0: iteration 2317/2501 train_loss: 0.9034006595611572 time_taken: 0.05613088607788086\n",
      "Epoch 0: iteration 2318/2501 train_loss: 0.9033635854721069 time_taken: 0.0563812255859375\n",
      "Epoch 0: iteration 2319/2501 train_loss: 0.9033348560333252 time_taken: 0.056160688400268555\n",
      "Epoch 0: iteration 2320/2501 train_loss: 0.9033111333847046 time_taken: 0.0564725399017334\n",
      "Epoch 0: iteration 2321/2501 train_loss: 0.9032672047615051 time_taken: 0.05624055862426758\n",
      "Epoch 0: iteration 2322/2501 train_loss: 0.9032202363014221 time_taken: 0.057068586349487305\n",
      "Epoch 0: iteration 2323/2501 train_loss: 0.9031763672828674 time_taken: 0.056343793869018555\n",
      "Epoch 0: iteration 2324/2501 train_loss: 0.9031252861022949 time_taken: 0.0575871467590332\n",
      "Epoch 0: iteration 2325/2501 train_loss: 0.9030961990356445 time_taken: 0.05611991882324219\n",
      "Epoch 0: iteration 2326/2501 train_loss: 0.9030851125717163 time_taken: 0.06456494331359863\n",
      "Epoch 0: iteration 2327/2501 train_loss: 0.9030877351760864 time_taken: 0.056133270263671875\n",
      "Epoch 0: iteration 2328/2501 train_loss: 0.903103232383728 time_taken: 0.05621814727783203\n",
      "Epoch 0: iteration 2329/2501 train_loss: 0.9031338095664978 time_taken: 0.05663943290710449\n",
      "Epoch 0: iteration 2330/2501 train_loss: 0.9031845927238464 time_taken: 0.05717015266418457\n",
      "Epoch 0: iteration 2331/2501 train_loss: 0.9032318592071533 time_taken: 0.057241201400756836\n",
      "Epoch 0: iteration 2332/2501 train_loss: 0.9032936096191406 time_taken: 0.05647134780883789\n",
      "Epoch 0: iteration 2333/2501 train_loss: 0.9033631086349487 time_taken: 0.05739188194274902\n",
      "Epoch 0: iteration 2334/2501 train_loss: 0.9034233093261719 time_taken: 0.05658125877380371\n",
      "Epoch 0: iteration 2335/2501 train_loss: 0.9034634828567505 time_taken: 0.05621600151062012\n",
      "Epoch 0: iteration 2336/2501 train_loss: 0.9035065770149231 time_taken: 0.05634880065917969\n",
      "Epoch 0: iteration 2337/2501 train_loss: 0.9035394191741943 time_taken: 0.05755782127380371\n",
      "Epoch 0: iteration 2338/2501 train_loss: 0.9035789370536804 time_taken: 0.05703425407409668\n",
      "Epoch 0: iteration 2339/2501 train_loss: 0.9036221504211426 time_taken: 0.05778622627258301\n",
      "Epoch 0: iteration 2340/2501 train_loss: 0.9036515355110168 time_taken: 0.05640864372253418\n",
      "Epoch 0: iteration 2341/2501 train_loss: 0.9036692976951599 time_taken: 0.056733131408691406\n",
      "Epoch 0: iteration 2342/2501 train_loss: 0.9036968946456909 time_taken: 0.057122230529785156\n",
      "Epoch 0: iteration 2343/2501 train_loss: 0.9037076830863953 time_taken: 0.05671429634094238\n",
      "Epoch 0: iteration 2344/2501 train_loss: 0.9037147760391235 time_taken: 0.0566248893737793\n",
      "Epoch 0: iteration 2345/2501 train_loss: 0.9037084579467773 time_taken: 0.056118011474609375\n",
      "Epoch 0: iteration 2346/2501 train_loss: 0.9036720991134644 time_taken: 0.05639481544494629\n",
      "Epoch 0: iteration 2347/2501 train_loss: 0.9036421179771423 time_taken: 0.05632376670837402\n",
      "Epoch 0: iteration 2348/2501 train_loss: 0.9036122560501099 time_taken: 0.05680203437805176\n",
      "Epoch 0: iteration 2349/2501 train_loss: 0.9035887718200684 time_taken: 0.056915998458862305\n",
      "Epoch 0: iteration 2350/2501 train_loss: 0.9035623669624329 time_taken: 0.05670356750488281\n",
      "Epoch 0: iteration 2351/2501 train_loss: 0.9035343527793884 time_taken: 0.056420087814331055\n",
      "Epoch 0: iteration 2352/2501 train_loss: 0.9034898281097412 time_taken: 0.057778120040893555\n",
      "Epoch 0: iteration 2353/2501 train_loss: 0.9034290909767151 time_taken: 0.05734705924987793\n",
      "Epoch 0: iteration 2354/2501 train_loss: 0.9033735990524292 time_taken: 0.056563615798950195\n",
      "Epoch 0: iteration 2355/2501 train_loss: 0.9032982587814331 time_taken: 0.05639767646789551\n",
      "Epoch 0: iteration 2356/2501 train_loss: 0.903225839138031 time_taken: 0.05649685859680176\n",
      "Epoch 0: iteration 2357/2501 train_loss: 0.9031448364257812 time_taken: 0.056070566177368164\n",
      "Epoch 0: iteration 2358/2501 train_loss: 0.9030553698539734 time_taken: 0.05624032020568848\n",
      "Epoch 0: iteration 2359/2501 train_loss: 0.9029615521430969 time_taken: 0.055852413177490234\n",
      "Epoch 0: iteration 2360/2501 train_loss: 0.9028628468513489 time_taken: 0.05643868446350098\n",
      "Epoch 0: iteration 2361/2501 train_loss: 0.9027531743049622 time_taken: 0.05782485008239746\n",
      "Epoch 0: iteration 2362/2501 train_loss: 0.902640163898468 time_taken: 0.05633854866027832\n",
      "Epoch 0: iteration 2363/2501 train_loss: 0.9025358557701111 time_taken: 0.05639171600341797\n",
      "Epoch 0: iteration 2364/2501 train_loss: 0.9024324417114258 time_taken: 0.05629563331604004\n",
      "Epoch 0: iteration 2365/2501 train_loss: 0.9023375511169434 time_taken: 0.056661367416381836\n",
      "Epoch 0: iteration 2366/2501 train_loss: 0.9022310972213745 time_taken: 0.056667327880859375\n",
      "Epoch 0: iteration 2367/2501 train_loss: 0.9021199941635132 time_taken: 0.05666041374206543\n",
      "Epoch 0: iteration 2368/2501 train_loss: 0.9020203351974487 time_taken: 0.0566105842590332\n",
      "Epoch 0: iteration 2369/2501 train_loss: 0.9019065499305725 time_taken: 0.05687832832336426\n",
      "Epoch 0: iteration 2370/2501 train_loss: 0.9017923474311829 time_taken: 0.05659985542297363\n",
      "Epoch 0: iteration 2371/2501 train_loss: 0.9017015099525452 time_taken: 0.056890010833740234\n",
      "Epoch 0: iteration 2372/2501 train_loss: 0.9016022682189941 time_taken: 0.056490421295166016\n",
      "Epoch 0: iteration 2373/2501 train_loss: 0.9015083909034729 time_taken: 0.05635666847229004\n",
      "Epoch 0: iteration 2374/2501 train_loss: 0.9014095664024353 time_taken: 0.05638742446899414\n",
      "Epoch 0: iteration 2375/2501 train_loss: 0.9013063311576843 time_taken: 0.056221723556518555\n",
      "Epoch 0: iteration 2376/2501 train_loss: 0.901197612285614 time_taken: 0.056267499923706055\n",
      "Epoch 0: iteration 2377/2501 train_loss: 0.901095449924469 time_taken: 0.05643892288208008\n",
      "Epoch 0: iteration 2378/2501 train_loss: 0.9009989500045776 time_taken: 0.056054115295410156\n",
      "Epoch 0: iteration 2379/2501 train_loss: 0.9009020924568176 time_taken: 0.056257009506225586\n",
      "Epoch 0: iteration 2380/2501 train_loss: 0.9008104205131531 time_taken: 0.0560150146484375\n",
      "Epoch 0: iteration 2381/2501 train_loss: 0.9007376432418823 time_taken: 0.05720043182373047\n",
      "Epoch 0: iteration 2382/2501 train_loss: 0.9006564021110535 time_taken: 0.05631542205810547\n",
      "Epoch 0: iteration 2383/2501 train_loss: 0.9005542993545532 time_taken: 0.05625605583190918\n",
      "Epoch 0: iteration 2384/2501 train_loss: 0.9004834890365601 time_taken: 0.05606198310852051\n",
      "Epoch 0: iteration 2385/2501 train_loss: 0.9004324674606323 time_taken: 0.05646324157714844\n",
      "Epoch 0: iteration 2386/2501 train_loss: 0.9003840684890747 time_taken: 0.056243896484375\n",
      "Epoch 0: iteration 2387/2501 train_loss: 0.900346040725708 time_taken: 0.05663609504699707\n",
      "Epoch 0: iteration 2388/2501 train_loss: 0.9003174304962158 time_taken: 0.056754350662231445\n",
      "Epoch 0: iteration 2389/2501 train_loss: 0.9003100395202637 time_taken: 0.05610179901123047\n",
      "Epoch 0: iteration 2390/2501 train_loss: 0.9003028273582458 time_taken: 0.08255910873413086\n",
      "Epoch 0: iteration 2391/2501 train_loss: 0.9003282785415649 time_taken: 0.056806087493896484\n",
      "Epoch 0: iteration 2392/2501 train_loss: 0.9003453254699707 time_taken: 0.0565338134765625\n",
      "Epoch 0: iteration 2393/2501 train_loss: 0.9003670811653137 time_taken: 0.05637168884277344\n",
      "Epoch 0: iteration 2394/2501 train_loss: 0.9004067182540894 time_taken: 0.056198835372924805\n",
      "Epoch 0: iteration 2395/2501 train_loss: 0.9004423022270203 time_taken: 0.05733060836791992\n",
      "Epoch 0: iteration 2396/2501 train_loss: 0.9004939794540405 time_taken: 0.05660867691040039\n",
      "Epoch 0: iteration 2397/2501 train_loss: 0.9005343914031982 time_taken: 0.0563359260559082\n",
      "Epoch 0: iteration 2398/2501 train_loss: 0.9005832672119141 time_taken: 0.057060956954956055\n",
      "Epoch 0: iteration 2399/2501 train_loss: 0.9005962014198303 time_taken: 0.05638837814331055\n",
      "Epoch 0: iteration 2400/2501 train_loss: 0.9005950093269348 time_taken: 0.05628561973571777\n",
      "Epoch 0: iteration 2401/2501 train_loss: 0.9005955457687378 time_taken: 0.05646872520446777\n",
      "Epoch 0: iteration 2402/2501 train_loss: 0.9005834460258484 time_taken: 0.056603431701660156\n",
      "Epoch 0: iteration 2403/2501 train_loss: 0.9005802273750305 time_taken: 0.05697154998779297\n",
      "Epoch 0: iteration 2404/2501 train_loss: 0.9005537629127502 time_taken: 0.05669808387756348\n",
      "Epoch 0: iteration 2405/2501 train_loss: 0.9005275368690491 time_taken: 0.061743974685668945\n",
      "Epoch 0: iteration 2406/2501 train_loss: 0.9004978537559509 time_taken: 0.05722665786743164\n",
      "Epoch 0: iteration 2407/2501 train_loss: 0.9004668593406677 time_taken: 0.05740666389465332\n",
      "Epoch 0: iteration 2408/2501 train_loss: 0.9004379510879517 time_taken: 0.056870460510253906\n",
      "Epoch 0: iteration 2409/2501 train_loss: 0.900408148765564 time_taken: 0.05650186538696289\n",
      "Epoch 0: iteration 2410/2501 train_loss: 0.9003791809082031 time_taken: 0.05659008026123047\n",
      "Epoch 0: iteration 2411/2501 train_loss: 0.9003486037254333 time_taken: 0.05810284614562988\n",
      "Epoch 0: iteration 2412/2501 train_loss: 0.9003252387046814 time_taken: 0.05648517608642578\n",
      "Epoch 0: iteration 2413/2501 train_loss: 0.9002825021743774 time_taken: 0.057073354721069336\n",
      "Epoch 0: iteration 2414/2501 train_loss: 0.9002528190612793 time_taken: 0.05678081512451172\n",
      "Epoch 0: iteration 2415/2501 train_loss: 0.9002249240875244 time_taken: 0.05676078796386719\n",
      "Epoch 0: iteration 2416/2501 train_loss: 0.9002053737640381 time_taken: 0.05757474899291992\n",
      "Epoch 0: iteration 2417/2501 train_loss: 0.9001908302307129 time_taken: 0.05619621276855469\n",
      "Epoch 0: iteration 2418/2501 train_loss: 0.9001591801643372 time_taken: 0.05683732032775879\n",
      "Epoch 0: iteration 2419/2501 train_loss: 0.9001449942588806 time_taken: 0.05753159523010254\n",
      "Epoch 0: iteration 2420/2501 train_loss: 0.9001163244247437 time_taken: 0.05712485313415527\n",
      "Epoch 0: iteration 2421/2501 train_loss: 0.9000988006591797 time_taken: 0.05734658241271973\n",
      "Epoch 0: iteration 2422/2501 train_loss: 0.9000803828239441 time_taken: 0.05723881721496582\n",
      "Epoch 0: iteration 2423/2501 train_loss: 0.9000548124313354 time_taken: 0.057268381118774414\n",
      "Epoch 0: iteration 2424/2501 train_loss: 0.9000242352485657 time_taken: 0.05703258514404297\n",
      "Epoch 0: iteration 2425/2501 train_loss: 0.899991512298584 time_taken: 0.05692577362060547\n",
      "Epoch 0: iteration 2426/2501 train_loss: 0.8999550342559814 time_taken: 0.05636191368103027\n",
      "Epoch 0: iteration 2427/2501 train_loss: 0.899928867816925 time_taken: 0.05684518814086914\n",
      "Epoch 0: iteration 2428/2501 train_loss: 0.8999125957489014 time_taken: 0.05663561820983887\n",
      "Epoch 0: iteration 2429/2501 train_loss: 0.8998839855194092 time_taken: 0.0562591552734375\n",
      "Epoch 0: iteration 2430/2501 train_loss: 0.8998470902442932 time_taken: 0.0560915470123291\n",
      "Epoch 0: iteration 2431/2501 train_loss: 0.8998238444328308 time_taken: 0.05818963050842285\n",
      "Epoch 0: iteration 2432/2501 train_loss: 0.8997944593429565 time_taken: 0.05707526206970215\n",
      "Epoch 0: iteration 2433/2501 train_loss: 0.8997649550437927 time_taken: 0.05635499954223633\n",
      "Epoch 0: iteration 2434/2501 train_loss: 0.899740993976593 time_taken: 0.056832075119018555\n",
      "Epoch 0: iteration 2435/2501 train_loss: 0.8997243642807007 time_taken: 0.056681156158447266\n",
      "Epoch 0: iteration 2436/2501 train_loss: 0.8997083902359009 time_taken: 0.056673288345336914\n",
      "Epoch 0: iteration 2437/2501 train_loss: 0.8996952772140503 time_taken: 0.05640053749084473\n",
      "Epoch 0: iteration 2438/2501 train_loss: 0.8996837139129639 time_taken: 0.05656266212463379\n",
      "Epoch 0: iteration 2439/2501 train_loss: 0.8996767997741699 time_taken: 0.05623674392700195\n",
      "Epoch 0: iteration 2440/2501 train_loss: 0.8996748328208923 time_taken: 0.056034088134765625\n",
      "Epoch 0: iteration 2441/2501 train_loss: 0.8996692895889282 time_taken: 0.05616426467895508\n",
      "Epoch 0: iteration 2442/2501 train_loss: 0.8996515870094299 time_taken: 0.05651283264160156\n",
      "Epoch 0: iteration 2443/2501 train_loss: 0.8996255397796631 time_taken: 0.05585193634033203\n",
      "Epoch 0: iteration 2444/2501 train_loss: 0.8996193408966064 time_taken: 0.05595898628234863\n",
      "Epoch 0: iteration 2445/2501 train_loss: 0.8996172547340393 time_taken: 0.05602455139160156\n",
      "Epoch 0: iteration 2446/2501 train_loss: 0.8995997309684753 time_taken: 0.05655264854431152\n",
      "Epoch 0: iteration 2447/2501 train_loss: 0.8995596766471863 time_taken: 0.05608034133911133\n",
      "Epoch 0: iteration 2448/2501 train_loss: 0.8995326161384583 time_taken: 0.056558847427368164\n",
      "Epoch 0: iteration 2449/2501 train_loss: 0.8994834423065186 time_taken: 0.05595088005065918\n",
      "Epoch 0: iteration 2450/2501 train_loss: 0.8994414806365967 time_taken: 0.057337284088134766\n",
      "Epoch 0: iteration 2451/2501 train_loss: 0.8993843793869019 time_taken: 0.05637979507446289\n",
      "Epoch 0: iteration 2452/2501 train_loss: 0.8993269801139832 time_taken: 0.05630183219909668\n",
      "Epoch 0: iteration 2453/2501 train_loss: 0.8992757797241211 time_taken: 0.056676626205444336\n",
      "Epoch 0: iteration 2454/2501 train_loss: 0.8992131948471069 time_taken: 0.05617713928222656\n",
      "Epoch 0: iteration 2455/2501 train_loss: 0.8991560935974121 time_taken: 0.0560147762298584\n",
      "Epoch 0: iteration 2456/2501 train_loss: 0.8990869522094727 time_taken: 0.056458234786987305\n",
      "Epoch 0: iteration 2457/2501 train_loss: 0.899015486240387 time_taken: 0.05583906173706055\n",
      "Epoch 0: iteration 2458/2501 train_loss: 0.8989523649215698 time_taken: 0.056391000747680664\n",
      "Epoch 0: iteration 2459/2501 train_loss: 0.8988819122314453 time_taken: 0.055890798568725586\n",
      "Epoch 0: iteration 2460/2501 train_loss: 0.8988035917282104 time_taken: 0.06059718132019043\n",
      "Epoch 0: iteration 2461/2501 train_loss: 0.898738443851471 time_taken: 0.05674099922180176\n",
      "Epoch 0: iteration 2462/2501 train_loss: 0.8986714482307434 time_taken: 0.05590391159057617\n",
      "Epoch 0: iteration 2463/2501 train_loss: 0.8986195921897888 time_taken: 0.0561830997467041\n",
      "Epoch 0: iteration 2464/2501 train_loss: 0.8985564708709717 time_taken: 0.056227684020996094\n",
      "Epoch 0: iteration 2465/2501 train_loss: 0.8985050320625305 time_taken: 0.056697845458984375\n",
      "Epoch 0: iteration 2466/2501 train_loss: 0.8984501957893372 time_taken: 0.05629420280456543\n",
      "Epoch 0: iteration 2467/2501 train_loss: 0.8984070420265198 time_taken: 0.05710124969482422\n",
      "Epoch 0: iteration 2468/2501 train_loss: 0.8983638286590576 time_taken: 0.05685997009277344\n",
      "Epoch 0: iteration 2469/2501 train_loss: 0.8983206748962402 time_taken: 0.0566558837890625\n",
      "Epoch 0: iteration 2470/2501 train_loss: 0.8982943296432495 time_taken: 0.05629992485046387\n",
      "Epoch 0: iteration 2471/2501 train_loss: 0.8982710838317871 time_taken: 0.05668759346008301\n",
      "Epoch 0: iteration 2472/2501 train_loss: 0.8982518911361694 time_taken: 0.05651688575744629\n",
      "Epoch 0: iteration 2473/2501 train_loss: 0.8982282876968384 time_taken: 0.056830644607543945\n",
      "Epoch 0: iteration 2474/2501 train_loss: 0.8982179164886475 time_taken: 0.057851314544677734\n",
      "Epoch 0: iteration 2475/2501 train_loss: 0.8982066512107849 time_taken: 0.05708765983581543\n",
      "Epoch 0: iteration 2476/2501 train_loss: 0.8981874585151672 time_taken: 0.05662655830383301\n",
      "Epoch 0: iteration 2477/2501 train_loss: 0.8981636762619019 time_taken: 0.05697894096374512\n",
      "Epoch 0: iteration 2478/2501 train_loss: 0.8981465101242065 time_taken: 0.057352304458618164\n",
      "Epoch 0: iteration 2479/2501 train_loss: 0.8981191515922546 time_taken: 0.05666399002075195\n",
      "Epoch 0: iteration 2480/2501 train_loss: 0.898095428943634 time_taken: 0.056682586669921875\n",
      "Epoch 0: iteration 2481/2501 train_loss: 0.8980749249458313 time_taken: 0.05684351921081543\n",
      "Epoch 0: iteration 2482/2501 train_loss: 0.8980500102043152 time_taken: 0.056650400161743164\n",
      "Epoch 0: iteration 2483/2501 train_loss: 0.8980290293693542 time_taken: 0.057245731353759766\n",
      "Epoch 0: iteration 2484/2501 train_loss: 0.8979960680007935 time_taken: 0.05722999572753906\n",
      "Epoch 0: iteration 2485/2501 train_loss: 0.8979769945144653 time_taken: 0.05763673782348633\n",
      "Epoch 0: iteration 2486/2501 train_loss: 0.8979695439338684 time_taken: 0.05692768096923828\n",
      "Epoch 0: iteration 2487/2501 train_loss: 0.8979582190513611 time_taken: 0.07283854484558105\n",
      "Epoch 0: iteration 2488/2501 train_loss: 0.8979467749595642 time_taken: 0.055899620056152344\n",
      "Epoch 0: iteration 2489/2501 train_loss: 0.8979312777519226 time_taken: 0.05601048469543457\n",
      "Epoch 0: iteration 2490/2501 train_loss: 0.8979198336601257 time_taken: 0.055811166763305664\n",
      "Epoch 0: iteration 2491/2501 train_loss: 0.8978986740112305 time_taken: 0.05617523193359375\n",
      "Epoch 0: iteration 2492/2501 train_loss: 0.897879958152771 time_taken: 0.05617094039916992\n",
      "Epoch 0: iteration 2493/2501 train_loss: 0.8978614211082458 time_taken: 0.05618000030517578\n",
      "Epoch 0: iteration 2494/2501 train_loss: 0.8978362679481506 time_taken: 0.05637621879577637\n",
      "Epoch 0: iteration 2495/2501 train_loss: 0.8978033065795898 time_taken: 0.05748438835144043\n",
      "Epoch 0: iteration 2496/2501 train_loss: 0.8977837562561035 time_taken: 0.05603432655334473\n",
      "Epoch 0: iteration 2497/2501 train_loss: 0.8977649211883545 time_taken: 0.05631899833679199\n",
      "Epoch 0: iteration 2498/2501 train_loss: 0.8977417945861816 time_taken: 0.05611562728881836\n",
      "Epoch 0: iteration 2499/2501 train_loss: 0.8977015614509583 time_taken: 0.05639791488647461\n",
      "Epoch 0: iteration 2500/2501 train_loss: 0.8976759910583496 time_taken: 0.05557870864868164\n",
      "Finished epoch 0 took 441.2559151649475\n",
      "Starting epoch 1/5\n",
      "Epoch 1: iteration 0/2501 train_loss: 1.137742519378662 time_taken: 0.05673646926879883\n",
      "Epoch 1: iteration 1/2501 train_loss: 1.048907995223999 time_taken: 0.05665850639343262\n",
      "Epoch 1: iteration 2/2501 train_loss: 1.041890025138855 time_taken: 0.056446075439453125\n",
      "Epoch 1: iteration 3/2501 train_loss: 1.017284631729126 time_taken: 0.0561065673828125\n",
      "Epoch 1: iteration 4/2501 train_loss: 0.9912527203559875 time_taken: 0.05649590492248535\n",
      "Epoch 1: iteration 5/2501 train_loss: 0.9765639305114746 time_taken: 0.0571744441986084\n",
      "Epoch 1: iteration 6/2501 train_loss: 0.9606059193611145 time_taken: 0.05651545524597168\n",
      "Epoch 1: iteration 7/2501 train_loss: 0.9411776065826416 time_taken: 0.05651402473449707\n",
      "Epoch 1: iteration 8/2501 train_loss: 0.9262831211090088 time_taken: 0.05644106864929199\n",
      "Epoch 1: iteration 9/2501 train_loss: 0.9149593114852905 time_taken: 0.05634737014770508\n",
      "Epoch 1: iteration 10/2501 train_loss: 0.9064147472381592 time_taken: 0.05655527114868164\n",
      "Epoch 1: iteration 11/2501 train_loss: 0.9008480906486511 time_taken: 0.056678056716918945\n",
      "Epoch 1: iteration 12/2501 train_loss: 0.8958102464675903 time_taken: 0.05659079551696777\n",
      "Epoch 1: iteration 13/2501 train_loss: 0.8904107809066772 time_taken: 0.056525230407714844\n",
      "Epoch 1: iteration 14/2501 train_loss: 0.8856499195098877 time_taken: 0.05658721923828125\n",
      "Epoch 1: iteration 15/2501 train_loss: 0.8794298768043518 time_taken: 0.056882381439208984\n",
      "Epoch 1: iteration 16/2501 train_loss: 0.8736914992332458 time_taken: 0.05734682083129883\n",
      "Epoch 1: iteration 17/2501 train_loss: 0.8695551753044128 time_taken: 0.0593564510345459\n",
      "Epoch 1: iteration 18/2501 train_loss: 0.8672136068344116 time_taken: 0.056511640548706055\n",
      "Epoch 1: iteration 19/2501 train_loss: 0.8646913766860962 time_taken: 0.05591011047363281\n",
      "Epoch 1: iteration 20/2501 train_loss: 0.8612295985221863 time_taken: 0.055916547775268555\n",
      "Epoch 1: iteration 21/2501 train_loss: 0.856424868106842 time_taken: 0.056145429611206055\n",
      "Epoch 1: iteration 22/2501 train_loss: 0.8526288866996765 time_taken: 0.056124210357666016\n",
      "Epoch 1: iteration 23/2501 train_loss: 0.8485455513000488 time_taken: 0.055989742279052734\n",
      "Epoch 1: iteration 24/2501 train_loss: 0.8447058200836182 time_taken: 0.05747866630554199\n",
      "Epoch 1: iteration 25/2501 train_loss: 0.8407096862792969 time_taken: 0.06020712852478027\n",
      "Epoch 1: iteration 26/2501 train_loss: 0.8382307887077332 time_taken: 0.05613541603088379\n",
      "Epoch 1: iteration 27/2501 train_loss: 0.8358365893363953 time_taken: 0.05600714683532715\n",
      "Epoch 1: iteration 28/2501 train_loss: 0.8332148790359497 time_taken: 0.06213235855102539\n",
      "Epoch 1: iteration 29/2501 train_loss: 0.8304986357688904 time_taken: 0.05636453628540039\n",
      "Epoch 1: iteration 30/2501 train_loss: 0.8285963535308838 time_taken: 0.05615687370300293\n",
      "Epoch 1: iteration 31/2501 train_loss: 0.8262032270431519 time_taken: 0.05649757385253906\n",
      "Epoch 1: iteration 32/2501 train_loss: 0.8233848810195923 time_taken: 0.056873321533203125\n",
      "Epoch 1: iteration 33/2501 train_loss: 0.8226040005683899 time_taken: 0.056828975677490234\n",
      "Epoch 1: iteration 34/2501 train_loss: 0.8215000629425049 time_taken: 0.05629920959472656\n",
      "Epoch 1: iteration 35/2501 train_loss: 0.8206945061683655 time_taken: 0.05649137496948242\n",
      "Epoch 1: iteration 36/2501 train_loss: 0.8201452493667603 time_taken: 0.05727124214172363\n",
      "Epoch 1: iteration 37/2501 train_loss: 0.8184491991996765 time_taken: 0.05702710151672363\n",
      "Epoch 1: iteration 38/2501 train_loss: 0.8171786069869995 time_taken: 0.05650830268859863\n",
      "Epoch 1: iteration 39/2501 train_loss: 0.8164274096488953 time_taken: 0.05705571174621582\n",
      "Epoch 1: iteration 40/2501 train_loss: 0.8156509399414062 time_taken: 0.05703616142272949\n",
      "Epoch 1: iteration 41/2501 train_loss: 0.8154218792915344 time_taken: 0.05689406394958496\n",
      "Epoch 1: iteration 42/2501 train_loss: 0.8142095804214478 time_taken: 0.05693387985229492\n",
      "Epoch 1: iteration 43/2501 train_loss: 0.8129028081893921 time_taken: 0.056647300720214844\n",
      "Epoch 1: iteration 44/2501 train_loss: 0.8121703267097473 time_taken: 0.05674457550048828\n",
      "Epoch 1: iteration 45/2501 train_loss: 0.8111019730567932 time_taken: 0.05649113655090332\n",
      "Epoch 1: iteration 46/2501 train_loss: 0.8100107908248901 time_taken: 0.05674147605895996\n",
      "Epoch 1: iteration 47/2501 train_loss: 0.8087928891181946 time_taken: 0.056351423263549805\n",
      "Epoch 1: iteration 48/2501 train_loss: 0.8079330325126648 time_taken: 0.05662846565246582\n",
      "Epoch 1: iteration 49/2501 train_loss: 0.8070054650306702 time_taken: 0.05661368370056152\n",
      "Epoch 1: iteration 50/2501 train_loss: 0.805807888507843 time_taken: 0.05675315856933594\n",
      "Epoch 1: iteration 51/2501 train_loss: 0.804989755153656 time_taken: 0.05627942085266113\n",
      "Epoch 1: iteration 52/2501 train_loss: 0.8042426705360413 time_taken: 0.05810213088989258\n",
      "Epoch 1: iteration 53/2501 train_loss: 0.8036959767341614 time_taken: 0.05738043785095215\n",
      "Epoch 1: iteration 54/2501 train_loss: 0.8027174472808838 time_taken: 0.05708599090576172\n",
      "Epoch 1: iteration 55/2501 train_loss: 0.8023390173912048 time_taken: 0.05649399757385254\n",
      "Epoch 1: iteration 56/2501 train_loss: 0.8012022972106934 time_taken: 0.0568394660949707\n",
      "Epoch 1: iteration 57/2501 train_loss: 0.8002973794937134 time_taken: 0.05690360069274902\n",
      "Epoch 1: iteration 58/2501 train_loss: 0.7998884320259094 time_taken: 0.05606961250305176\n",
      "Epoch 1: iteration 59/2501 train_loss: 0.7992865443229675 time_taken: 0.05632424354553223\n",
      "Epoch 1: iteration 60/2501 train_loss: 0.7984915375709534 time_taken: 0.05674099922180176\n",
      "Epoch 1: iteration 61/2501 train_loss: 0.7981030941009521 time_taken: 0.056025028228759766\n",
      "Epoch 1: iteration 62/2501 train_loss: 0.7976205945014954 time_taken: 0.05648016929626465\n",
      "Epoch 1: iteration 63/2501 train_loss: 0.7971179485321045 time_taken: 0.05621838569641113\n",
      "Epoch 1: iteration 64/2501 train_loss: 0.7960624694824219 time_taken: 0.05661344528198242\n",
      "Epoch 1: iteration 65/2501 train_loss: 0.7951350808143616 time_taken: 0.057082176208496094\n",
      "Epoch 1: iteration 66/2501 train_loss: 0.7937331199645996 time_taken: 0.05666518211364746\n",
      "Epoch 1: iteration 67/2501 train_loss: 0.7923077344894409 time_taken: 0.05672883987426758\n",
      "Epoch 1: iteration 68/2501 train_loss: 0.7907419800758362 time_taken: 0.05750775337219238\n",
      "Epoch 1: iteration 69/2501 train_loss: 0.789002001285553 time_taken: 0.057134389877319336\n",
      "Epoch 1: iteration 70/2501 train_loss: 0.7875000238418579 time_taken: 0.05676770210266113\n",
      "Epoch 1: iteration 71/2501 train_loss: 0.7857174277305603 time_taken: 0.05700850486755371\n",
      "Epoch 1: iteration 72/2501 train_loss: 0.783744215965271 time_taken: 0.056444406509399414\n",
      "Epoch 1: iteration 73/2501 train_loss: 0.7820900678634644 time_taken: 0.05631256103515625\n",
      "Epoch 1: iteration 74/2501 train_loss: 0.7807157635688782 time_taken: 0.05661153793334961\n",
      "Epoch 1: iteration 75/2501 train_loss: 0.7789721488952637 time_taken: 0.05683159828186035\n",
      "Epoch 1: iteration 76/2501 train_loss: 0.777145266532898 time_taken: 0.056032657623291016\n",
      "Epoch 1: iteration 77/2501 train_loss: 0.7758364081382751 time_taken: 0.05631303787231445\n",
      "Epoch 1: iteration 78/2501 train_loss: 0.7746932506561279 time_taken: 0.056865692138671875\n",
      "Epoch 1: iteration 79/2501 train_loss: 0.773224949836731 time_taken: 0.056816816329956055\n",
      "Epoch 1: iteration 80/2501 train_loss: 0.7717885375022888 time_taken: 0.05701017379760742\n",
      "Epoch 1: iteration 81/2501 train_loss: 0.770296573638916 time_taken: 0.056948184967041016\n",
      "Epoch 1: iteration 82/2501 train_loss: 0.7689401507377625 time_taken: 0.05703306198120117\n",
      "Epoch 1: iteration 83/2501 train_loss: 0.7677863836288452 time_taken: 0.056734323501586914\n",
      "Epoch 1: iteration 84/2501 train_loss: 0.7665210366249084 time_taken: 0.05677390098571777\n",
      "Epoch 1: iteration 85/2501 train_loss: 0.765448272228241 time_taken: 0.05680346488952637\n",
      "Epoch 1: iteration 86/2501 train_loss: 0.7647541761398315 time_taken: 0.056279659271240234\n",
      "Epoch 1: iteration 87/2501 train_loss: 0.7642320394515991 time_taken: 0.057997703552246094\n",
      "Epoch 1: iteration 88/2501 train_loss: 0.7635838985443115 time_taken: 0.05681467056274414\n",
      "Epoch 1: iteration 89/2501 train_loss: 0.7630077600479126 time_taken: 0.05702829360961914\n",
      "Epoch 1: iteration 90/2501 train_loss: 0.7624661922454834 time_taken: 0.05680990219116211\n",
      "Epoch 1: iteration 91/2501 train_loss: 0.7620872259140015 time_taken: 0.05644392967224121\n",
      "Epoch 1: iteration 92/2501 train_loss: 0.761638343334198 time_taken: 0.056278228759765625\n",
      "Epoch 1: iteration 93/2501 train_loss: 0.7611417770385742 time_taken: 0.05629849433898926\n",
      "Epoch 1: iteration 94/2501 train_loss: 0.7606852650642395 time_taken: 0.05623483657836914\n",
      "Epoch 1: iteration 95/2501 train_loss: 0.7597718238830566 time_taken: 0.056601524353027344\n",
      "Epoch 1: iteration 96/2501 train_loss: 0.7588503956794739 time_taken: 0.05672931671142578\n",
      "Epoch 1: iteration 97/2501 train_loss: 0.7577680349349976 time_taken: 0.057111501693725586\n",
      "Epoch 1: iteration 98/2501 train_loss: 0.7570840120315552 time_taken: 0.0564885139465332\n",
      "Epoch 1: iteration 99/2501 train_loss: 0.7559462785720825 time_taken: 0.056726932525634766\n",
      "Epoch 1: iteration 100/2501 train_loss: 0.7549265027046204 time_taken: 0.05725240707397461\n",
      "Epoch 1: iteration 101/2501 train_loss: 0.7540364265441895 time_taken: 0.056916236877441406\n",
      "Epoch 1: iteration 102/2501 train_loss: 0.7531909346580505 time_taken: 0.056910037994384766\n",
      "Epoch 1: iteration 103/2501 train_loss: 0.7526784539222717 time_taken: 0.0577085018157959\n",
      "Epoch 1: iteration 104/2501 train_loss: 0.7521083354949951 time_taken: 0.05667614936828613\n",
      "Epoch 1: iteration 105/2501 train_loss: 0.7513249516487122 time_taken: 0.0575714111328125\n",
      "Epoch 1: iteration 106/2501 train_loss: 0.7506173849105835 time_taken: 0.05733299255371094\n",
      "Epoch 1: iteration 107/2501 train_loss: 0.7498987913131714 time_taken: 0.05696845054626465\n",
      "Epoch 1: iteration 108/2501 train_loss: 0.7492530941963196 time_taken: 0.05651450157165527\n",
      "Epoch 1: iteration 109/2501 train_loss: 0.7485928535461426 time_taken: 0.056516170501708984\n",
      "Epoch 1: iteration 110/2501 train_loss: 0.7477086782455444 time_taken: 0.057604074478149414\n",
      "Epoch 1: iteration 111/2501 train_loss: 0.7470080256462097 time_taken: 0.05703592300415039\n",
      "Epoch 1: iteration 112/2501 train_loss: 0.7466865181922913 time_taken: 0.05700826644897461\n",
      "Epoch 1: iteration 113/2501 train_loss: 0.7462067604064941 time_taken: 0.05684709548950195\n",
      "Epoch 1: iteration 114/2501 train_loss: 0.7460081577301025 time_taken: 0.05613064765930176\n",
      "Epoch 1: iteration 115/2501 train_loss: 0.7456707954406738 time_taken: 0.05759286880493164\n",
      "Epoch 1: iteration 116/2501 train_loss: 0.7453451752662659 time_taken: 0.05652117729187012\n",
      "Epoch 1: iteration 117/2501 train_loss: 0.7452245354652405 time_taken: 0.05646824836730957\n",
      "Epoch 1: iteration 118/2501 train_loss: 0.7449926733970642 time_taken: 0.0565793514251709\n",
      "Epoch 1: iteration 119/2501 train_loss: 0.7445179224014282 time_taken: 0.05722522735595703\n",
      "Epoch 1: iteration 120/2501 train_loss: 0.7441118955612183 time_taken: 0.05699038505554199\n",
      "Epoch 1: iteration 121/2501 train_loss: 0.7436069250106812 time_taken: 0.05614757537841797\n",
      "Epoch 1: iteration 122/2501 train_loss: 0.7432475686073303 time_taken: 0.05681300163269043\n",
      "Epoch 1: iteration 123/2501 train_loss: 0.742874264717102 time_taken: 0.05658578872680664\n",
      "Epoch 1: iteration 124/2501 train_loss: 0.7426257729530334 time_taken: 0.05617213249206543\n",
      "Epoch 1: iteration 125/2501 train_loss: 0.742516040802002 time_taken: 0.05677366256713867\n",
      "Epoch 1: iteration 126/2501 train_loss: 0.7422371506690979 time_taken: 0.05657148361206055\n",
      "Epoch 1: iteration 127/2501 train_loss: 0.7420731782913208 time_taken: 0.05715823173522949\n",
      "Epoch 1: iteration 128/2501 train_loss: 0.7421290278434753 time_taken: 0.05651497840881348\n",
      "Epoch 1: iteration 129/2501 train_loss: 0.7422508597373962 time_taken: 0.05635952949523926\n",
      "Epoch 1: iteration 130/2501 train_loss: 0.7423166036605835 time_taken: 0.05825543403625488\n",
      "Epoch 1: iteration 131/2501 train_loss: 0.7423123717308044 time_taken: 0.05719423294067383\n",
      "Epoch 1: iteration 132/2501 train_loss: 0.7423439025878906 time_taken: 0.056617021560668945\n",
      "Epoch 1: iteration 133/2501 train_loss: 0.7421729564666748 time_taken: 0.05758309364318848\n",
      "Epoch 1: iteration 134/2501 train_loss: 0.7421367168426514 time_taken: 0.05687689781188965\n",
      "Epoch 1: iteration 135/2501 train_loss: 0.7420082092285156 time_taken: 0.05675077438354492\n",
      "Epoch 1: iteration 136/2501 train_loss: 0.7417196035385132 time_taken: 0.05717802047729492\n",
      "Epoch 1: iteration 137/2501 train_loss: 0.7413872480392456 time_taken: 0.056679487228393555\n",
      "Epoch 1: iteration 138/2501 train_loss: 0.7410886883735657 time_taken: 0.057219743728637695\n",
      "Epoch 1: iteration 139/2501 train_loss: 0.7407248616218567 time_taken: 0.057350873947143555\n",
      "Epoch 1: iteration 140/2501 train_loss: 0.7403717041015625 time_taken: 0.05766916275024414\n",
      "Epoch 1: iteration 141/2501 train_loss: 0.7400733232498169 time_taken: 0.05663418769836426\n",
      "Epoch 1: iteration 142/2501 train_loss: 0.7397803664207458 time_taken: 0.05700063705444336\n",
      "Epoch 1: iteration 143/2501 train_loss: 0.7394149303436279 time_taken: 0.05677318572998047\n",
      "Epoch 1: iteration 144/2501 train_loss: 0.7391362190246582 time_taken: 0.05745339393615723\n",
      "Epoch 1: iteration 145/2501 train_loss: 0.7387417554855347 time_taken: 0.05658888816833496\n",
      "Epoch 1: iteration 146/2501 train_loss: 0.7384558916091919 time_taken: 0.05635547637939453\n",
      "Epoch 1: iteration 147/2501 train_loss: 0.7382254004478455 time_taken: 0.05708479881286621\n",
      "Epoch 1: iteration 148/2501 train_loss: 0.7378849983215332 time_taken: 0.05680704116821289\n",
      "Epoch 1: iteration 149/2501 train_loss: 0.7376139760017395 time_taken: 0.05756711959838867\n",
      "Epoch 1: iteration 150/2501 train_loss: 0.7372981905937195 time_taken: 0.05660676956176758\n",
      "Epoch 1: iteration 151/2501 train_loss: 0.7370148301124573 time_taken: 0.05704784393310547\n",
      "Epoch 1: iteration 152/2501 train_loss: 0.7368706464767456 time_taken: 0.0568537712097168\n",
      "Epoch 1: iteration 153/2501 train_loss: 0.7367750406265259 time_taken: 0.05683755874633789\n",
      "Epoch 1: iteration 154/2501 train_loss: 0.736509382724762 time_taken: 0.05652356147766113\n",
      "Epoch 1: iteration 155/2501 train_loss: 0.7363124489784241 time_taken: 0.05693173408508301\n",
      "Epoch 1: iteration 156/2501 train_loss: 0.7359840869903564 time_taken: 0.056741952896118164\n",
      "Epoch 1: iteration 157/2501 train_loss: 0.7356947660446167 time_taken: 0.05617046356201172\n",
      "Epoch 1: iteration 158/2501 train_loss: 0.7353695631027222 time_taken: 0.05656242370605469\n",
      "Epoch 1: iteration 159/2501 train_loss: 0.7351712584495544 time_taken: 0.05664467811584473\n",
      "Epoch 1: iteration 160/2501 train_loss: 0.7349034547805786 time_taken: 0.05729055404663086\n",
      "Epoch 1: iteration 161/2501 train_loss: 0.7347062230110168 time_taken: 0.057849884033203125\n",
      "Epoch 1: iteration 162/2501 train_loss: 0.734559953212738 time_taken: 0.05698680877685547\n",
      "Epoch 1: iteration 163/2501 train_loss: 0.7345705032348633 time_taken: 0.05642890930175781\n",
      "Epoch 1: iteration 164/2501 train_loss: 0.7345644235610962 time_taken: 0.05721712112426758\n",
      "Epoch 1: iteration 165/2501 train_loss: 0.7345325350761414 time_taken: 0.05709409713745117\n",
      "Epoch 1: iteration 166/2501 train_loss: 0.7345473170280457 time_taken: 0.05643486976623535\n",
      "Epoch 1: iteration 167/2501 train_loss: 0.734533429145813 time_taken: 0.057079315185546875\n",
      "Epoch 1: iteration 168/2501 train_loss: 0.7345293760299683 time_taken: 0.05751466751098633\n",
      "Epoch 1: iteration 169/2501 train_loss: 0.7347143888473511 time_taken: 0.05721712112426758\n",
      "Epoch 1: iteration 170/2501 train_loss: 0.7348120808601379 time_taken: 0.05662822723388672\n",
      "Epoch 1: iteration 171/2501 train_loss: 0.7347970604896545 time_taken: 0.05663704872131348\n",
      "Epoch 1: iteration 172/2501 train_loss: 0.7347320914268494 time_taken: 0.05648612976074219\n",
      "Epoch 1: iteration 173/2501 train_loss: 0.7347613573074341 time_taken: 0.05669903755187988\n",
      "Epoch 1: iteration 174/2501 train_loss: 0.7348222136497498 time_taken: 0.05733084678649902\n",
      "Epoch 1: iteration 175/2501 train_loss: 0.73464035987854 time_taken: 0.056726932525634766\n",
      "Epoch 1: iteration 176/2501 train_loss: 0.7344605326652527 time_taken: 0.05767965316772461\n",
      "Epoch 1: iteration 177/2501 train_loss: 0.7343028783798218 time_taken: 0.05769467353820801\n",
      "Epoch 1: iteration 178/2501 train_loss: 0.7341970205307007 time_taken: 0.057306528091430664\n",
      "Epoch 1: iteration 179/2501 train_loss: 0.7339389324188232 time_taken: 0.05714297294616699\n",
      "Epoch 1: iteration 180/2501 train_loss: 0.7337310910224915 time_taken: 0.056612491607666016\n",
      "Epoch 1: iteration 181/2501 train_loss: 0.7336245775222778 time_taken: 0.057450056076049805\n",
      "Epoch 1: iteration 182/2501 train_loss: 0.7335599660873413 time_taken: 0.056838274002075195\n",
      "Epoch 1: iteration 183/2501 train_loss: 0.7335107326507568 time_taken: 0.05677938461303711\n",
      "Epoch 1: iteration 184/2501 train_loss: 0.7334027886390686 time_taken: 0.05731320381164551\n",
      "Epoch 1: iteration 185/2501 train_loss: 0.7333284616470337 time_taken: 0.057064056396484375\n",
      "Epoch 1: iteration 186/2501 train_loss: 0.7331203818321228 time_taken: 0.05670285224914551\n",
      "Epoch 1: iteration 187/2501 train_loss: 0.7329675555229187 time_taken: 0.057070016860961914\n",
      "Epoch 1: iteration 188/2501 train_loss: 0.732798159122467 time_taken: 0.05836772918701172\n",
      "Epoch 1: iteration 189/2501 train_loss: 0.7326410412788391 time_taken: 0.05675673484802246\n",
      "Epoch 1: iteration 190/2501 train_loss: 0.7326310873031616 time_taken: 0.0572657585144043\n",
      "Epoch 1: iteration 191/2501 train_loss: 0.732417106628418 time_taken: 0.05692172050476074\n",
      "Epoch 1: iteration 192/2501 train_loss: 0.7322986125946045 time_taken: 0.057236433029174805\n",
      "Epoch 1: iteration 193/2501 train_loss: 0.7321925163269043 time_taken: 0.056531429290771484\n",
      "Epoch 1: iteration 194/2501 train_loss: 0.7321119904518127 time_taken: 0.05677294731140137\n",
      "Epoch 1: iteration 195/2501 train_loss: 0.7322502136230469 time_taken: 0.057802677154541016\n",
      "Epoch 1: iteration 196/2501 train_loss: 0.7324073910713196 time_taken: 0.05670619010925293\n",
      "Epoch 1: iteration 197/2501 train_loss: 0.7326331734657288 time_taken: 0.05722856521606445\n",
      "Epoch 1: iteration 198/2501 train_loss: 0.7327715754508972 time_taken: 0.05690312385559082\n",
      "Epoch 1: iteration 199/2501 train_loss: 0.7331820726394653 time_taken: 0.05675768852233887\n",
      "Epoch 1: iteration 200/2501 train_loss: 0.7334988117218018 time_taken: 0.05787992477416992\n",
      "Epoch 1: iteration 201/2501 train_loss: 0.7338228225708008 time_taken: 0.057290077209472656\n",
      "Epoch 1: iteration 202/2501 train_loss: 0.7342345118522644 time_taken: 0.056746721267700195\n",
      "Epoch 1: iteration 203/2501 train_loss: 0.7344934940338135 time_taken: 0.056519508361816406\n",
      "Epoch 1: iteration 204/2501 train_loss: 0.7346158623695374 time_taken: 0.05673336982727051\n",
      "Epoch 1: iteration 205/2501 train_loss: 0.7348999977111816 time_taken: 0.05658125877380371\n",
      "Epoch 1: iteration 206/2501 train_loss: 0.7350283265113831 time_taken: 0.05877256393432617\n",
      "Epoch 1: iteration 207/2501 train_loss: 0.7351176142692566 time_taken: 0.05625104904174805\n",
      "Epoch 1: iteration 208/2501 train_loss: 0.7351962924003601 time_taken: 0.0567164421081543\n",
      "Epoch 1: iteration 209/2501 train_loss: 0.7353038787841797 time_taken: 0.0563511848449707\n",
      "Epoch 1: iteration 210/2501 train_loss: 0.7353573441505432 time_taken: 0.05655479431152344\n",
      "Epoch 1: iteration 211/2501 train_loss: 0.7353290319442749 time_taken: 0.0564265251159668\n",
      "Epoch 1: iteration 212/2501 train_loss: 0.7351630926132202 time_taken: 0.056269168853759766\n",
      "Epoch 1: iteration 213/2501 train_loss: 0.7349233627319336 time_taken: 0.056426286697387695\n",
      "Epoch 1: iteration 214/2501 train_loss: 0.7346739768981934 time_taken: 0.056438446044921875\n",
      "Epoch 1: iteration 215/2501 train_loss: 0.7344440817832947 time_taken: 0.05641293525695801\n",
      "Epoch 1: iteration 216/2501 train_loss: 0.7343170642852783 time_taken: 0.05642223358154297\n",
      "Epoch 1: iteration 217/2501 train_loss: 0.7342641353607178 time_taken: 0.05795574188232422\n",
      "Epoch 1: iteration 218/2501 train_loss: 0.7343193292617798 time_taken: 0.05675458908081055\n",
      "Epoch 1: iteration 219/2501 train_loss: 0.7342824935913086 time_taken: 0.05662965774536133\n",
      "Epoch 1: iteration 220/2501 train_loss: 0.7343405485153198 time_taken: 0.056476593017578125\n",
      "Epoch 1: iteration 221/2501 train_loss: 0.7344516515731812 time_taken: 0.056438446044921875\n",
      "Epoch 1: iteration 222/2501 train_loss: 0.7345572710037231 time_taken: 0.05614829063415527\n",
      "Epoch 1: iteration 223/2501 train_loss: 0.7345899939537048 time_taken: 0.05667853355407715\n",
      "Epoch 1: iteration 224/2501 train_loss: 0.7347740530967712 time_taken: 0.05646681785583496\n",
      "Epoch 1: iteration 225/2501 train_loss: 0.7349455952644348 time_taken: 0.05663251876831055\n",
      "Epoch 1: iteration 226/2501 train_loss: 0.7350362539291382 time_taken: 0.056227684020996094\n",
      "Epoch 1: iteration 227/2501 train_loss: 0.7349721193313599 time_taken: 0.056215524673461914\n",
      "Epoch 1: iteration 228/2501 train_loss: 0.7348723411560059 time_taken: 0.056127309799194336\n",
      "Epoch 1: iteration 229/2501 train_loss: 0.7347899675369263 time_taken: 0.05624508857727051\n",
      "Epoch 1: iteration 230/2501 train_loss: 0.7345550060272217 time_taken: 0.05593538284301758\n",
      "Epoch 1: iteration 231/2501 train_loss: 0.7342329621315002 time_taken: 0.0565190315246582\n",
      "Epoch 1: iteration 232/2501 train_loss: 0.7339597940444946 time_taken: 0.055914878845214844\n",
      "Epoch 1: iteration 233/2501 train_loss: 0.7336649298667908 time_taken: 0.056383371353149414\n",
      "Epoch 1: iteration 234/2501 train_loss: 0.7334898710250854 time_taken: 0.056066036224365234\n",
      "Epoch 1: iteration 235/2501 train_loss: 0.7332821488380432 time_taken: 0.05699419975280762\n",
      "Epoch 1: iteration 236/2501 train_loss: 0.733146607875824 time_taken: 0.056366920471191406\n",
      "Epoch 1: iteration 237/2501 train_loss: 0.7330195903778076 time_taken: 0.05676698684692383\n",
      "Epoch 1: iteration 238/2501 train_loss: 0.7328906655311584 time_taken: 0.05596017837524414\n",
      "Epoch 1: iteration 239/2501 train_loss: 0.7327536940574646 time_taken: 0.05700230598449707\n",
      "Epoch 1: iteration 240/2501 train_loss: 0.7326814532279968 time_taken: 0.05586099624633789\n",
      "Epoch 1: iteration 241/2501 train_loss: 0.7325267791748047 time_taken: 0.05671381950378418\n",
      "Epoch 1: iteration 242/2501 train_loss: 0.732498824596405 time_taken: 0.056592702865600586\n",
      "Epoch 1: iteration 243/2501 train_loss: 0.7323455810546875 time_taken: 0.05648612976074219\n",
      "Epoch 1: iteration 244/2501 train_loss: 0.7322792410850525 time_taken: 0.05686497688293457\n",
      "Epoch 1: iteration 245/2501 train_loss: 0.7322096228599548 time_taken: 0.06109261512756348\n",
      "Epoch 1: iteration 246/2501 train_loss: 0.7321171164512634 time_taken: 0.056645870208740234\n",
      "Epoch 1: iteration 247/2501 train_loss: 0.7319894433021545 time_taken: 0.057117462158203125\n",
      "Epoch 1: iteration 248/2501 train_loss: 0.7319249510765076 time_taken: 0.056113243103027344\n",
      "Epoch 1: iteration 249/2501 train_loss: 0.7318679690361023 time_taken: 0.05683255195617676\n",
      "Epoch 1: iteration 250/2501 train_loss: 0.7317840456962585 time_taken: 0.05783271789550781\n",
      "Epoch 1: iteration 251/2501 train_loss: 0.7317174077033997 time_taken: 0.05620598793029785\n",
      "Epoch 1: iteration 252/2501 train_loss: 0.7316325902938843 time_taken: 0.05663609504699707\n",
      "Epoch 1: iteration 253/2501 train_loss: 0.731521725654602 time_taken: 0.05630207061767578\n",
      "Epoch 1: iteration 254/2501 train_loss: 0.7313913702964783 time_taken: 0.07233238220214844\n",
      "Epoch 1: iteration 255/2501 train_loss: 0.7312598824501038 time_taken: 0.0779104232788086\n",
      "Epoch 1: iteration 256/2501 train_loss: 0.7312073111534119 time_taken: 0.06596803665161133\n",
      "Epoch 1: iteration 257/2501 train_loss: 0.7310922145843506 time_taken: 0.0559382438659668\n",
      "Epoch 1: iteration 258/2501 train_loss: 0.7310296893119812 time_taken: 0.05636119842529297\n",
      "Epoch 1: iteration 259/2501 train_loss: 0.7309450507164001 time_taken: 0.05675172805786133\n",
      "Epoch 1: iteration 260/2501 train_loss: 0.7308791875839233 time_taken: 0.0575413703918457\n",
      "Epoch 1: iteration 261/2501 train_loss: 0.7307182550430298 time_taken: 0.05636930465698242\n",
      "Epoch 1: iteration 262/2501 train_loss: 0.7305397987365723 time_taken: 0.05692768096923828\n",
      "Epoch 1: iteration 263/2501 train_loss: 0.7303952574729919 time_taken: 0.05668330192565918\n",
      "Epoch 1: iteration 264/2501 train_loss: 0.73024582862854 time_taken: 0.056421518325805664\n",
      "Epoch 1: iteration 265/2501 train_loss: 0.7300735116004944 time_taken: 0.056986331939697266\n",
      "Epoch 1: iteration 266/2501 train_loss: 0.729887843132019 time_taken: 0.05764913558959961\n",
      "Epoch 1: iteration 267/2501 train_loss: 0.7296993136405945 time_taken: 0.05692648887634277\n",
      "Epoch 1: iteration 268/2501 train_loss: 0.7294703722000122 time_taken: 0.05700182914733887\n",
      "Epoch 1: iteration 269/2501 train_loss: 0.7293360233306885 time_taken: 0.05725288391113281\n",
      "Epoch 1: iteration 270/2501 train_loss: 0.729115903377533 time_taken: 0.056921958923339844\n",
      "Epoch 1: iteration 271/2501 train_loss: 0.7289734482765198 time_taken: 0.05745816230773926\n",
      "Epoch 1: iteration 272/2501 train_loss: 0.7287781238555908 time_taken: 0.056851863861083984\n",
      "Epoch 1: iteration 273/2501 train_loss: 0.7286173701286316 time_taken: 0.05694246292114258\n",
      "Epoch 1: iteration 274/2501 train_loss: 0.7284770011901855 time_taken: 0.056266069412231445\n",
      "Epoch 1: iteration 275/2501 train_loss: 0.7282336950302124 time_taken: 0.05646228790283203\n",
      "Epoch 1: iteration 276/2501 train_loss: 0.7280756235122681 time_taken: 0.05634951591491699\n",
      "Epoch 1: iteration 277/2501 train_loss: 0.7278745770454407 time_taken: 0.056596994400024414\n",
      "Epoch 1: iteration 278/2501 train_loss: 0.727708637714386 time_taken: 0.056044816970825195\n",
      "Epoch 1: iteration 279/2501 train_loss: 0.7274193167686462 time_taken: 0.056339263916015625\n",
      "Epoch 1: iteration 280/2501 train_loss: 0.7271786332130432 time_taken: 0.05618095397949219\n",
      "Epoch 1: iteration 281/2501 train_loss: 0.7269409894943237 time_taken: 0.05635643005371094\n",
      "Epoch 1: iteration 282/2501 train_loss: 0.7267634868621826 time_taken: 0.05613589286804199\n",
      "Epoch 1: iteration 283/2501 train_loss: 0.7265490293502808 time_taken: 0.056255340576171875\n",
      "Epoch 1: iteration 284/2501 train_loss: 0.7263762354850769 time_taken: 0.05667233467102051\n",
      "Epoch 1: iteration 285/2501 train_loss: 0.7262220978736877 time_taken: 0.05692696571350098\n",
      "Epoch 1: iteration 286/2501 train_loss: 0.7260634303092957 time_taken: 0.05763530731201172\n",
      "Epoch 1: iteration 287/2501 train_loss: 0.7259867787361145 time_taken: 0.05655050277709961\n",
      "Epoch 1: iteration 288/2501 train_loss: 0.7259256839752197 time_taken: 0.05688595771789551\n",
      "Epoch 1: iteration 289/2501 train_loss: 0.72593092918396 time_taken: 0.057074546813964844\n",
      "Epoch 1: iteration 290/2501 train_loss: 0.72591632604599 time_taken: 0.056442975997924805\n",
      "Epoch 1: iteration 291/2501 train_loss: 0.7259480953216553 time_taken: 0.05598878860473633\n",
      "Epoch 1: iteration 292/2501 train_loss: 0.7259403467178345 time_taken: 0.05607938766479492\n",
      "Epoch 1: iteration 293/2501 train_loss: 0.7257881760597229 time_taken: 0.05676388740539551\n",
      "Epoch 1: iteration 294/2501 train_loss: 0.7258024215698242 time_taken: 0.0564265251159668\n",
      "Epoch 1: iteration 295/2501 train_loss: 0.7257626056671143 time_taken: 0.05640053749084473\n",
      "Epoch 1: iteration 296/2501 train_loss: 0.7257792949676514 time_taken: 0.05619502067565918\n",
      "Epoch 1: iteration 297/2501 train_loss: 0.7258127331733704 time_taken: 0.05731916427612305\n",
      "Epoch 1: iteration 298/2501 train_loss: 0.7258298993110657 time_taken: 0.0566408634185791\n",
      "Epoch 1: iteration 299/2501 train_loss: 0.7258214354515076 time_taken: 0.05650448799133301\n",
      "Epoch 1: iteration 300/2501 train_loss: 0.7257928252220154 time_taken: 0.05610013008117676\n",
      "Epoch 1: iteration 301/2501 train_loss: 0.7257960438728333 time_taken: 0.05781364440917969\n",
      "Epoch 1: iteration 302/2501 train_loss: 0.7258425951004028 time_taken: 0.056691646575927734\n",
      "Epoch 1: iteration 303/2501 train_loss: 0.725904643535614 time_taken: 0.056226253509521484\n",
      "Epoch 1: iteration 304/2501 train_loss: 0.7259567975997925 time_taken: 0.056268930435180664\n",
      "Epoch 1: iteration 305/2501 train_loss: 0.7259237766265869 time_taken: 0.05597424507141113\n",
      "Epoch 1: iteration 306/2501 train_loss: 0.7259140014648438 time_taken: 0.05687379837036133\n",
      "Epoch 1: iteration 307/2501 train_loss: 0.7259078025817871 time_taken: 0.05646920204162598\n",
      "Epoch 1: iteration 308/2501 train_loss: 0.7258641719818115 time_taken: 0.05645442008972168\n",
      "Epoch 1: iteration 309/2501 train_loss: 0.7257949113845825 time_taken: 0.05651044845581055\n",
      "Epoch 1: iteration 310/2501 train_loss: 0.725714385509491 time_taken: 0.05699443817138672\n",
      "Epoch 1: iteration 311/2501 train_loss: 0.7256240844726562 time_taken: 0.056456804275512695\n",
      "Epoch 1: iteration 312/2501 train_loss: 0.7254270911216736 time_taken: 0.05680346488952637\n",
      "Epoch 1: iteration 313/2501 train_loss: 0.7252827286720276 time_taken: 0.05712103843688965\n",
      "Epoch 1: iteration 314/2501 train_loss: 0.725225031375885 time_taken: 0.05656886100769043\n",
      "Epoch 1: iteration 315/2501 train_loss: 0.7251137495040894 time_taken: 0.056643009185791016\n",
      "Epoch 1: iteration 316/2501 train_loss: 0.7249357104301453 time_taken: 0.05777478218078613\n",
      "Epoch 1: iteration 317/2501 train_loss: 0.7247694134712219 time_taken: 0.05661821365356445\n",
      "Epoch 1: iteration 318/2501 train_loss: 0.7246439456939697 time_taken: 0.05614209175109863\n",
      "Epoch 1: iteration 319/2501 train_loss: 0.7245445847511292 time_taken: 0.05655932426452637\n",
      "Epoch 1: iteration 320/2501 train_loss: 0.724538266658783 time_taken: 0.05618596076965332\n",
      "Epoch 1: iteration 321/2501 train_loss: 0.7243993878364563 time_taken: 0.056420087814331055\n",
      "Epoch 1: iteration 322/2501 train_loss: 0.7242478132247925 time_taken: 0.0561680793762207\n",
      "Epoch 1: iteration 323/2501 train_loss: 0.7241206765174866 time_taken: 0.05642342567443848\n",
      "Epoch 1: iteration 324/2501 train_loss: 0.7239946126937866 time_taken: 0.056292057037353516\n",
      "Epoch 1: iteration 325/2501 train_loss: 0.7238084077835083 time_taken: 0.05640602111816406\n",
      "Epoch 1: iteration 326/2501 train_loss: 0.7236549854278564 time_taken: 0.05643582344055176\n",
      "Epoch 1: iteration 327/2501 train_loss: 0.7234064340591431 time_taken: 0.05655622482299805\n",
      "Epoch 1: iteration 328/2501 train_loss: 0.7232283353805542 time_taken: 0.0562744140625\n",
      "Epoch 1: iteration 329/2501 train_loss: 0.7229827046394348 time_taken: 0.06174492835998535\n",
      "Epoch 1: iteration 330/2501 train_loss: 0.722683310508728 time_taken: 0.05634498596191406\n",
      "Epoch 1: iteration 331/2501 train_loss: 0.7223702669143677 time_taken: 0.056386709213256836\n",
      "Epoch 1: iteration 332/2501 train_loss: 0.7220469117164612 time_taken: 0.05704307556152344\n",
      "Epoch 1: iteration 333/2501 train_loss: 0.7218590974807739 time_taken: 0.05961108207702637\n",
      "Epoch 1: iteration 334/2501 train_loss: 0.7216047048568726 time_taken: 0.056472063064575195\n",
      "Epoch 1: iteration 335/2501 train_loss: 0.7214309573173523 time_taken: 0.05769538879394531\n",
      "Epoch 1: iteration 336/2501 train_loss: 0.7211670875549316 time_taken: 0.05690574645996094\n",
      "Epoch 1: iteration 337/2501 train_loss: 0.7209655046463013 time_taken: 0.05676412582397461\n",
      "Epoch 1: iteration 338/2501 train_loss: 0.7207708954811096 time_taken: 0.05688977241516113\n",
      "Epoch 1: iteration 339/2501 train_loss: 0.7205333709716797 time_taken: 0.056215763092041016\n",
      "Epoch 1: iteration 340/2501 train_loss: 0.7203449010848999 time_taken: 0.05627632141113281\n",
      "Epoch 1: iteration 341/2501 train_loss: 0.7201507091522217 time_taken: 0.05606555938720703\n",
      "Epoch 1: iteration 342/2501 train_loss: 0.7199313044548035 time_taken: 0.05679607391357422\n",
      "Epoch 1: iteration 343/2501 train_loss: 0.7197232246398926 time_taken: 0.05587482452392578\n",
      "Epoch 1: iteration 344/2501 train_loss: 0.7195051312446594 time_taken: 0.05629682540893555\n",
      "Epoch 1: iteration 345/2501 train_loss: 0.7193439602851868 time_taken: 0.05617380142211914\n",
      "Epoch 1: iteration 346/2501 train_loss: 0.7191311120986938 time_taken: 0.05631542205810547\n",
      "Epoch 1: iteration 347/2501 train_loss: 0.7188290357589722 time_taken: 0.0564115047454834\n",
      "Epoch 1: iteration 348/2501 train_loss: 0.7186363339424133 time_taken: 0.05636858940124512\n",
      "Epoch 1: iteration 349/2501 train_loss: 0.7183864712715149 time_taken: 0.05640912055969238\n",
      "Epoch 1: iteration 350/2501 train_loss: 0.7181654572486877 time_taken: 0.0569455623626709\n",
      "Epoch 1: iteration 351/2501 train_loss: 0.717943549156189 time_taken: 0.0563199520111084\n",
      "Epoch 1: iteration 352/2501 train_loss: 0.7177162766456604 time_taken: 0.057402610778808594\n",
      "Epoch 1: iteration 353/2501 train_loss: 0.7175524234771729 time_taken: 0.06123018264770508\n",
      "Epoch 1: iteration 354/2501 train_loss: 0.717434287071228 time_taken: 0.0563817024230957\n",
      "Epoch 1: iteration 355/2501 train_loss: 0.7172971367835999 time_taken: 0.06002402305603027\n",
      "Epoch 1: iteration 356/2501 train_loss: 0.7171863317489624 time_taken: 0.05630755424499512\n",
      "Epoch 1: iteration 357/2501 train_loss: 0.7170904278755188 time_taken: 0.056436777114868164\n",
      "Epoch 1: iteration 358/2501 train_loss: 0.7169780135154724 time_taken: 0.05623197555541992\n",
      "Epoch 1: iteration 359/2501 train_loss: 0.7168956995010376 time_taken: 0.05625343322753906\n",
      "Epoch 1: iteration 360/2501 train_loss: 0.7167558073997498 time_taken: 0.05625128746032715\n",
      "Epoch 1: iteration 361/2501 train_loss: 0.7165464758872986 time_taken: 0.05644655227661133\n",
      "Epoch 1: iteration 362/2501 train_loss: 0.7163637280464172 time_taken: 0.057300567626953125\n",
      "Epoch 1: iteration 363/2501 train_loss: 0.7161638140678406 time_taken: 0.05614137649536133\n",
      "Epoch 1: iteration 364/2501 train_loss: 0.7160382866859436 time_taken: 0.05609393119812012\n",
      "Epoch 1: iteration 365/2501 train_loss: 0.7158280611038208 time_taken: 0.059728145599365234\n",
      "Epoch 1: iteration 366/2501 train_loss: 0.715647280216217 time_taken: 0.05603957176208496\n",
      "Epoch 1: iteration 367/2501 train_loss: 0.7154706120491028 time_taken: 0.05606532096862793\n",
      "Epoch 1: iteration 368/2501 train_loss: 0.7152940034866333 time_taken: 0.05685687065124512\n",
      "Epoch 1: iteration 369/2501 train_loss: 0.7150982022285461 time_taken: 0.06361126899719238\n",
      "Epoch 1: iteration 370/2501 train_loss: 0.7149287462234497 time_taken: 0.056105613708496094\n",
      "Epoch 1: iteration 371/2501 train_loss: 0.714691162109375 time_taken: 0.058345794677734375\n",
      "Epoch 1: iteration 372/2501 train_loss: 0.7144945859909058 time_taken: 0.056571245193481445\n",
      "Epoch 1: iteration 373/2501 train_loss: 0.7144052982330322 time_taken: 0.05657839775085449\n",
      "Epoch 1: iteration 374/2501 train_loss: 0.714214026927948 time_taken: 0.05684304237365723\n",
      "Epoch 1: iteration 375/2501 train_loss: 0.7140394449234009 time_taken: 0.05660223960876465\n",
      "Epoch 1: iteration 376/2501 train_loss: 0.7138903141021729 time_taken: 0.056261539459228516\n",
      "Epoch 1: iteration 377/2501 train_loss: 0.7137296795845032 time_taken: 0.05646514892578125\n",
      "Epoch 1: iteration 378/2501 train_loss: 0.713580846786499 time_taken: 0.0570979118347168\n",
      "Epoch 1: iteration 379/2501 train_loss: 0.7134014964103699 time_taken: 0.05685615539550781\n",
      "Epoch 1: iteration 380/2501 train_loss: 0.7132769227027893 time_taken: 0.05626845359802246\n",
      "Epoch 1: iteration 381/2501 train_loss: 0.7131004333496094 time_taken: 0.056578874588012695\n",
      "Epoch 1: iteration 382/2501 train_loss: 0.713038444519043 time_taken: 0.05772900581359863\n",
      "Epoch 1: iteration 383/2501 train_loss: 0.7129380702972412 time_taken: 0.05689382553100586\n",
      "Epoch 1: iteration 384/2501 train_loss: 0.712839663028717 time_taken: 0.05739235877990723\n",
      "Epoch 1: iteration 385/2501 train_loss: 0.712751030921936 time_taken: 0.05720686912536621\n",
      "Epoch 1: iteration 386/2501 train_loss: 0.7126179933547974 time_taken: 0.05783438682556152\n",
      "Epoch 1: iteration 387/2501 train_loss: 0.7125153541564941 time_taken: 0.05676436424255371\n",
      "Epoch 1: iteration 388/2501 train_loss: 0.7122802138328552 time_taken: 0.056845903396606445\n",
      "Epoch 1: iteration 389/2501 train_loss: 0.7121207118034363 time_taken: 0.057125091552734375\n",
      "Epoch 1: iteration 390/2501 train_loss: 0.7119374871253967 time_taken: 0.05682682991027832\n",
      "Epoch 1: iteration 391/2501 train_loss: 0.7118245959281921 time_taken: 0.05649423599243164\n",
      "Epoch 1: iteration 392/2501 train_loss: 0.7116945385932922 time_taken: 0.05675339698791504\n",
      "Epoch 1: iteration 393/2501 train_loss: 0.7115360498428345 time_taken: 0.056380271911621094\n",
      "Epoch 1: iteration 394/2501 train_loss: 0.711369514465332 time_taken: 0.05687355995178223\n",
      "Epoch 1: iteration 395/2501 train_loss: 0.7111902236938477 time_taken: 0.05610990524291992\n",
      "Epoch 1: iteration 396/2501 train_loss: 0.7109793424606323 time_taken: 0.056235551834106445\n",
      "Epoch 1: iteration 397/2501 train_loss: 0.7107816934585571 time_taken: 0.05720973014831543\n",
      "Epoch 1: iteration 398/2501 train_loss: 0.7105709314346313 time_taken: 0.056708335876464844\n",
      "Epoch 1: iteration 399/2501 train_loss: 0.710411548614502 time_taken: 0.05652976036071777\n",
      "Epoch 1: iteration 400/2501 train_loss: 0.7101644277572632 time_taken: 0.05662131309509277\n",
      "Epoch 1: iteration 401/2501 train_loss: 0.7099769711494446 time_taken: 0.05665993690490723\n",
      "Epoch 1: iteration 402/2501 train_loss: 0.7097271680831909 time_taken: 0.05803346633911133\n",
      "Epoch 1: iteration 403/2501 train_loss: 0.7094983458518982 time_taken: 0.057485342025756836\n",
      "Epoch 1: iteration 404/2501 train_loss: 0.7091954946517944 time_taken: 0.05688619613647461\n",
      "Epoch 1: iteration 405/2501 train_loss: 0.7089031338691711 time_taken: 0.0585787296295166\n",
      "Epoch 1: iteration 406/2501 train_loss: 0.7086986303329468 time_taken: 0.057015419006347656\n",
      "Epoch 1: iteration 407/2501 train_loss: 0.7084771990776062 time_taken: 0.05696272850036621\n",
      "Epoch 1: iteration 408/2501 train_loss: 0.7082812190055847 time_taken: 0.05673956871032715\n",
      "Epoch 1: iteration 409/2501 train_loss: 0.7081652283668518 time_taken: 0.05656743049621582\n",
      "Epoch 1: iteration 410/2501 train_loss: 0.7080072164535522 time_taken: 0.05739927291870117\n",
      "Epoch 1: iteration 411/2501 train_loss: 0.7078283429145813 time_taken: 0.05716276168823242\n",
      "Epoch 1: iteration 412/2501 train_loss: 0.7076894640922546 time_taken: 0.057701826095581055\n",
      "Epoch 1: iteration 413/2501 train_loss: 0.7074502110481262 time_taken: 0.05657768249511719\n",
      "Epoch 1: iteration 414/2501 train_loss: 0.7072970271110535 time_taken: 0.05747509002685547\n",
      "Epoch 1: iteration 415/2501 train_loss: 0.7071049213409424 time_taken: 0.056737422943115234\n",
      "Epoch 1: iteration 416/2501 train_loss: 0.7069322466850281 time_taken: 0.05736804008483887\n",
      "Epoch 1: iteration 417/2501 train_loss: 0.7068072557449341 time_taken: 0.05698657035827637\n",
      "Epoch 1: iteration 418/2501 train_loss: 0.706646740436554 time_taken: 0.05686688423156738\n",
      "Epoch 1: iteration 419/2501 train_loss: 0.7065427303314209 time_taken: 0.05767250061035156\n",
      "Epoch 1: iteration 420/2501 train_loss: 0.7064613699913025 time_taken: 0.05653119087219238\n",
      "Epoch 1: iteration 421/2501 train_loss: 0.7062900066375732 time_taken: 0.056723833084106445\n",
      "Epoch 1: iteration 422/2501 train_loss: 0.7061250805854797 time_taken: 0.05640387535095215\n",
      "Epoch 1: iteration 423/2501 train_loss: 0.7059623003005981 time_taken: 0.05713057518005371\n",
      "Epoch 1: iteration 424/2501 train_loss: 0.705765962600708 time_taken: 0.05697345733642578\n",
      "Epoch 1: iteration 425/2501 train_loss: 0.7055433988571167 time_taken: 0.05682730674743652\n",
      "Epoch 1: iteration 426/2501 train_loss: 0.7053564786911011 time_taken: 0.05717587471008301\n",
      "Epoch 1: iteration 427/2501 train_loss: 0.7051948308944702 time_taken: 0.05667686462402344\n",
      "Epoch 1: iteration 428/2501 train_loss: 0.7049891352653503 time_taken: 0.05648016929626465\n",
      "Epoch 1: iteration 429/2501 train_loss: 0.704833984375 time_taken: 0.05704498291015625\n",
      "Epoch 1: iteration 430/2501 train_loss: 0.7046739459037781 time_taken: 0.056577205657958984\n",
      "Epoch 1: iteration 431/2501 train_loss: 0.7045077085494995 time_taken: 0.056290626525878906\n",
      "Epoch 1: iteration 432/2501 train_loss: 0.7043658494949341 time_taken: 0.05657458305358887\n",
      "Epoch 1: iteration 433/2501 train_loss: 0.7042001485824585 time_taken: 0.05691814422607422\n",
      "Epoch 1: iteration 434/2501 train_loss: 0.7040742635726929 time_taken: 0.05690574645996094\n",
      "Epoch 1: iteration 435/2501 train_loss: 0.7039390802383423 time_taken: 0.05768609046936035\n",
      "Epoch 1: iteration 436/2501 train_loss: 0.7038483023643494 time_taken: 0.05702018737792969\n",
      "Epoch 1: iteration 437/2501 train_loss: 0.7037396430969238 time_taken: 0.05698800086975098\n",
      "Epoch 1: iteration 438/2501 train_loss: 0.7036371827125549 time_taken: 0.05658555030822754\n",
      "Epoch 1: iteration 439/2501 train_loss: 0.7035227417945862 time_taken: 0.057379722595214844\n",
      "Epoch 1: iteration 440/2501 train_loss: 0.703410267829895 time_taken: 0.05672192573547363\n",
      "Epoch 1: iteration 441/2501 train_loss: 0.7032602429389954 time_taken: 0.057128190994262695\n",
      "Epoch 1: iteration 442/2501 train_loss: 0.7031447887420654 time_taken: 0.0569767951965332\n",
      "Epoch 1: iteration 443/2501 train_loss: 0.7030681371688843 time_taken: 0.05721569061279297\n",
      "Epoch 1: iteration 444/2501 train_loss: 0.7029995918273926 time_taken: 0.056876182556152344\n",
      "Epoch 1: iteration 445/2501 train_loss: 0.7029294371604919 time_taken: 0.05724906921386719\n",
      "Epoch 1: iteration 446/2501 train_loss: 0.7027936577796936 time_taken: 0.05680036544799805\n",
      "Epoch 1: iteration 447/2501 train_loss: 0.7027707099914551 time_taken: 0.05645322799682617\n",
      "Epoch 1: iteration 448/2501 train_loss: 0.702704668045044 time_taken: 0.05687570571899414\n",
      "Epoch 1: iteration 449/2501 train_loss: 0.7026075124740601 time_taken: 0.05700039863586426\n",
      "Epoch 1: iteration 450/2501 train_loss: 0.7025548219680786 time_taken: 0.05688023567199707\n",
      "Epoch 1: iteration 451/2501 train_loss: 0.702434241771698 time_taken: 0.056690216064453125\n",
      "Epoch 1: iteration 452/2501 train_loss: 0.70232754945755 time_taken: 0.05784726142883301\n",
      "Epoch 1: iteration 453/2501 train_loss: 0.702251672744751 time_taken: 0.057416439056396484\n",
      "Epoch 1: iteration 454/2501 train_loss: 0.7022079229354858 time_taken: 0.056587934494018555\n",
      "Epoch 1: iteration 455/2501 train_loss: 0.7021392583847046 time_taken: 0.09895467758178711\n",
      "Epoch 1: iteration 456/2501 train_loss: 0.702009916305542 time_taken: 0.05631613731384277\n",
      "Epoch 1: iteration 457/2501 train_loss: 0.7018215656280518 time_taken: 0.05608344078063965\n",
      "Epoch 1: iteration 458/2501 train_loss: 0.7016451954841614 time_taken: 0.056266069412231445\n",
      "Epoch 1: iteration 459/2501 train_loss: 0.7014006972312927 time_taken: 0.05626797676086426\n",
      "Epoch 1: iteration 460/2501 train_loss: 0.701144278049469 time_taken: 0.056644439697265625\n",
      "Epoch 1: iteration 461/2501 train_loss: 0.7008625268936157 time_taken: 0.0562746524810791\n",
      "Epoch 1: iteration 462/2501 train_loss: 0.700644850730896 time_taken: 0.05686235427856445\n",
      "Epoch 1: iteration 463/2501 train_loss: 0.7003834247589111 time_taken: 0.057065486907958984\n",
      "Epoch 1: iteration 464/2501 train_loss: 0.7001363039016724 time_taken: 0.05710625648498535\n",
      "Epoch 1: iteration 465/2501 train_loss: 0.6998531222343445 time_taken: 0.05655407905578613\n",
      "Epoch 1: iteration 466/2501 train_loss: 0.6995603442192078 time_taken: 0.057065486907958984\n",
      "Epoch 1: iteration 467/2501 train_loss: 0.699299693107605 time_taken: 0.05690622329711914\n",
      "Epoch 1: iteration 468/2501 train_loss: 0.6990365386009216 time_taken: 0.05698347091674805\n",
      "Epoch 1: iteration 469/2501 train_loss: 0.6988207697868347 time_taken: 0.05645108222961426\n",
      "Epoch 1: iteration 470/2501 train_loss: 0.6985908150672913 time_taken: 0.05620265007019043\n",
      "Epoch 1: iteration 471/2501 train_loss: 0.6983767151832581 time_taken: 0.057799339294433594\n",
      "Epoch 1: iteration 472/2501 train_loss: 0.698202908039093 time_taken: 0.05649733543395996\n",
      "Epoch 1: iteration 473/2501 train_loss: 0.6980775594711304 time_taken: 0.05728459358215332\n",
      "Epoch 1: iteration 474/2501 train_loss: 0.6979330778121948 time_taken: 0.05650186538696289\n",
      "Epoch 1: iteration 475/2501 train_loss: 0.697819709777832 time_taken: 0.056916236877441406\n",
      "Epoch 1: iteration 476/2501 train_loss: 0.6977325081825256 time_taken: 0.05669283866882324\n",
      "Epoch 1: iteration 477/2501 train_loss: 0.6976243853569031 time_taken: 0.05690360069274902\n",
      "Epoch 1: iteration 478/2501 train_loss: 0.697483241558075 time_taken: 0.05718278884887695\n",
      "Epoch 1: iteration 479/2501 train_loss: 0.6974256634712219 time_taken: 0.05630993843078613\n",
      "Epoch 1: iteration 480/2501 train_loss: 0.6972925662994385 time_taken: 0.05637693405151367\n",
      "Epoch 1: iteration 481/2501 train_loss: 0.6971926093101501 time_taken: 0.056577205657958984\n",
      "Epoch 1: iteration 482/2501 train_loss: 0.6970857381820679 time_taken: 0.05674409866333008\n",
      "Epoch 1: iteration 483/2501 train_loss: 0.6970135569572449 time_taken: 0.05655694007873535\n",
      "Epoch 1: iteration 484/2501 train_loss: 0.6969220638275146 time_taken: 0.07523465156555176\n",
      "Epoch 1: iteration 485/2501 train_loss: 0.6968691349029541 time_taken: 0.05650639533996582\n",
      "Epoch 1: iteration 486/2501 train_loss: 0.6967687606811523 time_taken: 0.05640983581542969\n",
      "Epoch 1: iteration 487/2501 train_loss: 0.6966491937637329 time_taken: 0.05676436424255371\n",
      "Epoch 1: iteration 488/2501 train_loss: 0.6965411901473999 time_taken: 0.056494712829589844\n",
      "Epoch 1: iteration 489/2501 train_loss: 0.6964691877365112 time_taken: 0.05797171592712402\n",
      "Epoch 1: iteration 490/2501 train_loss: 0.696344792842865 time_taken: 0.05687379837036133\n",
      "Epoch 1: iteration 491/2501 train_loss: 0.6962588429450989 time_taken: 0.05771684646606445\n",
      "Epoch 1: iteration 492/2501 train_loss: 0.6962061524391174 time_taken: 0.05650639533996582\n",
      "Epoch 1: iteration 493/2501 train_loss: 0.6961921453475952 time_taken: 0.05687451362609863\n",
      "Epoch 1: iteration 494/2501 train_loss: 0.6961280107498169 time_taken: 0.057189226150512695\n",
      "Epoch 1: iteration 495/2501 train_loss: 0.696025013923645 time_taken: 0.05699515342712402\n",
      "Epoch 1: iteration 496/2501 train_loss: 0.6959738731384277 time_taken: 0.056502580642700195\n",
      "Epoch 1: iteration 497/2501 train_loss: 0.6959327459335327 time_taken: 0.05695390701293945\n",
      "Epoch 1: iteration 498/2501 train_loss: 0.695856511592865 time_taken: 0.05649304389953613\n",
      "Epoch 1: iteration 499/2501 train_loss: 0.6957824230194092 time_taken: 0.05782318115234375\n",
      "Epoch 1: iteration 500/2501 train_loss: 0.6957377791404724 time_taken: 0.056862831115722656\n",
      "Epoch 1: iteration 501/2501 train_loss: 0.6956579685211182 time_taken: 0.056752681732177734\n",
      "Epoch 1: iteration 502/2501 train_loss: 0.6956021785736084 time_taken: 0.05735445022583008\n",
      "Epoch 1: iteration 503/2501 train_loss: 0.6955441236495972 time_taken: 0.05655407905578613\n",
      "Epoch 1: iteration 504/2501 train_loss: 0.6954848766326904 time_taken: 0.05689740180969238\n",
      "Epoch 1: iteration 505/2501 train_loss: 0.6954236626625061 time_taken: 0.057120561599731445\n",
      "Epoch 1: iteration 506/2501 train_loss: 0.6953475475311279 time_taken: 0.05688118934631348\n",
      "Epoch 1: iteration 507/2501 train_loss: 0.6952695250511169 time_taken: 0.05722761154174805\n",
      "Epoch 1: iteration 508/2501 train_loss: 0.6952391266822815 time_taken: 0.05673670768737793\n",
      "Epoch 1: iteration 509/2501 train_loss: 0.6951385736465454 time_taken: 0.05690360069274902\n",
      "Epoch 1: iteration 510/2501 train_loss: 0.6950990557670593 time_taken: 0.056833505630493164\n",
      "Epoch 1: iteration 511/2501 train_loss: 0.6950510144233704 time_taken: 0.05733156204223633\n",
      "Epoch 1: iteration 512/2501 train_loss: 0.694977343082428 time_taken: 0.05694246292114258\n",
      "Epoch 1: iteration 513/2501 train_loss: 0.6949234008789062 time_taken: 0.0587310791015625\n",
      "Epoch 1: iteration 514/2501 train_loss: 0.6948742866516113 time_taken: 0.05684256553649902\n",
      "Epoch 1: iteration 515/2501 train_loss: 0.6947886347770691 time_taken: 0.056890249252319336\n",
      "Epoch 1: iteration 516/2501 train_loss: 0.694705069065094 time_taken: 0.056921958923339844\n",
      "Epoch 1: iteration 517/2501 train_loss: 0.6946228742599487 time_taken: 0.05634284019470215\n",
      "Epoch 1: iteration 518/2501 train_loss: 0.6945218443870544 time_taken: 0.05668759346008301\n",
      "Epoch 1: iteration 519/2501 train_loss: 0.6943977475166321 time_taken: 0.05633044242858887\n",
      "Epoch 1: iteration 520/2501 train_loss: 0.6942834258079529 time_taken: 0.05722618103027344\n",
      "Epoch 1: iteration 521/2501 train_loss: 0.6941791772842407 time_taken: 0.057212114334106445\n",
      "Epoch 1: iteration 522/2501 train_loss: 0.6941038966178894 time_taken: 0.05687737464904785\n",
      "Epoch 1: iteration 523/2501 train_loss: 0.6940166354179382 time_taken: 0.05695319175720215\n",
      "Epoch 1: iteration 524/2501 train_loss: 0.6938872933387756 time_taken: 0.05790352821350098\n",
      "Epoch 1: iteration 525/2501 train_loss: 0.6937986016273499 time_taken: 0.05680584907531738\n",
      "Epoch 1: iteration 526/2501 train_loss: 0.6937034726142883 time_taken: 0.05724215507507324\n",
      "Epoch 1: iteration 527/2501 train_loss: 0.6936017274856567 time_taken: 0.05710268020629883\n",
      "Epoch 1: iteration 528/2501 train_loss: 0.6935059428215027 time_taken: 0.05644655227661133\n",
      "Epoch 1: iteration 529/2501 train_loss: 0.693379819393158 time_taken: 0.05644941329956055\n",
      "Epoch 1: iteration 530/2501 train_loss: 0.6932976841926575 time_taken: 0.0565187931060791\n",
      "Epoch 1: iteration 531/2501 train_loss: 0.6932448744773865 time_taken: 0.05666708946228027\n",
      "Epoch 1: iteration 532/2501 train_loss: 0.6931126117706299 time_taken: 0.05740165710449219\n",
      "Epoch 1: iteration 533/2501 train_loss: 0.6930193305015564 time_taken: 0.05652594566345215\n",
      "Epoch 1: iteration 534/2501 train_loss: 0.6929094791412354 time_taken: 0.0564570426940918\n",
      "Epoch 1: iteration 535/2501 train_loss: 0.692828357219696 time_taken: 0.05660748481750488\n",
      "Epoch 1: iteration 536/2501 train_loss: 0.6926971077919006 time_taken: 0.05891895294189453\n",
      "Epoch 1: iteration 537/2501 train_loss: 0.6925139427185059 time_taken: 0.056864261627197266\n",
      "Epoch 1: iteration 538/2501 train_loss: 0.6923418045043945 time_taken: 0.056345224380493164\n",
      "Epoch 1: iteration 539/2501 train_loss: 0.6921730041503906 time_taken: 0.0564875602722168\n",
      "Epoch 1: iteration 540/2501 train_loss: 0.6919623017311096 time_taken: 0.0574040412902832\n",
      "Epoch 1: iteration 541/2501 train_loss: 0.69179368019104 time_taken: 0.055969953536987305\n",
      "Epoch 1: iteration 542/2501 train_loss: 0.6916507482528687 time_taken: 0.05621623992919922\n",
      "Epoch 1: iteration 543/2501 train_loss: 0.6915423274040222 time_taken: 0.0563654899597168\n",
      "Epoch 1: iteration 544/2501 train_loss: 0.6914339661598206 time_taken: 0.05652737617492676\n",
      "Epoch 1: iteration 545/2501 train_loss: 0.6913380026817322 time_taken: 0.0560915470123291\n",
      "Epoch 1: iteration 546/2501 train_loss: 0.6912401914596558 time_taken: 0.05665397644042969\n",
      "Epoch 1: iteration 547/2501 train_loss: 0.6911661028862 time_taken: 0.05607724189758301\n",
      "Epoch 1: iteration 548/2501 train_loss: 0.691085696220398 time_taken: 0.056043148040771484\n",
      "Epoch 1: iteration 549/2501 train_loss: 0.6909853219985962 time_taken: 0.05661201477050781\n",
      "Epoch 1: iteration 550/2501 train_loss: 0.6908936500549316 time_taken: 0.05595040321350098\n",
      "Epoch 1: iteration 551/2501 train_loss: 0.6907945275306702 time_taken: 0.05591988563537598\n",
      "Epoch 1: iteration 552/2501 train_loss: 0.6907222270965576 time_taken: 0.056678056716918945\n",
      "Epoch 1: iteration 553/2501 train_loss: 0.69060879945755 time_taken: 0.05600261688232422\n",
      "Epoch 1: iteration 554/2501 train_loss: 0.6904763579368591 time_taken: 0.05600690841674805\n",
      "Epoch 1: iteration 555/2501 train_loss: 0.6903874278068542 time_taken: 0.056139230728149414\n",
      "Epoch 1: iteration 556/2501 train_loss: 0.6903055310249329 time_taken: 0.05614519119262695\n",
      "Epoch 1: iteration 557/2501 train_loss: 0.6902121305465698 time_taken: 0.056111812591552734\n",
      "Epoch 1: iteration 558/2501 train_loss: 0.690114438533783 time_taken: 0.056142568588256836\n",
      "Epoch 1: iteration 559/2501 train_loss: 0.6899627447128296 time_taken: 0.05605721473693848\n",
      "Epoch 1: iteration 560/2501 train_loss: 0.6898277401924133 time_taken: 0.05675983428955078\n",
      "Epoch 1: iteration 561/2501 train_loss: 0.6897091269493103 time_taken: 0.056585073471069336\n",
      "Epoch 1: iteration 562/2501 train_loss: 0.6895656585693359 time_taken: 0.05684232711791992\n",
      "Epoch 1: iteration 563/2501 train_loss: 0.6894077062606812 time_taken: 0.05730152130126953\n",
      "Epoch 1: iteration 564/2501 train_loss: 0.6892843842506409 time_taken: 0.05660247802734375\n",
      "Epoch 1: iteration 565/2501 train_loss: 0.6891081929206848 time_taken: 0.05724740028381348\n",
      "Epoch 1: iteration 566/2501 train_loss: 0.6889631748199463 time_taken: 0.0569760799407959\n",
      "Epoch 1: iteration 567/2501 train_loss: 0.6888112425804138 time_taken: 0.05627036094665527\n",
      "Epoch 1: iteration 568/2501 train_loss: 0.6886646151542664 time_taken: 0.0566103458404541\n",
      "Epoch 1: iteration 569/2501 train_loss: 0.6885343790054321 time_taken: 0.056465864181518555\n",
      "Epoch 1: iteration 570/2501 train_loss: 0.6884292364120483 time_taken: 0.056348562240600586\n",
      "Epoch 1: iteration 571/2501 train_loss: 0.6883427500724792 time_taken: 0.056802988052368164\n",
      "Epoch 1: iteration 572/2501 train_loss: 0.6882832050323486 time_taken: 0.056682586669921875\n",
      "Epoch 1: iteration 573/2501 train_loss: 0.6882577538490295 time_taken: 0.056427001953125\n",
      "Epoch 1: iteration 574/2501 train_loss: 0.688232958316803 time_taken: 0.05662703514099121\n",
      "Epoch 1: iteration 575/2501 train_loss: 0.6882202625274658 time_taken: 0.05700397491455078\n",
      "Epoch 1: iteration 576/2501 train_loss: 0.688144862651825 time_taken: 0.0563817024230957\n",
      "Epoch 1: iteration 577/2501 train_loss: 0.6880865097045898 time_taken: 0.05689716339111328\n",
      "Epoch 1: iteration 578/2501 train_loss: 0.6880236268043518 time_taken: 0.05622553825378418\n",
      "Epoch 1: iteration 579/2501 train_loss: 0.6879175901412964 time_taken: 0.05664396286010742\n",
      "Epoch 1: iteration 580/2501 train_loss: 0.6878505349159241 time_taken: 0.0562441349029541\n",
      "Epoch 1: iteration 581/2501 train_loss: 0.6877830624580383 time_taken: 0.05680537223815918\n",
      "Epoch 1: iteration 582/2501 train_loss: 0.6876940727233887 time_taken: 0.056272029876708984\n",
      "Epoch 1: iteration 583/2501 train_loss: 0.6876129508018494 time_taken: 0.056806325912475586\n",
      "Epoch 1: iteration 584/2501 train_loss: 0.6875775456428528 time_taken: 0.05707430839538574\n",
      "Epoch 1: iteration 585/2501 train_loss: 0.687518298625946 time_taken: 0.0569005012512207\n",
      "Epoch 1: iteration 586/2501 train_loss: 0.6874550580978394 time_taken: 0.05751156806945801\n",
      "Epoch 1: iteration 587/2501 train_loss: 0.6873810887336731 time_taken: 0.05696821212768555\n",
      "Epoch 1: iteration 588/2501 train_loss: 0.6873074173927307 time_taken: 0.05662822723388672\n",
      "Epoch 1: iteration 589/2501 train_loss: 0.687205970287323 time_taken: 0.05768990516662598\n",
      "Epoch 1: iteration 590/2501 train_loss: 0.6871220469474792 time_taken: 0.056711435317993164\n",
      "Epoch 1: iteration 591/2501 train_loss: 0.6870224475860596 time_taken: 0.05636882781982422\n",
      "Epoch 1: iteration 592/2501 train_loss: 0.6869350671768188 time_taken: 0.05716896057128906\n",
      "Epoch 1: iteration 593/2501 train_loss: 0.6868332624435425 time_taken: 0.056246280670166016\n",
      "Epoch 1: iteration 594/2501 train_loss: 0.686725378036499 time_taken: 0.05722165107727051\n",
      "Epoch 1: iteration 595/2501 train_loss: 0.6866446733474731 time_taken: 0.05716705322265625\n",
      "Epoch 1: iteration 596/2501 train_loss: 0.6865405440330505 time_taken: 0.05691957473754883\n",
      "Epoch 1: iteration 597/2501 train_loss: 0.6864523887634277 time_taken: 0.0565640926361084\n",
      "Epoch 1: iteration 598/2501 train_loss: 0.6863144636154175 time_taken: 0.05687141418457031\n",
      "Epoch 1: iteration 599/2501 train_loss: 0.686229944229126 time_taken: 0.05633115768432617\n",
      "Epoch 1: iteration 600/2501 train_loss: 0.686104953289032 time_taken: 0.057229042053222656\n",
      "Epoch 1: iteration 601/2501 train_loss: 0.6860052943229675 time_taken: 0.05695343017578125\n",
      "Epoch 1: iteration 602/2501 train_loss: 0.6859340667724609 time_taken: 0.05672311782836914\n",
      "Epoch 1: iteration 603/2501 train_loss: 0.6858783960342407 time_taken: 0.057784318923950195\n",
      "Epoch 1: iteration 604/2501 train_loss: 0.6857990622520447 time_taken: 0.05757021903991699\n",
      "Epoch 1: iteration 605/2501 train_loss: 0.6856931447982788 time_taken: 0.05663418769836426\n",
      "Epoch 1: iteration 606/2501 train_loss: 0.6855764985084534 time_taken: 0.05656290054321289\n",
      "Epoch 1: iteration 607/2501 train_loss: 0.6855010390281677 time_taken: 0.0567018985748291\n",
      "Epoch 1: iteration 608/2501 train_loss: 0.6853932738304138 time_taken: 0.05711984634399414\n",
      "Epoch 1: iteration 609/2501 train_loss: 0.6853083372116089 time_taken: 0.0565643310546875\n",
      "Epoch 1: iteration 610/2501 train_loss: 0.6852418780326843 time_taken: 0.05833077430725098\n",
      "Epoch 1: iteration 611/2501 train_loss: 0.6851534843444824 time_taken: 0.05636739730834961\n",
      "Epoch 1: iteration 612/2501 train_loss: 0.6850714087486267 time_taken: 0.05688667297363281\n",
      "Epoch 1: iteration 613/2501 train_loss: 0.6849758625030518 time_taken: 0.05652260780334473\n",
      "Epoch 1: iteration 614/2501 train_loss: 0.6848742961883545 time_taken: 0.05633997917175293\n",
      "Epoch 1: iteration 615/2501 train_loss: 0.6847372055053711 time_taken: 0.05730152130126953\n",
      "Epoch 1: iteration 616/2501 train_loss: 0.6845802068710327 time_taken: 0.056868791580200195\n",
      "Epoch 1: iteration 617/2501 train_loss: 0.6844662427902222 time_taken: 0.05691266059875488\n",
      "Epoch 1: iteration 618/2501 train_loss: 0.6842899322509766 time_taken: 0.057210683822631836\n",
      "Epoch 1: iteration 619/2501 train_loss: 0.6841323971748352 time_taken: 0.05668234825134277\n",
      "Epoch 1: iteration 620/2501 train_loss: 0.6839724183082581 time_taken: 0.05714702606201172\n",
      "Epoch 1: iteration 621/2501 train_loss: 0.6838367581367493 time_taken: 0.056394338607788086\n",
      "Epoch 1: iteration 622/2501 train_loss: 0.6837098598480225 time_taken: 0.057576894760131836\n",
      "Epoch 1: iteration 623/2501 train_loss: 0.6835830807685852 time_taken: 0.056337833404541016\n",
      "Epoch 1: iteration 624/2501 train_loss: 0.6834605932235718 time_taken: 0.05695962905883789\n",
      "Epoch 1: iteration 625/2501 train_loss: 0.6833308339118958 time_taken: 0.056740522384643555\n",
      "Epoch 1: iteration 626/2501 train_loss: 0.6831954121589661 time_taken: 0.0562288761138916\n",
      "Epoch 1: iteration 627/2501 train_loss: 0.6831393241882324 time_taken: 0.05695033073425293\n",
      "Epoch 1: iteration 628/2501 train_loss: 0.6830368041992188 time_taken: 0.056525230407714844\n",
      "Epoch 1: iteration 629/2501 train_loss: 0.6829217672348022 time_taken: 0.05596780776977539\n",
      "Epoch 1: iteration 630/2501 train_loss: 0.6828129887580872 time_taken: 0.05677151679992676\n",
      "Epoch 1: iteration 631/2501 train_loss: 0.6827391386032104 time_taken: 0.056772708892822266\n",
      "Epoch 1: iteration 632/2501 train_loss: 0.6826547980308533 time_taken: 0.05616593360900879\n",
      "Epoch 1: iteration 633/2501 train_loss: 0.6825305819511414 time_taken: 0.05629396438598633\n",
      "Epoch 1: iteration 634/2501 train_loss: 0.6824473738670349 time_taken: 0.056761980056762695\n",
      "Epoch 1: iteration 635/2501 train_loss: 0.6823591589927673 time_taken: 0.05639290809631348\n",
      "Epoch 1: iteration 636/2501 train_loss: 0.6822201609611511 time_taken: 0.05689525604248047\n",
      "Epoch 1: iteration 637/2501 train_loss: 0.6820905208587646 time_taken: 0.05686759948730469\n",
      "Epoch 1: iteration 638/2501 train_loss: 0.6819607615470886 time_taken: 0.05649614334106445\n",
      "Epoch 1: iteration 639/2501 train_loss: 0.6817859411239624 time_taken: 0.056778907775878906\n",
      "Epoch 1: iteration 640/2501 train_loss: 0.6816380620002747 time_taken: 0.057314395904541016\n",
      "Epoch 1: iteration 641/2501 train_loss: 0.6814542412757874 time_taken: 0.05614495277404785\n",
      "Epoch 1: iteration 642/2501 train_loss: 0.6813100576400757 time_taken: 0.05634045600891113\n",
      "Epoch 1: iteration 643/2501 train_loss: 0.6811395287513733 time_taken: 0.056169986724853516\n",
      "Epoch 1: iteration 644/2501 train_loss: 0.6809588074684143 time_taken: 0.06499648094177246\n",
      "Epoch 1: iteration 645/2501 train_loss: 0.6807781457901001 time_taken: 0.056832075119018555\n",
      "Epoch 1: iteration 646/2501 train_loss: 0.6805704832077026 time_taken: 0.05661487579345703\n",
      "Epoch 1: iteration 647/2501 train_loss: 0.6803964376449585 time_taken: 0.05712294578552246\n",
      "Epoch 1: iteration 648/2501 train_loss: 0.6802151203155518 time_taken: 0.05628705024719238\n",
      "Epoch 1: iteration 649/2501 train_loss: 0.6801027059555054 time_taken: 0.05605649948120117\n",
      "Epoch 1: iteration 650/2501 train_loss: 0.6799673438072205 time_taken: 0.056303977966308594\n",
      "Epoch 1: iteration 651/2501 train_loss: 0.6798551082611084 time_taken: 0.05629992485046387\n",
      "Epoch 1: iteration 652/2501 train_loss: 0.6797556281089783 time_taken: 0.05634927749633789\n",
      "Epoch 1: iteration 653/2501 train_loss: 0.6796703934669495 time_taken: 0.0577092170715332\n",
      "Epoch 1: iteration 654/2501 train_loss: 0.679596483707428 time_taken: 0.05706143379211426\n",
      "Epoch 1: iteration 655/2501 train_loss: 0.6795514225959778 time_taken: 0.05637669563293457\n",
      "Epoch 1: iteration 656/2501 train_loss: 0.679473876953125 time_taken: 0.05731534957885742\n",
      "Epoch 1: iteration 657/2501 train_loss: 0.6794060468673706 time_taken: 0.056685686111450195\n",
      "Epoch 1: iteration 658/2501 train_loss: 0.6793291568756104 time_taken: 0.056809186935424805\n",
      "Epoch 1: iteration 659/2501 train_loss: 0.6792430281639099 time_taken: 0.057085514068603516\n",
      "Epoch 1: iteration 660/2501 train_loss: 0.6791861057281494 time_taken: 0.056815147399902344\n",
      "Epoch 1: iteration 661/2501 train_loss: 0.6791118383407593 time_taken: 0.05696749687194824\n",
      "Epoch 1: iteration 662/2501 train_loss: 0.679007351398468 time_taken: 0.057019948959350586\n",
      "Epoch 1: iteration 663/2501 train_loss: 0.6789259314537048 time_taken: 0.056456804275512695\n",
      "Epoch 1: iteration 664/2501 train_loss: 0.6788672208786011 time_taken: 0.056885480880737305\n",
      "Epoch 1: iteration 665/2501 train_loss: 0.678810179233551 time_taken: 0.05721426010131836\n",
      "Epoch 1: iteration 666/2501 train_loss: 0.678768515586853 time_taken: 0.05680274963378906\n",
      "Epoch 1: iteration 667/2501 train_loss: 0.6787232160568237 time_taken: 0.05652308464050293\n",
      "Epoch 1: iteration 668/2501 train_loss: 0.6786784529685974 time_taken: 0.05670762062072754\n",
      "Epoch 1: iteration 669/2501 train_loss: 0.678638219833374 time_taken: 0.056476593017578125\n",
      "Epoch 1: iteration 670/2501 train_loss: 0.6786255240440369 time_taken: 0.056593894958496094\n",
      "Epoch 1: iteration 671/2501 train_loss: 0.6785874366760254 time_taken: 0.05610227584838867\n",
      "Epoch 1: iteration 672/2501 train_loss: 0.6785330176353455 time_taken: 0.05645561218261719\n",
      "Epoch 1: iteration 673/2501 train_loss: 0.6785257458686829 time_taken: 0.06357622146606445\n",
      "Epoch 1: iteration 674/2501 train_loss: 0.6785329580307007 time_taken: 0.05649614334106445\n",
      "Epoch 1: iteration 675/2501 train_loss: 0.6785087585449219 time_taken: 0.05611777305603027\n",
      "Epoch 1: iteration 676/2501 train_loss: 0.6785035133361816 time_taken: 0.05646800994873047\n",
      "Epoch 1: iteration 677/2501 train_loss: 0.6785010695457458 time_taken: 0.05641770362854004\n",
      "Epoch 1: iteration 678/2501 train_loss: 0.6784705519676208 time_taken: 0.0565493106842041\n",
      "Epoch 1: iteration 679/2501 train_loss: 0.6784652471542358 time_taken: 0.056577205657958984\n",
      "Epoch 1: iteration 680/2501 train_loss: 0.6784422993659973 time_taken: 0.05660080909729004\n",
      "Epoch 1: iteration 681/2501 train_loss: 0.6784176230430603 time_taken: 0.056801795959472656\n",
      "Epoch 1: iteration 682/2501 train_loss: 0.6783808469772339 time_taken: 0.056652069091796875\n",
      "Epoch 1: iteration 683/2501 train_loss: 0.6783708930015564 time_taken: 0.05726933479309082\n",
      "Epoch 1: iteration 684/2501 train_loss: 0.6783291101455688 time_taken: 0.057199954986572266\n",
      "Epoch 1: iteration 685/2501 train_loss: 0.6782967448234558 time_taken: 0.0578005313873291\n",
      "Epoch 1: iteration 686/2501 train_loss: 0.6782656908035278 time_taken: 0.05605649948120117\n",
      "Epoch 1: iteration 687/2501 train_loss: 0.6782112121582031 time_taken: 0.05606698989868164\n",
      "Epoch 1: iteration 688/2501 train_loss: 0.6781477332115173 time_taken: 0.056310415267944336\n",
      "Epoch 1: iteration 689/2501 train_loss: 0.6780805587768555 time_taken: 0.05660104751586914\n",
      "Epoch 1: iteration 690/2501 train_loss: 0.6779997944831848 time_taken: 0.056655168533325195\n",
      "Epoch 1: iteration 691/2501 train_loss: 0.6778898239135742 time_taken: 0.057285308837890625\n",
      "Epoch 1: iteration 692/2501 train_loss: 0.6778005361557007 time_taken: 0.056401729583740234\n",
      "Epoch 1: iteration 693/2501 train_loss: 0.6777018308639526 time_taken: 0.056642770767211914\n",
      "Epoch 1: iteration 694/2501 train_loss: 0.6775966882705688 time_taken: 0.056801557540893555\n",
      "Epoch 1: iteration 695/2501 train_loss: 0.6774771809577942 time_taken: 0.05659365653991699\n",
      "Epoch 1: iteration 696/2501 train_loss: 0.6773540377616882 time_taken: 0.056446075439453125\n",
      "Epoch 1: iteration 697/2501 train_loss: 0.677265465259552 time_taken: 0.05698561668395996\n",
      "Epoch 1: iteration 698/2501 train_loss: 0.6771301627159119 time_taken: 0.05679798126220703\n",
      "Epoch 1: iteration 699/2501 train_loss: 0.6770142316818237 time_taken: 0.05645394325256348\n",
      "Epoch 1: iteration 700/2501 train_loss: 0.6769216656684875 time_taken: 0.05719876289367676\n",
      "Epoch 1: iteration 701/2501 train_loss: 0.6768514513969421 time_taken: 0.056800127029418945\n",
      "Epoch 1: iteration 702/2501 train_loss: 0.6767714619636536 time_taken: 0.05715203285217285\n",
      "Epoch 1: iteration 703/2501 train_loss: 0.6767638325691223 time_taken: 0.05775165557861328\n",
      "Epoch 1: iteration 704/2501 train_loss: 0.6767004132270813 time_taken: 0.05632328987121582\n",
      "Epoch 1: iteration 705/2501 train_loss: 0.6766630411148071 time_taken: 0.05633950233459473\n",
      "Epoch 1: iteration 706/2501 train_loss: 0.6766389608383179 time_taken: 0.05611753463745117\n",
      "Epoch 1: iteration 707/2501 train_loss: 0.6765995621681213 time_taken: 0.055855512619018555\n",
      "Epoch 1: iteration 708/2501 train_loss: 0.6765440106391907 time_taken: 0.056255340576171875\n",
      "Epoch 1: iteration 709/2501 train_loss: 0.6765236258506775 time_taken: 0.05619168281555176\n",
      "Epoch 1: iteration 710/2501 train_loss: 0.6765161752700806 time_taken: 0.05607175827026367\n",
      "Epoch 1: iteration 711/2501 train_loss: 0.6765300631523132 time_taken: 0.05596113204956055\n",
      "Epoch 1: iteration 712/2501 train_loss: 0.6765316724777222 time_taken: 0.05700850486755371\n",
      "Epoch 1: iteration 713/2501 train_loss: 0.6765277981758118 time_taken: 0.05669713020324707\n",
      "Epoch 1: iteration 714/2501 train_loss: 0.6765305995941162 time_taken: 0.05675172805786133\n",
      "Epoch 1: iteration 715/2501 train_loss: 0.6765497922897339 time_taken: 0.0566713809967041\n",
      "Epoch 1: iteration 716/2501 train_loss: 0.6765193343162537 time_taken: 0.05615520477294922\n",
      "Epoch 1: iteration 717/2501 train_loss: 0.6765152215957642 time_taken: 0.05656909942626953\n",
      "Epoch 1: iteration 718/2501 train_loss: 0.6765090823173523 time_taken: 0.05632901191711426\n",
      "Epoch 1: iteration 719/2501 train_loss: 0.6764976382255554 time_taken: 0.05714082717895508\n",
      "Epoch 1: iteration 720/2501 train_loss: 0.6764914393424988 time_taken: 0.05613422393798828\n",
      "Epoch 1: iteration 721/2501 train_loss: 0.6765086650848389 time_taken: 0.05678820610046387\n",
      "Epoch 1: iteration 722/2501 train_loss: 0.6765267848968506 time_taken: 0.05656170845031738\n",
      "Epoch 1: iteration 723/2501 train_loss: 0.6765576601028442 time_taken: 0.05731630325317383\n",
      "Epoch 1: iteration 724/2501 train_loss: 0.6765666604042053 time_taken: 0.056360483169555664\n",
      "Epoch 1: iteration 725/2501 train_loss: 0.6765840649604797 time_taken: 0.05744338035583496\n",
      "Epoch 1: iteration 726/2501 train_loss: 0.6765344738960266 time_taken: 0.056870460510253906\n",
      "Epoch 1: iteration 727/2501 train_loss: 0.6764549016952515 time_taken: 0.05659890174865723\n",
      "Epoch 1: iteration 728/2501 train_loss: 0.6764202117919922 time_taken: 0.057000160217285156\n",
      "Epoch 1: iteration 729/2501 train_loss: 0.676350474357605 time_taken: 0.0569303035736084\n",
      "Epoch 1: iteration 730/2501 train_loss: 0.6762745976448059 time_taken: 0.057846784591674805\n",
      "Epoch 1: iteration 731/2501 train_loss: 0.6761839985847473 time_taken: 0.057068586349487305\n",
      "Epoch 1: iteration 732/2501 train_loss: 0.6760740876197815 time_taken: 0.05679941177368164\n",
      "Epoch 1: iteration 733/2501 train_loss: 0.6759788393974304 time_taken: 0.05633687973022461\n",
      "Epoch 1: iteration 734/2501 train_loss: 0.6758629679679871 time_taken: 0.058676719665527344\n",
      "Epoch 1: iteration 735/2501 train_loss: 0.6757540702819824 time_taken: 0.05597209930419922\n",
      "Epoch 1: iteration 736/2501 train_loss: 0.675613284111023 time_taken: 0.05718684196472168\n",
      "Epoch 1: iteration 737/2501 train_loss: 0.6754930019378662 time_taken: 0.11553049087524414\n",
      "Epoch 1: iteration 738/2501 train_loss: 0.6753793358802795 time_taken: 0.055945634841918945\n",
      "Epoch 1: iteration 739/2501 train_loss: 0.6752722859382629 time_taken: 0.056533098220825195\n",
      "Epoch 1: iteration 740/2501 train_loss: 0.6751724481582642 time_taken: 0.05633211135864258\n",
      "Epoch 1: iteration 741/2501 train_loss: 0.6750745177268982 time_taken: 0.05672740936279297\n",
      "Epoch 1: iteration 742/2501 train_loss: 0.6749863624572754 time_taken: 0.0563507080078125\n",
      "Epoch 1: iteration 743/2501 train_loss: 0.6749048829078674 time_taken: 0.05662989616394043\n",
      "Epoch 1: iteration 744/2501 train_loss: 0.6748015880584717 time_taken: 0.05629849433898926\n",
      "Epoch 1: iteration 745/2501 train_loss: 0.6747149229049683 time_taken: 0.05652141571044922\n",
      "Epoch 1: iteration 746/2501 train_loss: 0.6746098399162292 time_taken: 0.056362152099609375\n",
      "Epoch 1: iteration 747/2501 train_loss: 0.6744973659515381 time_taken: 0.056523799896240234\n",
      "Epoch 1: iteration 748/2501 train_loss: 0.6743878126144409 time_taken: 0.05742645263671875\n",
      "Epoch 1: iteration 749/2501 train_loss: 0.6742588877677917 time_taken: 0.0571293830871582\n",
      "Epoch 1: iteration 750/2501 train_loss: 0.6741568446159363 time_taken: 0.056900978088378906\n",
      "Epoch 1: iteration 751/2501 train_loss: 0.6740490794181824 time_taken: 0.057227373123168945\n",
      "Epoch 1: iteration 752/2501 train_loss: 0.6739370822906494 time_taken: 0.0573885440826416\n",
      "Epoch 1: iteration 753/2501 train_loss: 0.6738055348396301 time_taken: 0.05782961845397949\n",
      "Epoch 1: iteration 754/2501 train_loss: 0.6736970543861389 time_taken: 0.056250572204589844\n",
      "Epoch 1: iteration 755/2501 train_loss: 0.6735721826553345 time_taken: 0.056272268295288086\n",
      "Epoch 1: iteration 756/2501 train_loss: 0.673444390296936 time_taken: 0.056752681732177734\n",
      "Epoch 1: iteration 757/2501 train_loss: 0.673327624797821 time_taken: 0.05781245231628418\n",
      "Epoch 1: iteration 758/2501 train_loss: 0.6732262969017029 time_taken: 0.05636334419250488\n",
      "Epoch 1: iteration 759/2501 train_loss: 0.6731396913528442 time_taken: 0.056176185607910156\n",
      "Epoch 1: iteration 760/2501 train_loss: 0.6730724573135376 time_taken: 0.056374549865722656\n",
      "Epoch 1: iteration 761/2501 train_loss: 0.6729872226715088 time_taken: 0.05619668960571289\n",
      "Epoch 1: iteration 762/2501 train_loss: 0.6729268431663513 time_taken: 0.056723594665527344\n",
      "Epoch 1: iteration 763/2501 train_loss: 0.6728779077529907 time_taken: 0.05659651756286621\n",
      "Epoch 1: iteration 764/2501 train_loss: 0.6728323101997375 time_taken: 0.05736088752746582\n",
      "Epoch 1: iteration 765/2501 train_loss: 0.6727964878082275 time_taken: 0.0575404167175293\n",
      "Epoch 1: iteration 766/2501 train_loss: 0.6727432608604431 time_taken: 0.055985450744628906\n",
      "Epoch 1: iteration 767/2501 train_loss: 0.6727339625358582 time_taken: 0.05638599395751953\n",
      "Epoch 1: iteration 768/2501 train_loss: 0.6727182865142822 time_taken: 0.05616044998168945\n",
      "Epoch 1: iteration 769/2501 train_loss: 0.6727134585380554 time_taken: 0.056603431701660156\n",
      "Epoch 1: iteration 770/2501 train_loss: 0.6727258563041687 time_taken: 0.057504892349243164\n",
      "Epoch 1: iteration 771/2501 train_loss: 0.6727399230003357 time_taken: 0.05610775947570801\n",
      "Epoch 1: iteration 772/2501 train_loss: 0.6727192401885986 time_taken: 0.056021690368652344\n",
      "Epoch 1: iteration 773/2501 train_loss: 0.6727355122566223 time_taken: 0.05619335174560547\n",
      "Epoch 1: iteration 774/2501 train_loss: 0.6727132797241211 time_taken: 0.05593681335449219\n",
      "Epoch 1: iteration 775/2501 train_loss: 0.6727035641670227 time_taken: 0.057251930236816406\n",
      "Epoch 1: iteration 776/2501 train_loss: 0.6727180480957031 time_taken: 0.056636810302734375\n",
      "Epoch 1: iteration 777/2501 train_loss: 0.6727699637413025 time_taken: 0.05621457099914551\n",
      "Epoch 1: iteration 778/2501 train_loss: 0.6727708578109741 time_taken: 0.056839704513549805\n",
      "Epoch 1: iteration 779/2501 train_loss: 0.6727675199508667 time_taken: 0.05695056915283203\n",
      "Epoch 1: iteration 780/2501 train_loss: 0.6727525591850281 time_taken: 0.057219743728637695\n",
      "Epoch 1: iteration 781/2501 train_loss: 0.6727882027626038 time_taken: 0.05742311477661133\n",
      "Epoch 1: iteration 782/2501 train_loss: 0.67274409532547 time_taken: 0.0570673942565918\n",
      "Epoch 1: iteration 783/2501 train_loss: 0.6727443337440491 time_taken: 0.05657649040222168\n",
      "Epoch 1: iteration 784/2501 train_loss: 0.6726999282836914 time_taken: 0.056720733642578125\n",
      "Epoch 1: iteration 785/2501 train_loss: 0.6726523637771606 time_taken: 0.05675077438354492\n",
      "Epoch 1: iteration 786/2501 train_loss: 0.6726357340812683 time_taken: 0.056940555572509766\n",
      "Epoch 1: iteration 787/2501 train_loss: 0.6725847125053406 time_taken: 0.05640864372253418\n",
      "Epoch 1: iteration 788/2501 train_loss: 0.6725392937660217 time_taken: 0.05780625343322754\n",
      "Epoch 1: iteration 789/2501 train_loss: 0.6724725961685181 time_taken: 0.05713248252868652\n",
      "Epoch 1: iteration 790/2501 train_loss: 0.6724324822425842 time_taken: 0.056874990463256836\n",
      "Epoch 1: iteration 791/2501 train_loss: 0.6723914742469788 time_taken: 0.05691027641296387\n",
      "Epoch 1: iteration 792/2501 train_loss: 0.6723853945732117 time_taken: 0.05699515342712402\n",
      "Epoch 1: iteration 793/2501 train_loss: 0.6723752021789551 time_taken: 0.05673551559448242\n",
      "Epoch 1: iteration 794/2501 train_loss: 0.6723790168762207 time_taken: 0.057058095932006836\n",
      "Epoch 1: iteration 795/2501 train_loss: 0.6723930835723877 time_taken: 0.05680060386657715\n",
      "Epoch 1: iteration 796/2501 train_loss: 0.6723823547363281 time_taken: 0.0573275089263916\n",
      "Epoch 1: iteration 797/2501 train_loss: 0.6723735332489014 time_taken: 0.05645871162414551\n",
      "Epoch 1: iteration 798/2501 train_loss: 0.6723768711090088 time_taken: 0.05688905715942383\n",
      "Epoch 1: iteration 799/2501 train_loss: 0.672382652759552 time_taken: 0.05678868293762207\n",
      "Epoch 1: iteration 800/2501 train_loss: 0.6723751425743103 time_taken: 0.05759167671203613\n",
      "Epoch 1: iteration 801/2501 train_loss: 0.6723566651344299 time_taken: 0.056690216064453125\n",
      "Epoch 1: iteration 802/2501 train_loss: 0.6723183393478394 time_taken: 0.05686140060424805\n",
      "Epoch 1: iteration 803/2501 train_loss: 0.6722884178161621 time_taken: 0.055982112884521484\n",
      "Epoch 1: iteration 804/2501 train_loss: 0.67226243019104 time_taken: 0.05609130859375\n",
      "Epoch 1: iteration 805/2501 train_loss: 0.6722339391708374 time_taken: 0.056005001068115234\n",
      "Epoch 1: iteration 806/2501 train_loss: 0.6721975207328796 time_taken: 0.05639338493347168\n",
      "Epoch 1: iteration 807/2501 train_loss: 0.6721655130386353 time_taken: 0.05646014213562012\n",
      "Epoch 1: iteration 808/2501 train_loss: 0.6721432209014893 time_taken: 0.05749392509460449\n",
      "Epoch 1: iteration 809/2501 train_loss: 0.6721128821372986 time_taken: 0.05662274360656738\n",
      "Epoch 1: iteration 810/2501 train_loss: 0.672071635723114 time_taken: 0.056165218353271484\n",
      "Epoch 1: iteration 811/2501 train_loss: 0.6720457673072815 time_taken: 0.056514739990234375\n",
      "Epoch 1: iteration 812/2501 train_loss: 0.6720326542854309 time_taken: 0.05640459060668945\n",
      "Epoch 1: iteration 813/2501 train_loss: 0.6720150113105774 time_taken: 0.056397438049316406\n",
      "Epoch 1: iteration 814/2501 train_loss: 0.6719920039176941 time_taken: 0.056569814682006836\n",
      "Epoch 1: iteration 815/2501 train_loss: 0.6719677448272705 time_taken: 0.05627131462097168\n",
      "Epoch 1: iteration 816/2501 train_loss: 0.6719216108322144 time_taken: 0.05680441856384277\n",
      "Epoch 1: iteration 817/2501 train_loss: 0.6719024777412415 time_taken: 0.05663800239562988\n",
      "Epoch 1: iteration 818/2501 train_loss: 0.6718944311141968 time_taken: 0.0570068359375\n",
      "Epoch 1: iteration 819/2501 train_loss: 0.6718946695327759 time_taken: 0.05721879005432129\n",
      "Epoch 1: iteration 820/2501 train_loss: 0.6719143986701965 time_taken: 0.057030439376831055\n",
      "Epoch 1: iteration 821/2501 train_loss: 0.6719235777854919 time_taken: 0.05783367156982422\n",
      "Epoch 1: iteration 822/2501 train_loss: 0.6719241142272949 time_taken: 0.056379079818725586\n",
      "Epoch 1: iteration 823/2501 train_loss: 0.6718777418136597 time_taken: 0.05690884590148926\n",
      "Epoch 1: iteration 824/2501 train_loss: 0.67183917760849 time_taken: 0.05715012550354004\n",
      "Epoch 1: iteration 825/2501 train_loss: 0.6718016862869263 time_taken: 0.05684924125671387\n",
      "Epoch 1: iteration 826/2501 train_loss: 0.6717454195022583 time_taken: 0.05751609802246094\n",
      "Epoch 1: iteration 827/2501 train_loss: 0.6717039942741394 time_taken: 0.05655789375305176\n",
      "Epoch 1: iteration 828/2501 train_loss: 0.6716539263725281 time_taken: 0.05780982971191406\n",
      "Epoch 1: iteration 829/2501 train_loss: 0.671595573425293 time_taken: 0.05654454231262207\n",
      "Epoch 1: iteration 830/2501 train_loss: 0.6715309619903564 time_taken: 0.0566563606262207\n",
      "Epoch 1: iteration 831/2501 train_loss: 0.6714495420455933 time_taken: 0.05670499801635742\n",
      "Epoch 1: iteration 832/2501 train_loss: 0.6713604927062988 time_taken: 0.056046485900878906\n",
      "Epoch 1: iteration 833/2501 train_loss: 0.6712971329689026 time_taken: 0.05624818801879883\n",
      "Epoch 1: iteration 834/2501 train_loss: 0.6712239980697632 time_taken: 0.05674028396606445\n",
      "Epoch 1: iteration 835/2501 train_loss: 0.6711611151695251 time_taken: 0.05689358711242676\n",
      "Epoch 1: iteration 836/2501 train_loss: 0.671085000038147 time_taken: 0.06479573249816895\n",
      "Epoch 1: iteration 837/2501 train_loss: 0.6709982752799988 time_taken: 0.057008981704711914\n",
      "Epoch 1: iteration 838/2501 train_loss: 0.6709380745887756 time_taken: 0.05710768699645996\n",
      "Epoch 1: iteration 839/2501 train_loss: 0.6708683371543884 time_taken: 0.057782888412475586\n",
      "Epoch 1: iteration 840/2501 train_loss: 0.670811116695404 time_taken: 0.05695295333862305\n",
      "Epoch 1: iteration 841/2501 train_loss: 0.6707499027252197 time_taken: 0.057094573974609375\n",
      "Epoch 1: iteration 842/2501 train_loss: 0.6706621050834656 time_taken: 0.057129859924316406\n",
      "Epoch 1: iteration 843/2501 train_loss: 0.6706027984619141 time_taken: 0.05654764175415039\n",
      "Epoch 1: iteration 844/2501 train_loss: 0.6705217957496643 time_taken: 0.056764841079711914\n",
      "Epoch 1: iteration 845/2501 train_loss: 0.6704646944999695 time_taken: 0.05690813064575195\n",
      "Epoch 1: iteration 846/2501 train_loss: 0.670394241809845 time_taken: 0.05674266815185547\n",
      "Epoch 1: iteration 847/2501 train_loss: 0.6703096032142639 time_taken: 0.05692124366760254\n",
      "Epoch 1: iteration 848/2501 train_loss: 0.6702257394790649 time_taken: 0.05708885192871094\n",
      "Epoch 1: iteration 849/2501 train_loss: 0.6701288819313049 time_taken: 0.056662797927856445\n",
      "Epoch 1: iteration 850/2501 train_loss: 0.6700451374053955 time_taken: 0.056748390197753906\n",
      "Epoch 1: iteration 851/2501 train_loss: 0.6699473261833191 time_taken: 0.05710649490356445\n",
      "Epoch 1: iteration 852/2501 train_loss: 0.6698555946350098 time_taken: 0.05668163299560547\n",
      "Epoch 1: iteration 853/2501 train_loss: 0.6697747707366943 time_taken: 0.057044029235839844\n",
      "Epoch 1: iteration 854/2501 train_loss: 0.669725775718689 time_taken: 0.05662655830383301\n",
      "Epoch 1: iteration 855/2501 train_loss: 0.6696373224258423 time_taken: 0.056622982025146484\n",
      "Epoch 1: iteration 856/2501 train_loss: 0.6695424318313599 time_taken: 0.056241512298583984\n",
      "Epoch 1: iteration 857/2501 train_loss: 0.6694809794425964 time_taken: 0.05718660354614258\n",
      "Epoch 1: iteration 858/2501 train_loss: 0.6694159507751465 time_taken: 0.05654168128967285\n",
      "Epoch 1: iteration 859/2501 train_loss: 0.6693670749664307 time_taken: 0.05693459510803223\n",
      "Epoch 1: iteration 860/2501 train_loss: 0.6693356037139893 time_taken: 0.056498050689697266\n",
      "Epoch 1: iteration 861/2501 train_loss: 0.6693122386932373 time_taken: 0.05728006362915039\n",
      "Epoch 1: iteration 862/2501 train_loss: 0.6693040132522583 time_taken: 0.05644536018371582\n",
      "Epoch 1: iteration 863/2501 train_loss: 0.669276773929596 time_taken: 0.056514739990234375\n",
      "Epoch 1: iteration 864/2501 train_loss: 0.6692318320274353 time_taken: 0.056920766830444336\n",
      "Epoch 1: iteration 865/2501 train_loss: 0.6691706776618958 time_taken: 0.05650687217712402\n",
      "Epoch 1: iteration 866/2501 train_loss: 0.6691131591796875 time_taken: 0.05670571327209473\n",
      "Epoch 1: iteration 867/2501 train_loss: 0.6690959930419922 time_taken: 0.056319236755371094\n",
      "Epoch 1: iteration 868/2501 train_loss: 0.6690582036972046 time_taken: 0.05707216262817383\n",
      "Epoch 1: iteration 869/2501 train_loss: 0.6690266728401184 time_taken: 0.05633115768432617\n",
      "Epoch 1: iteration 870/2501 train_loss: 0.6690337657928467 time_taken: 0.05632781982421875\n",
      "Epoch 1: iteration 871/2501 train_loss: 0.6690172553062439 time_taken: 0.056162118911743164\n",
      "Epoch 1: iteration 872/2501 train_loss: 0.6689955592155457 time_taken: 0.05660080909729004\n",
      "Epoch 1: iteration 873/2501 train_loss: 0.6689983606338501 time_taken: 0.0574498176574707\n",
      "Epoch 1: iteration 874/2501 train_loss: 0.6689865589141846 time_taken: 0.0566103458404541\n",
      "Epoch 1: iteration 875/2501 train_loss: 0.6689930558204651 time_taken: 0.056595563888549805\n",
      "Epoch 1: iteration 876/2501 train_loss: 0.6689910888671875 time_taken: 0.05654406547546387\n",
      "Epoch 1: iteration 877/2501 train_loss: 0.6689716577529907 time_taken: 0.05635190010070801\n",
      "Epoch 1: iteration 878/2501 train_loss: 0.6689469218254089 time_taken: 0.05722689628601074\n",
      "Epoch 1: iteration 879/2501 train_loss: 0.6689407825469971 time_taken: 0.056833744049072266\n",
      "Epoch 1: iteration 880/2501 train_loss: 0.6689340472221375 time_taken: 0.07187342643737793\n",
      "Epoch 1: iteration 881/2501 train_loss: 0.6689532995223999 time_taken: 0.05695796012878418\n",
      "Epoch 1: iteration 882/2501 train_loss: 0.6689509749412537 time_taken: 0.05680584907531738\n",
      "Epoch 1: iteration 883/2501 train_loss: 0.6689832210540771 time_taken: 0.056307315826416016\n",
      "Epoch 1: iteration 884/2501 train_loss: 0.6690129637718201 time_taken: 0.05651545524597168\n",
      "Epoch 1: iteration 885/2501 train_loss: 0.6690273880958557 time_taken: 0.0567479133605957\n",
      "Epoch 1: iteration 886/2501 train_loss: 0.6690629720687866 time_taken: 0.0563349723815918\n",
      "Epoch 1: iteration 887/2501 train_loss: 0.6690902709960938 time_taken: 0.05642533302307129\n",
      "Epoch 1: iteration 888/2501 train_loss: 0.6691466569900513 time_taken: 0.05684304237365723\n",
      "Epoch 1: iteration 889/2501 train_loss: 0.6691973209381104 time_taken: 0.05687427520751953\n",
      "Epoch 1: iteration 890/2501 train_loss: 0.6692605018615723 time_taken: 0.056359291076660156\n",
      "Epoch 1: iteration 891/2501 train_loss: 0.6693308353424072 time_taken: 0.05684399604797363\n",
      "Epoch 1: iteration 892/2501 train_loss: 0.6693931818008423 time_taken: 0.05710124969482422\n",
      "Epoch 1: iteration 893/2501 train_loss: 0.6694088578224182 time_taken: 0.056700944900512695\n",
      "Epoch 1: iteration 894/2501 train_loss: 0.6694316864013672 time_taken: 0.05690288543701172\n",
      "Epoch 1: iteration 895/2501 train_loss: 0.669427216053009 time_taken: 0.05677652359008789\n",
      "Epoch 1: iteration 896/2501 train_loss: 0.6694076657295227 time_taken: 0.056505680084228516\n",
      "Epoch 1: iteration 897/2501 train_loss: 0.6693974137306213 time_taken: 0.05711674690246582\n",
      "Epoch 1: iteration 898/2501 train_loss: 0.6693616509437561 time_taken: 0.0564427375793457\n",
      "Epoch 1: iteration 899/2501 train_loss: 0.6693124175071716 time_taken: 0.05690431594848633\n",
      "Epoch 1: iteration 900/2501 train_loss: 0.669282853603363 time_taken: 0.056062936782836914\n",
      "Epoch 1: iteration 901/2501 train_loss: 0.6692688465118408 time_taken: 0.056798696517944336\n",
      "Epoch 1: iteration 902/2501 train_loss: 0.6692051887512207 time_taken: 0.05651092529296875\n",
      "Epoch 1: iteration 903/2501 train_loss: 0.6691552400588989 time_taken: 0.05659294128417969\n",
      "Epoch 1: iteration 904/2501 train_loss: 0.6690834760665894 time_taken: 0.0567014217376709\n",
      "Epoch 1: iteration 905/2501 train_loss: 0.6690048575401306 time_taken: 0.056700944900512695\n",
      "Epoch 1: iteration 906/2501 train_loss: 0.6689222455024719 time_taken: 0.05662274360656738\n",
      "Epoch 1: iteration 907/2501 train_loss: 0.6688424944877625 time_taken: 0.05616927146911621\n",
      "Epoch 1: iteration 908/2501 train_loss: 0.6687493324279785 time_taken: 0.05751752853393555\n",
      "Epoch 1: iteration 909/2501 train_loss: 0.668707013130188 time_taken: 0.056520938873291016\n",
      "Epoch 1: iteration 910/2501 train_loss: 0.668647825717926 time_taken: 0.0565037727355957\n",
      "Epoch 1: iteration 911/2501 train_loss: 0.668617844581604 time_taken: 0.05663943290710449\n",
      "Epoch 1: iteration 912/2501 train_loss: 0.6685951948165894 time_taken: 0.056998491287231445\n",
      "Epoch 1: iteration 913/2501 train_loss: 0.668569803237915 time_taken: 0.0566408634185791\n",
      "Epoch 1: iteration 914/2501 train_loss: 0.6685888171195984 time_taken: 0.05707097053527832\n",
      "Epoch 1: iteration 915/2501 train_loss: 0.668609619140625 time_taken: 0.05735945701599121\n",
      "Epoch 1: iteration 916/2501 train_loss: 0.668602466583252 time_taken: 0.0564265251159668\n",
      "Epoch 1: iteration 917/2501 train_loss: 0.6686323285102844 time_taken: 0.05598926544189453\n",
      "Epoch 1: iteration 918/2501 train_loss: 0.6686481237411499 time_taken: 0.055803775787353516\n",
      "Epoch 1: iteration 919/2501 train_loss: 0.6686518788337708 time_taken: 0.056611061096191406\n",
      "Epoch 1: iteration 920/2501 train_loss: 0.6686257719993591 time_taken: 0.05584406852722168\n",
      "Epoch 1: iteration 921/2501 train_loss: 0.66859370470047 time_taken: 0.05664539337158203\n",
      "Epoch 1: iteration 922/2501 train_loss: 0.6685659289360046 time_taken: 0.055850982666015625\n",
      "Epoch 1: iteration 923/2501 train_loss: 0.6685243844985962 time_taken: 0.05612683296203613\n",
      "Epoch 1: iteration 924/2501 train_loss: 0.6684293746948242 time_taken: 0.05644416809082031\n",
      "Epoch 1: iteration 925/2501 train_loss: 0.6683263778686523 time_taken: 0.05637192726135254\n",
      "Epoch 1: iteration 926/2501 train_loss: 0.6682416200637817 time_taken: 0.05701303482055664\n",
      "Epoch 1: iteration 927/2501 train_loss: 0.6681463122367859 time_taken: 0.05639076232910156\n",
      "Epoch 1: iteration 928/2501 train_loss: 0.6680248975753784 time_taken: 0.056275129318237305\n",
      "Epoch 1: iteration 929/2501 train_loss: 0.6678946614265442 time_taken: 0.055761098861694336\n",
      "Epoch 1: iteration 930/2501 train_loss: 0.6677570343017578 time_taken: 0.05618715286254883\n",
      "Epoch 1: iteration 931/2501 train_loss: 0.6676114201545715 time_taken: 0.05745244026184082\n",
      "Epoch 1: iteration 932/2501 train_loss: 0.6674606204032898 time_taken: 0.05628561973571777\n",
      "Epoch 1: iteration 933/2501 train_loss: 0.667316198348999 time_taken: 0.0641024112701416\n",
      "Epoch 1: iteration 934/2501 train_loss: 0.6671566963195801 time_taken: 0.055876731872558594\n",
      "Epoch 1: iteration 935/2501 train_loss: 0.6670095920562744 time_taken: 0.05620431900024414\n",
      "Epoch 1: iteration 936/2501 train_loss: 0.6668688058853149 time_taken: 0.05634140968322754\n",
      "Epoch 1: iteration 937/2501 train_loss: 0.6667181849479675 time_taken: 0.05631232261657715\n",
      "Epoch 1: iteration 938/2501 train_loss: 0.6665778160095215 time_taken: 0.0565035343170166\n",
      "Epoch 1: iteration 939/2501 train_loss: 0.6664503812789917 time_taken: 0.05636858940124512\n",
      "Epoch 1: iteration 940/2501 train_loss: 0.6663212180137634 time_taken: 0.05636930465698242\n",
      "Epoch 1: iteration 941/2501 train_loss: 0.6662116050720215 time_taken: 0.05580306053161621\n",
      "Epoch 1: iteration 942/2501 train_loss: 0.6661099195480347 time_taken: 0.056459665298461914\n",
      "Epoch 1: iteration 943/2501 train_loss: 0.6659806370735168 time_taken: 0.05688762664794922\n",
      "Epoch 1: iteration 944/2501 train_loss: 0.6658449769020081 time_taken: 0.05664777755737305\n",
      "Epoch 1: iteration 945/2501 train_loss: 0.665702760219574 time_taken: 0.05699419975280762\n",
      "Epoch 1: iteration 946/2501 train_loss: 0.6655724048614502 time_taken: 0.056285858154296875\n",
      "Epoch 1: iteration 947/2501 train_loss: 0.6654521226882935 time_taken: 0.05633902549743652\n",
      "Epoch 1: iteration 948/2501 train_loss: 0.6653533577919006 time_taken: 0.05662178993225098\n",
      "Epoch 1: iteration 949/2501 train_loss: 0.6652686595916748 time_taken: 0.056610107421875\n",
      "Epoch 1: iteration 950/2501 train_loss: 0.6651790142059326 time_taken: 0.05643773078918457\n",
      "Epoch 1: iteration 951/2501 train_loss: 0.6650939583778381 time_taken: 0.05673027038574219\n",
      "Epoch 1: iteration 952/2501 train_loss: 0.6650366187095642 time_taken: 0.05720806121826172\n",
      "Epoch 1: iteration 953/2501 train_loss: 0.6649648547172546 time_taken: 0.056267738342285156\n",
      "Epoch 1: iteration 954/2501 train_loss: 0.6649182438850403 time_taken: 0.056040048599243164\n",
      "Epoch 1: iteration 955/2501 train_loss: 0.6648497581481934 time_taken: 0.056226253509521484\n",
      "Epoch 1: iteration 956/2501 train_loss: 0.664783775806427 time_taken: 0.056359291076660156\n",
      "Epoch 1: iteration 957/2501 train_loss: 0.664729118347168 time_taken: 0.05700206756591797\n",
      "Epoch 1: iteration 958/2501 train_loss: 0.664657711982727 time_taken: 0.056160688400268555\n",
      "Epoch 1: iteration 959/2501 train_loss: 0.66461580991745 time_taken: 0.05664229393005371\n",
      "Epoch 1: iteration 960/2501 train_loss: 0.664563000202179 time_taken: 0.05669546127319336\n",
      "Epoch 1: iteration 961/2501 train_loss: 0.664504885673523 time_taken: 0.05596661567687988\n",
      "Epoch 1: iteration 962/2501 train_loss: 0.6644397377967834 time_taken: 0.05652785301208496\n",
      "Epoch 1: iteration 963/2501 train_loss: 0.664383053779602 time_taken: 0.0565030574798584\n",
      "Epoch 1: iteration 964/2501 train_loss: 0.6643166542053223 time_taken: 0.0560910701751709\n",
      "Epoch 1: iteration 965/2501 train_loss: 0.6642553806304932 time_taken: 0.05640602111816406\n",
      "Epoch 1: iteration 966/2501 train_loss: 0.6642109155654907 time_taken: 0.05670642852783203\n",
      "Epoch 1: iteration 967/2501 train_loss: 0.6641943454742432 time_taken: 0.056455135345458984\n",
      "Epoch 1: iteration 968/2501 train_loss: 0.6641620993614197 time_taken: 0.05637478828430176\n",
      "Epoch 1: iteration 969/2501 train_loss: 0.6641584038734436 time_taken: 0.05605506896972656\n",
      "Epoch 1: iteration 970/2501 train_loss: 0.6641745567321777 time_taken: 0.05628085136413574\n",
      "Epoch 1: iteration 971/2501 train_loss: 0.6641982197761536 time_taken: 0.056529998779296875\n",
      "Epoch 1: iteration 972/2501 train_loss: 0.6642153263092041 time_taken: 0.05601000785827637\n",
      "Epoch 1: iteration 973/2501 train_loss: 0.6642330288887024 time_taken: 0.056075096130371094\n",
      "Epoch 1: iteration 974/2501 train_loss: 0.6642765402793884 time_taken: 0.05705857276916504\n",
      "Epoch 1: iteration 975/2501 train_loss: 0.664307177066803 time_taken: 0.05722236633300781\n",
      "Epoch 1: iteration 976/2501 train_loss: 0.6643187403678894 time_taken: 0.05666756629943848\n",
      "Epoch 1: iteration 977/2501 train_loss: 0.6643422245979309 time_taken: 0.05669283866882324\n",
      "Epoch 1: iteration 978/2501 train_loss: 0.6643798351287842 time_taken: 0.05613851547241211\n",
      "Epoch 1: iteration 979/2501 train_loss: 0.6644259691238403 time_taken: 0.05628633499145508\n",
      "Epoch 1: iteration 980/2501 train_loss: 0.6644682288169861 time_taken: 0.05632948875427246\n",
      "Epoch 1: iteration 981/2501 train_loss: 0.6645070314407349 time_taken: 0.05641317367553711\n",
      "Epoch 1: iteration 982/2501 train_loss: 0.664566695690155 time_taken: 0.05640745162963867\n",
      "Epoch 1: iteration 983/2501 train_loss: 0.6646251678466797 time_taken: 0.05748724937438965\n",
      "Epoch 1: iteration 984/2501 train_loss: 0.6646804213523865 time_taken: 0.05638575553894043\n",
      "Epoch 1: iteration 985/2501 train_loss: 0.6646855473518372 time_taken: 0.05688786506652832\n",
      "Epoch 1: iteration 986/2501 train_loss: 0.6647266149520874 time_taken: 0.05765557289123535\n",
      "Epoch 1: iteration 987/2501 train_loss: 0.6647686958312988 time_taken: 0.05663895606994629\n",
      "Epoch 1: iteration 988/2501 train_loss: 0.6648202538490295 time_taken: 0.057146310806274414\n",
      "Epoch 1: iteration 989/2501 train_loss: 0.6648477911949158 time_taken: 0.056363821029663086\n",
      "Epoch 1: iteration 990/2501 train_loss: 0.664891242980957 time_taken: 0.05702400207519531\n",
      "Epoch 1: iteration 991/2501 train_loss: 0.6649090051651001 time_taken: 0.05710339546203613\n",
      "Epoch 1: iteration 992/2501 train_loss: 0.6649714112281799 time_taken: 0.05684018135070801\n",
      "Epoch 1: iteration 993/2501 train_loss: 0.6650070548057556 time_taken: 0.05635952949523926\n",
      "Epoch 1: iteration 994/2501 train_loss: 0.6650387644767761 time_taken: 0.05668473243713379\n",
      "Epoch 1: iteration 995/2501 train_loss: 0.6650916934013367 time_taken: 0.0574040412902832\n",
      "Epoch 1: iteration 996/2501 train_loss: 0.6651533246040344 time_taken: 0.05623364448547363\n",
      "Epoch 1: iteration 997/2501 train_loss: 0.6651917695999146 time_taken: 0.0566408634185791\n",
      "Epoch 1: iteration 998/2501 train_loss: 0.6652311682701111 time_taken: 0.056618452072143555\n",
      "Epoch 1: iteration 999/2501 train_loss: 0.665261447429657 time_taken: 0.056771278381347656\n",
      "Epoch 1: iteration 1000/2501 train_loss: 0.6652711033821106 time_taken: 0.056533098220825195\n",
      "Epoch 1: iteration 1001/2501 train_loss: 0.6652541756629944 time_taken: 0.05685615539550781\n",
      "Epoch 1: iteration 1002/2501 train_loss: 0.6652150750160217 time_taken: 0.05621767044067383\n",
      "Epoch 1: iteration 1003/2501 train_loss: 0.6651727557182312 time_taken: 0.05738544464111328\n",
      "Epoch 1: iteration 1004/2501 train_loss: 0.6651120781898499 time_taken: 0.05625104904174805\n",
      "Epoch 1: iteration 1005/2501 train_loss: 0.665058970451355 time_taken: 0.05620217323303223\n",
      "Epoch 1: iteration 1006/2501 train_loss: 0.6650086045265198 time_taken: 0.05686759948730469\n",
      "Epoch 1: iteration 1007/2501 train_loss: 0.66494220495224 time_taken: 0.05675148963928223\n",
      "Epoch 1: iteration 1008/2501 train_loss: 0.6648669242858887 time_taken: 0.05640602111816406\n",
      "Epoch 1: iteration 1009/2501 train_loss: 0.6647894978523254 time_taken: 0.056344032287597656\n",
      "Epoch 1: iteration 1010/2501 train_loss: 0.6647048592567444 time_taken: 0.05687284469604492\n",
      "Epoch 1: iteration 1011/2501 train_loss: 0.6646196246147156 time_taken: 0.05603957176208496\n",
      "Epoch 1: iteration 1012/2501 train_loss: 0.6645249128341675 time_taken: 0.05758976936340332\n",
      "Epoch 1: iteration 1013/2501 train_loss: 0.6644308567047119 time_taken: 0.057856082916259766\n",
      "Epoch 1: iteration 1014/2501 train_loss: 0.6643211245536804 time_taken: 0.056581735610961914\n",
      "Epoch 1: iteration 1015/2501 train_loss: 0.6642228960990906 time_taken: 0.05733776092529297\n",
      "Epoch 1: iteration 1016/2501 train_loss: 0.66412752866745 time_taken: 0.05777859687805176\n",
      "Epoch 1: iteration 1017/2501 train_loss: 0.6640586853027344 time_taken: 0.056861162185668945\n",
      "Epoch 1: iteration 1018/2501 train_loss: 0.6640015840530396 time_taken: 0.056723594665527344\n",
      "Epoch 1: iteration 1019/2501 train_loss: 0.6639295816421509 time_taken: 0.05646657943725586\n",
      "Epoch 1: iteration 1020/2501 train_loss: 0.6638888120651245 time_taken: 0.05693554878234863\n",
      "Epoch 1: iteration 1021/2501 train_loss: 0.6638334393501282 time_taken: 0.056412458419799805\n",
      "Epoch 1: iteration 1022/2501 train_loss: 0.6637965440750122 time_taken: 0.05635809898376465\n",
      "Epoch 1: iteration 1023/2501 train_loss: 0.6637463569641113 time_taken: 0.05634474754333496\n",
      "Epoch 1: iteration 1024/2501 train_loss: 0.663738489151001 time_taken: 0.05648541450500488\n",
      "Epoch 1: iteration 1025/2501 train_loss: 0.6637125015258789 time_taken: 0.057732582092285156\n",
      "Epoch 1: iteration 1026/2501 train_loss: 0.6636943221092224 time_taken: 0.056513309478759766\n",
      "Epoch 1: iteration 1027/2501 train_loss: 0.6636669635772705 time_taken: 0.0566103458404541\n",
      "Epoch 1: iteration 1028/2501 train_loss: 0.6636221408843994 time_taken: 0.05665445327758789\n",
      "Epoch 1: iteration 1029/2501 train_loss: 0.6635853052139282 time_taken: 0.05690646171569824\n",
      "Epoch 1: iteration 1030/2501 train_loss: 0.663559079170227 time_taken: 0.05678677558898926\n",
      "Epoch 1: iteration 1031/2501 train_loss: 0.6635291576385498 time_taken: 0.05639076232910156\n",
      "Epoch 1: iteration 1032/2501 train_loss: 0.6634824872016907 time_taken: 0.05623507499694824\n",
      "Epoch 1: iteration 1033/2501 train_loss: 0.6634584665298462 time_taken: 0.05668497085571289\n",
      "Epoch 1: iteration 1034/2501 train_loss: 0.6634189486503601 time_taken: 0.05661463737487793\n",
      "Epoch 1: iteration 1035/2501 train_loss: 0.6633589863777161 time_taken: 0.056319475173950195\n",
      "Epoch 1: iteration 1036/2501 train_loss: 0.6632997989654541 time_taken: 0.056546926498413086\n",
      "Epoch 1: iteration 1037/2501 train_loss: 0.6632494330406189 time_taken: 0.05615401268005371\n",
      "Epoch 1: iteration 1038/2501 train_loss: 0.6631700992584229 time_taken: 0.05633401870727539\n",
      "Epoch 1: iteration 1039/2501 train_loss: 0.6630963683128357 time_taken: 0.05705690383911133\n",
      "Epoch 1: iteration 1040/2501 train_loss: 0.6630396246910095 time_taken: 0.05705666542053223\n",
      "Epoch 1: iteration 1041/2501 train_loss: 0.6629807353019714 time_taken: 0.05635237693786621\n",
      "Epoch 1: iteration 1042/2501 train_loss: 0.6628888845443726 time_taken: 0.057254791259765625\n",
      "Epoch 1: iteration 1043/2501 train_loss: 0.6628233194351196 time_taken: 0.05756878852844238\n",
      "Epoch 1: iteration 1044/2501 train_loss: 0.662746012210846 time_taken: 0.05807971954345703\n",
      "Epoch 1: iteration 1045/2501 train_loss: 0.6626731753349304 time_taken: 0.05717277526855469\n",
      "Epoch 1: iteration 1046/2501 train_loss: 0.6625874042510986 time_taken: 0.05652117729187012\n",
      "Epoch 1: iteration 1047/2501 train_loss: 0.6625204086303711 time_taken: 0.056878089904785156\n",
      "Epoch 1: iteration 1048/2501 train_loss: 0.6624619364738464 time_taken: 0.05743122100830078\n",
      "Epoch 1: iteration 1049/2501 train_loss: 0.6624042391777039 time_taken: 0.057451725006103516\n",
      "Epoch 1: iteration 1050/2501 train_loss: 0.6623433232307434 time_taken: 0.05743241310119629\n",
      "Epoch 1: iteration 1051/2501 train_loss: 0.66228848695755 time_taken: 0.05645895004272461\n",
      "Epoch 1: iteration 1052/2501 train_loss: 0.6622258424758911 time_taken: 0.05677962303161621\n",
      "Epoch 1: iteration 1053/2501 train_loss: 0.6621761918067932 time_taken: 0.05667710304260254\n",
      "Epoch 1: iteration 1054/2501 train_loss: 0.6621236205101013 time_taken: 0.05723738670349121\n",
      "Epoch 1: iteration 1055/2501 train_loss: 0.6620835661888123 time_taken: 0.056461334228515625\n",
      "Epoch 1: iteration 1056/2501 train_loss: 0.6620575189590454 time_taken: 0.05688142776489258\n",
      "Epoch 1: iteration 1057/2501 train_loss: 0.662031352519989 time_taken: 0.05762362480163574\n",
      "Epoch 1: iteration 1058/2501 train_loss: 0.6620045304298401 time_taken: 0.058461666107177734\n",
      "Epoch 1: iteration 1059/2501 train_loss: 0.6619905829429626 time_taken: 0.056722402572631836\n",
      "Epoch 1: iteration 1060/2501 train_loss: 0.6619436144828796 time_taken: 0.05678844451904297\n",
      "Epoch 1: iteration 1061/2501 train_loss: 0.6619012355804443 time_taken: 0.05681467056274414\n",
      "Epoch 1: iteration 1062/2501 train_loss: 0.6618556976318359 time_taken: 0.057131052017211914\n",
      "Epoch 1: iteration 1063/2501 train_loss: 0.6618270874023438 time_taken: 0.05689406394958496\n",
      "Epoch 1: iteration 1064/2501 train_loss: 0.6618123054504395 time_taken: 0.05682849884033203\n",
      "Epoch 1: iteration 1065/2501 train_loss: 0.6617889404296875 time_taken: 0.05677008628845215\n",
      "Epoch 1: iteration 1066/2501 train_loss: 0.6617975234985352 time_taken: 0.05646705627441406\n",
      "Epoch 1: iteration 1067/2501 train_loss: 0.661798357963562 time_taken: 0.08123779296875\n",
      "Epoch 1: iteration 1068/2501 train_loss: 0.6618058085441589 time_taken: 0.05662679672241211\n",
      "Epoch 1: iteration 1069/2501 train_loss: 0.6617996692657471 time_taken: 0.0577394962310791\n",
      "Epoch 1: iteration 1070/2501 train_loss: 0.6618021726608276 time_taken: 0.056470394134521484\n",
      "Epoch 1: iteration 1071/2501 train_loss: 0.6618018746376038 time_taken: 0.05741405487060547\n",
      "Epoch 1: iteration 1072/2501 train_loss: 0.6618140935897827 time_taken: 0.05640435218811035\n",
      "Epoch 1: iteration 1073/2501 train_loss: 0.6618316173553467 time_taken: 0.05706667900085449\n",
      "Epoch 1: iteration 1074/2501 train_loss: 0.661823570728302 time_taken: 0.06178712844848633\n",
      "Epoch 1: iteration 1075/2501 train_loss: 0.6618045568466187 time_taken: 0.05620527267456055\n",
      "Epoch 1: iteration 1076/2501 train_loss: 0.6617947816848755 time_taken: 0.05678081512451172\n",
      "Epoch 1: iteration 1077/2501 train_loss: 0.6617738008499146 time_taken: 0.056101083755493164\n",
      "Epoch 1: iteration 1078/2501 train_loss: 0.6617792844772339 time_taken: 0.05626630783081055\n",
      "Epoch 1: iteration 1079/2501 train_loss: 0.661755383014679 time_taken: 0.05625557899475098\n",
      "Epoch 1: iteration 1080/2501 train_loss: 0.6617197394371033 time_taken: 0.056215763092041016\n",
      "Epoch 1: iteration 1081/2501 train_loss: 0.6617034673690796 time_taken: 0.05994701385498047\n",
      "Epoch 1: iteration 1082/2501 train_loss: 0.6616836786270142 time_taken: 0.056758880615234375\n",
      "Epoch 1: iteration 1083/2501 train_loss: 0.6616748571395874 time_taken: 0.0567622184753418\n",
      "Epoch 1: iteration 1084/2501 train_loss: 0.6616687178611755 time_taken: 0.05596160888671875\n",
      "Epoch 1: iteration 1085/2501 train_loss: 0.6616480350494385 time_taken: 0.06357216835021973\n",
      "Epoch 1: iteration 1086/2501 train_loss: 0.6616331934928894 time_taken: 0.059450626373291016\n",
      "Epoch 1: iteration 1087/2501 train_loss: 0.6616231203079224 time_taken: 0.05642890930175781\n",
      "Epoch 1: iteration 1088/2501 train_loss: 0.6616300940513611 time_taken: 0.05659008026123047\n",
      "Epoch 1: iteration 1089/2501 train_loss: 0.6616320610046387 time_taken: 0.05608558654785156\n",
      "Epoch 1: iteration 1090/2501 train_loss: 0.6616306900978088 time_taken: 0.05611395835876465\n",
      "Epoch 1: iteration 1091/2501 train_loss: 0.661614716053009 time_taken: 0.05923652648925781\n",
      "Epoch 1: iteration 1092/2501 train_loss: 0.661613404750824 time_taken: 0.05604243278503418\n",
      "Epoch 1: iteration 1093/2501 train_loss: 0.6615886092185974 time_taken: 0.05584979057312012\n",
      "Epoch 1: iteration 1094/2501 train_loss: 0.6615666151046753 time_taken: 0.05601835250854492\n",
      "Epoch 1: iteration 1095/2501 train_loss: 0.6615462303161621 time_taken: 0.055762290954589844\n",
      "Epoch 1: iteration 1096/2501 train_loss: 0.6615211963653564 time_taken: 0.05708956718444824\n",
      "Epoch 1: iteration 1097/2501 train_loss: 0.6615076661109924 time_taken: 0.0563051700592041\n",
      "Epoch 1: iteration 1098/2501 train_loss: 0.6614874601364136 time_taken: 0.05646944046020508\n",
      "Epoch 1: iteration 1099/2501 train_loss: 0.6614742279052734 time_taken: 0.05606365203857422\n",
      "Epoch 1: iteration 1100/2501 train_loss: 0.6614573001861572 time_taken: 0.05682706832885742\n",
      "Epoch 1: iteration 1101/2501 train_loss: 0.6614311933517456 time_taken: 0.056453704833984375\n",
      "Epoch 1: iteration 1102/2501 train_loss: 0.6614245176315308 time_taken: 0.05686807632446289\n",
      "Epoch 1: iteration 1103/2501 train_loss: 0.661408543586731 time_taken: 0.0565495491027832\n",
      "Epoch 1: iteration 1104/2501 train_loss: 0.6613879799842834 time_taken: 0.05689287185668945\n",
      "Epoch 1: iteration 1105/2501 train_loss: 0.6613516211509705 time_taken: 0.05635571479797363\n",
      "Epoch 1: iteration 1106/2501 train_loss: 0.6613250374794006 time_taken: 0.05686497688293457\n",
      "Epoch 1: iteration 1107/2501 train_loss: 0.6612972617149353 time_taken: 0.05661964416503906\n",
      "Epoch 1: iteration 1108/2501 train_loss: 0.6612743139266968 time_taken: 0.05643606185913086\n",
      "Epoch 1: iteration 1109/2501 train_loss: 0.661239743232727 time_taken: 0.05793595314025879\n",
      "Epoch 1: iteration 1110/2501 train_loss: 0.6612152457237244 time_taken: 0.05690503120422363\n",
      "Epoch 1: iteration 1111/2501 train_loss: 0.6612140536308289 time_taken: 0.05715465545654297\n",
      "Epoch 1: iteration 1112/2501 train_loss: 0.6612173318862915 time_taken: 0.05704307556152344\n",
      "Epoch 1: iteration 1113/2501 train_loss: 0.661233127117157 time_taken: 0.05666327476501465\n",
      "Epoch 1: iteration 1114/2501 train_loss: 0.6612553000450134 time_taken: 0.056900978088378906\n",
      "Epoch 1: iteration 1115/2501 train_loss: 0.6612634658813477 time_taken: 0.05628180503845215\n",
      "Epoch 1: iteration 1116/2501 train_loss: 0.6612780094146729 time_taken: 0.057718515396118164\n",
      "Epoch 1: iteration 1117/2501 train_loss: 0.6613086462020874 time_taken: 0.056697845458984375\n",
      "Epoch 1: iteration 1118/2501 train_loss: 0.661329984664917 time_taken: 0.05641913414001465\n",
      "Epoch 1: iteration 1119/2501 train_loss: 0.6613368391990662 time_taken: 0.056383609771728516\n",
      "Epoch 1: iteration 1120/2501 train_loss: 0.6613520979881287 time_taken: 0.056809425354003906\n",
      "Epoch 1: iteration 1121/2501 train_loss: 0.6613775491714478 time_taken: 0.05633687973022461\n",
      "Epoch 1: iteration 1122/2501 train_loss: 0.6614172458648682 time_taken: 0.056749820709228516\n",
      "Epoch 1: iteration 1123/2501 train_loss: 0.661433756351471 time_taken: 0.056632041931152344\n",
      "Epoch 1: iteration 1124/2501 train_loss: 0.6614365577697754 time_taken: 0.05634665489196777\n",
      "Epoch 1: iteration 1125/2501 train_loss: 0.661454439163208 time_taken: 0.05681490898132324\n",
      "Epoch 1: iteration 1126/2501 train_loss: 0.6614732146263123 time_taken: 0.05671215057373047\n",
      "Epoch 1: iteration 1127/2501 train_loss: 0.6614671945571899 time_taken: 0.05705094337463379\n",
      "Epoch 1: iteration 1128/2501 train_loss: 0.6614823937416077 time_taken: 0.05624270439147949\n",
      "Epoch 1: iteration 1129/2501 train_loss: 0.6615180373191833 time_taken: 0.056543827056884766\n",
      "Epoch 1: iteration 1130/2501 train_loss: 0.6615181565284729 time_taken: 0.05838513374328613\n",
      "Epoch 1: iteration 1131/2501 train_loss: 0.6615410447120667 time_taken: 0.05661416053771973\n",
      "Epoch 1: iteration 1132/2501 train_loss: 0.6615426540374756 time_taken: 0.05630660057067871\n",
      "Epoch 1: iteration 1133/2501 train_loss: 0.6615418791770935 time_taken: 0.056313276290893555\n",
      "Epoch 1: iteration 1134/2501 train_loss: 0.6615372896194458 time_taken: 0.05617880821228027\n",
      "Epoch 1: iteration 1135/2501 train_loss: 0.6615469455718994 time_taken: 0.056210994720458984\n",
      "Epoch 1: iteration 1136/2501 train_loss: 0.6615622043609619 time_taken: 0.05631256103515625\n",
      "Epoch 1: iteration 1137/2501 train_loss: 0.6615769863128662 time_taken: 0.056923627853393555\n",
      "Epoch 1: iteration 1138/2501 train_loss: 0.6615796089172363 time_taken: 0.05678892135620117\n",
      "Epoch 1: iteration 1139/2501 train_loss: 0.6615997552871704 time_taken: 0.056937456130981445\n",
      "Epoch 1: iteration 1140/2501 train_loss: 0.6615878343582153 time_taken: 0.0559077262878418\n",
      "Epoch 1: iteration 1141/2501 train_loss: 0.6615756154060364 time_taken: 0.056166648864746094\n",
      "Epoch 1: iteration 1142/2501 train_loss: 0.6615568995475769 time_taken: 0.05666375160217285\n",
      "Epoch 1: iteration 1143/2501 train_loss: 0.6615297198295593 time_taken: 0.05638480186462402\n",
      "Epoch 1: iteration 1144/2501 train_loss: 0.6615065932273865 time_taken: 0.05623674392700195\n",
      "Epoch 1: iteration 1145/2501 train_loss: 0.6614995002746582 time_taken: 0.05682635307312012\n",
      "Epoch 1: iteration 1146/2501 train_loss: 0.6614672541618347 time_taken: 0.05673336982727051\n",
      "Epoch 1: iteration 1147/2501 train_loss: 0.6614260673522949 time_taken: 0.05640292167663574\n",
      "Epoch 1: iteration 1148/2501 train_loss: 0.6613864898681641 time_taken: 0.056566715240478516\n",
      "Epoch 1: iteration 1149/2501 train_loss: 0.6613451242446899 time_taken: 0.05685257911682129\n",
      "Epoch 1: iteration 1150/2501 train_loss: 0.6612886190414429 time_taken: 0.05678296089172363\n",
      "Epoch 1: iteration 1151/2501 train_loss: 0.6612432599067688 time_taken: 0.05649614334106445\n",
      "Epoch 1: iteration 1152/2501 train_loss: 0.6611989736557007 time_taken: 0.05680561065673828\n",
      "Epoch 1: iteration 1153/2501 train_loss: 0.6611348986625671 time_taken: 0.06145358085632324\n",
      "Epoch 1: iteration 1154/2501 train_loss: 0.6610666513442993 time_taken: 0.0563962459564209\n",
      "Epoch 1: iteration 1155/2501 train_loss: 0.6610036492347717 time_taken: 0.05709052085876465\n",
      "Epoch 1: iteration 1156/2501 train_loss: 0.6609652042388916 time_taken: 0.05723381042480469\n",
      "Epoch 1: iteration 1157/2501 train_loss: 0.660938560962677 time_taken: 0.05720233917236328\n",
      "Epoch 1: iteration 1158/2501 train_loss: 0.6608914732933044 time_taken: 0.05682086944580078\n",
      "Epoch 1: iteration 1159/2501 train_loss: 0.6608763933181763 time_taken: 0.05732583999633789\n",
      "Epoch 1: iteration 1160/2501 train_loss: 0.6608368754386902 time_taken: 0.057127952575683594\n",
      "Epoch 1: iteration 1161/2501 train_loss: 0.6608227491378784 time_taken: 0.05628561973571777\n",
      "Epoch 1: iteration 1162/2501 train_loss: 0.6608185172080994 time_taken: 0.05654478073120117\n",
      "Epoch 1: iteration 1163/2501 train_loss: 0.6607981324195862 time_taken: 0.05626511573791504\n",
      "Epoch 1: iteration 1164/2501 train_loss: 0.6607815027236938 time_taken: 0.05654335021972656\n",
      "Epoch 1: iteration 1165/2501 train_loss: 0.6607414484024048 time_taken: 0.05694937705993652\n",
      "Epoch 1: iteration 1166/2501 train_loss: 0.6607239842414856 time_taken: 0.05637502670288086\n",
      "Epoch 1: iteration 1167/2501 train_loss: 0.6606691479682922 time_taken: 0.057341575622558594\n",
      "Epoch 1: iteration 1168/2501 train_loss: 0.6606358885765076 time_taken: 0.056649208068847656\n",
      "Epoch 1: iteration 1169/2501 train_loss: 0.6606308817863464 time_taken: 0.05646038055419922\n",
      "Epoch 1: iteration 1170/2501 train_loss: 0.6606110334396362 time_taken: 0.05653786659240723\n",
      "Epoch 1: iteration 1171/2501 train_loss: 0.6606054902076721 time_taken: 0.056423187255859375\n",
      "Epoch 1: iteration 1172/2501 train_loss: 0.6605949401855469 time_taken: 0.0570073127746582\n",
      "Epoch 1: iteration 1173/2501 train_loss: 0.6605875492095947 time_taken: 0.05688071250915527\n",
      "Epoch 1: iteration 1174/2501 train_loss: 0.6605940461158752 time_taken: 0.05677533149719238\n",
      "Epoch 1: iteration 1175/2501 train_loss: 0.6605823636054993 time_taken: 0.056656599044799805\n",
      "Epoch 1: iteration 1176/2501 train_loss: 0.6605949401855469 time_taken: 0.056345224380493164\n",
      "Epoch 1: iteration 1177/2501 train_loss: 0.6605926752090454 time_taken: 0.05665302276611328\n",
      "Epoch 1: iteration 1178/2501 train_loss: 0.660597026348114 time_taken: 0.055890560150146484\n",
      "Epoch 1: iteration 1179/2501 train_loss: 0.6605935096740723 time_taken: 0.056006431579589844\n",
      "Epoch 1: iteration 1180/2501 train_loss: 0.6605718731880188 time_taken: 0.05660748481750488\n",
      "Epoch 1: iteration 1181/2501 train_loss: 0.6605393290519714 time_taken: 0.05605006217956543\n",
      "Epoch 1: iteration 1182/2501 train_loss: 0.6604936122894287 time_taken: 0.05685710906982422\n",
      "Epoch 1: iteration 1183/2501 train_loss: 0.6604538559913635 time_taken: 0.05754232406616211\n",
      "Epoch 1: iteration 1184/2501 train_loss: 0.6604255437850952 time_taken: 0.05670928955078125\n",
      "Epoch 1: iteration 1185/2501 train_loss: 0.6603938341140747 time_taken: 0.05653977394104004\n",
      "Epoch 1: iteration 1186/2501 train_loss: 0.6603610515594482 time_taken: 0.056421756744384766\n",
      "Epoch 1: iteration 1187/2501 train_loss: 0.6603188514709473 time_taken: 0.05637645721435547\n",
      "Epoch 1: iteration 1188/2501 train_loss: 0.6602734923362732 time_taken: 0.05748486518859863\n",
      "Epoch 1: iteration 1189/2501 train_loss: 0.6602450013160706 time_taken: 0.05638313293457031\n",
      "Epoch 1: iteration 1190/2501 train_loss: 0.6601867079734802 time_taken: 0.05640983581542969\n",
      "Epoch 1: iteration 1191/2501 train_loss: 0.6601620316505432 time_taken: 0.056548357009887695\n",
      "Epoch 1: iteration 1192/2501 train_loss: 0.6601133942604065 time_taken: 0.05645275115966797\n",
      "Epoch 1: iteration 1193/2501 train_loss: 0.6600584387779236 time_taken: 0.07175183296203613\n",
      "Epoch 1: iteration 1194/2501 train_loss: 0.6600066423416138 time_taken: 0.057390689849853516\n",
      "Epoch 1: iteration 1195/2501 train_loss: 0.6599546074867249 time_taken: 0.05658292770385742\n",
      "Epoch 1: iteration 1196/2501 train_loss: 0.659908652305603 time_taken: 0.056041717529296875\n",
      "Epoch 1: iteration 1197/2501 train_loss: 0.659852147102356 time_taken: 0.05644488334655762\n",
      "Epoch 1: iteration 1198/2501 train_loss: 0.6597975492477417 time_taken: 0.06108260154724121\n",
      "Epoch 1: iteration 1199/2501 train_loss: 0.6597610712051392 time_taken: 0.05684328079223633\n",
      "Epoch 1: iteration 1200/2501 train_loss: 0.6597213745117188 time_taken: 0.05644512176513672\n",
      "Epoch 1: iteration 1201/2501 train_loss: 0.6596719026565552 time_taken: 0.0563051700592041\n",
      "Epoch 1: iteration 1202/2501 train_loss: 0.659635066986084 time_taken: 0.057470083236694336\n",
      "Epoch 1: iteration 1203/2501 train_loss: 0.6596030592918396 time_taken: 0.05597329139709473\n",
      "Epoch 1: iteration 1204/2501 train_loss: 0.6595697999000549 time_taken: 0.05629086494445801\n",
      "Epoch 1: iteration 1205/2501 train_loss: 0.6595361828804016 time_taken: 0.05601239204406738\n",
      "Epoch 1: iteration 1206/2501 train_loss: 0.6595072746276855 time_taken: 0.05651068687438965\n",
      "Epoch 1: iteration 1207/2501 train_loss: 0.6595214009284973 time_taken: 0.05652046203613281\n",
      "Epoch 1: iteration 1208/2501 train_loss: 0.6595166325569153 time_taken: 0.05635857582092285\n",
      "Epoch 1: iteration 1209/2501 train_loss: 0.6595057249069214 time_taken: 0.057454586029052734\n",
      "Epoch 1: iteration 1210/2501 train_loss: 0.6594904065132141 time_taken: 0.0565185546875\n",
      "Epoch 1: iteration 1211/2501 train_loss: 0.6594741344451904 time_taken: 0.056862831115722656\n",
      "Epoch 1: iteration 1212/2501 train_loss: 0.6594630479812622 time_taken: 0.05744290351867676\n",
      "Epoch 1: iteration 1213/2501 train_loss: 0.6594454050064087 time_taken: 0.05720925331115723\n",
      "Epoch 1: iteration 1214/2501 train_loss: 0.6594405770301819 time_taken: 0.05692577362060547\n",
      "Epoch 1: iteration 1215/2501 train_loss: 0.6594451665878296 time_taken: 0.05720877647399902\n",
      "Epoch 1: iteration 1216/2501 train_loss: 0.6594471335411072 time_taken: 0.05712270736694336\n",
      "Epoch 1: iteration 1217/2501 train_loss: 0.6594610810279846 time_taken: 0.05669856071472168\n",
      "Epoch 1: iteration 1218/2501 train_loss: 0.6594609618186951 time_taken: 0.05653572082519531\n",
      "Epoch 1: iteration 1219/2501 train_loss: 0.659455418586731 time_taken: 0.06235074996948242\n",
      "Epoch 1: iteration 1220/2501 train_loss: 0.6594426035881042 time_taken: 0.05642986297607422\n",
      "Epoch 1: iteration 1221/2501 train_loss: 0.6594177484512329 time_taken: 0.05661773681640625\n",
      "Epoch 1: iteration 1222/2501 train_loss: 0.65938401222229 time_taken: 0.06731414794921875\n",
      "Epoch 1: iteration 1223/2501 train_loss: 0.6593365669250488 time_taken: 0.06449222564697266\n",
      "Epoch 1: iteration 1224/2501 train_loss: 0.6593063473701477 time_taken: 0.05675697326660156\n",
      "Epoch 1: iteration 1225/2501 train_loss: 0.6592735648155212 time_taken: 0.05612349510192871\n",
      "Epoch 1: iteration 1226/2501 train_loss: 0.6592409014701843 time_taken: 0.05954456329345703\n",
      "Epoch 1: iteration 1227/2501 train_loss: 0.6592198610305786 time_taken: 0.05645275115966797\n",
      "Epoch 1: iteration 1228/2501 train_loss: 0.6591929197311401 time_taken: 0.05624747276306152\n",
      "Epoch 1: iteration 1229/2501 train_loss: 0.6591665148735046 time_taken: 0.05976414680480957\n",
      "Epoch 1: iteration 1230/2501 train_loss: 0.6591569185256958 time_taken: 0.0563046932220459\n",
      "Epoch 1: iteration 1231/2501 train_loss: 0.6591501832008362 time_taken: 0.05656933784484863\n",
      "Epoch 1: iteration 1232/2501 train_loss: 0.6591485738754272 time_taken: 0.0561676025390625\n",
      "Epoch 1: iteration 1233/2501 train_loss: 0.6591458320617676 time_taken: 0.06500077247619629\n",
      "Epoch 1: iteration 1234/2501 train_loss: 0.6591503620147705 time_taken: 0.055925607681274414\n",
      "Epoch 1: iteration 1235/2501 train_loss: 0.6591605544090271 time_taken: 0.05612778663635254\n",
      "Epoch 1: iteration 1236/2501 train_loss: 0.6591733694076538 time_taken: 0.058544158935546875\n",
      "Epoch 1: iteration 1237/2501 train_loss: 0.6591840982437134 time_taken: 0.05649280548095703\n",
      "Epoch 1: iteration 1238/2501 train_loss: 0.659209132194519 time_taken: 0.056101083755493164\n",
      "Epoch 1: iteration 1239/2501 train_loss: 0.6592144966125488 time_taken: 0.05600881576538086\n",
      "Epoch 1: iteration 1240/2501 train_loss: 0.6592208743095398 time_taken: 0.05681109428405762\n",
      "Epoch 1: iteration 1241/2501 train_loss: 0.6592271327972412 time_taken: 0.056082963943481445\n",
      "Epoch 1: iteration 1242/2501 train_loss: 0.6592314839363098 time_taken: 0.05609011650085449\n",
      "Epoch 1: iteration 1243/2501 train_loss: 0.6592183709144592 time_taken: 0.05621957778930664\n",
      "Epoch 1: iteration 1244/2501 train_loss: 0.6592171788215637 time_taken: 0.05697178840637207\n",
      "Epoch 1: iteration 1245/2501 train_loss: 0.6592077612876892 time_taken: 0.05661892890930176\n",
      "Epoch 1: iteration 1246/2501 train_loss: 0.6591941118240356 time_taken: 0.05743050575256348\n",
      "Epoch 1: iteration 1247/2501 train_loss: 0.6591917276382446 time_taken: 0.05657505989074707\n",
      "Epoch 1: iteration 1248/2501 train_loss: 0.6591932773590088 time_taken: 0.05768632888793945\n",
      "Epoch 1: iteration 1249/2501 train_loss: 0.6591914892196655 time_taken: 0.05656266212463379\n",
      "Epoch 1: iteration 1250/2501 train_loss: 0.6591847538948059 time_taken: 0.05665159225463867\n",
      "Epoch 1: iteration 1251/2501 train_loss: 0.6591629385948181 time_taken: 0.05650758743286133\n",
      "Epoch 1: iteration 1252/2501 train_loss: 0.6591594815254211 time_taken: 0.0671079158782959\n",
      "Epoch 1: iteration 1253/2501 train_loss: 0.6591564416885376 time_taken: 0.056936025619506836\n",
      "Epoch 1: iteration 1254/2501 train_loss: 0.6591552495956421 time_taken: 0.0567469596862793\n",
      "Epoch 1: iteration 1255/2501 train_loss: 0.6591426134109497 time_taken: 0.05613899230957031\n",
      "Epoch 1: iteration 1256/2501 train_loss: 0.659113347530365 time_taken: 0.05652642250061035\n",
      "Epoch 1: iteration 1257/2501 train_loss: 0.6590869426727295 time_taken: 0.05668926239013672\n",
      "Epoch 1: iteration 1258/2501 train_loss: 0.6590520143508911 time_taken: 0.05681467056274414\n",
      "Epoch 1: iteration 1259/2501 train_loss: 0.6590047478675842 time_taken: 0.05646920204162598\n",
      "Epoch 1: iteration 1260/2501 train_loss: 0.6589677929878235 time_taken: 0.0562891960144043\n",
      "Epoch 1: iteration 1261/2501 train_loss: 0.6589338779449463 time_taken: 0.056830644607543945\n",
      "Epoch 1: iteration 1262/2501 train_loss: 0.658876359462738 time_taken: 0.056410789489746094\n",
      "Epoch 1: iteration 1263/2501 train_loss: 0.658819317817688 time_taken: 0.05653023719787598\n",
      "Epoch 1: iteration 1264/2501 train_loss: 0.6587716341018677 time_taken: 0.05641365051269531\n",
      "Epoch 1: iteration 1265/2501 train_loss: 0.6587186455726624 time_taken: 0.056386709213256836\n",
      "Epoch 1: iteration 1266/2501 train_loss: 0.6586405038833618 time_taken: 0.06141805648803711\n",
      "Epoch 1: iteration 1267/2501 train_loss: 0.6585756540298462 time_taken: 0.05641818046569824\n",
      "Epoch 1: iteration 1268/2501 train_loss: 0.6584990620613098 time_taken: 0.0563352108001709\n",
      "Epoch 1: iteration 1269/2501 train_loss: 0.6584134101867676 time_taken: 0.05726146697998047\n",
      "Epoch 1: iteration 1270/2501 train_loss: 0.6583458781242371 time_taken: 0.05668282508850098\n",
      "Epoch 1: iteration 1271/2501 train_loss: 0.6582846641540527 time_taken: 0.060790061950683594\n",
      "Epoch 1: iteration 1272/2501 train_loss: 0.6582236289978027 time_taken: 0.05720686912536621\n",
      "Epoch 1: iteration 1273/2501 train_loss: 0.6581476330757141 time_taken: 0.05820274353027344\n",
      "Epoch 1: iteration 1274/2501 train_loss: 0.6580971479415894 time_taken: 0.05664205551147461\n",
      "Epoch 1: iteration 1275/2501 train_loss: 0.6580654382705688 time_taken: 0.056978464126586914\n",
      "Epoch 1: iteration 1276/2501 train_loss: 0.658046305179596 time_taken: 0.055998802185058594\n",
      "Epoch 1: iteration 1277/2501 train_loss: 0.6580216884613037 time_taken: 0.05652022361755371\n",
      "Epoch 1: iteration 1278/2501 train_loss: 0.6579803824424744 time_taken: 0.056792497634887695\n",
      "Epoch 1: iteration 1279/2501 train_loss: 0.6579434275627136 time_taken: 0.05683445930480957\n",
      "Epoch 1: iteration 1280/2501 train_loss: 0.6579049825668335 time_taken: 0.05666494369506836\n",
      "Epoch 1: iteration 1281/2501 train_loss: 0.6578612327575684 time_taken: 0.05655026435852051\n",
      "Epoch 1: iteration 1282/2501 train_loss: 0.6578311920166016 time_taken: 0.05624222755432129\n",
      "Epoch 1: iteration 1283/2501 train_loss: 0.6577776074409485 time_taken: 0.05638432502746582\n",
      "Epoch 1: iteration 1284/2501 train_loss: 0.6577226519584656 time_taken: 0.0565495491027832\n",
      "Epoch 1: iteration 1285/2501 train_loss: 0.6576623916625977 time_taken: 0.05600285530090332\n",
      "Epoch 1: iteration 1286/2501 train_loss: 0.6576193571090698 time_taken: 0.056090354919433594\n",
      "Epoch 1: iteration 1287/2501 train_loss: 0.6575596332550049 time_taken: 0.05677485466003418\n",
      "Epoch 1: iteration 1288/2501 train_loss: 0.6574829816818237 time_taken: 0.05596184730529785\n",
      "Epoch 1: iteration 1289/2501 train_loss: 0.6574314832687378 time_taken: 0.0565488338470459\n",
      "Epoch 1: iteration 1290/2501 train_loss: 0.6573626399040222 time_taken: 0.05781984329223633\n",
      "Epoch 1: iteration 1291/2501 train_loss: 0.6573091149330139 time_taken: 0.05605292320251465\n",
      "Epoch 1: iteration 1292/2501 train_loss: 0.657263457775116 time_taken: 0.056943655014038086\n",
      "Epoch 1: iteration 1293/2501 train_loss: 0.6572149395942688 time_taken: 0.05660414695739746\n",
      "Epoch 1: iteration 1294/2501 train_loss: 0.6571521759033203 time_taken: 0.05642580986022949\n",
      "Epoch 1: iteration 1295/2501 train_loss: 0.6571086049079895 time_taken: 0.057126760482788086\n",
      "Epoch 1: iteration 1296/2501 train_loss: 0.6570636630058289 time_taken: 0.05612540245056152\n",
      "Epoch 1: iteration 1297/2501 train_loss: 0.6570299863815308 time_taken: 0.056856393814086914\n",
      "Epoch 1: iteration 1298/2501 train_loss: 0.657001256942749 time_taken: 0.056818246841430664\n",
      "Epoch 1: iteration 1299/2501 train_loss: 0.6570080518722534 time_taken: 0.056635141372680664\n",
      "Epoch 1: iteration 1300/2501 train_loss: 0.6570143103599548 time_taken: 0.05654644966125488\n",
      "Epoch 1: iteration 1301/2501 train_loss: 0.6569947600364685 time_taken: 0.05650734901428223\n",
      "Epoch 1: iteration 1302/2501 train_loss: 0.6569827198982239 time_taken: 0.05650949478149414\n",
      "Epoch 1: iteration 1303/2501 train_loss: 0.6569588780403137 time_taken: 0.05643796920776367\n",
      "Epoch 1: iteration 1304/2501 train_loss: 0.6569182276725769 time_taken: 0.05676460266113281\n",
      "Epoch 1: iteration 1305/2501 train_loss: 0.656877338886261 time_taken: 0.05651450157165527\n",
      "Epoch 1: iteration 1306/2501 train_loss: 0.6568334102630615 time_taken: 0.05627870559692383\n",
      "Epoch 1: iteration 1307/2501 train_loss: 0.6568076014518738 time_taken: 0.056302785873413086\n",
      "Epoch 1: iteration 1308/2501 train_loss: 0.6567900776863098 time_taken: 0.056501150131225586\n",
      "Epoch 1: iteration 1309/2501 train_loss: 0.6567572355270386 time_taken: 0.05609536170959473\n",
      "Epoch 1: iteration 1310/2501 train_loss: 0.6567320227622986 time_taken: 0.0565333366394043\n",
      "Epoch 1: iteration 1311/2501 train_loss: 0.656708300113678 time_taken: 0.056221723556518555\n",
      "Epoch 1: iteration 1312/2501 train_loss: 0.656684398651123 time_taken: 0.056496620178222656\n",
      "Epoch 1: iteration 1313/2501 train_loss: 0.6566682457923889 time_taken: 0.05625462532043457\n",
      "Epoch 1: iteration 1314/2501 train_loss: 0.6566760540008545 time_taken: 0.05617213249206543\n",
      "Epoch 1: iteration 1315/2501 train_loss: 0.6566705107688904 time_taken: 0.056905269622802734\n",
      "Epoch 1: iteration 1316/2501 train_loss: 0.6566606760025024 time_taken: 0.05652809143066406\n",
      "Epoch 1: iteration 1317/2501 train_loss: 0.656656801700592 time_taken: 0.05597209930419922\n",
      "Epoch 1: iteration 1318/2501 train_loss: 0.6566427946090698 time_taken: 0.05634593963623047\n",
      "Epoch 1: iteration 1319/2501 train_loss: 0.6566156148910522 time_taken: 0.057439565658569336\n",
      "Epoch 1: iteration 1320/2501 train_loss: 0.6565836071968079 time_taken: 0.05744314193725586\n",
      "Epoch 1: iteration 1321/2501 train_loss: 0.6565637588500977 time_taken: 0.056603431701660156\n",
      "Epoch 1: iteration 1322/2501 train_loss: 0.6565256714820862 time_taken: 0.05651974678039551\n",
      "Epoch 1: iteration 1323/2501 train_loss: 0.6564903259277344 time_taken: 0.05675959587097168\n",
      "Epoch 1: iteration 1324/2501 train_loss: 0.6564391851425171 time_taken: 0.057192325592041016\n",
      "Epoch 1: iteration 1325/2501 train_loss: 0.6564050912857056 time_taken: 0.05669856071472168\n",
      "Epoch 1: iteration 1326/2501 train_loss: 0.6563495993614197 time_taken: 0.056758880615234375\n",
      "Epoch 1: iteration 1327/2501 train_loss: 0.6563331484794617 time_taken: 0.056894540786743164\n",
      "Epoch 1: iteration 1328/2501 train_loss: 0.6563031673431396 time_taken: 0.056420087814331055\n",
      "Epoch 1: iteration 1329/2501 train_loss: 0.6562544703483582 time_taken: 0.05685615539550781\n",
      "Epoch 1: iteration 1330/2501 train_loss: 0.656221866607666 time_taken: 0.061009883880615234\n",
      "Epoch 1: iteration 1331/2501 train_loss: 0.6561810374259949 time_taken: 0.056612253189086914\n",
      "Epoch 1: iteration 1332/2501 train_loss: 0.6561310291290283 time_taken: 0.05694913864135742\n",
      "Epoch 1: iteration 1333/2501 train_loss: 0.6560872197151184 time_taken: 0.05696368217468262\n",
      "Epoch 1: iteration 1334/2501 train_loss: 0.6560543775558472 time_taken: 0.0567014217376709\n",
      "Epoch 1: iteration 1335/2501 train_loss: 0.6560192704200745 time_taken: 0.056613922119140625\n",
      "Epoch 1: iteration 1336/2501 train_loss: 0.6559777855873108 time_taken: 0.05685019493103027\n",
      "Epoch 1: iteration 1337/2501 train_loss: 0.6559479832649231 time_taken: 0.05672430992126465\n",
      "Epoch 1: iteration 1338/2501 train_loss: 0.655918300151825 time_taken: 0.05694580078125\n",
      "Epoch 1: iteration 1339/2501 train_loss: 0.6558917760848999 time_taken: 0.05675244331359863\n",
      "Epoch 1: iteration 1340/2501 train_loss: 0.6558651924133301 time_taken: 0.05692028999328613\n",
      "Epoch 1: iteration 1341/2501 train_loss: 0.6558500528335571 time_taken: 0.05683326721191406\n",
      "Epoch 1: iteration 1342/2501 train_loss: 0.65583336353302 time_taken: 0.05689191818237305\n",
      "Epoch 1: iteration 1343/2501 train_loss: 0.6558368802070618 time_taken: 0.05682945251464844\n",
      "Epoch 1: iteration 1344/2501 train_loss: 0.6558362245559692 time_taken: 0.056836843490600586\n",
      "Epoch 1: iteration 1345/2501 train_loss: 0.6558495759963989 time_taken: 0.07538032531738281\n",
      "Epoch 1: iteration 1346/2501 train_loss: 0.6558578014373779 time_taken: 0.0567626953125\n",
      "Epoch 1: iteration 1347/2501 train_loss: 0.6558669209480286 time_taken: 0.05684685707092285\n",
      "Epoch 1: iteration 1348/2501 train_loss: 0.6558797359466553 time_taken: 0.05741143226623535\n",
      "Epoch 1: iteration 1349/2501 train_loss: 0.6558703780174255 time_taken: 0.056624650955200195\n",
      "Epoch 1: iteration 1350/2501 train_loss: 0.6558745503425598 time_taken: 0.0567164421081543\n",
      "Epoch 1: iteration 1351/2501 train_loss: 0.6558745503425598 time_taken: 0.056841135025024414\n",
      "Epoch 1: iteration 1352/2501 train_loss: 0.6558823585510254 time_taken: 0.05660367012023926\n",
      "Epoch 1: iteration 1353/2501 train_loss: 0.6558802723884583 time_taken: 0.05744647979736328\n",
      "Epoch 1: iteration 1354/2501 train_loss: 0.6558851599693298 time_taken: 0.056761980056762695\n",
      "Epoch 1: iteration 1355/2501 train_loss: 0.6559039950370789 time_taken: 0.05663490295410156\n",
      "Epoch 1: iteration 1356/2501 train_loss: 0.655914843082428 time_taken: 0.05634927749633789\n",
      "Epoch 1: iteration 1357/2501 train_loss: 0.6559246182441711 time_taken: 0.05633401870727539\n",
      "Epoch 1: iteration 1358/2501 train_loss: 0.6559263467788696 time_taken: 0.057228803634643555\n",
      "Epoch 1: iteration 1359/2501 train_loss: 0.6559308767318726 time_taken: 0.0567021369934082\n",
      "Epoch 1: iteration 1360/2501 train_loss: 0.6559228301048279 time_taken: 0.05665087699890137\n",
      "Epoch 1: iteration 1361/2501 train_loss: 0.6559275984764099 time_taken: 0.056693077087402344\n",
      "Epoch 1: iteration 1362/2501 train_loss: 0.6559299230575562 time_taken: 0.05664324760437012\n",
      "Epoch 1: iteration 1363/2501 train_loss: 0.655927300453186 time_taken: 0.05677390098571777\n",
      "Epoch 1: iteration 1364/2501 train_loss: 0.6559304594993591 time_taken: 0.056555986404418945\n",
      "Epoch 1: iteration 1365/2501 train_loss: 0.6559265851974487 time_taken: 0.05726265907287598\n",
      "Epoch 1: iteration 1366/2501 train_loss: 0.6559149622917175 time_taken: 0.0564570426940918\n",
      "Epoch 1: iteration 1367/2501 train_loss: 0.6559082865715027 time_taken: 0.05641603469848633\n",
      "Epoch 1: iteration 1368/2501 train_loss: 0.6559149026870728 time_taken: 0.05643796920776367\n",
      "Epoch 1: iteration 1369/2501 train_loss: 0.6559244394302368 time_taken: 0.05623650550842285\n",
      "Epoch 1: iteration 1370/2501 train_loss: 0.6559358239173889 time_taken: 0.056394100189208984\n",
      "Epoch 1: iteration 1371/2501 train_loss: 0.6559463739395142 time_taken: 0.05723452568054199\n",
      "Epoch 1: iteration 1372/2501 train_loss: 0.655945360660553 time_taken: 0.05673408508300781\n",
      "Epoch 1: iteration 1373/2501 train_loss: 0.6559622883796692 time_taken: 0.05641579627990723\n",
      "Epoch 1: iteration 1374/2501 train_loss: 0.655989408493042 time_taken: 0.056777000427246094\n",
      "Epoch 1: iteration 1375/2501 train_loss: 0.6560089588165283 time_taken: 0.05633068084716797\n",
      "Epoch 1: iteration 1376/2501 train_loss: 0.6560465097427368 time_taken: 0.06752252578735352\n",
      "Epoch 1: iteration 1377/2501 train_loss: 0.6560879945755005 time_taken: 0.056255340576171875\n",
      "Epoch 1: iteration 1378/2501 train_loss: 0.6561488509178162 time_taken: 0.0568232536315918\n",
      "Epoch 1: iteration 1379/2501 train_loss: 0.6562144756317139 time_taken: 0.05648326873779297\n",
      "Epoch 1: iteration 1380/2501 train_loss: 0.6562681198120117 time_taken: 0.057579994201660156\n",
      "Epoch 1: iteration 1381/2501 train_loss: 0.6563181281089783 time_taken: 0.05809903144836426\n",
      "Epoch 1: iteration 1382/2501 train_loss: 0.6563709378242493 time_taken: 0.05675077438354492\n",
      "Epoch 1: iteration 1383/2501 train_loss: 0.6564234495162964 time_taken: 0.05644679069519043\n",
      "Epoch 1: iteration 1384/2501 train_loss: 0.6564670205116272 time_taken: 0.05632591247558594\n",
      "Epoch 1: iteration 1385/2501 train_loss: 0.6565241813659668 time_taken: 0.056504249572753906\n",
      "Epoch 1: iteration 1386/2501 train_loss: 0.6565743684768677 time_taken: 0.0569612979888916\n",
      "Epoch 1: iteration 1387/2501 train_loss: 0.6566072106361389 time_taken: 0.05737113952636719\n",
      "Epoch 1: iteration 1388/2501 train_loss: 0.6566528081893921 time_taken: 0.0567317008972168\n",
      "Epoch 1: iteration 1389/2501 train_loss: 0.6566982269287109 time_taken: 0.05654740333557129\n",
      "Epoch 1: iteration 1390/2501 train_loss: 0.6567338109016418 time_taken: 0.05603456497192383\n",
      "Epoch 1: iteration 1391/2501 train_loss: 0.6567590832710266 time_taken: 0.05650663375854492\n",
      "Epoch 1: iteration 1392/2501 train_loss: 0.6567822098731995 time_taken: 0.05653071403503418\n",
      "Epoch 1: iteration 1393/2501 train_loss: 0.6567990779876709 time_taken: 0.05641961097717285\n",
      "Epoch 1: iteration 1394/2501 train_loss: 0.6568180918693542 time_taken: 0.056738853454589844\n",
      "Epoch 1: iteration 1395/2501 train_loss: 0.6568290591239929 time_taken: 0.05670809745788574\n",
      "Epoch 1: iteration 1396/2501 train_loss: 0.656823456287384 time_taken: 0.05666613578796387\n",
      "Epoch 1: iteration 1397/2501 train_loss: 0.6568189859390259 time_taken: 0.057199716567993164\n",
      "Epoch 1: iteration 1398/2501 train_loss: 0.656822144985199 time_taken: 0.057289838790893555\n",
      "Epoch 1: iteration 1399/2501 train_loss: 0.6568437814712524 time_taken: 0.05631542205810547\n",
      "Epoch 1: iteration 1400/2501 train_loss: 0.6568348407745361 time_taken: 0.056507110595703125\n",
      "Epoch 1: iteration 1401/2501 train_loss: 0.6568217873573303 time_taken: 0.056939125061035156\n",
      "Epoch 1: iteration 1402/2501 train_loss: 0.6568235158920288 time_taken: 0.0647728443145752\n",
      "Epoch 1: iteration 1403/2501 train_loss: 0.6568198204040527 time_taken: 0.056789398193359375\n",
      "Epoch 1: iteration 1404/2501 train_loss: 0.6568139791488647 time_taken: 0.05614948272705078\n",
      "Epoch 1: iteration 1405/2501 train_loss: 0.6568055152893066 time_taken: 0.056429147720336914\n",
      "Epoch 1: iteration 1406/2501 train_loss: 0.6567940711975098 time_taken: 0.05592966079711914\n",
      "Epoch 1: iteration 1407/2501 train_loss: 0.6567806005477905 time_taken: 0.05624580383300781\n",
      "Epoch 1: iteration 1408/2501 train_loss: 0.6567634344100952 time_taken: 0.05730605125427246\n",
      "Epoch 1: iteration 1409/2501 train_loss: 0.6567355394363403 time_taken: 0.05629420280456543\n",
      "Epoch 1: iteration 1410/2501 train_loss: 0.6567065119743347 time_taken: 0.05934286117553711\n",
      "Epoch 1: iteration 1411/2501 train_loss: 0.6566697955131531 time_taken: 0.05623745918273926\n",
      "Epoch 1: iteration 1412/2501 train_loss: 0.6566345691680908 time_taken: 0.05697011947631836\n",
      "Epoch 1: iteration 1413/2501 train_loss: 0.6565923690795898 time_taken: 0.057769060134887695\n",
      "Epoch 1: iteration 1414/2501 train_loss: 0.6565519571304321 time_taken: 0.057912588119506836\n",
      "Epoch 1: iteration 1415/2501 train_loss: 0.656514048576355 time_taken: 0.060651302337646484\n",
      "Epoch 1: iteration 1416/2501 train_loss: 0.6564866304397583 time_taken: 0.056426286697387695\n",
      "Epoch 1: iteration 1417/2501 train_loss: 0.6564480662345886 time_taken: 0.056153059005737305\n",
      "Epoch 1: iteration 1418/2501 train_loss: 0.6564403772354126 time_taken: 0.056412458419799805\n",
      "Epoch 1: iteration 1419/2501 train_loss: 0.6564168334007263 time_taken: 0.05620384216308594\n",
      "Epoch 1: iteration 1420/2501 train_loss: 0.6564022302627563 time_taken: 0.056571245193481445\n",
      "Epoch 1: iteration 1421/2501 train_loss: 0.6563921570777893 time_taken: 0.06153535842895508\n",
      "Epoch 1: iteration 1422/2501 train_loss: 0.6563894748687744 time_taken: 0.05627274513244629\n",
      "Epoch 1: iteration 1423/2501 train_loss: 0.6563883423805237 time_taken: 0.056444406509399414\n",
      "Epoch 1: iteration 1424/2501 train_loss: 0.656396210193634 time_taken: 0.05641961097717285\n",
      "Epoch 1: iteration 1425/2501 train_loss: 0.6564061045646667 time_taken: 0.0567469596862793\n",
      "Epoch 1: iteration 1426/2501 train_loss: 0.6564151644706726 time_taken: 0.056465864181518555\n",
      "Epoch 1: iteration 1427/2501 train_loss: 0.6564007997512817 time_taken: 0.05724787712097168\n",
      "Epoch 1: iteration 1428/2501 train_loss: 0.6563864946365356 time_taken: 0.05761361122131348\n",
      "Epoch 1: iteration 1429/2501 train_loss: 0.6563769578933716 time_taken: 0.0566103458404541\n",
      "Epoch 1: iteration 1430/2501 train_loss: 0.6563533544540405 time_taken: 0.05665159225463867\n",
      "Epoch 1: iteration 1431/2501 train_loss: 0.6563342213630676 time_taken: 0.05650472640991211\n",
      "Epoch 1: iteration 1432/2501 train_loss: 0.6562979817390442 time_taken: 0.0569005012512207\n",
      "Epoch 1: iteration 1433/2501 train_loss: 0.6562598347663879 time_taken: 0.056450843811035156\n",
      "Epoch 1: iteration 1434/2501 train_loss: 0.6562260389328003 time_taken: 0.05677175521850586\n",
      "Epoch 1: iteration 1435/2501 train_loss: 0.6562049984931946 time_taken: 0.05669832229614258\n",
      "Epoch 1: iteration 1436/2501 train_loss: 0.6561914682388306 time_taken: 0.05638933181762695\n",
      "Epoch 1: iteration 1437/2501 train_loss: 0.6561815142631531 time_taken: 0.0577392578125\n",
      "Epoch 1: iteration 1438/2501 train_loss: 0.6561724543571472 time_taken: 0.05695176124572754\n",
      "Epoch 1: iteration 1439/2501 train_loss: 0.6561818718910217 time_taken: 0.058144569396972656\n",
      "Epoch 1: iteration 1440/2501 train_loss: 0.6561985015869141 time_taken: 0.05755877494812012\n",
      "Epoch 1: iteration 1441/2501 train_loss: 0.6562042832374573 time_taken: 0.05633854866027832\n",
      "Epoch 1: iteration 1442/2501 train_loss: 0.6562085151672363 time_taken: 0.05691695213317871\n",
      "Epoch 1: iteration 1443/2501 train_loss: 0.6562032103538513 time_taken: 0.05718564987182617\n",
      "Epoch 1: iteration 1444/2501 train_loss: 0.6561999320983887 time_taken: 0.05677676200866699\n",
      "Epoch 1: iteration 1445/2501 train_loss: 0.6562032103538513 time_taken: 0.05680203437805176\n",
      "Epoch 1: iteration 1446/2501 train_loss: 0.6562057137489319 time_taken: 0.056982994079589844\n",
      "Epoch 1: iteration 1447/2501 train_loss: 0.656207799911499 time_taken: 0.05701780319213867\n",
      "Epoch 1: iteration 1448/2501 train_loss: 0.6562000513076782 time_taken: 0.0565793514251709\n",
      "Epoch 1: iteration 1449/2501 train_loss: 0.6561768054962158 time_taken: 0.05680203437805176\n",
      "Epoch 1: iteration 1450/2501 train_loss: 0.6561645865440369 time_taken: 0.05799269676208496\n",
      "Epoch 1: iteration 1451/2501 train_loss: 0.6561565399169922 time_taken: 0.057038068771362305\n",
      "Epoch 1: iteration 1452/2501 train_loss: 0.6561636924743652 time_taken: 0.05659222602844238\n",
      "Epoch 1: iteration 1453/2501 train_loss: 0.6561643481254578 time_taken: 0.05698513984680176\n",
      "Epoch 1: iteration 1454/2501 train_loss: 0.6561894416809082 time_taken: 0.05660104751586914\n",
      "Epoch 1: iteration 1455/2501 train_loss: 0.6562138795852661 time_taken: 0.05643868446350098\n",
      "Epoch 1: iteration 1456/2501 train_loss: 0.6562268733978271 time_taken: 0.056870460510253906\n",
      "Epoch 1: iteration 1457/2501 train_loss: 0.6562387943267822 time_taken: 0.05758523941040039\n",
      "Epoch 1: iteration 1458/2501 train_loss: 0.6562626957893372 time_taken: 0.05703258514404297\n",
      "Epoch 1: iteration 1459/2501 train_loss: 0.6562884449958801 time_taken: 0.05624818801879883\n",
      "Epoch 1: iteration 1460/2501 train_loss: 0.65631502866745 time_taken: 0.05679821968078613\n",
      "Epoch 1: iteration 1461/2501 train_loss: 0.6563299298286438 time_taken: 0.08150529861450195\n",
      "Epoch 1: iteration 1462/2501 train_loss: 0.6563485264778137 time_taken: 0.05979800224304199\n",
      "Epoch 1: iteration 1463/2501 train_loss: 0.6563627123832703 time_taken: 0.05601072311401367\n",
      "Epoch 1: iteration 1464/2501 train_loss: 0.6563630104064941 time_taken: 0.05599069595336914\n",
      "Epoch 1: iteration 1465/2501 train_loss: 0.6563631892204285 time_taken: 0.05681419372558594\n",
      "Epoch 1: iteration 1466/2501 train_loss: 0.6563718914985657 time_taken: 0.055988311767578125\n",
      "Epoch 1: iteration 1467/2501 train_loss: 0.6563900709152222 time_taken: 0.05626249313354492\n",
      "Epoch 1: iteration 1468/2501 train_loss: 0.6563941240310669 time_taken: 0.057051658630371094\n",
      "Epoch 1: iteration 1469/2501 train_loss: 0.6564035415649414 time_taken: 0.05707716941833496\n",
      "Epoch 1: iteration 1470/2501 train_loss: 0.6563970446586609 time_taken: 0.05660653114318848\n",
      "Epoch 1: iteration 1471/2501 train_loss: 0.6563941836357117 time_taken: 0.05675196647644043\n",
      "Epoch 1: iteration 1472/2501 train_loss: 0.6564010977745056 time_taken: 0.0570375919342041\n",
      "Epoch 1: iteration 1473/2501 train_loss: 0.6564068794250488 time_taken: 0.05605936050415039\n",
      "Epoch 1: iteration 1474/2501 train_loss: 0.6564089059829712 time_taken: 0.05697941780090332\n",
      "Epoch 1: iteration 1475/2501 train_loss: 0.6564294695854187 time_taken: 0.05607867240905762\n",
      "Epoch 1: iteration 1476/2501 train_loss: 0.6564531326293945 time_taken: 0.0564882755279541\n",
      "Epoch 1: iteration 1477/2501 train_loss: 0.6564894318580627 time_taken: 0.05681943893432617\n",
      "Epoch 1: iteration 1478/2501 train_loss: 0.6565237045288086 time_taken: 0.05620861053466797\n",
      "Epoch 1: iteration 1479/2501 train_loss: 0.6565596461296082 time_taken: 0.05684208869934082\n",
      "Epoch 1: iteration 1480/2501 train_loss: 0.6565932631492615 time_taken: 0.06186366081237793\n",
      "Epoch 1: iteration 1481/2501 train_loss: 0.6566340923309326 time_taken: 0.05721735954284668\n",
      "Epoch 1: iteration 1482/2501 train_loss: 0.6566675901412964 time_taken: 0.057204246520996094\n",
      "Epoch 1: iteration 1483/2501 train_loss: 0.6566826105117798 time_taken: 0.05638575553894043\n",
      "Epoch 1: iteration 1484/2501 train_loss: 0.6566992402076721 time_taken: 0.05707573890686035\n",
      "Epoch 1: iteration 1485/2501 train_loss: 0.6567174196243286 time_taken: 0.05610060691833496\n",
      "Epoch 1: iteration 1486/2501 train_loss: 0.6567243337631226 time_taken: 0.05603170394897461\n",
      "Epoch 1: iteration 1487/2501 train_loss: 0.6567264795303345 time_taken: 0.056282758712768555\n",
      "Epoch 1: iteration 1488/2501 train_loss: 0.6567195653915405 time_taken: 0.056295156478881836\n",
      "Epoch 1: iteration 1489/2501 train_loss: 0.6566994786262512 time_taken: 0.05632281303405762\n",
      "Epoch 1: iteration 1490/2501 train_loss: 0.6566754579544067 time_taken: 0.05648493766784668\n",
      "Epoch 1: iteration 1491/2501 train_loss: 0.6566449403762817 time_taken: 0.05617928504943848\n",
      "Epoch 1: iteration 1492/2501 train_loss: 0.6566243767738342 time_taken: 0.05649232864379883\n",
      "Epoch 1: iteration 1493/2501 train_loss: 0.6566094756126404 time_taken: 0.056531667709350586\n",
      "Epoch 1: iteration 1494/2501 train_loss: 0.6565710306167603 time_taken: 0.056447744369506836\n",
      "Epoch 1: iteration 1495/2501 train_loss: 0.6565438508987427 time_taken: 0.05657672882080078\n",
      "Epoch 1: iteration 1496/2501 train_loss: 0.6565176844596863 time_taken: 0.05672407150268555\n",
      "Epoch 1: iteration 1497/2501 train_loss: 0.6565014123916626 time_taken: 0.05751156806945801\n",
      "Epoch 1: iteration 1498/2501 train_loss: 0.6564851403236389 time_taken: 0.0573124885559082\n",
      "Epoch 1: iteration 1499/2501 train_loss: 0.6564701795578003 time_taken: 0.05774211883544922\n",
      "Epoch 1: iteration 1500/2501 train_loss: 0.6564668416976929 time_taken: 0.05643868446350098\n",
      "Epoch 1: iteration 1501/2501 train_loss: 0.6564496159553528 time_taken: 0.057500362396240234\n",
      "Epoch 1: iteration 1502/2501 train_loss: 0.6564319729804993 time_taken: 0.056906700134277344\n",
      "Epoch 1: iteration 1503/2501 train_loss: 0.656409502029419 time_taken: 0.056977272033691406\n",
      "Epoch 1: iteration 1504/2501 train_loss: 0.656387209892273 time_taken: 0.056580305099487305\n",
      "Epoch 1: iteration 1505/2501 train_loss: 0.656376838684082 time_taken: 0.056622982025146484\n",
      "Epoch 1: iteration 1506/2501 train_loss: 0.6563665866851807 time_taken: 0.05674934387207031\n",
      "Epoch 1: iteration 1507/2501 train_loss: 0.656365692615509 time_taken: 0.056478261947631836\n",
      "Epoch 1: iteration 1508/2501 train_loss: 0.6563600301742554 time_taken: 0.05716371536254883\n",
      "Epoch 1: iteration 1509/2501 train_loss: 0.6563555598258972 time_taken: 0.05709385871887207\n",
      "Epoch 1: iteration 1510/2501 train_loss: 0.6563546061515808 time_taken: 0.05689668655395508\n",
      "Epoch 1: iteration 1511/2501 train_loss: 0.65635085105896 time_taken: 0.05759906768798828\n",
      "Epoch 1: iteration 1512/2501 train_loss: 0.6563394069671631 time_taken: 0.05652022361755371\n",
      "Epoch 1: iteration 1513/2501 train_loss: 0.6563489437103271 time_taken: 0.05641007423400879\n",
      "Epoch 1: iteration 1514/2501 train_loss: 0.6563417911529541 time_taken: 0.05728936195373535\n",
      "Epoch 1: iteration 1515/2501 train_loss: 0.6563361287117004 time_taken: 0.05741262435913086\n",
      "Epoch 1: iteration 1516/2501 train_loss: 0.6563196182250977 time_taken: 0.05716848373413086\n",
      "Epoch 1: iteration 1517/2501 train_loss: 0.6563115119934082 time_taken: 0.058110713958740234\n",
      "Epoch 1: iteration 1518/2501 train_loss: 0.6562976241111755 time_taken: 0.05679512023925781\n",
      "Epoch 1: iteration 1519/2501 train_loss: 0.6562926769256592 time_taken: 0.05652189254760742\n",
      "Epoch 1: iteration 1520/2501 train_loss: 0.6562868356704712 time_taken: 0.05679631233215332\n",
      "Epoch 1: iteration 1521/2501 train_loss: 0.6562759280204773 time_taken: 0.05752158164978027\n",
      "Epoch 1: iteration 1522/2501 train_loss: 0.6562590003013611 time_taken: 0.0571599006652832\n",
      "Epoch 1: iteration 1523/2501 train_loss: 0.6562329530715942 time_taken: 0.05696415901184082\n",
      "Epoch 1: iteration 1524/2501 train_loss: 0.6561989188194275 time_taken: 0.0565335750579834\n",
      "Epoch 1: iteration 1525/2501 train_loss: 0.6561506986618042 time_taken: 0.07612133026123047\n",
      "Epoch 1: iteration 1526/2501 train_loss: 0.656103789806366 time_taken: 0.06412434577941895\n",
      "Epoch 1: iteration 1527/2501 train_loss: 0.6560564041137695 time_taken: 0.057231903076171875\n",
      "Epoch 1: iteration 1528/2501 train_loss: 0.6560052633285522 time_taken: 0.05711507797241211\n",
      "Epoch 1: iteration 1529/2501 train_loss: 0.6559403538703918 time_taken: 0.05661177635192871\n",
      "Epoch 1: iteration 1530/2501 train_loss: 0.6558754444122314 time_taken: 0.056859731674194336\n",
      "Epoch 1: iteration 1531/2501 train_loss: 0.655826985836029 time_taken: 0.05656886100769043\n",
      "Epoch 1: iteration 1532/2501 train_loss: 0.6557548642158508 time_taken: 0.0571751594543457\n",
      "Epoch 1: iteration 1533/2501 train_loss: 0.6556861400604248 time_taken: 0.05743217468261719\n",
      "Epoch 1: iteration 1534/2501 train_loss: 0.6556368470191956 time_taken: 0.05674862861633301\n",
      "Epoch 1: iteration 1535/2501 train_loss: 0.6556063294410706 time_taken: 0.056824684143066406\n",
      "Epoch 1: iteration 1536/2501 train_loss: 0.6555598378181458 time_taken: 0.0567474365234375\n",
      "Epoch 1: iteration 1537/2501 train_loss: 0.6555272936820984 time_taken: 0.05809640884399414\n",
      "Epoch 1: iteration 1538/2501 train_loss: 0.6554919481277466 time_taken: 0.05670642852783203\n",
      "Epoch 1: iteration 1539/2501 train_loss: 0.6554732918739319 time_taken: 0.05645394325256348\n",
      "Epoch 1: iteration 1540/2501 train_loss: 0.6554483771324158 time_taken: 0.05661797523498535\n",
      "Epoch 1: iteration 1541/2501 train_loss: 0.6554325819015503 time_taken: 0.05673646926879883\n",
      "Epoch 1: iteration 1542/2501 train_loss: 0.655419647693634 time_taken: 0.057013511657714844\n",
      "Epoch 1: iteration 1543/2501 train_loss: 0.6554064750671387 time_taken: 0.056607723236083984\n",
      "Epoch 1: iteration 1544/2501 train_loss: 0.6554086208343506 time_taken: 0.05675077438354492\n",
      "Epoch 1: iteration 1545/2501 train_loss: 0.6554054021835327 time_taken: 0.05657029151916504\n",
      "Epoch 1: iteration 1546/2501 train_loss: 0.6554246544837952 time_taken: 0.05643129348754883\n",
      "Epoch 1: iteration 1547/2501 train_loss: 0.6554318070411682 time_taken: 0.0564265251159668\n",
      "Epoch 1: iteration 1548/2501 train_loss: 0.6554334759712219 time_taken: 0.05669355392456055\n",
      "Epoch 1: iteration 1549/2501 train_loss: 0.6554293036460876 time_taken: 0.05665278434753418\n",
      "Epoch 1: iteration 1550/2501 train_loss: 0.6554436087608337 time_taken: 0.0568084716796875\n",
      "Epoch 1: iteration 1551/2501 train_loss: 0.6554399132728577 time_taken: 0.05639505386352539\n",
      "Epoch 1: iteration 1552/2501 train_loss: 0.6554379463195801 time_taken: 0.05657148361206055\n",
      "Epoch 1: iteration 1553/2501 train_loss: 0.6554368734359741 time_taken: 0.05680704116821289\n",
      "Epoch 1: iteration 1554/2501 train_loss: 0.6554321050643921 time_taken: 0.05703163146972656\n",
      "Epoch 1: iteration 1555/2501 train_loss: 0.6554231643676758 time_taken: 0.0566706657409668\n",
      "Epoch 1: iteration 1556/2501 train_loss: 0.6554247140884399 time_taken: 0.056673526763916016\n",
      "Epoch 1: iteration 1557/2501 train_loss: 0.6554228067398071 time_taken: 0.056629180908203125\n",
      "Epoch 1: iteration 1558/2501 train_loss: 0.655410885810852 time_taken: 0.05648159980773926\n",
      "Epoch 1: iteration 1559/2501 train_loss: 0.6554118990898132 time_taken: 0.056226491928100586\n",
      "Epoch 1: iteration 1560/2501 train_loss: 0.6554036140441895 time_taken: 0.056597232818603516\n",
      "Epoch 1: iteration 1561/2501 train_loss: 0.6554002165794373 time_taken: 0.056197166442871094\n",
      "Epoch 1: iteration 1562/2501 train_loss: 0.6553969979286194 time_taken: 0.05638265609741211\n",
      "Epoch 1: iteration 1563/2501 train_loss: 0.6553993821144104 time_taken: 0.05595970153808594\n",
      "Epoch 1: iteration 1564/2501 train_loss: 0.6553910374641418 time_taken: 0.05602598190307617\n",
      "Epoch 1: iteration 1565/2501 train_loss: 0.6553840637207031 time_taken: 0.05661344528198242\n",
      "Epoch 1: iteration 1566/2501 train_loss: 0.6553820967674255 time_taken: 0.05764460563659668\n",
      "Epoch 1: iteration 1567/2501 train_loss: 0.6553647518157959 time_taken: 0.05609703063964844\n",
      "Epoch 1: iteration 1568/2501 train_loss: 0.6553728580474854 time_taken: 0.05622553825378418\n",
      "Epoch 1: iteration 1569/2501 train_loss: 0.6553632616996765 time_taken: 0.05604815483093262\n",
      "Epoch 1: iteration 1570/2501 train_loss: 0.6553592085838318 time_taken: 0.05609250068664551\n",
      "Epoch 1: iteration 1571/2501 train_loss: 0.6553570628166199 time_taken: 0.05611157417297363\n",
      "Epoch 1: iteration 1572/2501 train_loss: 0.6553428173065186 time_taken: 0.05698394775390625\n",
      "Epoch 1: iteration 1573/2501 train_loss: 0.6553462743759155 time_taken: 0.05629992485046387\n",
      "Epoch 1: iteration 1574/2501 train_loss: 0.6553526520729065 time_taken: 0.05627107620239258\n",
      "Epoch 1: iteration 1575/2501 train_loss: 0.6553470492362976 time_taken: 0.05655789375305176\n",
      "Epoch 1: iteration 1576/2501 train_loss: 0.6553454995155334 time_taken: 0.05736494064331055\n",
      "Epoch 1: iteration 1577/2501 train_loss: 0.6553441286087036 time_taken: 0.05628252029418945\n",
      "Epoch 1: iteration 1578/2501 train_loss: 0.6553312540054321 time_taken: 0.056018829345703125\n",
      "Epoch 1: iteration 1579/2501 train_loss: 0.6553323864936829 time_taken: 0.05641484260559082\n",
      "Epoch 1: iteration 1580/2501 train_loss: 0.6553176045417786 time_taken: 0.056493520736694336\n",
      "Epoch 1: iteration 1581/2501 train_loss: 0.6552867293357849 time_taken: 0.055916786193847656\n",
      "Epoch 1: iteration 1582/2501 train_loss: 0.6552650928497314 time_taken: 0.05672764778137207\n",
      "Epoch 1: iteration 1583/2501 train_loss: 0.6552385091781616 time_taken: 0.05636262893676758\n",
      "Epoch 1: iteration 1584/2501 train_loss: 0.6552239060401917 time_taken: 0.056871652603149414\n",
      "Epoch 1: iteration 1585/2501 train_loss: 0.655205488204956 time_taken: 0.05710291862487793\n",
      "Epoch 1: iteration 1586/2501 train_loss: 0.6551873087882996 time_taken: 0.05694437026977539\n",
      "Epoch 1: iteration 1587/2501 train_loss: 0.6551791429519653 time_taken: 0.05661892890930176\n",
      "Epoch 1: iteration 1588/2501 train_loss: 0.6551706790924072 time_taken: 0.05715775489807129\n",
      "Epoch 1: iteration 1589/2501 train_loss: 0.6551654934883118 time_taken: 0.058194637298583984\n",
      "Epoch 1: iteration 1590/2501 train_loss: 0.6551510691642761 time_taken: 0.05750584602355957\n",
      "Epoch 1: iteration 1591/2501 train_loss: 0.655154287815094 time_taken: 0.08984971046447754\n",
      "Epoch 1: iteration 1592/2501 train_loss: 0.655152440071106 time_taken: 0.06209874153137207\n",
      "Epoch 1: iteration 1593/2501 train_loss: 0.6551606059074402 time_taken: 0.05590653419494629\n",
      "Epoch 1: iteration 1594/2501 train_loss: 0.6551782488822937 time_taken: 0.05607962608337402\n",
      "Epoch 1: iteration 1595/2501 train_loss: 0.6552011370658875 time_taken: 0.05666303634643555\n",
      "Epoch 1: iteration 1596/2501 train_loss: 0.6552285552024841 time_taken: 0.05683493614196777\n",
      "Epoch 1: iteration 1597/2501 train_loss: 0.6552442312240601 time_taken: 0.05666351318359375\n",
      "Epoch 1: iteration 1598/2501 train_loss: 0.6552804708480835 time_taken: 0.05639076232910156\n",
      "Epoch 1: iteration 1599/2501 train_loss: 0.6553053259849548 time_taken: 0.05621194839477539\n",
      "Epoch 1: iteration 1600/2501 train_loss: 0.6553241610527039 time_taken: 0.05697941780090332\n",
      "Epoch 1: iteration 1601/2501 train_loss: 0.6553289890289307 time_taken: 0.056125640869140625\n",
      "Epoch 1: iteration 1602/2501 train_loss: 0.6553213596343994 time_taken: 0.056723833084106445\n",
      "Epoch 1: iteration 1603/2501 train_loss: 0.655327320098877 time_taken: 0.05621695518493652\n",
      "Epoch 1: iteration 1604/2501 train_loss: 0.6553379893302917 time_taken: 0.05628824234008789\n",
      "Epoch 1: iteration 1605/2501 train_loss: 0.6553425788879395 time_taken: 0.056612253189086914\n",
      "Epoch 1: iteration 1606/2501 train_loss: 0.6553539633750916 time_taken: 0.056545257568359375\n",
      "Epoch 1: iteration 1607/2501 train_loss: 0.6553657650947571 time_taken: 0.05624127388000488\n",
      "Epoch 1: iteration 1608/2501 train_loss: 0.6553649306297302 time_taken: 0.056063175201416016\n",
      "Epoch 1: iteration 1609/2501 train_loss: 0.6553490161895752 time_taken: 0.05666351318359375\n",
      "Epoch 1: iteration 1610/2501 train_loss: 0.6553363800048828 time_taken: 0.0563967227935791\n",
      "Epoch 1: iteration 1611/2501 train_loss: 0.6553266048431396 time_taken: 0.05619692802429199\n",
      "Epoch 1: iteration 1612/2501 train_loss: 0.6553227305412292 time_taken: 0.05624747276306152\n",
      "Epoch 1: iteration 1613/2501 train_loss: 0.6553142070770264 time_taken: 0.05655312538146973\n",
      "Epoch 1: iteration 1614/2501 train_loss: 0.6553308963775635 time_taken: 0.05721163749694824\n",
      "Epoch 1: iteration 1615/2501 train_loss: 0.6553217768669128 time_taken: 0.05642342567443848\n",
      "Epoch 1: iteration 1616/2501 train_loss: 0.6553037166595459 time_taken: 0.056717872619628906\n",
      "Epoch 1: iteration 1617/2501 train_loss: 0.6552966833114624 time_taken: 0.05654287338256836\n",
      "Epoch 1: iteration 1618/2501 train_loss: 0.6552761793136597 time_taken: 0.0569303035736084\n",
      "Epoch 1: iteration 1619/2501 train_loss: 0.6552472114562988 time_taken: 0.056253671646118164\n",
      "Epoch 1: iteration 1620/2501 train_loss: 0.6552188396453857 time_taken: 0.05647563934326172\n",
      "Epoch 1: iteration 1621/2501 train_loss: 0.655206561088562 time_taken: 0.05646371841430664\n",
      "Epoch 1: iteration 1622/2501 train_loss: 0.6551800966262817 time_taken: 0.05596113204956055\n",
      "Epoch 1: iteration 1623/2501 train_loss: 0.6551536321640015 time_taken: 0.05610036849975586\n",
      "Epoch 1: iteration 1624/2501 train_loss: 0.6551055312156677 time_taken: 0.056197404861450195\n",
      "Epoch 1: iteration 1625/2501 train_loss: 0.6550660133361816 time_taken: 0.05646467208862305\n",
      "Epoch 1: iteration 1626/2501 train_loss: 0.6550149917602539 time_taken: 0.05709719657897949\n",
      "Epoch 1: iteration 1627/2501 train_loss: 0.654979944229126 time_taken: 0.05691170692443848\n",
      "Epoch 1: iteration 1628/2501 train_loss: 0.6549389362335205 time_taken: 0.05649685859680176\n",
      "Epoch 1: iteration 1629/2501 train_loss: 0.6548680067062378 time_taken: 0.056040048599243164\n",
      "Epoch 1: iteration 1630/2501 train_loss: 0.654796302318573 time_taken: 0.05608248710632324\n",
      "Epoch 1: iteration 1631/2501 train_loss: 0.6547307968139648 time_taken: 0.05755782127380371\n",
      "Epoch 1: iteration 1632/2501 train_loss: 0.6546801924705505 time_taken: 0.05677485466003418\n",
      "Epoch 1: iteration 1633/2501 train_loss: 0.6546353101730347 time_taken: 0.05719161033630371\n",
      "Epoch 1: iteration 1634/2501 train_loss: 0.6545935869216919 time_taken: 0.056720733642578125\n",
      "Epoch 1: iteration 1635/2501 train_loss: 0.654560387134552 time_taken: 0.05653858184814453\n",
      "Epoch 1: iteration 1636/2501 train_loss: 0.6545306444168091 time_taken: 0.05662679672241211\n",
      "Epoch 1: iteration 1637/2501 train_loss: 0.6545220017433167 time_taken: 0.05763649940490723\n",
      "Epoch 1: iteration 1638/2501 train_loss: 0.6545159220695496 time_taken: 0.05623435974121094\n",
      "Epoch 1: iteration 1639/2501 train_loss: 0.6545224189758301 time_taken: 0.05706334114074707\n",
      "Epoch 1: iteration 1640/2501 train_loss: 0.6545146703720093 time_taken: 0.05614614486694336\n",
      "Epoch 1: iteration 1641/2501 train_loss: 0.6545074582099915 time_taken: 0.05649852752685547\n",
      "Epoch 1: iteration 1642/2501 train_loss: 0.6544943451881409 time_taken: 0.05666828155517578\n",
      "Epoch 1: iteration 1643/2501 train_loss: 0.6544817090034485 time_taken: 0.05701565742492676\n",
      "Epoch 1: iteration 1644/2501 train_loss: 0.6544690132141113 time_taken: 0.05644416809082031\n",
      "Epoch 1: iteration 1645/2501 train_loss: 0.6544532775878906 time_taken: 0.05665302276611328\n",
      "Epoch 1: iteration 1646/2501 train_loss: 0.6544389724731445 time_taken: 0.05746269226074219\n",
      "Epoch 1: iteration 1647/2501 train_loss: 0.6544167399406433 time_taken: 0.05716395378112793\n",
      "Epoch 1: iteration 1648/2501 train_loss: 0.6543985605239868 time_taken: 0.05733203887939453\n",
      "Epoch 1: iteration 1649/2501 train_loss: 0.6543849110603333 time_taken: 0.05681347846984863\n",
      "Epoch 1: iteration 1650/2501 train_loss: 0.6543618440628052 time_taken: 0.057198524475097656\n",
      "Epoch 1: iteration 1651/2501 train_loss: 0.654341459274292 time_taken: 0.05754828453063965\n",
      "Epoch 1: iteration 1652/2501 train_loss: 0.6543099284172058 time_taken: 0.057116031646728516\n",
      "Epoch 1: iteration 1653/2501 train_loss: 0.6542823910713196 time_taken: 0.057187795639038086\n",
      "Epoch 1: iteration 1654/2501 train_loss: 0.6542518734931946 time_taken: 0.05695390701293945\n",
      "Epoch 1: iteration 1655/2501 train_loss: 0.6542215347290039 time_taken: 0.05711078643798828\n",
      "Epoch 1: iteration 1656/2501 train_loss: 0.6542056202888489 time_taken: 0.056467294692993164\n",
      "Epoch 1: iteration 1657/2501 train_loss: 0.6541761159896851 time_taken: 0.056887149810791016\n",
      "Epoch 1: iteration 1658/2501 train_loss: 0.6541348695755005 time_taken: 0.0568997859954834\n",
      "Epoch 1: iteration 1659/2501 train_loss: 0.6541136503219604 time_taken: 0.05695700645446777\n",
      "Epoch 1: iteration 1660/2501 train_loss: 0.654094398021698 time_taken: 0.0578920841217041\n",
      "Epoch 1: iteration 1661/2501 train_loss: 0.6540672779083252 time_taken: 0.057506561279296875\n",
      "Epoch 1: iteration 1662/2501 train_loss: 0.6540427803993225 time_taken: 0.05704832077026367\n",
      "Epoch 1: iteration 1663/2501 train_loss: 0.6540312170982361 time_taken: 0.057341575622558594\n",
      "Epoch 1: iteration 1664/2501 train_loss: 0.6540061831474304 time_taken: 0.057428836822509766\n",
      "Epoch 1: iteration 1665/2501 train_loss: 0.6539957523345947 time_taken: 0.05804157257080078\n",
      "Epoch 1: iteration 1666/2501 train_loss: 0.6539819836616516 time_taken: 0.05798792839050293\n",
      "Epoch 1: iteration 1667/2501 train_loss: 0.653964102268219 time_taken: 0.057413578033447266\n",
      "Epoch 1: iteration 1668/2501 train_loss: 0.6539531350135803 time_taken: 0.05727887153625488\n",
      "Epoch 1: iteration 1669/2501 train_loss: 0.6539669036865234 time_taken: 0.056879520416259766\n",
      "Epoch 1: iteration 1670/2501 train_loss: 0.6539909839630127 time_taken: 0.057114601135253906\n",
      "Epoch 1: iteration 1671/2501 train_loss: 0.6540212631225586 time_taken: 0.05657052993774414\n",
      "Epoch 1: iteration 1672/2501 train_loss: 0.6540634036064148 time_taken: 0.05729269981384277\n",
      "Epoch 1: iteration 1673/2501 train_loss: 0.6541038751602173 time_taken: 0.05704975128173828\n",
      "Epoch 1: iteration 1674/2501 train_loss: 0.6541555523872375 time_taken: 0.0570979118347168\n",
      "Epoch 1: iteration 1675/2501 train_loss: 0.6542372107505798 time_taken: 0.05767083168029785\n",
      "Epoch 1: iteration 1676/2501 train_loss: 0.6543245315551758 time_taken: 0.056439876556396484\n",
      "Epoch 1: iteration 1677/2501 train_loss: 0.6544338464736938 time_taken: 0.05643320083618164\n",
      "Epoch 1: iteration 1678/2501 train_loss: 0.6545346975326538 time_taken: 0.08991599082946777\n",
      "Epoch 1: iteration 1679/2501 train_loss: 0.6546487212181091 time_taken: 0.05668210983276367\n",
      "Epoch 1: iteration 1680/2501 train_loss: 0.6547675132751465 time_taken: 0.05650210380554199\n",
      "Epoch 1: iteration 1681/2501 train_loss: 0.6548805832862854 time_taken: 0.05648517608642578\n",
      "Epoch 1: iteration 1682/2501 train_loss: 0.6550092101097107 time_taken: 0.0576624870300293\n",
      "Epoch 1: iteration 1683/2501 train_loss: 0.6551281213760376 time_taken: 0.0567629337310791\n",
      "Epoch 1: iteration 1684/2501 train_loss: 0.6552495956420898 time_taken: 0.05648088455200195\n",
      "Epoch 1: iteration 1685/2501 train_loss: 0.6553767323493958 time_taken: 0.057090044021606445\n",
      "Epoch 1: iteration 1686/2501 train_loss: 0.6555020809173584 time_taken: 0.057145118713378906\n",
      "Epoch 1: iteration 1687/2501 train_loss: 0.6556161642074585 time_taken: 0.05713605880737305\n",
      "Epoch 1: iteration 1688/2501 train_loss: 0.6557236909866333 time_taken: 0.05633735656738281\n",
      "Epoch 1: iteration 1689/2501 train_loss: 0.6558286547660828 time_taken: 0.05616641044616699\n",
      "Epoch 1: iteration 1690/2501 train_loss: 0.6559291481971741 time_taken: 0.056318044662475586\n",
      "Epoch 1: iteration 1691/2501 train_loss: 0.6560112237930298 time_taken: 0.056998491287231445\n",
      "Epoch 1: iteration 1692/2501 train_loss: 0.6560858488082886 time_taken: 0.05655980110168457\n",
      "Epoch 1: iteration 1693/2501 train_loss: 0.6561705470085144 time_taken: 0.05629897117614746\n",
      "Epoch 1: iteration 1694/2501 train_loss: 0.6562384963035583 time_taken: 0.05673074722290039\n",
      "Epoch 1: iteration 1695/2501 train_loss: 0.6563015580177307 time_taken: 0.056478023529052734\n",
      "Epoch 1: iteration 1696/2501 train_loss: 0.6563741564750671 time_taken: 0.05817675590515137\n",
      "Epoch 1: iteration 1697/2501 train_loss: 0.6564498543739319 time_taken: 0.05695772171020508\n",
      "Epoch 1: iteration 1698/2501 train_loss: 0.6565125584602356 time_taken: 0.05748105049133301\n",
      "Epoch 1: iteration 1699/2501 train_loss: 0.6565772294998169 time_taken: 0.056715965270996094\n",
      "Epoch 1: iteration 1700/2501 train_loss: 0.6566429138183594 time_taken: 0.05651593208312988\n",
      "Epoch 1: iteration 1701/2501 train_loss: 0.6567068099975586 time_taken: 0.05657076835632324\n",
      "Epoch 1: iteration 1702/2501 train_loss: 0.656761646270752 time_taken: 0.05648303031921387\n",
      "Epoch 1: iteration 1703/2501 train_loss: 0.6568253636360168 time_taken: 0.056672096252441406\n",
      "Epoch 1: iteration 1704/2501 train_loss: 0.6568830609321594 time_taken: 0.05663609504699707\n",
      "Epoch 1: iteration 1705/2501 train_loss: 0.6569174528121948 time_taken: 0.05990028381347656\n",
      "Epoch 1: iteration 1706/2501 train_loss: 0.6569587588310242 time_taken: 0.05691409111022949\n",
      "Epoch 1: iteration 1707/2501 train_loss: 0.6569894552230835 time_taken: 0.05725860595703125\n",
      "Epoch 1: iteration 1708/2501 train_loss: 0.657010018825531 time_taken: 0.057195186614990234\n",
      "Epoch 1: iteration 1709/2501 train_loss: 0.657035231590271 time_taken: 0.056915998458862305\n",
      "Epoch 1: iteration 1710/2501 train_loss: 0.6570693850517273 time_taken: 0.056464433670043945\n",
      "Epoch 1: iteration 1711/2501 train_loss: 0.6570842862129211 time_taken: 0.0566258430480957\n",
      "Epoch 1: iteration 1712/2501 train_loss: 0.6571086049079895 time_taken: 0.05686068534851074\n",
      "Epoch 1: iteration 1713/2501 train_loss: 0.6571115851402283 time_taken: 0.05782318115234375\n",
      "Epoch 1: iteration 1714/2501 train_loss: 0.6571213603019714 time_taken: 0.05659031867980957\n",
      "Epoch 1: iteration 1715/2501 train_loss: 0.6571343541145325 time_taken: 0.05689120292663574\n",
      "Epoch 1: iteration 1716/2501 train_loss: 0.6571527719497681 time_taken: 0.0563809871673584\n",
      "Epoch 1: iteration 1717/2501 train_loss: 0.6571648716926575 time_taken: 0.0564732551574707\n",
      "Epoch 1: iteration 1718/2501 train_loss: 0.6571727395057678 time_taken: 0.056691884994506836\n",
      "Epoch 1: iteration 1719/2501 train_loss: 0.6571800708770752 time_taken: 0.05667424201965332\n",
      "Epoch 1: iteration 1720/2501 train_loss: 0.6571820378303528 time_taken: 0.06850147247314453\n",
      "Epoch 1: iteration 1721/2501 train_loss: 0.6571846008300781 time_taken: 0.05608487129211426\n",
      "Epoch 1: iteration 1722/2501 train_loss: 0.6571798920631409 time_taken: 0.056036949157714844\n",
      "Epoch 1: iteration 1723/2501 train_loss: 0.6571786403656006 time_taken: 0.07496523857116699\n",
      "Epoch 1: iteration 1724/2501 train_loss: 0.6571829915046692 time_taken: 0.07687592506408691\n",
      "Epoch 1: iteration 1725/2501 train_loss: 0.657200276851654 time_taken: 0.056153297424316406\n",
      "Epoch 1: iteration 1726/2501 train_loss: 0.6572036743164062 time_taken: 0.056722164154052734\n",
      "Epoch 1: iteration 1727/2501 train_loss: 0.6572177410125732 time_taken: 0.057286739349365234\n",
      "Epoch 1: iteration 1728/2501 train_loss: 0.6572411060333252 time_taken: 0.05647563934326172\n",
      "Epoch 1: iteration 1729/2501 train_loss: 0.6572600603103638 time_taken: 0.05706286430358887\n",
      "Epoch 1: iteration 1730/2501 train_loss: 0.6572874784469604 time_taken: 0.05642366409301758\n",
      "Epoch 1: iteration 1731/2501 train_loss: 0.6573078036308289 time_taken: 0.05623173713684082\n",
      "Epoch 1: iteration 1732/2501 train_loss: 0.6573355197906494 time_taken: 0.05681419372558594\n",
      "Epoch 1: iteration 1733/2501 train_loss: 0.6573657989501953 time_taken: 0.05605745315551758\n",
      "Epoch 1: iteration 1734/2501 train_loss: 0.657382607460022 time_taken: 0.056287527084350586\n",
      "Epoch 1: iteration 1735/2501 train_loss: 0.6573948264122009 time_taken: 0.05644702911376953\n",
      "Epoch 1: iteration 1736/2501 train_loss: 0.6574134826660156 time_taken: 0.055960655212402344\n",
      "Epoch 1: iteration 1737/2501 train_loss: 0.6574490070343018 time_taken: 0.0559847354888916\n",
      "Epoch 1: iteration 1738/2501 train_loss: 0.6574668288230896 time_taken: 0.057030439376831055\n",
      "Epoch 1: iteration 1739/2501 train_loss: 0.6574956178665161 time_taken: 0.05624651908874512\n",
      "Epoch 1: iteration 1740/2501 train_loss: 0.6575044393539429 time_taken: 0.05635666847229004\n",
      "Epoch 1: iteration 1741/2501 train_loss: 0.6575238108634949 time_taken: 0.056276798248291016\n",
      "Epoch 1: iteration 1742/2501 train_loss: 0.6575519442558289 time_taken: 0.05649113655090332\n",
      "Epoch 1: iteration 1743/2501 train_loss: 0.6575734615325928 time_taken: 0.05659747123718262\n",
      "Epoch 1: iteration 1744/2501 train_loss: 0.6576047539710999 time_taken: 0.0565340518951416\n",
      "Epoch 1: iteration 1745/2501 train_loss: 0.6576347947120667 time_taken: 0.05653238296508789\n",
      "Epoch 1: iteration 1746/2501 train_loss: 0.6576685309410095 time_taken: 0.05627250671386719\n",
      "Epoch 1: iteration 1747/2501 train_loss: 0.6576928496360779 time_taken: 0.05654549598693848\n",
      "Epoch 1: iteration 1748/2501 train_loss: 0.6577276587486267 time_taken: 0.05724334716796875\n",
      "Epoch 1: iteration 1749/2501 train_loss: 0.6577563285827637 time_taken: 0.06104111671447754\n",
      "Epoch 1: iteration 1750/2501 train_loss: 0.6578111052513123 time_taken: 0.05699658393859863\n",
      "Epoch 1: iteration 1751/2501 train_loss: 0.6578360199928284 time_taken: 0.056717634201049805\n",
      "Epoch 1: iteration 1752/2501 train_loss: 0.6578618288040161 time_taken: 0.05616259574890137\n",
      "Epoch 1: iteration 1753/2501 train_loss: 0.6579066514968872 time_taken: 0.05702018737792969\n",
      "Epoch 1: iteration 1754/2501 train_loss: 0.657943844795227 time_taken: 0.05654430389404297\n",
      "Epoch 1: iteration 1755/2501 train_loss: 0.6579806208610535 time_taken: 0.05683183670043945\n",
      "Epoch 1: iteration 1756/2501 train_loss: 0.6580166220664978 time_taken: 0.056700706481933594\n",
      "Epoch 1: iteration 1757/2501 train_loss: 0.6580630540847778 time_taken: 0.05618143081665039\n",
      "Epoch 1: iteration 1758/2501 train_loss: 0.6580983996391296 time_taken: 0.057274818420410156\n",
      "Epoch 1: iteration 1759/2501 train_loss: 0.6581242084503174 time_taken: 0.056505680084228516\n",
      "Epoch 1: iteration 1760/2501 train_loss: 0.6581494808197021 time_taken: 0.05625438690185547\n",
      "Epoch 1: iteration 1761/2501 train_loss: 0.6581715941429138 time_taken: 0.05616950988769531\n",
      "Epoch 1: iteration 1762/2501 train_loss: 0.6581825613975525 time_taken: 0.05784726142883301\n",
      "Epoch 1: iteration 1763/2501 train_loss: 0.6581802368164062 time_taken: 0.05794882774353027\n",
      "Epoch 1: iteration 1764/2501 train_loss: 0.6581885814666748 time_taken: 0.05617356300354004\n",
      "Epoch 1: iteration 1765/2501 train_loss: 0.658179759979248 time_taken: 0.05740499496459961\n",
      "Epoch 1: iteration 1766/2501 train_loss: 0.6581700444221497 time_taken: 0.05712127685546875\n",
      "Epoch 1: iteration 1767/2501 train_loss: 0.6581597924232483 time_taken: 0.05641770362854004\n",
      "Epoch 1: iteration 1768/2501 train_loss: 0.6581571102142334 time_taken: 0.058130741119384766\n",
      "Epoch 1: iteration 1769/2501 train_loss: 0.6581549048423767 time_taken: 0.05657529830932617\n",
      "Epoch 1: iteration 1770/2501 train_loss: 0.6581482291221619 time_taken: 0.05759072303771973\n",
      "Epoch 1: iteration 1771/2501 train_loss: 0.658137321472168 time_taken: 0.05609583854675293\n",
      "Epoch 1: iteration 1772/2501 train_loss: 0.6581377387046814 time_taken: 0.0574498176574707\n",
      "Epoch 1: iteration 1773/2501 train_loss: 0.6581334471702576 time_taken: 0.05689835548400879\n",
      "Epoch 1: iteration 1774/2501 train_loss: 0.6581236720085144 time_taken: 0.05713820457458496\n",
      "Epoch 1: iteration 1775/2501 train_loss: 0.6581136584281921 time_taken: 0.0562288761138916\n",
      "Epoch 1: iteration 1776/2501 train_loss: 0.6581037044525146 time_taken: 0.05770993232727051\n",
      "Epoch 1: iteration 1777/2501 train_loss: 0.6580917835235596 time_taken: 0.0580906867980957\n",
      "Epoch 1: iteration 1778/2501 train_loss: 0.6580675840377808 time_taken: 0.05613374710083008\n",
      "Epoch 1: iteration 1779/2501 train_loss: 0.6580652594566345 time_taken: 0.05683088302612305\n",
      "Epoch 1: iteration 1780/2501 train_loss: 0.6580473184585571 time_taken: 0.05705618858337402\n",
      "Epoch 1: iteration 1781/2501 train_loss: 0.6580435037612915 time_taken: 0.05703234672546387\n",
      "Epoch 1: iteration 1782/2501 train_loss: 0.6580334901809692 time_taken: 0.056787729263305664\n",
      "Epoch 1: iteration 1783/2501 train_loss: 0.6580381393432617 time_taken: 0.05696845054626465\n",
      "Epoch 1: iteration 1784/2501 train_loss: 0.6580333113670349 time_taken: 0.05722522735595703\n",
      "Epoch 1: iteration 1785/2501 train_loss: 0.6580151915550232 time_taken: 0.056890249252319336\n",
      "Epoch 1: iteration 1786/2501 train_loss: 0.6579908132553101 time_taken: 0.05644559860229492\n",
      "Epoch 1: iteration 1787/2501 train_loss: 0.6579833030700684 time_taken: 0.05686616897583008\n",
      "Epoch 1: iteration 1788/2501 train_loss: 0.6579881310462952 time_taken: 0.05682706832885742\n",
      "Epoch 1: iteration 1789/2501 train_loss: 0.6580020785331726 time_taken: 0.05703306198120117\n",
      "Epoch 1: iteration 1790/2501 train_loss: 0.6580172777175903 time_taken: 0.05747342109680176\n",
      "Epoch 1: iteration 1791/2501 train_loss: 0.6580433249473572 time_taken: 0.05656862258911133\n",
      "Epoch 1: iteration 1792/2501 train_loss: 0.6580646634101868 time_taken: 0.057327985763549805\n",
      "Epoch 1: iteration 1793/2501 train_loss: 0.658102810382843 time_taken: 0.05685257911682129\n",
      "Epoch 1: iteration 1794/2501 train_loss: 0.6581470966339111 time_taken: 0.05678153038024902\n",
      "Epoch 1: iteration 1795/2501 train_loss: 0.658198356628418 time_taken: 0.05709052085876465\n",
      "Epoch 1: iteration 1796/2501 train_loss: 0.6582478284835815 time_taken: 0.056856393814086914\n",
      "Epoch 1: iteration 1797/2501 train_loss: 0.6582888960838318 time_taken: 0.05709028244018555\n",
      "Epoch 1: iteration 1798/2501 train_loss: 0.6583349108695984 time_taken: 0.0565185546875\n",
      "Epoch 1: iteration 1799/2501 train_loss: 0.6583663821220398 time_taken: 0.05692648887634277\n",
      "Epoch 1: iteration 1800/2501 train_loss: 0.6584004759788513 time_taken: 0.056891679763793945\n",
      "Epoch 1: iteration 1801/2501 train_loss: 0.6584371328353882 time_taken: 0.056864261627197266\n",
      "Epoch 1: iteration 1802/2501 train_loss: 0.658466100692749 time_taken: 0.05687999725341797\n",
      "Epoch 1: iteration 1803/2501 train_loss: 0.6584839820861816 time_taken: 0.05626392364501953\n",
      "Epoch 1: iteration 1804/2501 train_loss: 0.6585112810134888 time_taken: 0.05711078643798828\n",
      "Epoch 1: iteration 1805/2501 train_loss: 0.6585385203361511 time_taken: 0.05728507041931152\n",
      "Epoch 1: iteration 1806/2501 train_loss: 0.6585732698440552 time_taken: 0.05714058876037598\n",
      "Epoch 1: iteration 1807/2501 train_loss: 0.6585820913314819 time_taken: 0.05681967735290527\n",
      "Epoch 1: iteration 1808/2501 train_loss: 0.65859454870224 time_taken: 0.05682682991027832\n",
      "Epoch 1: iteration 1809/2501 train_loss: 0.658613920211792 time_taken: 0.05637931823730469\n",
      "Epoch 1: iteration 1810/2501 train_loss: 0.6586151123046875 time_taken: 0.056314945220947266\n",
      "Epoch 1: iteration 1811/2501 train_loss: 0.6586236357688904 time_taken: 0.056850433349609375\n",
      "Epoch 1: iteration 1812/2501 train_loss: 0.6586183309555054 time_taken: 0.057125091552734375\n",
      "Epoch 1: iteration 1813/2501 train_loss: 0.6586162447929382 time_taken: 0.05688977241516113\n",
      "Epoch 1: iteration 1814/2501 train_loss: 0.6586135029792786 time_taken: 0.056011199951171875\n",
      "Epoch 1: iteration 1815/2501 train_loss: 0.6586058139801025 time_taken: 0.056668758392333984\n",
      "Epoch 1: iteration 1816/2501 train_loss: 0.6585914492607117 time_taken: 0.05720376968383789\n",
      "Epoch 1: iteration 1817/2501 train_loss: 0.6585936546325684 time_taken: 0.05649161338806152\n",
      "Epoch 1: iteration 1818/2501 train_loss: 0.6585900187492371 time_taken: 0.05671834945678711\n",
      "Epoch 1: iteration 1819/2501 train_loss: 0.6585644483566284 time_taken: 0.056235551834106445\n",
      "Epoch 1: iteration 1820/2501 train_loss: 0.6585537195205688 time_taken: 0.05747342109680176\n",
      "Epoch 1: iteration 1821/2501 train_loss: 0.6585494875907898 time_taken: 0.05775332450866699\n",
      "Epoch 1: iteration 1822/2501 train_loss: 0.6585517525672913 time_taken: 0.0580449104309082\n",
      "Epoch 1: iteration 1823/2501 train_loss: 0.6585522294044495 time_taken: 0.05702328681945801\n",
      "Epoch 1: iteration 1824/2501 train_loss: 0.6585493087768555 time_taken: 0.05642127990722656\n",
      "Epoch 1: iteration 1825/2501 train_loss: 0.6585454940795898 time_taken: 0.05674099922180176\n",
      "Epoch 1: iteration 1826/2501 train_loss: 0.658557116985321 time_taken: 0.05693650245666504\n",
      "Epoch 1: iteration 1827/2501 train_loss: 0.6585821509361267 time_taken: 0.056884050369262695\n",
      "Epoch 1: iteration 1828/2501 train_loss: 0.6586074233055115 time_taken: 0.0565037727355957\n",
      "Epoch 1: iteration 1829/2501 train_loss: 0.6586371064186096 time_taken: 0.056287527084350586\n",
      "Epoch 1: iteration 1830/2501 train_loss: 0.6586793661117554 time_taken: 0.05676841735839844\n",
      "Epoch 1: iteration 1831/2501 train_loss: 0.6587075591087341 time_taken: 0.05682992935180664\n",
      "Epoch 1: iteration 1832/2501 train_loss: 0.6587347388267517 time_taken: 0.057056427001953125\n",
      "Epoch 1: iteration 1833/2501 train_loss: 0.658764660358429 time_taken: 0.05692696571350098\n",
      "Epoch 1: iteration 1834/2501 train_loss: 0.6587988138198853 time_taken: 0.05691790580749512\n",
      "Epoch 1: iteration 1835/2501 train_loss: 0.6588289141654968 time_taken: 0.057032108306884766\n",
      "Epoch 1: iteration 1836/2501 train_loss: 0.6588706374168396 time_taken: 0.05616497993469238\n",
      "Epoch 1: iteration 1837/2501 train_loss: 0.6589016914367676 time_taken: 0.0570063591003418\n",
      "Epoch 1: iteration 1838/2501 train_loss: 0.6589384078979492 time_taken: 0.05657029151916504\n",
      "Epoch 1: iteration 1839/2501 train_loss: 0.658963680267334 time_taken: 0.057196617126464844\n",
      "Epoch 1: iteration 1840/2501 train_loss: 0.6589932441711426 time_taken: 0.05661296844482422\n",
      "Epoch 1: iteration 1841/2501 train_loss: 0.6590114831924438 time_taken: 0.05662226676940918\n",
      "Epoch 1: iteration 1842/2501 train_loss: 0.6590287685394287 time_taken: 0.056783437728881836\n",
      "Epoch 1: iteration 1843/2501 train_loss: 0.6590563058853149 time_taken: 0.05623507499694824\n",
      "Epoch 1: iteration 1844/2501 train_loss: 0.659070611000061 time_taken: 0.056612491607666016\n",
      "Epoch 1: iteration 1845/2501 train_loss: 0.6590849757194519 time_taken: 0.05649089813232422\n",
      "Epoch 1: iteration 1846/2501 train_loss: 0.6591019630432129 time_taken: 0.05657839775085449\n",
      "Epoch 1: iteration 1847/2501 train_loss: 0.6591249108314514 time_taken: 0.05695652961730957\n",
      "Epoch 1: iteration 1848/2501 train_loss: 0.659128725528717 time_taken: 0.056640625\n",
      "Epoch 1: iteration 1849/2501 train_loss: 0.659143328666687 time_taken: 0.05715513229370117\n",
      "Epoch 1: iteration 1850/2501 train_loss: 0.6591600179672241 time_taken: 0.05648207664489746\n",
      "Epoch 1: iteration 1851/2501 train_loss: 0.6591739058494568 time_taken: 0.05697011947631836\n",
      "Epoch 1: iteration 1852/2501 train_loss: 0.6591800451278687 time_taken: 0.0570218563079834\n",
      "Epoch 1: iteration 1853/2501 train_loss: 0.6591760516166687 time_taken: 0.05736112594604492\n",
      "Epoch 1: iteration 1854/2501 train_loss: 0.6591843962669373 time_taken: 0.0570070743560791\n",
      "Epoch 1: iteration 1855/2501 train_loss: 0.6591807007789612 time_taken: 0.057082414627075195\n",
      "Epoch 1: iteration 1856/2501 train_loss: 0.6591832637786865 time_taken: 0.05714774131774902\n",
      "Epoch 1: iteration 1857/2501 train_loss: 0.6591761112213135 time_taken: 0.05659627914428711\n",
      "Epoch 1: iteration 1858/2501 train_loss: 0.6591699719429016 time_taken: 0.05636882781982422\n",
      "Epoch 1: iteration 1859/2501 train_loss: 0.6591522097587585 time_taken: 0.05636763572692871\n",
      "Epoch 1: iteration 1860/2501 train_loss: 0.659129798412323 time_taken: 0.05723237991333008\n",
      "Epoch 1: iteration 1861/2501 train_loss: 0.6591073870658875 time_taken: 0.056381940841674805\n",
      "Epoch 1: iteration 1862/2501 train_loss: 0.6590827703475952 time_taken: 0.057347774505615234\n",
      "Epoch 1: iteration 1863/2501 train_loss: 0.659045934677124 time_taken: 0.05766725540161133\n",
      "Epoch 1: iteration 1864/2501 train_loss: 0.6590188145637512 time_taken: 0.056867361068725586\n",
      "Epoch 1: iteration 1865/2501 train_loss: 0.6589853763580322 time_taken: 0.05681419372558594\n",
      "Epoch 1: iteration 1866/2501 train_loss: 0.6589610576629639 time_taken: 0.058089256286621094\n",
      "Epoch 1: iteration 1867/2501 train_loss: 0.658953070640564 time_taken: 0.05686759948730469\n",
      "Epoch 1: iteration 1868/2501 train_loss: 0.6589375734329224 time_taken: 0.05678868293762207\n",
      "Epoch 1: iteration 1869/2501 train_loss: 0.6589251160621643 time_taken: 0.05701327323913574\n",
      "Epoch 1: iteration 1870/2501 train_loss: 0.6589123606681824 time_taken: 0.057280778884887695\n",
      "Epoch 1: iteration 1871/2501 train_loss: 0.6588936448097229 time_taken: 0.05749845504760742\n",
      "Epoch 1: iteration 1872/2501 train_loss: 0.658877968788147 time_taken: 0.056205034255981445\n",
      "Epoch 1: iteration 1873/2501 train_loss: 0.6588731408119202 time_taken: 0.056596994400024414\n",
      "Epoch 1: iteration 1874/2501 train_loss: 0.658869206905365 time_taken: 0.05672430992126465\n",
      "Epoch 1: iteration 1875/2501 train_loss: 0.6588765978813171 time_taken: 0.05706620216369629\n",
      "Epoch 1: iteration 1876/2501 train_loss: 0.6588771343231201 time_taken: 0.0741128921508789\n",
      "Epoch 1: iteration 1877/2501 train_loss: 0.6588659286499023 time_taken: 0.07246255874633789\n",
      "Epoch 1: iteration 1878/2501 train_loss: 0.6588508486747742 time_taken: 0.07230234146118164\n",
      "Epoch 1: iteration 1879/2501 train_loss: 0.6588388085365295 time_taken: 0.06452035903930664\n",
      "Epoch 1: iteration 1880/2501 train_loss: 0.6588258147239685 time_taken: 0.056920528411865234\n",
      "Epoch 1: iteration 1881/2501 train_loss: 0.6588173508644104 time_taken: 0.05751323699951172\n",
      "Epoch 1: iteration 1882/2501 train_loss: 0.6588033437728882 time_taken: 0.057070255279541016\n",
      "Epoch 1: iteration 1883/2501 train_loss: 0.6587913632392883 time_taken: 0.05660223960876465\n",
      "Epoch 1: iteration 1884/2501 train_loss: 0.6587792038917542 time_taken: 0.05700826644897461\n",
      "Epoch 1: iteration 1885/2501 train_loss: 0.6587700843811035 time_taken: 0.05667853355407715\n",
      "Epoch 1: iteration 1886/2501 train_loss: 0.6587657332420349 time_taken: 0.05693507194519043\n",
      "Epoch 1: iteration 1887/2501 train_loss: 0.6587547659873962 time_taken: 0.05684852600097656\n",
      "Epoch 1: iteration 1888/2501 train_loss: 0.6587421298027039 time_taken: 0.05676388740539551\n",
      "Epoch 1: iteration 1889/2501 train_loss: 0.6587305068969727 time_taken: 0.05816531181335449\n",
      "Epoch 1: iteration 1890/2501 train_loss: 0.6587198376655579 time_taken: 0.057099342346191406\n",
      "Epoch 1: iteration 1891/2501 train_loss: 0.6587145328521729 time_taken: 0.06147122383117676\n",
      "Epoch 1: iteration 1892/2501 train_loss: 0.6587160229682922 time_taken: 0.05743885040283203\n",
      "Epoch 1: iteration 1893/2501 train_loss: 0.6587249636650085 time_taken: 0.05706954002380371\n",
      "Epoch 1: iteration 1894/2501 train_loss: 0.6587313413619995 time_taken: 0.05725240707397461\n",
      "Epoch 1: iteration 1895/2501 train_loss: 0.658764123916626 time_taken: 0.05623269081115723\n",
      "Epoch 1: iteration 1896/2501 train_loss: 0.6587757468223572 time_taken: 0.05699276924133301\n",
      "Epoch 1: iteration 1897/2501 train_loss: 0.6587815284729004 time_taken: 0.05725383758544922\n",
      "Epoch 1: iteration 1898/2501 train_loss: 0.6588029265403748 time_taken: 0.05716824531555176\n",
      "Epoch 1: iteration 1899/2501 train_loss: 0.6588181853294373 time_taken: 0.05711793899536133\n",
      "Epoch 1: iteration 1900/2501 train_loss: 0.658835232257843 time_taken: 0.05719256401062012\n",
      "Epoch 1: iteration 1901/2501 train_loss: 0.6588388085365295 time_taken: 0.0567326545715332\n",
      "Epoch 1: iteration 1902/2501 train_loss: 0.6588435769081116 time_taken: 0.05640220642089844\n",
      "Epoch 1: iteration 1903/2501 train_loss: 0.6588320136070251 time_taken: 0.05736184120178223\n",
      "Epoch 1: iteration 1904/2501 train_loss: 0.6588332653045654 time_taken: 0.05619549751281738\n",
      "Epoch 1: iteration 1905/2501 train_loss: 0.6588412523269653 time_taken: 0.057028770446777344\n",
      "Epoch 1: iteration 1906/2501 train_loss: 0.6588538885116577 time_taken: 0.05698204040527344\n",
      "Epoch 1: iteration 1907/2501 train_loss: 0.6588665246963501 time_taken: 0.05724167823791504\n",
      "Epoch 1: iteration 1908/2501 train_loss: 0.6588816046714783 time_taken: 0.05639910697937012\n",
      "Epoch 1: iteration 1909/2501 train_loss: 0.6588789820671082 time_taken: 0.1290276050567627\n",
      "Epoch 1: iteration 1910/2501 train_loss: 0.6588930487632751 time_taken: 0.05650615692138672\n",
      "Epoch 1: iteration 1911/2501 train_loss: 0.6588993668556213 time_taken: 0.05672025680541992\n",
      "Epoch 1: iteration 1912/2501 train_loss: 0.658907413482666 time_taken: 0.05665874481201172\n",
      "Epoch 1: iteration 1913/2501 train_loss: 0.6589086055755615 time_taken: 0.056824445724487305\n",
      "Epoch 1: iteration 1914/2501 train_loss: 0.6589174270629883 time_taken: 0.056381940841674805\n",
      "Epoch 1: iteration 1915/2501 train_loss: 0.6589268445968628 time_taken: 0.05652022361755371\n",
      "Epoch 1: iteration 1916/2501 train_loss: 0.6589329838752747 time_taken: 0.056670427322387695\n",
      "Epoch 1: iteration 1917/2501 train_loss: 0.6589362025260925 time_taken: 0.057231903076171875\n",
      "Epoch 1: iteration 1918/2501 train_loss: 0.6589291095733643 time_taken: 0.05689740180969238\n",
      "Epoch 1: iteration 1919/2501 train_loss: 0.6589393615722656 time_taken: 0.057306766510009766\n",
      "Epoch 1: iteration 1920/2501 train_loss: 0.6589395999908447 time_taken: 0.05691123008728027\n",
      "Epoch 1: iteration 1921/2501 train_loss: 0.658954381942749 time_taken: 0.056696176528930664\n",
      "Epoch 1: iteration 1922/2501 train_loss: 0.6589640378952026 time_taken: 0.05723738670349121\n",
      "Epoch 1: iteration 1923/2501 train_loss: 0.658976674079895 time_taken: 0.05667304992675781\n",
      "Epoch 1: iteration 1924/2501 train_loss: 0.6589866876602173 time_taken: 0.05717206001281738\n",
      "Epoch 1: iteration 1925/2501 train_loss: 0.6590049862861633 time_taken: 0.05758309364318848\n",
      "Epoch 1: iteration 1926/2501 train_loss: 0.6590149402618408 time_taken: 0.057285308837890625\n",
      "Epoch 1: iteration 1927/2501 train_loss: 0.6590297818183899 time_taken: 0.057207345962524414\n",
      "Epoch 1: iteration 1928/2501 train_loss: 0.6590442061424255 time_taken: 0.057357072830200195\n",
      "Epoch 1: iteration 1929/2501 train_loss: 0.6590706706047058 time_taken: 0.05653190612792969\n",
      "Epoch 1: iteration 1930/2501 train_loss: 0.6590820550918579 time_taken: 0.05732083320617676\n",
      "Epoch 1: iteration 1931/2501 train_loss: 0.6591125130653381 time_taken: 0.057145118713378906\n",
      "Epoch 1: iteration 1932/2501 train_loss: 0.659144937992096 time_taken: 0.05680418014526367\n",
      "Epoch 1: iteration 1933/2501 train_loss: 0.6591689586639404 time_taken: 0.05668449401855469\n",
      "Epoch 1: iteration 1934/2501 train_loss: 0.6591768860816956 time_taken: 0.05681037902832031\n",
      "Epoch 1: iteration 1935/2501 train_loss: 0.6591861248016357 time_taken: 0.0577845573425293\n",
      "Epoch 1: iteration 1936/2501 train_loss: 0.6591821908950806 time_taken: 0.05754518508911133\n",
      "Epoch 1: iteration 1937/2501 train_loss: 0.6591843366622925 time_taken: 0.05681467056274414\n",
      "Epoch 1: iteration 1938/2501 train_loss: 0.6591805815696716 time_taken: 0.056790828704833984\n",
      "Epoch 1: iteration 1939/2501 train_loss: 0.6591718196868896 time_taken: 0.05682182312011719\n",
      "Epoch 1: iteration 1940/2501 train_loss: 0.6591638922691345 time_taken: 0.056276559829711914\n",
      "Epoch 1: iteration 1941/2501 train_loss: 0.6591488122940063 time_taken: 0.056929826736450195\n",
      "Epoch 1: iteration 1942/2501 train_loss: 0.6591311693191528 time_taken: 0.056337594985961914\n",
      "Epoch 1: iteration 1943/2501 train_loss: 0.6591033339500427 time_taken: 0.05648517608642578\n",
      "Epoch 1: iteration 1944/2501 train_loss: 0.6590750217437744 time_taken: 0.05644679069519043\n",
      "Epoch 1: iteration 1945/2501 train_loss: 0.659037709236145 time_taken: 0.05678439140319824\n",
      "Epoch 1: iteration 1946/2501 train_loss: 0.6589826941490173 time_taken: 0.056980133056640625\n",
      "Epoch 1: iteration 1947/2501 train_loss: 0.6589283347129822 time_taken: 0.05682086944580078\n",
      "Epoch 1: iteration 1948/2501 train_loss: 0.6588813066482544 time_taken: 0.05627560615539551\n",
      "Epoch 1: iteration 1949/2501 train_loss: 0.6588197946548462 time_taken: 0.056694984436035156\n",
      "Epoch 1: iteration 1950/2501 train_loss: 0.6587769985198975 time_taken: 0.05713367462158203\n",
      "Epoch 1: iteration 1951/2501 train_loss: 0.6587470173835754 time_taken: 0.05735015869140625\n",
      "Epoch 1: iteration 1952/2501 train_loss: 0.6587224006652832 time_taken: 0.05819845199584961\n",
      "Epoch 1: iteration 1953/2501 train_loss: 0.6587087512016296 time_taken: 0.05698204040527344\n",
      "Epoch 1: iteration 1954/2501 train_loss: 0.6586747765541077 time_taken: 0.056842803955078125\n",
      "Epoch 1: iteration 1955/2501 train_loss: 0.6586464643478394 time_taken: 0.05761218070983887\n",
      "Epoch 1: iteration 1956/2501 train_loss: 0.6586180329322815 time_taken: 0.057346343994140625\n",
      "Epoch 1: iteration 1957/2501 train_loss: 0.6586010456085205 time_taken: 0.0565032958984375\n",
      "Epoch 1: iteration 1958/2501 train_loss: 0.6585867404937744 time_taken: 0.05689096450805664\n",
      "Epoch 1: iteration 1959/2501 train_loss: 0.6585708260536194 time_taken: 0.05673527717590332\n",
      "Epoch 1: iteration 1960/2501 train_loss: 0.6585569381713867 time_taken: 0.05662894248962402\n",
      "Epoch 1: iteration 1961/2501 train_loss: 0.6585451364517212 time_taken: 0.05710291862487793\n",
      "Epoch 1: iteration 1962/2501 train_loss: 0.6585227251052856 time_taken: 0.05646491050720215\n",
      "Epoch 1: iteration 1963/2501 train_loss: 0.6584954261779785 time_taken: 0.057425737380981445\n",
      "Epoch 1: iteration 1964/2501 train_loss: 0.6584710478782654 time_taken: 0.05661630630493164\n",
      "Epoch 1: iteration 1965/2501 train_loss: 0.6584488153457642 time_taken: 0.056665658950805664\n",
      "Epoch 1: iteration 1966/2501 train_loss: 0.6584221720695496 time_taken: 0.056336402893066406\n",
      "Epoch 1: iteration 1967/2501 train_loss: 0.658390998840332 time_taken: 0.05706381797790527\n",
      "Epoch 1: iteration 1968/2501 train_loss: 0.6583635210990906 time_taken: 0.05690598487854004\n",
      "Epoch 1: iteration 1969/2501 train_loss: 0.6583256125450134 time_taken: 0.05666828155517578\n",
      "Epoch 1: iteration 1970/2501 train_loss: 0.658297598361969 time_taken: 0.05706310272216797\n",
      "Epoch 1: iteration 1971/2501 train_loss: 0.6582693457603455 time_taken: 0.05679202079772949\n",
      "Epoch 1: iteration 1972/2501 train_loss: 0.658250629901886 time_taken: 0.05649614334106445\n",
      "Epoch 1: iteration 1973/2501 train_loss: 0.6582333445549011 time_taken: 0.05694246292114258\n",
      "Epoch 1: iteration 1974/2501 train_loss: 0.6582155823707581 time_taken: 0.05681967735290527\n",
      "Epoch 1: iteration 1975/2501 train_loss: 0.6582009792327881 time_taken: 0.057214975357055664\n",
      "Epoch 1: iteration 1976/2501 train_loss: 0.6581883430480957 time_taken: 0.05673718452453613\n",
      "Epoch 1: iteration 1977/2501 train_loss: 0.6581724286079407 time_taken: 0.05716991424560547\n",
      "Epoch 1: iteration 1978/2501 train_loss: 0.6581480503082275 time_taken: 0.05736136436462402\n",
      "Epoch 1: iteration 1979/2501 train_loss: 0.6581355929374695 time_taken: 0.0569918155670166\n",
      "Epoch 1: iteration 1980/2501 train_loss: 0.6581040620803833 time_taken: 0.05695176124572754\n",
      "Epoch 1: iteration 1981/2501 train_loss: 0.6580771207809448 time_taken: 0.056514739990234375\n",
      "Epoch 1: iteration 1982/2501 train_loss: 0.6580536961555481 time_taken: 0.05689692497253418\n",
      "Epoch 1: iteration 1983/2501 train_loss: 0.6580216884613037 time_taken: 0.05657339096069336\n",
      "Epoch 1: iteration 1984/2501 train_loss: 0.6579816937446594 time_taken: 0.0566864013671875\n",
      "Epoch 1: iteration 1985/2501 train_loss: 0.657963752746582 time_taken: 0.05669450759887695\n",
      "Epoch 1: iteration 1986/2501 train_loss: 0.6579391360282898 time_taken: 0.05694270133972168\n",
      "Epoch 1: iteration 1987/2501 train_loss: 0.6579148769378662 time_taken: 0.057383060455322266\n",
      "Epoch 1: iteration 1988/2501 train_loss: 0.6578803062438965 time_taken: 0.056658029556274414\n",
      "Epoch 1: iteration 1989/2501 train_loss: 0.6578481197357178 time_taken: 0.05765128135681152\n",
      "Epoch 1: iteration 1990/2501 train_loss: 0.6578100323677063 time_taken: 0.05728888511657715\n",
      "Epoch 1: iteration 1991/2501 train_loss: 0.6577756404876709 time_taken: 0.057005882263183594\n",
      "Epoch 1: iteration 1992/2501 train_loss: 0.6577444672584534 time_taken: 0.05712556838989258\n",
      "Epoch 1: iteration 1993/2501 train_loss: 0.6577169895172119 time_taken: 0.05732440948486328\n",
      "Epoch 1: iteration 1994/2501 train_loss: 0.6576946973800659 time_taken: 0.05657243728637695\n",
      "Epoch 1: iteration 1995/2501 train_loss: 0.6576647758483887 time_taken: 0.05679488182067871\n",
      "Epoch 1: iteration 1996/2501 train_loss: 0.657642662525177 time_taken: 0.05690503120422363\n",
      "Epoch 1: iteration 1997/2501 train_loss: 0.6576220989227295 time_taken: 0.05678915977478027\n",
      "Epoch 1: iteration 1998/2501 train_loss: 0.6576102375984192 time_taken: 0.056633949279785156\n",
      "Epoch 1: iteration 1999/2501 train_loss: 0.6576014757156372 time_taken: 0.05649971961975098\n",
      "Epoch 1: iteration 2000/2501 train_loss: 0.6575881242752075 time_taken: 0.05689287185668945\n",
      "Epoch 1: iteration 2001/2501 train_loss: 0.6575652956962585 time_taken: 0.05694937705993652\n",
      "Epoch 1: iteration 2002/2501 train_loss: 0.6575335264205933 time_taken: 0.056971073150634766\n",
      "Epoch 1: iteration 2003/2501 train_loss: 0.6575105786323547 time_taken: 0.08013343811035156\n",
      "Epoch 1: iteration 2004/2501 train_loss: 0.6574978232383728 time_taken: 0.08441019058227539\n",
      "Epoch 1: iteration 2005/2501 train_loss: 0.657479465007782 time_taken: 0.10651111602783203\n",
      "Epoch 1: iteration 2006/2501 train_loss: 0.6574665904045105 time_taken: 0.056138038635253906\n",
      "Epoch 1: iteration 2007/2501 train_loss: 0.6574536561965942 time_taken: 0.05646204948425293\n",
      "Epoch 1: iteration 2008/2501 train_loss: 0.6574435830116272 time_taken: 0.05667591094970703\n",
      "Epoch 1: iteration 2009/2501 train_loss: 0.657451868057251 time_taken: 0.05765271186828613\n",
      "Epoch 1: iteration 2010/2501 train_loss: 0.657457709312439 time_taken: 0.05674123764038086\n",
      "Epoch 1: iteration 2011/2501 train_loss: 0.6574667096138 time_taken: 0.05676722526550293\n",
      "Epoch 1: iteration 2012/2501 train_loss: 0.6574919819831848 time_taken: 0.05654740333557129\n",
      "Epoch 1: iteration 2013/2501 train_loss: 0.6575059294700623 time_taken: 0.05729341506958008\n",
      "Epoch 1: iteration 2014/2501 train_loss: 0.6575207710266113 time_taken: 0.057301998138427734\n",
      "Epoch 1: iteration 2015/2501 train_loss: 0.657537579536438 time_taken: 0.05688023567199707\n",
      "Epoch 1: iteration 2016/2501 train_loss: 0.6575552821159363 time_taken: 0.056838035583496094\n",
      "Epoch 1: iteration 2017/2501 train_loss: 0.6575658321380615 time_taken: 0.05658984184265137\n",
      "Epoch 1: iteration 2018/2501 train_loss: 0.6575803160667419 time_taken: 0.0568084716796875\n",
      "Epoch 1: iteration 2019/2501 train_loss: 0.6576096415519714 time_taken: 0.057123422622680664\n",
      "Epoch 1: iteration 2020/2501 train_loss: 0.6576243042945862 time_taken: 0.05672788619995117\n",
      "Epoch 1: iteration 2021/2501 train_loss: 0.6576317548751831 time_taken: 0.05651974678039551\n",
      "Epoch 1: iteration 2022/2501 train_loss: 0.6576381921768188 time_taken: 0.05673336982727051\n",
      "Epoch 1: iteration 2023/2501 train_loss: 0.6576383113861084 time_taken: 0.05771374702453613\n",
      "Epoch 1: iteration 2024/2501 train_loss: 0.657646119594574 time_taken: 0.056371212005615234\n",
      "Epoch 1: iteration 2025/2501 train_loss: 0.6576536297798157 time_taken: 0.057005882263183594\n",
      "Epoch 1: iteration 2026/2501 train_loss: 0.657648503780365 time_taken: 0.05725550651550293\n",
      "Epoch 1: iteration 2027/2501 train_loss: 0.6576524376869202 time_taken: 0.05713605880737305\n",
      "Epoch 1: iteration 2028/2501 train_loss: 0.6576544642448425 time_taken: 0.056775808334350586\n",
      "Epoch 1: iteration 2029/2501 train_loss: 0.6576604843139648 time_taken: 0.05639505386352539\n",
      "Epoch 1: iteration 2030/2501 train_loss: 0.6576626300811768 time_taken: 0.056792259216308594\n",
      "Epoch 1: iteration 2031/2501 train_loss: 0.6576741933822632 time_taken: 0.057127952575683594\n",
      "Epoch 1: iteration 2032/2501 train_loss: 0.6576992869377136 time_taken: 0.05645489692687988\n",
      "Epoch 1: iteration 2033/2501 train_loss: 0.6577300429344177 time_taken: 0.05667567253112793\n",
      "Epoch 1: iteration 2034/2501 train_loss: 0.6577519774436951 time_taken: 0.05634593963623047\n",
      "Epoch 1: iteration 2035/2501 train_loss: 0.6577829718589783 time_taken: 0.056661128997802734\n",
      "Epoch 1: iteration 2036/2501 train_loss: 0.657809317111969 time_taken: 0.05684328079223633\n",
      "Epoch 1: iteration 2037/2501 train_loss: 0.6578406095504761 time_taken: 0.05772733688354492\n",
      "Epoch 1: iteration 2038/2501 train_loss: 0.6578625440597534 time_taken: 0.05737638473510742\n",
      "Epoch 1: iteration 2039/2501 train_loss: 0.6579048037528992 time_taken: 0.0569453239440918\n",
      "Epoch 1: iteration 2040/2501 train_loss: 0.6579439640045166 time_taken: 0.05680561065673828\n",
      "Epoch 1: iteration 2041/2501 train_loss: 0.6579917669296265 time_taken: 0.0569453239440918\n",
      "Epoch 1: iteration 2042/2501 train_loss: 0.6580303907394409 time_taken: 0.0563502311706543\n",
      "Epoch 1: iteration 2043/2501 train_loss: 0.6580458879470825 time_taken: 0.056427001953125\n",
      "Epoch 1: iteration 2044/2501 train_loss: 0.6580657362937927 time_taken: 0.05728793144226074\n",
      "Epoch 1: iteration 2045/2501 train_loss: 0.6580804586410522 time_taken: 0.0564122200012207\n",
      "Epoch 1: iteration 2046/2501 train_loss: 0.6580841541290283 time_taken: 0.0561223030090332\n",
      "Epoch 1: iteration 2047/2501 train_loss: 0.6580867171287537 time_taken: 0.05622601509094238\n",
      "Epoch 1: iteration 2048/2501 train_loss: 0.6580978631973267 time_taken: 0.05619335174560547\n",
      "Epoch 1: iteration 2049/2501 train_loss: 0.6581162810325623 time_taken: 0.056496381759643555\n",
      "Epoch 1: iteration 2050/2501 train_loss: 0.6581335663795471 time_taken: 0.05660700798034668\n",
      "Epoch 1: iteration 2051/2501 train_loss: 0.6581327319145203 time_taken: 0.05634117126464844\n",
      "Epoch 1: iteration 2052/2501 train_loss: 0.6581276059150696 time_taken: 0.05638313293457031\n",
      "Epoch 1: iteration 2053/2501 train_loss: 0.6581210494041443 time_taken: 0.05634450912475586\n",
      "Epoch 1: iteration 2054/2501 train_loss: 0.658109724521637 time_taken: 0.05648398399353027\n",
      "Epoch 1: iteration 2055/2501 train_loss: 0.6580970287322998 time_taken: 0.056147098541259766\n",
      "Epoch 1: iteration 2056/2501 train_loss: 0.6581009030342102 time_taken: 0.05658721923828125\n",
      "Epoch 1: iteration 2057/2501 train_loss: 0.6580945253372192 time_taken: 0.055908203125\n",
      "Epoch 1: iteration 2058/2501 train_loss: 0.6580910682678223 time_taken: 0.0560455322265625\n",
      "Epoch 1: iteration 2059/2501 train_loss: 0.6580864787101746 time_taken: 0.05646920204162598\n",
      "Epoch 1: iteration 2060/2501 train_loss: 0.6580738425254822 time_taken: 0.05624699592590332\n",
      "Epoch 1: iteration 2061/2501 train_loss: 0.6580678224563599 time_taken: 0.05699443817138672\n",
      "Epoch 1: iteration 2062/2501 train_loss: 0.6580736041069031 time_taken: 0.05675339698791504\n",
      "Epoch 1: iteration 2063/2501 train_loss: 0.6580870151519775 time_taken: 0.05624961853027344\n",
      "Epoch 1: iteration 2064/2501 train_loss: 0.6581102609634399 time_taken: 0.056487083435058594\n",
      "Epoch 1: iteration 2065/2501 train_loss: 0.6581364870071411 time_taken: 0.05690956115722656\n",
      "Epoch 1: iteration 2066/2501 train_loss: 0.65815269947052 time_taken: 0.056810617446899414\n",
      "Epoch 1: iteration 2067/2501 train_loss: 0.6581708192825317 time_taken: 0.05606794357299805\n",
      "Epoch 1: iteration 2068/2501 train_loss: 0.6581882238388062 time_taken: 0.05723905563354492\n",
      "Epoch 1: iteration 2069/2501 train_loss: 0.6581936478614807 time_taken: 0.05676746368408203\n",
      "Epoch 1: iteration 2070/2501 train_loss: 0.6581940650939941 time_taken: 0.056398630142211914\n",
      "Epoch 1: iteration 2071/2501 train_loss: 0.6581927537918091 time_taken: 0.05669879913330078\n",
      "Epoch 1: iteration 2072/2501 train_loss: 0.658181369304657 time_taken: 0.05622053146362305\n",
      "Epoch 1: iteration 2073/2501 train_loss: 0.6581678986549377 time_taken: 0.05717778205871582\n",
      "Epoch 1: iteration 2074/2501 train_loss: 0.6581549048423767 time_taken: 0.05753040313720703\n",
      "Epoch 1: iteration 2075/2501 train_loss: 0.6581355929374695 time_taken: 0.056688547134399414\n",
      "Epoch 1: iteration 2076/2501 train_loss: 0.6581203937530518 time_taken: 0.05644488334655762\n",
      "Epoch 1: iteration 2077/2501 train_loss: 0.6581083536148071 time_taken: 0.05696845054626465\n",
      "Epoch 1: iteration 2078/2501 train_loss: 0.6580851078033447 time_taken: 0.05719256401062012\n",
      "Epoch 1: iteration 2079/2501 train_loss: 0.6580724716186523 time_taken: 0.056571245193481445\n",
      "Epoch 1: iteration 2080/2501 train_loss: 0.6580629944801331 time_taken: 0.05799555778503418\n",
      "Epoch 1: iteration 2081/2501 train_loss: 0.6580455303192139 time_taken: 0.056685686111450195\n",
      "Epoch 1: iteration 2082/2501 train_loss: 0.6580344438552856 time_taken: 0.05628037452697754\n",
      "Epoch 1: iteration 2083/2501 train_loss: 0.6580163240432739 time_taken: 0.05707359313964844\n",
      "Epoch 1: iteration 2084/2501 train_loss: 0.6580092906951904 time_taken: 0.05620002746582031\n",
      "Epoch 1: iteration 2085/2501 train_loss: 0.6580013632774353 time_taken: 0.056284427642822266\n",
      "Epoch 1: iteration 2086/2501 train_loss: 0.6579831838607788 time_taken: 0.0572047233581543\n",
      "Epoch 1: iteration 2087/2501 train_loss: 0.6579689383506775 time_taken: 0.05709433555603027\n",
      "Epoch 1: iteration 2088/2501 train_loss: 0.6579566597938538 time_taken: 0.05684685707092285\n",
      "Epoch 1: iteration 2089/2501 train_loss: 0.6579408049583435 time_taken: 0.05679488182067871\n",
      "Epoch 1: iteration 2090/2501 train_loss: 0.657926082611084 time_taken: 0.05676412582397461\n",
      "Epoch 1: iteration 2091/2501 train_loss: 0.6579078435897827 time_taken: 0.05665874481201172\n",
      "Epoch 1: iteration 2092/2501 train_loss: 0.6578820943832397 time_taken: 0.0565185546875\n",
      "Epoch 1: iteration 2093/2501 train_loss: 0.6578586101531982 time_taken: 0.05617165565490723\n",
      "Epoch 1: iteration 2094/2501 train_loss: 0.6578373908996582 time_taken: 0.0565335750579834\n",
      "Epoch 1: iteration 2095/2501 train_loss: 0.6578032374382019 time_taken: 0.056047916412353516\n",
      "Epoch 1: iteration 2096/2501 train_loss: 0.6577796936035156 time_taken: 0.05654573440551758\n",
      "Epoch 1: iteration 2097/2501 train_loss: 0.6577439308166504 time_taken: 0.05598855018615723\n",
      "Epoch 1: iteration 2098/2501 train_loss: 0.6577072739601135 time_taken: 0.05659794807434082\n",
      "Epoch 1: iteration 2099/2501 train_loss: 0.6576672792434692 time_taken: 0.056549787521362305\n",
      "Epoch 1: iteration 2100/2501 train_loss: 0.6576353311538696 time_taken: 0.056787967681884766\n",
      "Epoch 1: iteration 2101/2501 train_loss: 0.6576043963432312 time_taken: 0.056334733963012695\n",
      "Epoch 1: iteration 2102/2501 train_loss: 0.6575736403465271 time_taken: 0.05611896514892578\n",
      "Epoch 1: iteration 2103/2501 train_loss: 0.6575361490249634 time_taken: 0.056112051010131836\n",
      "Epoch 1: iteration 2104/2501 train_loss: 0.657491147518158 time_taken: 0.05675816535949707\n",
      "Epoch 1: iteration 2105/2501 train_loss: 0.6574487686157227 time_taken: 0.056886911392211914\n",
      "Epoch 1: iteration 2106/2501 train_loss: 0.6574099659919739 time_taken: 0.05681276321411133\n",
      "Epoch 1: iteration 2107/2501 train_loss: 0.6573736071586609 time_taken: 0.056763410568237305\n",
      "Epoch 1: iteration 2108/2501 train_loss: 0.6573371887207031 time_taken: 0.05726766586303711\n",
      "Epoch 1: iteration 2109/2501 train_loss: 0.6572981476783752 time_taken: 0.05667757987976074\n",
      "Epoch 1: iteration 2110/2501 train_loss: 0.6572604775428772 time_taken: 0.05693984031677246\n",
      "Epoch 1: iteration 2111/2501 train_loss: 0.657218873500824 time_taken: 0.0565187931060791\n",
      "Epoch 1: iteration 2112/2501 train_loss: 0.6571837067604065 time_taken: 0.05680036544799805\n",
      "Epoch 1: iteration 2113/2501 train_loss: 0.6571645736694336 time_taken: 0.05674624443054199\n",
      "Epoch 1: iteration 2114/2501 train_loss: 0.6571524143218994 time_taken: 0.055963993072509766\n",
      "Epoch 1: iteration 2115/2501 train_loss: 0.6571423411369324 time_taken: 0.05651235580444336\n",
      "Epoch 1: iteration 2116/2501 train_loss: 0.657133936882019 time_taken: 0.05657029151916504\n",
      "Epoch 1: iteration 2117/2501 train_loss: 0.6571270227432251 time_taken: 0.056604862213134766\n",
      "Epoch 1: iteration 2118/2501 train_loss: 0.6571168303489685 time_taken: 0.056305646896362305\n",
      "Epoch 1: iteration 2119/2501 train_loss: 0.6571052074432373 time_taken: 0.05666947364807129\n",
      "Epoch 1: iteration 2120/2501 train_loss: 0.6571019291877747 time_taken: 0.05587005615234375\n",
      "Epoch 1: iteration 2121/2501 train_loss: 0.6571021676063538 time_taken: 0.05649924278259277\n",
      "Epoch 1: iteration 2122/2501 train_loss: 0.6571040749549866 time_taken: 0.056040048599243164\n",
      "Epoch 1: iteration 2123/2501 train_loss: 0.6571059226989746 time_taken: 0.0558476448059082\n",
      "Epoch 1: iteration 2124/2501 train_loss: 0.6571078896522522 time_taken: 0.055916786193847656\n",
      "Epoch 1: iteration 2125/2501 train_loss: 0.6571108102798462 time_taken: 0.0557708740234375\n",
      "Epoch 1: iteration 2126/2501 train_loss: 0.6571199893951416 time_taken: 0.05623459815979004\n",
      "Epoch 1: iteration 2127/2501 train_loss: 0.657124400138855 time_taken: 0.05625605583190918\n",
      "Epoch 1: iteration 2128/2501 train_loss: 0.6571330428123474 time_taken: 0.05773425102233887\n",
      "Epoch 1: iteration 2129/2501 train_loss: 0.6571424603462219 time_taken: 0.056024789810180664\n",
      "Epoch 1: iteration 2130/2501 train_loss: 0.6571584343910217 time_taken: 0.05607199668884277\n",
      "Epoch 1: iteration 2131/2501 train_loss: 0.6571696996688843 time_taken: 0.05640220642089844\n",
      "Epoch 1: iteration 2132/2501 train_loss: 0.6571748852729797 time_taken: 0.056264638900756836\n",
      "Epoch 1: iteration 2133/2501 train_loss: 0.6571894288063049 time_taken: 0.056804656982421875\n",
      "Epoch 1: iteration 2134/2501 train_loss: 0.6572079062461853 time_taken: 0.056436777114868164\n",
      "Epoch 1: iteration 2135/2501 train_loss: 0.6572314500808716 time_taken: 0.05631709098815918\n",
      "Epoch 1: iteration 2136/2501 train_loss: 0.6572502255439758 time_taken: 0.05630016326904297\n",
      "Epoch 1: iteration 2137/2501 train_loss: 0.6572611331939697 time_taken: 0.05649113655090332\n",
      "Epoch 1: iteration 2138/2501 train_loss: 0.6572919487953186 time_taken: 0.056183815002441406\n",
      "Epoch 1: iteration 2139/2501 train_loss: 0.6573116779327393 time_taken: 0.05588030815124512\n",
      "Epoch 1: iteration 2140/2501 train_loss: 0.6573312282562256 time_taken: 0.056252479553222656\n",
      "Epoch 1: iteration 2141/2501 train_loss: 0.6573505997657776 time_taken: 0.05619359016418457\n",
      "Epoch 1: iteration 2142/2501 train_loss: 0.6573812961578369 time_taken: 0.05584311485290527\n",
      "Epoch 1: iteration 2143/2501 train_loss: 0.6574088931083679 time_taken: 0.056305885314941406\n",
      "Epoch 1: iteration 2144/2501 train_loss: 0.6574292778968811 time_taken: 0.0560152530670166\n",
      "Epoch 1: iteration 2145/2501 train_loss: 0.6574463248252869 time_taken: 0.055938005447387695\n",
      "Epoch 1: iteration 2146/2501 train_loss: 0.6574663519859314 time_taken: 0.056427955627441406\n",
      "Epoch 1: iteration 2147/2501 train_loss: 0.6574748754501343 time_taken: 0.056119680404663086\n",
      "Epoch 1: iteration 2148/2501 train_loss: 0.6574910879135132 time_taken: 0.05613374710083008\n",
      "Epoch 1: iteration 2149/2501 train_loss: 0.6575085520744324 time_taken: 0.055871009826660156\n",
      "Epoch 1: iteration 2150/2501 train_loss: 0.6575199961662292 time_taken: 0.05572962760925293\n",
      "Epoch 1: iteration 2151/2501 train_loss: 0.6575285196304321 time_taken: 0.05621767044067383\n",
      "Epoch 1: iteration 2152/2501 train_loss: 0.6575355529785156 time_taken: 0.05628848075866699\n",
      "Epoch 1: iteration 2153/2501 train_loss: 0.6575392484664917 time_taken: 0.05610299110412598\n",
      "Epoch 1: iteration 2154/2501 train_loss: 0.6575407385826111 time_taken: 0.05649971961975098\n",
      "Epoch 1: iteration 2155/2501 train_loss: 0.6575445532798767 time_taken: 0.05644559860229492\n",
      "Epoch 1: iteration 2156/2501 train_loss: 0.6575434803962708 time_taken: 0.05683445930480957\n",
      "Epoch 1: iteration 2157/2501 train_loss: 0.6575391888618469 time_taken: 0.05610370635986328\n",
      "Epoch 1: iteration 2158/2501 train_loss: 0.657543420791626 time_taken: 0.056012630462646484\n",
      "Epoch 1: iteration 2159/2501 train_loss: 0.6575443148612976 time_taken: 0.055884361267089844\n",
      "Epoch 1: iteration 2160/2501 train_loss: 0.6575473546981812 time_taken: 0.05601906776428223\n",
      "Epoch 1: iteration 2161/2501 train_loss: 0.6575473546981812 time_taken: 0.056265830993652344\n",
      "Epoch 1: iteration 2162/2501 train_loss: 0.6575574278831482 time_taken: 0.05595541000366211\n",
      "Epoch 1: iteration 2163/2501 train_loss: 0.657565176486969 time_taken: 0.056396484375\n",
      "Epoch 1: iteration 2164/2501 train_loss: 0.6575659513473511 time_taken: 0.056441307067871094\n",
      "Epoch 1: iteration 2165/2501 train_loss: 0.657556414604187 time_taken: 0.05633258819580078\n",
      "Epoch 1: iteration 2166/2501 train_loss: 0.6575607657432556 time_taken: 0.05623912811279297\n",
      "Epoch 1: iteration 2167/2501 train_loss: 0.6575705409049988 time_taken: 0.05573606491088867\n",
      "Epoch 1: iteration 2168/2501 train_loss: 0.6575729846954346 time_taken: 0.055628061294555664\n",
      "Epoch 1: iteration 2169/2501 train_loss: 0.6575720906257629 time_taken: 0.061528682708740234\n",
      "Epoch 1: iteration 2170/2501 train_loss: 0.6575760841369629 time_taken: 0.05617237091064453\n",
      "Epoch 1: iteration 2171/2501 train_loss: 0.6575637459754944 time_taken: 0.05585837364196777\n",
      "Epoch 1: iteration 2172/2501 train_loss: 0.6575592160224915 time_taken: 0.0563201904296875\n",
      "Epoch 1: iteration 2173/2501 train_loss: 0.6575454473495483 time_taken: 0.05625557899475098\n",
      "Epoch 1: iteration 2174/2501 train_loss: 0.6575387716293335 time_taken: 0.05655074119567871\n",
      "Epoch 1: iteration 2175/2501 train_loss: 0.6575190424919128 time_taken: 0.05699658393859863\n",
      "Epoch 1: iteration 2176/2501 train_loss: 0.6574870944023132 time_taken: 0.056862592697143555\n",
      "Epoch 1: iteration 2177/2501 train_loss: 0.6574711799621582 time_taken: 0.05769085884094238\n",
      "Epoch 1: iteration 2178/2501 train_loss: 0.6574441194534302 time_taken: 0.05789804458618164\n",
      "Epoch 1: iteration 2179/2501 train_loss: 0.65742027759552 time_taken: 0.05712604522705078\n",
      "Epoch 1: iteration 2180/2501 train_loss: 0.6573925018310547 time_taken: 0.05610942840576172\n",
      "Epoch 1: iteration 2181/2501 train_loss: 0.6573619246482849 time_taken: 0.056417226791381836\n",
      "Epoch 1: iteration 2182/2501 train_loss: 0.6573365330696106 time_taken: 0.07276010513305664\n",
      "Epoch 1: iteration 2183/2501 train_loss: 0.6573134064674377 time_taken: 0.07153677940368652\n",
      "Epoch 1: iteration 2184/2501 train_loss: 0.6572921872138977 time_taken: 0.06398248672485352\n",
      "Epoch 1: iteration 2185/2501 train_loss: 0.6572836637496948 time_taken: 0.05604887008666992\n",
      "Epoch 1: iteration 2186/2501 train_loss: 0.6572695970535278 time_taken: 0.05707907676696777\n",
      "Epoch 1: iteration 2187/2501 train_loss: 0.6572666168212891 time_taken: 0.05663919448852539\n",
      "Epoch 1: iteration 2188/2501 train_loss: 0.6572602987289429 time_taken: 0.0568852424621582\n",
      "Epoch 1: iteration 2189/2501 train_loss: 0.6572505831718445 time_taken: 0.056296348571777344\n",
      "Epoch 1: iteration 2190/2501 train_loss: 0.657229483127594 time_taken: 0.05727815628051758\n",
      "Epoch 1: iteration 2191/2501 train_loss: 0.6572077870368958 time_taken: 0.05677056312561035\n",
      "Epoch 1: iteration 2192/2501 train_loss: 0.657178521156311 time_taken: 0.05651378631591797\n",
      "Epoch 1: iteration 2193/2501 train_loss: 0.6571402549743652 time_taken: 0.056447744369506836\n",
      "Epoch 1: iteration 2194/2501 train_loss: 0.657095193862915 time_taken: 0.05709433555603027\n",
      "Epoch 1: iteration 2195/2501 train_loss: 0.657046377658844 time_taken: 0.05700969696044922\n",
      "Epoch 1: iteration 2196/2501 train_loss: 0.6569907665252686 time_taken: 0.05690574645996094\n",
      "Epoch 1: iteration 2197/2501 train_loss: 0.6569344401359558 time_taken: 0.0564267635345459\n",
      "Epoch 1: iteration 2198/2501 train_loss: 0.6568807363510132 time_taken: 0.05739116668701172\n",
      "Epoch 1: iteration 2199/2501 train_loss: 0.6568228602409363 time_taken: 0.057558536529541016\n",
      "Epoch 1: iteration 2200/2501 train_loss: 0.6567570567131042 time_taken: 0.0567927360534668\n",
      "Epoch 1: iteration 2201/2501 train_loss: 0.6566861867904663 time_taken: 0.05636000633239746\n",
      "Epoch 1: iteration 2202/2501 train_loss: 0.6566175818443298 time_taken: 0.05661582946777344\n",
      "Epoch 1: iteration 2203/2501 train_loss: 0.6565514802932739 time_taken: 0.05628681182861328\n",
      "Epoch 1: iteration 2204/2501 train_loss: 0.6564910411834717 time_taken: 0.056380510330200195\n",
      "Epoch 1: iteration 2205/2501 train_loss: 0.6564321517944336 time_taken: 0.057082414627075195\n",
      "Epoch 1: iteration 2206/2501 train_loss: 0.6563822627067566 time_taken: 0.05648970603942871\n",
      "Epoch 1: iteration 2207/2501 train_loss: 0.6563376188278198 time_taken: 0.05626058578491211\n",
      "Epoch 1: iteration 2208/2501 train_loss: 0.656286895275116 time_taken: 0.05637216567993164\n",
      "Epoch 1: iteration 2209/2501 train_loss: 0.6562524437904358 time_taken: 0.056304931640625\n",
      "Epoch 1: iteration 2210/2501 train_loss: 0.6562153100967407 time_taken: 0.06952166557312012\n",
      "Epoch 1: iteration 2211/2501 train_loss: 0.6561847925186157 time_taken: 0.05709552764892578\n",
      "Epoch 1: iteration 2212/2501 train_loss: 0.6561616063117981 time_taken: 0.056291818618774414\n",
      "Epoch 1: iteration 2213/2501 train_loss: 0.6561614871025085 time_taken: 0.056520700454711914\n",
      "Epoch 1: iteration 2214/2501 train_loss: 0.6561368107795715 time_taken: 0.056423187255859375\n",
      "Epoch 1: iteration 2215/2501 train_loss: 0.6561350226402283 time_taken: 0.05649447441101074\n",
      "Epoch 1: iteration 2216/2501 train_loss: 0.6561307907104492 time_taken: 0.05632376670837402\n",
      "Epoch 1: iteration 2217/2501 train_loss: 0.6561269760131836 time_taken: 0.0565190315246582\n",
      "Epoch 1: iteration 2218/2501 train_loss: 0.6561264991760254 time_taken: 0.05655097961425781\n",
      "Epoch 1: iteration 2219/2501 train_loss: 0.6561375856399536 time_taken: 0.057053565979003906\n",
      "Epoch 1: iteration 2220/2501 train_loss: 0.6561536192893982 time_taken: 0.05732846260070801\n",
      "Epoch 1: iteration 2221/2501 train_loss: 0.6561605930328369 time_taken: 0.05724954605102539\n",
      "Epoch 1: iteration 2222/2501 train_loss: 0.6561647653579712 time_taken: 0.05687665939331055\n",
      "Epoch 1: iteration 2223/2501 train_loss: 0.6561837196350098 time_taken: 0.056996822357177734\n",
      "Epoch 1: iteration 2224/2501 train_loss: 0.6562035083770752 time_taken: 0.0573580265045166\n",
      "Epoch 1: iteration 2225/2501 train_loss: 0.656222939491272 time_taken: 0.056551456451416016\n",
      "Epoch 1: iteration 2226/2501 train_loss: 0.6562408804893494 time_taken: 0.05737757682800293\n",
      "Epoch 1: iteration 2227/2501 train_loss: 0.6562634110450745 time_taken: 0.05717206001281738\n",
      "Epoch 1: iteration 2228/2501 train_loss: 0.6562830209732056 time_taken: 0.05647587776184082\n",
      "Epoch 1: iteration 2229/2501 train_loss: 0.6562865376472473 time_taken: 0.05641055107116699\n",
      "Epoch 1: iteration 2230/2501 train_loss: 0.6562949419021606 time_taken: 0.057024478912353516\n",
      "Epoch 1: iteration 2231/2501 train_loss: 0.6563194990158081 time_taken: 0.05688333511352539\n",
      "Epoch 1: iteration 2232/2501 train_loss: 0.6563387513160706 time_taken: 0.056705474853515625\n",
      "Epoch 1: iteration 2233/2501 train_loss: 0.6563571095466614 time_taken: 0.05706357955932617\n",
      "Epoch 1: iteration 2234/2501 train_loss: 0.6563825011253357 time_taken: 0.05621480941772461\n",
      "Epoch 1: iteration 2235/2501 train_loss: 0.6563982963562012 time_taken: 0.0568845272064209\n",
      "Epoch 1: iteration 2236/2501 train_loss: 0.6564196348190308 time_taken: 0.057312726974487305\n",
      "Epoch 1: iteration 2237/2501 train_loss: 0.6564420461654663 time_taken: 0.05651140213012695\n",
      "Epoch 1: iteration 2238/2501 train_loss: 0.6564658880233765 time_taken: 0.057015180587768555\n",
      "Epoch 1: iteration 2239/2501 train_loss: 0.6565011739730835 time_taken: 0.056450843811035156\n",
      "Epoch 1: iteration 2240/2501 train_loss: 0.6565305590629578 time_taken: 0.0561981201171875\n",
      "Epoch 1: iteration 2241/2501 train_loss: 0.6565640568733215 time_taken: 0.05734753608703613\n",
      "Epoch 1: iteration 2242/2501 train_loss: 0.6566032767295837 time_taken: 0.05667877197265625\n",
      "Epoch 1: iteration 2243/2501 train_loss: 0.6566406488418579 time_taken: 0.05586957931518555\n",
      "Epoch 1: iteration 2244/2501 train_loss: 0.6566684246063232 time_taken: 0.056078195571899414\n",
      "Epoch 1: iteration 2245/2501 train_loss: 0.6566866040229797 time_taken: 0.09415197372436523\n",
      "Epoch 1: iteration 2246/2501 train_loss: 0.6567094922065735 time_taken: 0.056197404861450195\n",
      "Epoch 1: iteration 2247/2501 train_loss: 0.6567248106002808 time_taken: 0.060302019119262695\n",
      "Epoch 1: iteration 2248/2501 train_loss: 0.656757116317749 time_taken: 0.05656075477600098\n",
      "Epoch 1: iteration 2249/2501 train_loss: 0.6567975878715515 time_taken: 0.05675029754638672\n",
      "Epoch 1: iteration 2250/2501 train_loss: 0.6568375825881958 time_taken: 0.05730462074279785\n",
      "Epoch 1: iteration 2251/2501 train_loss: 0.6568748950958252 time_taken: 0.05698037147521973\n",
      "Epoch 1: iteration 2252/2501 train_loss: 0.6569105982780457 time_taken: 0.0569300651550293\n",
      "Epoch 1: iteration 2253/2501 train_loss: 0.6569496989250183 time_taken: 0.05678439140319824\n",
      "Epoch 1: iteration 2254/2501 train_loss: 0.6569790244102478 time_taken: 0.05651378631591797\n",
      "Epoch 1: iteration 2255/2501 train_loss: 0.6570093631744385 time_taken: 0.0563962459564209\n",
      "Epoch 1: iteration 2256/2501 train_loss: 0.6570326685905457 time_taken: 0.05673551559448242\n",
      "Epoch 1: iteration 2257/2501 train_loss: 0.6570577025413513 time_taken: 0.0570223331451416\n",
      "Epoch 1: iteration 2258/2501 train_loss: 0.657079815864563 time_taken: 0.05604910850524902\n",
      "Epoch 1: iteration 2259/2501 train_loss: 0.6570925116539001 time_taken: 0.056481361389160156\n",
      "Epoch 1: iteration 2260/2501 train_loss: 0.6571070551872253 time_taken: 0.05640459060668945\n",
      "Epoch 1: iteration 2261/2501 train_loss: 0.6571217775344849 time_taken: 0.05672645568847656\n",
      "Epoch 1: iteration 2262/2501 train_loss: 0.6571345925331116 time_taken: 0.056491851806640625\n",
      "Epoch 1: iteration 2263/2501 train_loss: 0.6571453213691711 time_taken: 0.055930137634277344\n",
      "Epoch 1: iteration 2264/2501 train_loss: 0.6571483016014099 time_taken: 0.05634164810180664\n",
      "Epoch 1: iteration 2265/2501 train_loss: 0.6571604013442993 time_taken: 0.0562894344329834\n",
      "Epoch 1: iteration 2266/2501 train_loss: 0.6571613550186157 time_taken: 0.056429147720336914\n",
      "Epoch 1: iteration 2267/2501 train_loss: 0.6571696400642395 time_taken: 0.05629611015319824\n",
      "Epoch 1: iteration 2268/2501 train_loss: 0.6571811437606812 time_taken: 0.05755901336669922\n",
      "Epoch 1: iteration 2269/2501 train_loss: 0.6571782827377319 time_taken: 0.05664539337158203\n",
      "Epoch 1: iteration 2270/2501 train_loss: 0.6571825742721558 time_taken: 0.057242631912231445\n",
      "Epoch 1: iteration 2271/2501 train_loss: 0.6571868062019348 time_taken: 0.05653882026672363\n",
      "Epoch 1: iteration 2272/2501 train_loss: 0.6571915745735168 time_taken: 0.0565493106842041\n",
      "Epoch 1: iteration 2273/2501 train_loss: 0.6571940183639526 time_taken: 0.05674338340759277\n",
      "Epoch 1: iteration 2274/2501 train_loss: 0.657195508480072 time_taken: 0.056383609771728516\n",
      "Epoch 1: iteration 2275/2501 train_loss: 0.657200038433075 time_taken: 0.05618739128112793\n",
      "Epoch 1: iteration 2276/2501 train_loss: 0.6572026014328003 time_taken: 0.05671358108520508\n",
      "Epoch 1: iteration 2277/2501 train_loss: 0.6572063565254211 time_taken: 0.05662226676940918\n",
      "Epoch 1: iteration 2278/2501 train_loss: 0.6572130918502808 time_taken: 0.056989431381225586\n",
      "Epoch 1: iteration 2279/2501 train_loss: 0.657213032245636 time_taken: 0.0567479133605957\n",
      "Epoch 1: iteration 2280/2501 train_loss: 0.6572211384773254 time_taken: 0.05706644058227539\n",
      "Epoch 1: iteration 2281/2501 train_loss: 0.6572374105453491 time_taken: 0.056728363037109375\n",
      "Epoch 1: iteration 2282/2501 train_loss: 0.6572375297546387 time_taken: 0.05672907829284668\n",
      "Epoch 1: iteration 2283/2501 train_loss: 0.657244861125946 time_taken: 0.05681180953979492\n",
      "Epoch 1: iteration 2284/2501 train_loss: 0.6572468876838684 time_taken: 0.05730605125427246\n",
      "Epoch 1: iteration 2285/2501 train_loss: 0.6572579145431519 time_taken: 0.05647110939025879\n",
      "Epoch 1: iteration 2286/2501 train_loss: 0.6572743058204651 time_taken: 0.05668210983276367\n",
      "Epoch 1: iteration 2287/2501 train_loss: 0.6572903990745544 time_taken: 0.0562744140625\n",
      "Epoch 1: iteration 2288/2501 train_loss: 0.6573004126548767 time_taken: 0.05688762664794922\n",
      "Epoch 1: iteration 2289/2501 train_loss: 0.6573246717453003 time_taken: 0.05640220642089844\n",
      "Epoch 1: iteration 2290/2501 train_loss: 0.6573438048362732 time_taken: 0.05633544921875\n",
      "Epoch 1: iteration 2291/2501 train_loss: 0.6573681235313416 time_taken: 0.05631732940673828\n",
      "Epoch 1: iteration 2292/2501 train_loss: 0.6574090719223022 time_taken: 0.056807518005371094\n",
      "Epoch 1: iteration 2293/2501 train_loss: 0.6574440002441406 time_taken: 0.05652952194213867\n",
      "Epoch 1: iteration 2294/2501 train_loss: 0.6574583649635315 time_taken: 0.05684399604797363\n",
      "Epoch 1: iteration 2295/2501 train_loss: 0.6574811935424805 time_taken: 0.05631899833679199\n",
      "Epoch 1: iteration 2296/2501 train_loss: 0.6575104594230652 time_taken: 0.05727648735046387\n",
      "Epoch 1: iteration 2297/2501 train_loss: 0.6575366258621216 time_taken: 0.05663275718688965\n",
      "Epoch 1: iteration 2298/2501 train_loss: 0.6575626730918884 time_taken: 0.05643939971923828\n",
      "Epoch 1: iteration 2299/2501 train_loss: 0.6575803160667419 time_taken: 0.05646800994873047\n",
      "Epoch 1: iteration 2300/2501 train_loss: 0.657593846321106 time_taken: 0.05646920204162598\n",
      "Epoch 1: iteration 2301/2501 train_loss: 0.6576118469238281 time_taken: 0.05634331703186035\n",
      "Epoch 1: iteration 2302/2501 train_loss: 0.6576326489448547 time_taken: 0.05713939666748047\n",
      "Epoch 1: iteration 2303/2501 train_loss: 0.6576427221298218 time_taken: 0.05709433555603027\n",
      "Epoch 1: iteration 2304/2501 train_loss: 0.6576595306396484 time_taken: 0.056113481521606445\n",
      "Epoch 1: iteration 2305/2501 train_loss: 0.6576687097549438 time_taken: 0.05673336982727051\n",
      "Epoch 1: iteration 2306/2501 train_loss: 0.6576830148696899 time_taken: 0.056997060775756836\n",
      "Epoch 1: iteration 2307/2501 train_loss: 0.6576955318450928 time_taken: 0.05713295936584473\n",
      "Epoch 1: iteration 2308/2501 train_loss: 0.6577016711235046 time_taken: 0.056832313537597656\n",
      "Epoch 1: iteration 2309/2501 train_loss: 0.6577222943305969 time_taken: 0.05670952796936035\n",
      "Epoch 1: iteration 2310/2501 train_loss: 0.6577373147010803 time_taken: 0.05632281303405762\n",
      "Epoch 1: iteration 2311/2501 train_loss: 0.6577566862106323 time_taken: 0.05752086639404297\n",
      "Epoch 1: iteration 2312/2501 train_loss: 0.6577745079994202 time_taken: 0.05711984634399414\n",
      "Epoch 1: iteration 2313/2501 train_loss: 0.6577885150909424 time_taken: 0.05669736862182617\n",
      "Epoch 1: iteration 2314/2501 train_loss: 0.6578058004379272 time_taken: 0.05676770210266113\n",
      "Epoch 1: iteration 2315/2501 train_loss: 0.6578189134597778 time_taken: 0.05673050880432129\n",
      "Epoch 1: iteration 2316/2501 train_loss: 0.657821536064148 time_taken: 0.05685257911682129\n",
      "Epoch 1: iteration 2317/2501 train_loss: 0.6578390002250671 time_taken: 0.05621337890625\n",
      "Epoch 1: iteration 2318/2501 train_loss: 0.6578637957572937 time_taken: 0.05703568458557129\n",
      "Epoch 1: iteration 2319/2501 train_loss: 0.6578823328018188 time_taken: 0.0571436882019043\n",
      "Epoch 1: iteration 2320/2501 train_loss: 0.6579079031944275 time_taken: 0.057942867279052734\n",
      "Epoch 1: iteration 2321/2501 train_loss: 0.6579272150993347 time_taken: 0.056585073471069336\n",
      "Epoch 1: iteration 2322/2501 train_loss: 0.6579420566558838 time_taken: 0.05982065200805664\n",
      "Epoch 1: iteration 2323/2501 train_loss: 0.6579490900039673 time_taken: 0.0565791130065918\n",
      "Epoch 1: iteration 2324/2501 train_loss: 0.6579492688179016 time_taken: 0.0563197135925293\n",
      "Epoch 1: iteration 2325/2501 train_loss: 0.6579689383506775 time_taken: 0.05714821815490723\n",
      "Epoch 1: iteration 2326/2501 train_loss: 0.6580014228820801 time_taken: 0.056195735931396484\n",
      "Epoch 1: iteration 2327/2501 train_loss: 0.6580415964126587 time_taken: 0.05705595016479492\n",
      "Epoch 1: iteration 2328/2501 train_loss: 0.6580803990364075 time_taken: 0.05695939064025879\n",
      "Epoch 1: iteration 2329/2501 train_loss: 0.6581280827522278 time_taken: 0.056603431701660156\n",
      "Epoch 1: iteration 2330/2501 train_loss: 0.6581811904907227 time_taken: 0.05724191665649414\n",
      "Epoch 1: iteration 2331/2501 train_loss: 0.6582358479499817 time_taken: 0.05634593963623047\n",
      "Epoch 1: iteration 2332/2501 train_loss: 0.6582861542701721 time_taken: 0.08020758628845215\n",
      "Epoch 1: iteration 2333/2501 train_loss: 0.658351480960846 time_taken: 0.060875654220581055\n",
      "Epoch 1: iteration 2334/2501 train_loss: 0.6584123373031616 time_taken: 0.05661201477050781\n",
      "Epoch 1: iteration 2335/2501 train_loss: 0.6584584712982178 time_taken: 0.05635523796081543\n",
      "Epoch 1: iteration 2336/2501 train_loss: 0.6585081219673157 time_taken: 0.057064056396484375\n",
      "Epoch 1: iteration 2337/2501 train_loss: 0.6585508584976196 time_taken: 0.056199073791503906\n",
      "Epoch 1: iteration 2338/2501 train_loss: 0.6585971713066101 time_taken: 0.05692172050476074\n",
      "Epoch 1: iteration 2339/2501 train_loss: 0.6586207747459412 time_taken: 0.05658435821533203\n",
      "Epoch 1: iteration 2340/2501 train_loss: 0.6586517095565796 time_taken: 0.0569307804107666\n",
      "Epoch 1: iteration 2341/2501 train_loss: 0.6586714386940002 time_taken: 0.05672621726989746\n",
      "Epoch 1: iteration 2342/2501 train_loss: 0.6586936712265015 time_taken: 0.05771231651306152\n",
      "Epoch 1: iteration 2343/2501 train_loss: 0.6587175130844116 time_taken: 0.0566859245300293\n",
      "Epoch 1: iteration 2344/2501 train_loss: 0.6587230563163757 time_taken: 0.0565800666809082\n",
      "Epoch 1: iteration 2345/2501 train_loss: 0.6587323546409607 time_taken: 0.05675196647644043\n",
      "Epoch 1: iteration 2346/2501 train_loss: 0.6587328314781189 time_taken: 0.05659127235412598\n",
      "Epoch 1: iteration 2347/2501 train_loss: 0.6587358713150024 time_taken: 0.056409597396850586\n",
      "Epoch 1: iteration 2348/2501 train_loss: 0.6587336659431458 time_taken: 0.0568385124206543\n",
      "Epoch 1: iteration 2349/2501 train_loss: 0.6587320566177368 time_taken: 0.05731201171875\n",
      "Epoch 1: iteration 2350/2501 train_loss: 0.658719539642334 time_taken: 0.05668044090270996\n",
      "Epoch 1: iteration 2351/2501 train_loss: 0.6587064862251282 time_taken: 0.06125020980834961\n",
      "Epoch 1: iteration 2352/2501 train_loss: 0.6586917042732239 time_taken: 0.056368112564086914\n",
      "Epoch 1: iteration 2353/2501 train_loss: 0.6586630344390869 time_taken: 0.05654025077819824\n",
      "Epoch 1: iteration 2354/2501 train_loss: 0.6586393713951111 time_taken: 0.057039499282836914\n",
      "Epoch 1: iteration 2355/2501 train_loss: 0.6586077809333801 time_taken: 0.05693483352661133\n",
      "Epoch 1: iteration 2356/2501 train_loss: 0.6585726737976074 time_taken: 0.05679941177368164\n",
      "Epoch 1: iteration 2357/2501 train_loss: 0.6585356593132019 time_taken: 0.05760908126831055\n",
      "Epoch 1: iteration 2358/2501 train_loss: 0.6584884524345398 time_taken: 0.05666470527648926\n",
      "Epoch 1: iteration 2359/2501 train_loss: 0.6584370732307434 time_taken: 0.05652737617492676\n",
      "Epoch 1: iteration 2360/2501 train_loss: 0.6583754420280457 time_taken: 0.05744171142578125\n",
      "Epoch 1: iteration 2361/2501 train_loss: 0.6583236455917358 time_taken: 0.056450843811035156\n",
      "Epoch 1: iteration 2362/2501 train_loss: 0.6582713723182678 time_taken: 0.056362152099609375\n",
      "Epoch 1: iteration 2363/2501 train_loss: 0.6582162380218506 time_taken: 0.056241512298583984\n",
      "Epoch 1: iteration 2364/2501 train_loss: 0.6581677198410034 time_taken: 0.05639505386352539\n",
      "Epoch 1: iteration 2365/2501 train_loss: 0.6581190824508667 time_taken: 0.056302785873413086\n",
      "Epoch 1: iteration 2366/2501 train_loss: 0.6580689549446106 time_taken: 0.05664491653442383\n",
      "Epoch 1: iteration 2367/2501 train_loss: 0.6580227613449097 time_taken: 0.05666613578796387\n",
      "Epoch 1: iteration 2368/2501 train_loss: 0.657974898815155 time_taken: 0.05719280242919922\n",
      "Epoch 1: iteration 2369/2501 train_loss: 0.6579262018203735 time_taken: 0.056305885314941406\n",
      "Epoch 1: iteration 2370/2501 train_loss: 0.6578751802444458 time_taken: 0.05662417411804199\n",
      "Epoch 1: iteration 2371/2501 train_loss: 0.6578287482261658 time_taken: 0.058126211166381836\n",
      "Epoch 1: iteration 2372/2501 train_loss: 0.6577867269515991 time_taken: 0.057253122329711914\n",
      "Epoch 1: iteration 2373/2501 train_loss: 0.6577404737472534 time_taken: 0.05638265609741211\n",
      "Epoch 1: iteration 2374/2501 train_loss: 0.6577012538909912 time_taken: 0.05640006065368652\n",
      "Epoch 1: iteration 2375/2501 train_loss: 0.6576620936393738 time_taken: 0.056546926498413086\n",
      "Epoch 1: iteration 2376/2501 train_loss: 0.6576154828071594 time_taken: 0.05621838569641113\n",
      "Epoch 1: iteration 2377/2501 train_loss: 0.6575726270675659 time_taken: 0.0565798282623291\n",
      "Epoch 1: iteration 2378/2501 train_loss: 0.657538115978241 time_taken: 0.05673360824584961\n",
      "Epoch 1: iteration 2379/2501 train_loss: 0.6575024724006653 time_taken: 0.05640578269958496\n",
      "Epoch 1: iteration 2380/2501 train_loss: 0.657470166683197 time_taken: 0.061583518981933594\n",
      "Epoch 1: iteration 2381/2501 train_loss: 0.6574419140815735 time_taken: 0.05670595169067383\n",
      "Epoch 1: iteration 2382/2501 train_loss: 0.6574093103408813 time_taken: 0.05662941932678223\n",
      "Epoch 1: iteration 2383/2501 train_loss: 0.6573756337165833 time_taken: 0.05716514587402344\n",
      "Epoch 1: iteration 2384/2501 train_loss: 0.6573574542999268 time_taken: 0.0569453239440918\n",
      "Epoch 1: iteration 2385/2501 train_loss: 0.6573483347892761 time_taken: 0.0567929744720459\n",
      "Epoch 1: iteration 2386/2501 train_loss: 0.6573355197906494 time_taken: 0.05744671821594238\n",
      "Epoch 1: iteration 2387/2501 train_loss: 0.6573307514190674 time_taken: 0.05700182914733887\n",
      "Epoch 1: iteration 2388/2501 train_loss: 0.6573233008384705 time_taken: 0.0569310188293457\n",
      "Epoch 1: iteration 2389/2501 train_loss: 0.6573359370231628 time_taken: 0.05726265907287598\n",
      "Epoch 1: iteration 2390/2501 train_loss: 0.6573410034179688 time_taken: 0.05638551712036133\n",
      "Epoch 1: iteration 2391/2501 train_loss: 0.6573336124420166 time_taken: 0.05642366409301758\n",
      "Epoch 1: iteration 2392/2501 train_loss: 0.6573311686515808 time_taken: 0.05640530586242676\n",
      "Epoch 1: iteration 2393/2501 train_loss: 0.6573297381401062 time_taken: 0.05672049522399902\n",
      "Epoch 1: iteration 2394/2501 train_loss: 0.6573394536972046 time_taken: 0.05670952796936035\n",
      "Epoch 1: iteration 2395/2501 train_loss: 0.6573508977890015 time_taken: 0.05686545372009277\n",
      "Epoch 1: iteration 2396/2501 train_loss: 0.6573697924613953 time_taken: 0.056888580322265625\n",
      "Epoch 1: iteration 2397/2501 train_loss: 0.6573840379714966 time_taken: 0.05626416206359863\n",
      "Epoch 1: iteration 2398/2501 train_loss: 0.6574035286903381 time_taken: 0.056494951248168945\n",
      "Epoch 1: iteration 2399/2501 train_loss: 0.6574042439460754 time_taken: 0.05664563179016113\n",
      "Epoch 1: iteration 2400/2501 train_loss: 0.6574114561080933 time_taken: 0.05655860900878906\n",
      "Epoch 1: iteration 2401/2501 train_loss: 0.657416582107544 time_taken: 0.056581974029541016\n",
      "Epoch 1: iteration 2402/2501 train_loss: 0.6574211716651917 time_taken: 0.05669879913330078\n",
      "Epoch 1: iteration 2403/2501 train_loss: 0.657417356967926 time_taken: 0.05673074722290039\n",
      "Epoch 1: iteration 2404/2501 train_loss: 0.6574244499206543 time_taken: 0.05716443061828613\n",
      "Epoch 1: iteration 2405/2501 train_loss: 0.6574239730834961 time_taken: 0.05661320686340332\n",
      "Epoch 1: iteration 2406/2501 train_loss: 0.6574199795722961 time_taken: 0.05698370933532715\n",
      "Epoch 1: iteration 2407/2501 train_loss: 0.6574193835258484 time_taken: 0.056639671325683594\n",
      "Epoch 1: iteration 2408/2501 train_loss: 0.6574279069900513 time_taken: 0.05690336227416992\n",
      "Epoch 1: iteration 2409/2501 train_loss: 0.6574286222457886 time_taken: 0.08200550079345703\n",
      "Epoch 1: iteration 2410/2501 train_loss: 0.6574252247810364 time_taken: 0.0808858871459961\n",
      "Epoch 1: iteration 2411/2501 train_loss: 0.6574231386184692 time_taken: 0.055812835693359375\n",
      "Epoch 1: iteration 2412/2501 train_loss: 0.6574272513389587 time_taken: 0.05655980110168457\n",
      "Epoch 1: iteration 2413/2501 train_loss: 0.6574377417564392 time_taken: 0.05674290657043457\n",
      "Epoch 1: iteration 2414/2501 train_loss: 0.6574413776397705 time_taken: 0.056620121002197266\n",
      "Epoch 1: iteration 2415/2501 train_loss: 0.6574512720108032 time_taken: 0.056121110916137695\n",
      "Epoch 1: iteration 2416/2501 train_loss: 0.657454252243042 time_taken: 0.05643010139465332\n",
      "Epoch 1: iteration 2417/2501 train_loss: 0.6574621796607971 time_taken: 0.056290626525878906\n",
      "Epoch 1: iteration 2418/2501 train_loss: 0.6574612855911255 time_taken: 0.057184696197509766\n",
      "Epoch 1: iteration 2419/2501 train_loss: 0.6574670076370239 time_taken: 0.0560610294342041\n",
      "Epoch 1: iteration 2420/2501 train_loss: 0.657471776008606 time_taken: 0.0564875602722168\n",
      "Epoch 1: iteration 2421/2501 train_loss: 0.6574926376342773 time_taken: 0.056296348571777344\n",
      "Epoch 1: iteration 2422/2501 train_loss: 0.6575060486793518 time_taken: 0.056131601333618164\n",
      "Epoch 1: iteration 2423/2501 train_loss: 0.6575083136558533 time_taken: 0.05628681182861328\n",
      "Epoch 1: iteration 2424/2501 train_loss: 0.6575158834457397 time_taken: 0.0561223030090332\n",
      "Epoch 1: iteration 2425/2501 train_loss: 0.6575192213058472 time_taken: 0.05643725395202637\n",
      "Epoch 1: iteration 2426/2501 train_loss: 0.6575221419334412 time_taken: 0.05679821968078613\n",
      "Epoch 1: iteration 2427/2501 train_loss: 0.6575297117233276 time_taken: 0.056382179260253906\n",
      "Epoch 1: iteration 2428/2501 train_loss: 0.6575402617454529 time_taken: 0.07644486427307129\n",
      "Epoch 1: iteration 2429/2501 train_loss: 0.6575491428375244 time_taken: 0.06838703155517578\n",
      "Epoch 1: iteration 2430/2501 train_loss: 0.6575596928596497 time_taken: 0.05596327781677246\n",
      "Epoch 1: iteration 2431/2501 train_loss: 0.657570481300354 time_taken: 0.05843710899353027\n",
      "Epoch 1: iteration 2432/2501 train_loss: 0.6575809121131897 time_taken: 0.05590057373046875\n",
      "Epoch 1: iteration 2433/2501 train_loss: 0.6575984358787537 time_taken: 0.055792808532714844\n",
      "Epoch 1: iteration 2434/2501 train_loss: 0.6576076745986938 time_taken: 0.05645895004272461\n",
      "Epoch 1: iteration 2435/2501 train_loss: 0.6576266884803772 time_taken: 0.056021690368652344\n",
      "Epoch 1: iteration 2436/2501 train_loss: 0.6576427817344666 time_taken: 0.05630993843078613\n",
      "Epoch 1: iteration 2437/2501 train_loss: 0.6576683521270752 time_taken: 0.05637860298156738\n",
      "Epoch 1: iteration 2438/2501 train_loss: 0.6576778888702393 time_taken: 0.057908058166503906\n",
      "Epoch 1: iteration 2439/2501 train_loss: 0.6576891541481018 time_taken: 0.05692458152770996\n",
      "Epoch 1: iteration 2440/2501 train_loss: 0.6577089428901672 time_taken: 0.05733942985534668\n",
      "Epoch 1: iteration 2441/2501 train_loss: 0.657719075679779 time_taken: 0.05689501762390137\n",
      "Epoch 1: iteration 2442/2501 train_loss: 0.6577366590499878 time_taken: 0.05698227882385254\n",
      "Epoch 1: iteration 2443/2501 train_loss: 0.6577526330947876 time_taken: 0.0566868782043457\n",
      "Epoch 1: iteration 2444/2501 train_loss: 0.6577652096748352 time_taken: 0.05739712715148926\n",
      "Epoch 1: iteration 2445/2501 train_loss: 0.6577715277671814 time_taken: 0.05656838417053223\n",
      "Epoch 1: iteration 2446/2501 train_loss: 0.6577764749526978 time_taken: 0.05703854560852051\n",
      "Epoch 1: iteration 2447/2501 train_loss: 0.6577873826026917 time_taken: 0.056862831115722656\n",
      "Epoch 1: iteration 2448/2501 train_loss: 0.6577907800674438 time_taken: 0.05703020095825195\n",
      "Epoch 1: iteration 2449/2501 train_loss: 0.6577925682067871 time_taken: 0.056803226470947266\n",
      "Epoch 1: iteration 2450/2501 train_loss: 0.6577915549278259 time_taken: 0.05709505081176758\n",
      "Epoch 1: iteration 2451/2501 train_loss: 0.6577838063240051 time_taken: 0.05742001533508301\n",
      "Epoch 1: iteration 2452/2501 train_loss: 0.6577728986740112 time_taken: 0.05693674087524414\n",
      "Epoch 1: iteration 2453/2501 train_loss: 0.657755434513092 time_taken: 0.056938886642456055\n",
      "Epoch 1: iteration 2454/2501 train_loss: 0.6577447056770325 time_taken: 0.05683302879333496\n",
      "Epoch 1: iteration 2455/2501 train_loss: 0.6577209830284119 time_taken: 0.056868553161621094\n",
      "Epoch 1: iteration 2456/2501 train_loss: 0.65770423412323 time_taken: 0.05779743194580078\n",
      "Epoch 1: iteration 2457/2501 train_loss: 0.6576844453811646 time_taken: 0.05716586112976074\n",
      "Epoch 1: iteration 2458/2501 train_loss: 0.6576597690582275 time_taken: 0.05672407150268555\n",
      "Epoch 1: iteration 2459/2501 train_loss: 0.6576325297355652 time_taken: 0.056539297103881836\n",
      "Epoch 1: iteration 2460/2501 train_loss: 0.657606303691864 time_taken: 0.05617690086364746\n",
      "Epoch 1: iteration 2461/2501 train_loss: 0.6575750112533569 time_taken: 0.05776381492614746\n",
      "Epoch 1: iteration 2462/2501 train_loss: 0.657549262046814 time_taken: 0.05696988105773926\n",
      "Epoch 1: iteration 2463/2501 train_loss: 0.6575227975845337 time_taken: 0.056242942810058594\n",
      "Epoch 1: iteration 2464/2501 train_loss: 0.6575118899345398 time_taken: 0.05655336380004883\n",
      "Epoch 1: iteration 2465/2501 train_loss: 0.6574995517730713 time_taken: 0.05643010139465332\n",
      "Epoch 1: iteration 2466/2501 train_loss: 0.6574930548667908 time_taken: 0.07157421112060547\n",
      "Epoch 1: iteration 2467/2501 train_loss: 0.6575050950050354 time_taken: 0.06845450401306152\n",
      "Epoch 1: iteration 2468/2501 train_loss: 0.6574966311454773 time_taken: 0.056301116943359375\n",
      "Epoch 1: iteration 2469/2501 train_loss: 0.6575029492378235 time_taken: 0.05624556541442871\n",
      "Epoch 1: iteration 2470/2501 train_loss: 0.6575090885162354 time_taken: 0.0568239688873291\n",
      "Epoch 1: iteration 2471/2501 train_loss: 0.6575181484222412 time_taken: 0.05744504928588867\n",
      "Epoch 1: iteration 2472/2501 train_loss: 0.6575311422348022 time_taken: 0.056151628494262695\n",
      "Epoch 1: iteration 2473/2501 train_loss: 0.6575416922569275 time_taken: 0.05701756477355957\n",
      "Epoch 1: iteration 2474/2501 train_loss: 0.6575482487678528 time_taken: 0.057290077209472656\n",
      "Epoch 1: iteration 2475/2501 train_loss: 0.6575576663017273 time_taken: 0.05720210075378418\n",
      "Epoch 1: iteration 2476/2501 train_loss: 0.657573938369751 time_taken: 0.05659985542297363\n",
      "Epoch 1: iteration 2477/2501 train_loss: 0.6575883626937866 time_taken: 0.056658029556274414\n",
      "Epoch 1: iteration 2478/2501 train_loss: 0.6576098203659058 time_taken: 0.05666637420654297\n",
      "Epoch 1: iteration 2479/2501 train_loss: 0.6576333045959473 time_taken: 0.056360721588134766\n",
      "Epoch 1: iteration 2480/2501 train_loss: 0.6576612591743469 time_taken: 0.056273698806762695\n",
      "Epoch 1: iteration 2481/2501 train_loss: 0.6576912999153137 time_taken: 0.05623936653137207\n",
      "Epoch 1: iteration 2482/2501 train_loss: 0.6577188968658447 time_taken: 0.05702781677246094\n",
      "Epoch 1: iteration 2483/2501 train_loss: 0.6577416062355042 time_taken: 0.05659365653991699\n",
      "Epoch 1: iteration 2484/2501 train_loss: 0.6577766537666321 time_taken: 0.0564732551574707\n",
      "Epoch 1: iteration 2485/2501 train_loss: 0.6578241586685181 time_taken: 0.05651259422302246\n",
      "Epoch 1: iteration 2486/2501 train_loss: 0.6578772068023682 time_taken: 0.05650162696838379\n",
      "Epoch 1: iteration 2487/2501 train_loss: 0.6579378247261047 time_taken: 0.05646681785583496\n",
      "Epoch 1: iteration 2488/2501 train_loss: 0.6579945683479309 time_taken: 0.05599832534790039\n",
      "Epoch 1: iteration 2489/2501 train_loss: 0.6580390334129333 time_taken: 0.05603361129760742\n",
      "Epoch 1: iteration 2490/2501 train_loss: 0.6580585837364197 time_taken: 0.0562596321105957\n",
      "Epoch 1: iteration 2491/2501 train_loss: 0.6580815315246582 time_taken: 0.05595827102661133\n",
      "Epoch 1: iteration 2492/2501 train_loss: 0.6581154465675354 time_taken: 0.05587935447692871\n",
      "Epoch 1: iteration 2493/2501 train_loss: 0.6581477522850037 time_taken: 0.05602312088012695\n",
      "Epoch 1: iteration 2494/2501 train_loss: 0.6581764817237854 time_taken: 0.05596351623535156\n",
      "Epoch 1: iteration 2495/2501 train_loss: 0.6581962704658508 time_taken: 0.05586814880371094\n",
      "Epoch 1: iteration 2496/2501 train_loss: 0.658226490020752 time_taken: 0.055933475494384766\n",
      "Epoch 1: iteration 2497/2501 train_loss: 0.6582542657852173 time_taken: 0.05634927749633789\n",
      "Epoch 1: iteration 2498/2501 train_loss: 0.6582727432250977 time_taken: 0.05604863166809082\n",
      "Epoch 1: iteration 2499/2501 train_loss: 0.6583009958267212 time_taken: 0.056493520736694336\n",
      "Epoch 1: iteration 2500/2501 train_loss: 0.6583091020584106 time_taken: 0.05702805519104004\n",
      "Finished epoch 1 took 446.38027453422546\n",
      "Starting epoch 2/5\n",
      "Epoch 2: iteration 0/2501 train_loss: 0.7938722968101501 time_taken: 0.056444644927978516\n",
      "Epoch 2: iteration 1/2501 train_loss: 0.7322724461555481 time_taken: 0.05627846717834473\n",
      "Epoch 2: iteration 2/2501 train_loss: 0.7114967703819275 time_taken: 0.05652022361755371\n",
      "Epoch 2: iteration 3/2501 train_loss: 0.6802217960357666 time_taken: 0.057195186614990234\n",
      "Epoch 2: iteration 4/2501 train_loss: 0.6599064469337463 time_taken: 0.05658698081970215\n",
      "Epoch 2: iteration 5/2501 train_loss: 0.6415464282035828 time_taken: 0.05624890327453613\n",
      "Epoch 2: iteration 6/2501 train_loss: 0.626319408416748 time_taken: 0.0561521053314209\n",
      "Epoch 2: iteration 7/2501 train_loss: 0.6116663217544556 time_taken: 0.056354522705078125\n",
      "Epoch 2: iteration 8/2501 train_loss: 0.6001635193824768 time_taken: 0.05659604072570801\n",
      "Epoch 2: iteration 9/2501 train_loss: 0.5895060300827026 time_taken: 0.05643725395202637\n",
      "Epoch 2: iteration 10/2501 train_loss: 0.5802955031394958 time_taken: 0.05617833137512207\n",
      "Epoch 2: iteration 11/2501 train_loss: 0.5727952718734741 time_taken: 0.05601215362548828\n",
      "Epoch 2: iteration 12/2501 train_loss: 0.5675463080406189 time_taken: 0.056595563888549805\n",
      "Epoch 2: iteration 13/2501 train_loss: 0.5642520189285278 time_taken: 0.05613398551940918\n",
      "Epoch 2: iteration 14/2501 train_loss: 0.5621448755264282 time_taken: 0.05687689781188965\n",
      "Epoch 2: iteration 15/2501 train_loss: 0.5587353706359863 time_taken: 0.05698251724243164\n",
      "Epoch 2: iteration 16/2501 train_loss: 0.5566713213920593 time_taken: 0.05620145797729492\n",
      "Epoch 2: iteration 17/2501 train_loss: 0.5550107359886169 time_taken: 0.0562136173248291\n",
      "Epoch 2: iteration 18/2501 train_loss: 0.5540879964828491 time_taken: 0.05627608299255371\n",
      "Epoch 2: iteration 19/2501 train_loss: 0.5527076721191406 time_taken: 0.05657768249511719\n",
      "Epoch 2: iteration 20/2501 train_loss: 0.5518537163734436 time_taken: 0.05659055709838867\n",
      "Epoch 2: iteration 21/2501 train_loss: 0.5512945652008057 time_taken: 0.05624890327453613\n",
      "Epoch 2: iteration 22/2501 train_loss: 0.550392746925354 time_taken: 0.05654621124267578\n",
      "Epoch 2: iteration 23/2501 train_loss: 0.5496028661727905 time_taken: 0.057405948638916016\n",
      "Epoch 2: iteration 24/2501 train_loss: 0.5492432713508606 time_taken: 0.056794166564941406\n",
      "Epoch 2: iteration 25/2501 train_loss: 0.5488720536231995 time_taken: 0.05684232711791992\n",
      "Epoch 2: iteration 26/2501 train_loss: 0.5484658479690552 time_taken: 0.056606292724609375\n",
      "Epoch 2: iteration 27/2501 train_loss: 0.548047661781311 time_taken: 0.05665302276611328\n",
      "Epoch 2: iteration 28/2501 train_loss: 0.5472803711891174 time_taken: 0.05623626708984375\n",
      "Epoch 2: iteration 29/2501 train_loss: 0.5470468401908875 time_taken: 0.06497693061828613\n",
      "Epoch 2: iteration 30/2501 train_loss: 0.5469086170196533 time_taken: 0.056201934814453125\n",
      "Epoch 2: iteration 31/2501 train_loss: 0.5466090440750122 time_taken: 0.05618166923522949\n",
      "Epoch 2: iteration 32/2501 train_loss: 0.5463817715644836 time_taken: 0.05618691444396973\n",
      "Epoch 2: iteration 33/2501 train_loss: 0.5471203923225403 time_taken: 0.05624842643737793\n",
      "Epoch 2: iteration 34/2501 train_loss: 0.5481188893318176 time_taken: 0.05627083778381348\n",
      "Epoch 2: iteration 35/2501 train_loss: 0.5492075681686401 time_taken: 0.05677008628845215\n",
      "Epoch 2: iteration 36/2501 train_loss: 0.5500277876853943 time_taken: 0.05736875534057617\n",
      "Epoch 2: iteration 37/2501 train_loss: 0.550234317779541 time_taken: 0.05690574645996094\n",
      "Epoch 2: iteration 38/2501 train_loss: 0.5504534244537354 time_taken: 0.056255340576171875\n",
      "Epoch 2: iteration 39/2501 train_loss: 0.5505629777908325 time_taken: 0.05700850486755371\n",
      "Epoch 2: iteration 40/2501 train_loss: 0.5510720610618591 time_taken: 0.0571446418762207\n",
      "Epoch 2: iteration 41/2501 train_loss: 0.5513232350349426 time_taken: 0.056943416595458984\n",
      "Epoch 2: iteration 42/2501 train_loss: 0.551753580570221 time_taken: 0.05695295333862305\n",
      "Epoch 2: iteration 43/2501 train_loss: 0.5519871115684509 time_taken: 0.05736351013183594\n",
      "Epoch 2: iteration 44/2501 train_loss: 0.5524331331253052 time_taken: 0.056474924087524414\n",
      "Epoch 2: iteration 45/2501 train_loss: 0.5528386831283569 time_taken: 0.05701088905334473\n",
      "Epoch 2: iteration 46/2501 train_loss: 0.552946925163269 time_taken: 0.05639934539794922\n",
      "Epoch 2: iteration 47/2501 train_loss: 0.5530869960784912 time_taken: 0.05650138854980469\n",
      "Epoch 2: iteration 48/2501 train_loss: 0.5533115863800049 time_taken: 0.056348562240600586\n",
      "Epoch 2: iteration 49/2501 train_loss: 0.5533243417739868 time_taken: 0.05651354789733887\n",
      "Epoch 2: iteration 50/2501 train_loss: 0.5531498193740845 time_taken: 0.05629897117614746\n",
      "Epoch 2: iteration 51/2501 train_loss: 0.5526686310768127 time_taken: 0.05667757987976074\n",
      "Epoch 2: iteration 52/2501 train_loss: 0.5522106885910034 time_taken: 0.056077003479003906\n",
      "Epoch 2: iteration 53/2501 train_loss: 0.5514096617698669 time_taken: 0.057170867919921875\n",
      "Epoch 2: iteration 54/2501 train_loss: 0.5506100058555603 time_taken: 0.05664372444152832\n",
      "Epoch 2: iteration 55/2501 train_loss: 0.5498419404029846 time_taken: 0.05655241012573242\n",
      "Epoch 2: iteration 56/2501 train_loss: 0.5487661361694336 time_taken: 0.056433677673339844\n",
      "Epoch 2: iteration 57/2501 train_loss: 0.548008382320404 time_taken: 0.05639481544494629\n",
      "Epoch 2: iteration 58/2501 train_loss: 0.5473806858062744 time_taken: 0.05642437934875488\n",
      "Epoch 2: iteration 59/2501 train_loss: 0.5468437671661377 time_taken: 0.05644655227661133\n",
      "Epoch 2: iteration 60/2501 train_loss: 0.5465112924575806 time_taken: 0.05635714530944824\n",
      "Epoch 2: iteration 61/2501 train_loss: 0.5460419654846191 time_taken: 0.056502342224121094\n",
      "Epoch 2: iteration 62/2501 train_loss: 0.5458430051803589 time_taken: 0.05605602264404297\n",
      "Epoch 2: iteration 63/2501 train_loss: 0.5453843474388123 time_taken: 0.05669045448303223\n",
      "Epoch 2: iteration 64/2501 train_loss: 0.5446392297744751 time_taken: 0.05646324157714844\n",
      "Epoch 2: iteration 65/2501 train_loss: 0.543786346912384 time_taken: 0.06801748275756836\n",
      "Epoch 2: iteration 66/2501 train_loss: 0.5426936745643616 time_taken: 0.056288957595825195\n",
      "Epoch 2: iteration 67/2501 train_loss: 0.5415256023406982 time_taken: 0.056130409240722656\n",
      "Epoch 2: iteration 68/2501 train_loss: 0.5404833555221558 time_taken: 0.055850982666015625\n",
      "Epoch 2: iteration 69/2501 train_loss: 0.5393109321594238 time_taken: 0.056250572204589844\n",
      "Epoch 2: iteration 70/2501 train_loss: 0.5381349921226501 time_taken: 0.05652785301208496\n",
      "Epoch 2: iteration 71/2501 train_loss: 0.5366652607917786 time_taken: 0.056047916412353516\n",
      "Epoch 2: iteration 72/2501 train_loss: 0.5352234244346619 time_taken: 0.05581951141357422\n",
      "Epoch 2: iteration 73/2501 train_loss: 0.5338543653488159 time_taken: 0.056589365005493164\n",
      "Epoch 2: iteration 74/2501 train_loss: 0.5325427055358887 time_taken: 0.05620241165161133\n",
      "Epoch 2: iteration 75/2501 train_loss: 0.53121018409729 time_taken: 0.05605435371398926\n",
      "Epoch 2: iteration 76/2501 train_loss: 0.529770016670227 time_taken: 0.05572986602783203\n",
      "Epoch 2: iteration 77/2501 train_loss: 0.5284701585769653 time_taken: 0.05601644515991211\n",
      "Epoch 2: iteration 78/2501 train_loss: 0.5271500945091248 time_taken: 0.05634665489196777\n",
      "Epoch 2: iteration 79/2501 train_loss: 0.5258076190948486 time_taken: 0.05625653266906738\n",
      "Epoch 2: iteration 80/2501 train_loss: 0.5248017311096191 time_taken: 0.05648970603942871\n",
      "Epoch 2: iteration 81/2501 train_loss: 0.5235610008239746 time_taken: 0.0565943717956543\n",
      "Epoch 2: iteration 82/2501 train_loss: 0.5223894119262695 time_taken: 0.05605196952819824\n",
      "Epoch 2: iteration 83/2501 train_loss: 0.521264374256134 time_taken: 0.05721259117126465\n",
      "Epoch 2: iteration 84/2501 train_loss: 0.520301103591919 time_taken: 0.056235313415527344\n",
      "Epoch 2: iteration 85/2501 train_loss: 0.5193697214126587 time_taken: 0.05624961853027344\n",
      "Epoch 2: iteration 86/2501 train_loss: 0.5186872482299805 time_taken: 0.05660867691040039\n",
      "Epoch 2: iteration 87/2501 train_loss: 0.518043041229248 time_taken: 0.05664801597595215\n",
      "Epoch 2: iteration 88/2501 train_loss: 0.5175530910491943 time_taken: 0.05634260177612305\n",
      "Epoch 2: iteration 89/2501 train_loss: 0.5169525742530823 time_taken: 0.056076765060424805\n",
      "Epoch 2: iteration 90/2501 train_loss: 0.5163953304290771 time_taken: 0.056586265563964844\n",
      "Epoch 2: iteration 91/2501 train_loss: 0.5161356329917908 time_taken: 0.057611942291259766\n",
      "Epoch 2: iteration 92/2501 train_loss: 0.5159002542495728 time_taken: 0.05713224411010742\n",
      "Epoch 2: iteration 93/2501 train_loss: 0.515822172164917 time_taken: 0.05683755874633789\n",
      "Epoch 2: iteration 94/2501 train_loss: 0.5154821276664734 time_taken: 0.06020784378051758\n",
      "Epoch 2: iteration 95/2501 train_loss: 0.5150144696235657 time_taken: 0.056439876556396484\n",
      "Epoch 2: iteration 96/2501 train_loss: 0.5145852565765381 time_taken: 0.05701184272766113\n",
      "Epoch 2: iteration 97/2501 train_loss: 0.5141578912734985 time_taken: 0.05626201629638672\n",
      "Epoch 2: iteration 98/2501 train_loss: 0.5137012004852295 time_taken: 0.056531429290771484\n",
      "Epoch 2: iteration 99/2501 train_loss: 0.513192892074585 time_taken: 0.057134151458740234\n",
      "Epoch 2: iteration 100/2501 train_loss: 0.5128853917121887 time_taken: 0.05708718299865723\n",
      "Epoch 2: iteration 101/2501 train_loss: 0.5124762058258057 time_taken: 0.05652618408203125\n",
      "Epoch 2: iteration 102/2501 train_loss: 0.5122662782669067 time_taken: 0.05666065216064453\n",
      "Epoch 2: iteration 103/2501 train_loss: 0.5121153593063354 time_taken: 0.05648207664489746\n",
      "Epoch 2: iteration 104/2501 train_loss: 0.5120368003845215 time_taken: 0.05693173408508301\n",
      "Epoch 2: iteration 105/2501 train_loss: 0.5118820667266846 time_taken: 0.05684614181518555\n",
      "Epoch 2: iteration 106/2501 train_loss: 0.5115658640861511 time_taken: 0.056719303131103516\n",
      "Epoch 2: iteration 107/2501 train_loss: 0.511375367641449 time_taken: 0.05703544616699219\n",
      "Epoch 2: iteration 108/2501 train_loss: 0.511134147644043 time_taken: 0.056336164474487305\n",
      "Epoch 2: iteration 109/2501 train_loss: 0.5108457207679749 time_taken: 0.056183576583862305\n",
      "Epoch 2: iteration 110/2501 train_loss: 0.5106140971183777 time_taken: 0.05643939971923828\n",
      "Epoch 2: iteration 111/2501 train_loss: 0.510388970375061 time_taken: 0.05683565139770508\n",
      "Epoch 2: iteration 112/2501 train_loss: 0.5102588534355164 time_taken: 0.05668950080871582\n",
      "Epoch 2: iteration 113/2501 train_loss: 0.510104238986969 time_taken: 0.056520938873291016\n",
      "Epoch 2: iteration 114/2501 train_loss: 0.5098592638969421 time_taken: 0.056752920150756836\n",
      "Epoch 2: iteration 115/2501 train_loss: 0.509682297706604 time_taken: 0.05586671829223633\n",
      "Epoch 2: iteration 116/2501 train_loss: 0.5094547867774963 time_taken: 0.05647993087768555\n",
      "Epoch 2: iteration 117/2501 train_loss: 0.5094209909439087 time_taken: 0.05673408508300781\n",
      "Epoch 2: iteration 118/2501 train_loss: 0.5091155767440796 time_taken: 0.056833744049072266\n",
      "Epoch 2: iteration 119/2501 train_loss: 0.5089150071144104 time_taken: 0.05610823631286621\n",
      "Epoch 2: iteration 120/2501 train_loss: 0.5086561441421509 time_taken: 0.05655980110168457\n",
      "Epoch 2: iteration 121/2501 train_loss: 0.5083887577056885 time_taken: 0.05625510215759277\n",
      "Epoch 2: iteration 122/2501 train_loss: 0.50823575258255 time_taken: 0.0570836067199707\n",
      "Epoch 2: iteration 123/2501 train_loss: 0.5079482793807983 time_taken: 0.05669546127319336\n",
      "Epoch 2: iteration 124/2501 train_loss: 0.507753849029541 time_taken: 0.056638240814208984\n",
      "Epoch 2: iteration 125/2501 train_loss: 0.507588803768158 time_taken: 0.05632448196411133\n",
      "Epoch 2: iteration 126/2501 train_loss: 0.5072961449623108 time_taken: 0.05647587776184082\n",
      "Epoch 2: iteration 127/2501 train_loss: 0.5069695711135864 time_taken: 0.05664634704589844\n",
      "Epoch 2: iteration 128/2501 train_loss: 0.5066198706626892 time_taken: 0.05626535415649414\n",
      "Epoch 2: iteration 129/2501 train_loss: 0.5065307021141052 time_taken: 0.05593466758728027\n",
      "Epoch 2: iteration 130/2501 train_loss: 0.5065420866012573 time_taken: 0.05598855018615723\n",
      "Epoch 2: iteration 131/2501 train_loss: 0.506568431854248 time_taken: 0.05637931823730469\n",
      "Epoch 2: iteration 132/2501 train_loss: 0.506496012210846 time_taken: 0.05689239501953125\n",
      "Epoch 2: iteration 133/2501 train_loss: 0.5063663125038147 time_taken: 0.056268930435180664\n",
      "Epoch 2: iteration 134/2501 train_loss: 0.5061677694320679 time_taken: 0.05691933631896973\n",
      "Epoch 2: iteration 135/2501 train_loss: 0.5058721899986267 time_taken: 0.056572675704956055\n",
      "Epoch 2: iteration 136/2501 train_loss: 0.5057148337364197 time_taken: 0.06134295463562012\n",
      "Epoch 2: iteration 137/2501 train_loss: 0.5054979920387268 time_taken: 0.05714893341064453\n",
      "Epoch 2: iteration 138/2501 train_loss: 0.5051277279853821 time_taken: 0.056398868560791016\n",
      "Epoch 2: iteration 139/2501 train_loss: 0.5048337578773499 time_taken: 0.056739091873168945\n",
      "Epoch 2: iteration 140/2501 train_loss: 0.5047440528869629 time_taken: 0.05684995651245117\n",
      "Epoch 2: iteration 141/2501 train_loss: 0.5045011043548584 time_taken: 0.05748248100280762\n",
      "Epoch 2: iteration 142/2501 train_loss: 0.5042890310287476 time_taken: 0.056456804275512695\n",
      "Epoch 2: iteration 143/2501 train_loss: 0.5040774941444397 time_taken: 0.05684781074523926\n",
      "Epoch 2: iteration 144/2501 train_loss: 0.5039313435554504 time_taken: 0.05639076232910156\n",
      "Epoch 2: iteration 145/2501 train_loss: 0.5037674307823181 time_taken: 0.05660843849182129\n",
      "Epoch 2: iteration 146/2501 train_loss: 0.5035800337791443 time_taken: 0.05689835548400879\n",
      "Epoch 2: iteration 147/2501 train_loss: 0.503409743309021 time_taken: 0.05684614181518555\n",
      "Epoch 2: iteration 148/2501 train_loss: 0.5032420754432678 time_taken: 0.05721139907836914\n",
      "Epoch 2: iteration 149/2501 train_loss: 0.503048300743103 time_taken: 0.05707883834838867\n",
      "Epoch 2: iteration 150/2501 train_loss: 0.5029080510139465 time_taken: 0.0618436336517334\n",
      "Epoch 2: iteration 151/2501 train_loss: 0.502707302570343 time_taken: 0.0571141242980957\n",
      "Epoch 2: iteration 152/2501 train_loss: 0.5025146007537842 time_taken: 0.05693840980529785\n",
      "Epoch 2: iteration 153/2501 train_loss: 0.5021959543228149 time_taken: 0.05664372444152832\n",
      "Epoch 2: iteration 154/2501 train_loss: 0.5018640756607056 time_taken: 0.05620288848876953\n",
      "Epoch 2: iteration 155/2501 train_loss: 0.5014858245849609 time_taken: 0.0569453239440918\n",
      "Epoch 2: iteration 156/2501 train_loss: 0.5010855793952942 time_taken: 0.056363582611083984\n",
      "Epoch 2: iteration 157/2501 train_loss: 0.5006841421127319 time_taken: 0.05664801597595215\n",
      "Epoch 2: iteration 158/2501 train_loss: 0.5003181099891663 time_taken: 0.05689191818237305\n",
      "Epoch 2: iteration 159/2501 train_loss: 0.5001354813575745 time_taken: 0.05689525604248047\n",
      "Epoch 2: iteration 160/2501 train_loss: 0.5001353025436401 time_taken: 0.05674409866333008\n",
      "Epoch 2: iteration 161/2501 train_loss: 0.4999612271785736 time_taken: 0.056620121002197266\n",
      "Epoch 2: iteration 162/2501 train_loss: 0.4997415244579315 time_taken: 0.07172536849975586\n",
      "Epoch 2: iteration 163/2501 train_loss: 0.49968767166137695 time_taken: 0.05664849281311035\n",
      "Epoch 2: iteration 164/2501 train_loss: 0.49943333864212036 time_taken: 0.05669593811035156\n",
      "Epoch 2: iteration 165/2501 train_loss: 0.49931010603904724 time_taken: 0.056743621826171875\n",
      "Epoch 2: iteration 166/2501 train_loss: 0.49903810024261475 time_taken: 0.05716681480407715\n",
      "Epoch 2: iteration 167/2501 train_loss: 0.49877071380615234 time_taken: 0.05705595016479492\n",
      "Epoch 2: iteration 168/2501 train_loss: 0.49857297539711 time_taken: 0.05700349807739258\n",
      "Epoch 2: iteration 169/2501 train_loss: 0.4983789026737213 time_taken: 0.057154178619384766\n",
      "Epoch 2: iteration 170/2501 train_loss: 0.4981568455696106 time_taken: 0.0566561222076416\n",
      "Epoch 2: iteration 171/2501 train_loss: 0.49803632497787476 time_taken: 0.05701470375061035\n",
      "Epoch 2: iteration 172/2501 train_loss: 0.4978707432746887 time_taken: 0.05670452117919922\n",
      "Epoch 2: iteration 173/2501 train_loss: 0.4976814389228821 time_taken: 0.05689430236816406\n",
      "Epoch 2: iteration 174/2501 train_loss: 0.49753615260124207 time_taken: 0.0572967529296875\n",
      "Epoch 2: iteration 175/2501 train_loss: 0.4973127245903015 time_taken: 0.057129621505737305\n",
      "Epoch 2: iteration 176/2501 train_loss: 0.497121661901474 time_taken: 0.056612253189086914\n",
      "Epoch 2: iteration 177/2501 train_loss: 0.49696627259254456 time_taken: 0.056929588317871094\n",
      "Epoch 2: iteration 178/2501 train_loss: 0.49665138125419617 time_taken: 0.05646085739135742\n",
      "Epoch 2: iteration 179/2501 train_loss: 0.49631381034851074 time_taken: 0.05682706832885742\n",
      "Epoch 2: iteration 180/2501 train_loss: 0.49609047174453735 time_taken: 0.056845664978027344\n",
      "Epoch 2: iteration 181/2501 train_loss: 0.49592792987823486 time_taken: 0.05658602714538574\n",
      "Epoch 2: iteration 182/2501 train_loss: 0.4958025813102722 time_taken: 0.05698728561401367\n",
      "Epoch 2: iteration 183/2501 train_loss: 0.4957500398159027 time_taken: 0.0568547248840332\n",
      "Epoch 2: iteration 184/2501 train_loss: 0.4956081807613373 time_taken: 0.056586265563964844\n",
      "Epoch 2: iteration 185/2501 train_loss: 0.49550750851631165 time_taken: 0.05780363082885742\n",
      "Epoch 2: iteration 186/2501 train_loss: 0.4954538643360138 time_taken: 0.05696439743041992\n",
      "Epoch 2: iteration 187/2501 train_loss: 0.49540168046951294 time_taken: 0.056528329849243164\n",
      "Epoch 2: iteration 188/2501 train_loss: 0.4951951801776886 time_taken: 0.056610107421875\n",
      "Epoch 2: iteration 189/2501 train_loss: 0.49508824944496155 time_taken: 0.05670452117919922\n",
      "Epoch 2: iteration 190/2501 train_loss: 0.49495768547058105 time_taken: 0.05770277976989746\n",
      "Epoch 2: iteration 191/2501 train_loss: 0.49471601843833923 time_taken: 0.05666041374206543\n",
      "Epoch 2: iteration 192/2501 train_loss: 0.4944743514060974 time_taken: 0.05691266059875488\n",
      "Epoch 2: iteration 193/2501 train_loss: 0.49423450231552124 time_taken: 0.05658864974975586\n",
      "Epoch 2: iteration 194/2501 train_loss: 0.49405309557914734 time_taken: 0.05686759948730469\n",
      "Epoch 2: iteration 195/2501 train_loss: 0.49388566613197327 time_taken: 0.056482791900634766\n",
      "Epoch 2: iteration 196/2501 train_loss: 0.49375447630882263 time_taken: 0.05648994445800781\n",
      "Epoch 2: iteration 197/2501 train_loss: 0.4936380982398987 time_taken: 0.056073904037475586\n",
      "Epoch 2: iteration 198/2501 train_loss: 0.49349361658096313 time_taken: 0.05669546127319336\n",
      "Epoch 2: iteration 199/2501 train_loss: 0.4933837950229645 time_taken: 0.05672645568847656\n",
      "Epoch 2: iteration 200/2501 train_loss: 0.49333369731903076 time_taken: 0.05659294128417969\n",
      "Epoch 2: iteration 201/2501 train_loss: 0.4934079647064209 time_taken: 0.05695796012878418\n",
      "Epoch 2: iteration 202/2501 train_loss: 0.49346137046813965 time_taken: 0.05663776397705078\n",
      "Epoch 2: iteration 203/2501 train_loss: 0.49351122975349426 time_taken: 0.0563960075378418\n",
      "Epoch 2: iteration 204/2501 train_loss: 0.4935908019542694 time_taken: 0.05641913414001465\n",
      "Epoch 2: iteration 205/2501 train_loss: 0.4936457872390747 time_taken: 0.056456565856933594\n",
      "Epoch 2: iteration 206/2501 train_loss: 0.49371835589408875 time_taken: 0.056878089904785156\n",
      "Epoch 2: iteration 207/2501 train_loss: 0.49379974603652954 time_taken: 0.05679917335510254\n",
      "Epoch 2: iteration 208/2501 train_loss: 0.49390774965286255 time_taken: 0.056835174560546875\n",
      "Epoch 2: iteration 209/2501 train_loss: 0.4939918518066406 time_taken: 0.05669569969177246\n",
      "Epoch 2: iteration 210/2501 train_loss: 0.49397528171539307 time_taken: 0.056258201599121094\n",
      "Epoch 2: iteration 211/2501 train_loss: 0.4939395487308502 time_taken: 0.056504011154174805\n",
      "Epoch 2: iteration 212/2501 train_loss: 0.4938291311264038 time_taken: 0.05690956115722656\n",
      "Epoch 2: iteration 213/2501 train_loss: 0.4937373399734497 time_taken: 0.056303977966308594\n",
      "Epoch 2: iteration 214/2501 train_loss: 0.4936434030532837 time_taken: 0.057333946228027344\n",
      "Epoch 2: iteration 215/2501 train_loss: 0.4936145544052124 time_taken: 0.05697298049926758\n",
      "Epoch 2: iteration 216/2501 train_loss: 0.49346497654914856 time_taken: 0.05681014060974121\n",
      "Epoch 2: iteration 217/2501 train_loss: 0.49352899193763733 time_taken: 0.05748271942138672\n",
      "Epoch 2: iteration 218/2501 train_loss: 0.49349093437194824 time_taken: 0.05705881118774414\n",
      "Epoch 2: iteration 219/2501 train_loss: 0.49350470304489136 time_taken: 0.05751371383666992\n",
      "Epoch 2: iteration 220/2501 train_loss: 0.49355918169021606 time_taken: 0.05840730667114258\n",
      "Epoch 2: iteration 221/2501 train_loss: 0.49370965361595154 time_taken: 0.05697321891784668\n",
      "Epoch 2: iteration 222/2501 train_loss: 0.49386972188949585 time_taken: 0.056374549865722656\n",
      "Epoch 2: iteration 223/2501 train_loss: 0.49403247237205505 time_taken: 0.056713104248046875\n",
      "Epoch 2: iteration 224/2501 train_loss: 0.49422338604927063 time_taken: 0.0564422607421875\n",
      "Epoch 2: iteration 225/2501 train_loss: 0.49434569478034973 time_taken: 0.05622076988220215\n",
      "Epoch 2: iteration 226/2501 train_loss: 0.494514137506485 time_taken: 0.056040287017822266\n",
      "Epoch 2: iteration 227/2501 train_loss: 0.49459564685821533 time_taken: 0.05635976791381836\n",
      "Epoch 2: iteration 228/2501 train_loss: 0.494728684425354 time_taken: 0.056133270263671875\n",
      "Epoch 2: iteration 229/2501 train_loss: 0.49476128816604614 time_taken: 0.056163787841796875\n",
      "Epoch 2: iteration 230/2501 train_loss: 0.4947595000267029 time_taken: 0.056552886962890625\n",
      "Epoch 2: iteration 231/2501 train_loss: 0.49482452869415283 time_taken: 0.05697941780090332\n",
      "Epoch 2: iteration 232/2501 train_loss: 0.4947974979877472 time_taken: 0.05669903755187988\n",
      "Epoch 2: iteration 233/2501 train_loss: 0.4948239326477051 time_taken: 0.05640053749084473\n",
      "Epoch 2: iteration 234/2501 train_loss: 0.494788259267807 time_taken: 0.05630993843078613\n",
      "Epoch 2: iteration 235/2501 train_loss: 0.49481454491615295 time_taken: 0.056688547134399414\n",
      "Epoch 2: iteration 236/2501 train_loss: 0.49475380778312683 time_taken: 0.056694984436035156\n",
      "Epoch 2: iteration 237/2501 train_loss: 0.4947594106197357 time_taken: 0.05651259422302246\n",
      "Epoch 2: iteration 238/2501 train_loss: 0.49464961886405945 time_taken: 0.05713653564453125\n",
      "Epoch 2: iteration 239/2501 train_loss: 0.49455296993255615 time_taken: 0.0565338134765625\n",
      "Epoch 2: iteration 240/2501 train_loss: 0.49440887570381165 time_taken: 0.057367563247680664\n",
      "Epoch 2: iteration 241/2501 train_loss: 0.49422648549079895 time_taken: 0.05685758590698242\n",
      "Epoch 2: iteration 242/2501 train_loss: 0.4939746856689453 time_taken: 0.0563051700592041\n",
      "Epoch 2: iteration 243/2501 train_loss: 0.4937320947647095 time_taken: 0.057047128677368164\n",
      "Epoch 2: iteration 244/2501 train_loss: 0.4934305250644684 time_taken: 0.05727791786193848\n",
      "Epoch 2: iteration 245/2501 train_loss: 0.4930780231952667 time_taken: 0.056276559829711914\n",
      "Epoch 2: iteration 246/2501 train_loss: 0.49274304509162903 time_taken: 0.05675959587097168\n",
      "Epoch 2: iteration 247/2501 train_loss: 0.49244868755340576 time_taken: 0.05699348449707031\n",
      "Epoch 2: iteration 248/2501 train_loss: 0.4922035038471222 time_taken: 0.056900739669799805\n",
      "Epoch 2: iteration 249/2501 train_loss: 0.49199023842811584 time_taken: 0.05687975883483887\n",
      "Epoch 2: iteration 250/2501 train_loss: 0.4916943609714508 time_taken: 0.05727791786193848\n",
      "Epoch 2: iteration 251/2501 train_loss: 0.49146267771720886 time_taken: 0.05684494972229004\n",
      "Epoch 2: iteration 252/2501 train_loss: 0.4912063479423523 time_taken: 0.05641674995422363\n",
      "Epoch 2: iteration 253/2501 train_loss: 0.49093902111053467 time_taken: 0.0562136173248291\n",
      "Epoch 2: iteration 254/2501 train_loss: 0.4907592833042145 time_taken: 0.05596566200256348\n",
      "Epoch 2: iteration 255/2501 train_loss: 0.4906299412250519 time_taken: 0.05624890327453613\n",
      "Epoch 2: iteration 256/2501 train_loss: 0.4904746413230896 time_taken: 0.0568232536315918\n",
      "Epoch 2: iteration 257/2501 train_loss: 0.49033862352371216 time_taken: 0.05636167526245117\n",
      "Epoch 2: iteration 258/2501 train_loss: 0.49025774002075195 time_taken: 0.05676078796386719\n",
      "Epoch 2: iteration 259/2501 train_loss: 0.4901975393295288 time_taken: 0.05710268020629883\n",
      "Epoch 2: iteration 260/2501 train_loss: 0.49005991220474243 time_taken: 0.05662202835083008\n",
      "Epoch 2: iteration 261/2501 train_loss: 0.48996034264564514 time_taken: 0.05641770362854004\n",
      "Epoch 2: iteration 262/2501 train_loss: 0.48985162377357483 time_taken: 0.05701184272766113\n",
      "Epoch 2: iteration 263/2501 train_loss: 0.4897060990333557 time_taken: 0.056321144104003906\n",
      "Epoch 2: iteration 264/2501 train_loss: 0.48961538076400757 time_taken: 0.056874752044677734\n",
      "Epoch 2: iteration 265/2501 train_loss: 0.4895063638687134 time_taken: 0.057050228118896484\n",
      "Epoch 2: iteration 266/2501 train_loss: 0.4893408417701721 time_taken: 0.05703091621398926\n",
      "Epoch 2: iteration 267/2501 train_loss: 0.4892214834690094 time_taken: 0.05731964111328125\n",
      "Epoch 2: iteration 268/2501 train_loss: 0.48908373713493347 time_taken: 0.06160259246826172\n",
      "Epoch 2: iteration 269/2501 train_loss: 0.48884865641593933 time_taken: 0.057250261306762695\n",
      "Epoch 2: iteration 270/2501 train_loss: 0.48864105343818665 time_taken: 0.05662393569946289\n",
      "Epoch 2: iteration 271/2501 train_loss: 0.4883926510810852 time_taken: 0.05646204948425293\n",
      "Epoch 2: iteration 272/2501 train_loss: 0.48811182379722595 time_taken: 0.05672788619995117\n",
      "Epoch 2: iteration 273/2501 train_loss: 0.4878326654434204 time_taken: 0.05687379837036133\n",
      "Epoch 2: iteration 274/2501 train_loss: 0.4876711666584015 time_taken: 0.05674028396606445\n",
      "Epoch 2: iteration 275/2501 train_loss: 0.48749032616615295 time_taken: 0.05641937255859375\n",
      "Epoch 2: iteration 276/2501 train_loss: 0.48734527826309204 time_taken: 0.056583404541015625\n",
      "Epoch 2: iteration 277/2501 train_loss: 0.4871983230113983 time_taken: 0.05683779716491699\n",
      "Epoch 2: iteration 278/2501 train_loss: 0.487050324678421 time_taken: 0.05704545974731445\n",
      "Epoch 2: iteration 279/2501 train_loss: 0.486909419298172 time_taken: 0.056906938552856445\n",
      "Epoch 2: iteration 280/2501 train_loss: 0.48683062195777893 time_taken: 0.057425737380981445\n",
      "Epoch 2: iteration 281/2501 train_loss: 0.48676663637161255 time_taken: 0.05687093734741211\n",
      "Epoch 2: iteration 282/2501 train_loss: 0.48674145340919495 time_taken: 0.0567469596862793\n",
      "Epoch 2: iteration 283/2501 train_loss: 0.486687034368515 time_taken: 0.05736041069030762\n",
      "Epoch 2: iteration 284/2501 train_loss: 0.48665857315063477 time_taken: 0.058007240295410156\n",
      "Epoch 2: iteration 285/2501 train_loss: 0.4866916537284851 time_taken: 0.0563197135925293\n",
      "Epoch 2: iteration 286/2501 train_loss: 0.4866911470890045 time_taken: 0.07146739959716797\n",
      "Epoch 2: iteration 287/2501 train_loss: 0.48670250177383423 time_taken: 0.0567173957824707\n",
      "Epoch 2: iteration 288/2501 train_loss: 0.48675617575645447 time_taken: 0.05644488334655762\n",
      "Epoch 2: iteration 289/2501 train_loss: 0.4868265688419342 time_taken: 0.05648326873779297\n",
      "Epoch 2: iteration 290/2501 train_loss: 0.48696091771125793 time_taken: 0.0573573112487793\n",
      "Epoch 2: iteration 291/2501 train_loss: 0.4871726930141449 time_taken: 0.05686163902282715\n",
      "Epoch 2: iteration 292/2501 train_loss: 0.48728734254837036 time_taken: 0.05673575401306152\n",
      "Epoch 2: iteration 293/2501 train_loss: 0.4874049127101898 time_taken: 0.05719947814941406\n",
      "Epoch 2: iteration 294/2501 train_loss: 0.4874882996082306 time_taken: 0.05640673637390137\n",
      "Epoch 2: iteration 295/2501 train_loss: 0.4876280725002289 time_taken: 0.05707240104675293\n",
      "Epoch 2: iteration 296/2501 train_loss: 0.48775357007980347 time_taken: 0.05718684196472168\n",
      "Epoch 2: iteration 297/2501 train_loss: 0.4879285991191864 time_taken: 0.05658531188964844\n",
      "Epoch 2: iteration 298/2501 train_loss: 0.48806002736091614 time_taken: 0.05640149116516113\n",
      "Epoch 2: iteration 299/2501 train_loss: 0.48820191621780396 time_taken: 0.05663251876831055\n",
      "Epoch 2: iteration 300/2501 train_loss: 0.48832812905311584 time_taken: 0.057152509689331055\n",
      "Epoch 2: iteration 301/2501 train_loss: 0.48849430680274963 time_taken: 0.05768871307373047\n",
      "Epoch 2: iteration 302/2501 train_loss: 0.48866352438926697 time_taken: 0.05673551559448242\n",
      "Epoch 2: iteration 303/2501 train_loss: 0.4887681305408478 time_taken: 0.056316375732421875\n",
      "Epoch 2: iteration 304/2501 train_loss: 0.48888570070266724 time_taken: 0.05685281753540039\n",
      "Epoch 2: iteration 305/2501 train_loss: 0.489040344953537 time_taken: 0.05666780471801758\n",
      "Epoch 2: iteration 306/2501 train_loss: 0.4891163110733032 time_taken: 0.05632829666137695\n",
      "Epoch 2: iteration 307/2501 train_loss: 0.4891507923603058 time_taken: 0.056746721267700195\n",
      "Epoch 2: iteration 308/2501 train_loss: 0.48923254013061523 time_taken: 0.05698657035827637\n",
      "Epoch 2: iteration 309/2501 train_loss: 0.4892658293247223 time_taken: 0.0565645694732666\n",
      "Epoch 2: iteration 310/2501 train_loss: 0.4892369508743286 time_taken: 0.0568540096282959\n",
      "Epoch 2: iteration 311/2501 train_loss: 0.4891700744628906 time_taken: 0.056946516036987305\n",
      "Epoch 2: iteration 312/2501 train_loss: 0.48906847834587097 time_taken: 0.05703902244567871\n",
      "Epoch 2: iteration 313/2501 train_loss: 0.488960325717926 time_taken: 0.05666542053222656\n",
      "Epoch 2: iteration 314/2501 train_loss: 0.4887573719024658 time_taken: 0.05652570724487305\n",
      "Epoch 2: iteration 315/2501 train_loss: 0.48853257298469543 time_taken: 0.05731821060180664\n",
      "Epoch 2: iteration 316/2501 train_loss: 0.4882521331310272 time_taken: 0.05674147605895996\n",
      "Epoch 2: iteration 317/2501 train_loss: 0.48806408047676086 time_taken: 0.057084083557128906\n",
      "Epoch 2: iteration 318/2501 train_loss: 0.48783764243125916 time_taken: 0.057114601135253906\n",
      "Epoch 2: iteration 319/2501 train_loss: 0.48763877153396606 time_taken: 0.056525230407714844\n",
      "Epoch 2: iteration 320/2501 train_loss: 0.48751118779182434 time_taken: 0.05658102035522461\n",
      "Epoch 2: iteration 321/2501 train_loss: 0.4873897135257721 time_taken: 0.056092262268066406\n",
      "Epoch 2: iteration 322/2501 train_loss: 0.48727473616600037 time_taken: 0.05623817443847656\n",
      "Epoch 2: iteration 323/2501 train_loss: 0.48716118931770325 time_taken: 0.05640578269958496\n",
      "Epoch 2: iteration 324/2501 train_loss: 0.4870530366897583 time_taken: 0.05686187744140625\n",
      "Epoch 2: iteration 325/2501 train_loss: 0.48692774772644043 time_taken: 0.05619955062866211\n",
      "Epoch 2: iteration 326/2501 train_loss: 0.4868076741695404 time_taken: 0.05626368522644043\n",
      "Epoch 2: iteration 327/2501 train_loss: 0.4867326319217682 time_taken: 0.05669093132019043\n",
      "Epoch 2: iteration 328/2501 train_loss: 0.48658302426338196 time_taken: 0.056978464126586914\n",
      "Epoch 2: iteration 329/2501 train_loss: 0.4865296483039856 time_taken: 0.05714702606201172\n",
      "Epoch 2: iteration 330/2501 train_loss: 0.4863821566104889 time_taken: 0.05676770210266113\n",
      "Epoch 2: iteration 331/2501 train_loss: 0.48620885610580444 time_taken: 0.056784629821777344\n",
      "Epoch 2: iteration 332/2501 train_loss: 0.48607903718948364 time_taken: 0.0576474666595459\n",
      "Epoch 2: iteration 333/2501 train_loss: 0.4859316647052765 time_taken: 0.05667519569396973\n",
      "Epoch 2: iteration 334/2501 train_loss: 0.48583951592445374 time_taken: 0.05719709396362305\n",
      "Epoch 2: iteration 335/2501 train_loss: 0.48581281304359436 time_taken: 0.057015419006347656\n",
      "Epoch 2: iteration 336/2501 train_loss: 0.485752671957016 time_taken: 0.05683302879333496\n",
      "Epoch 2: iteration 337/2501 train_loss: 0.4856739938259125 time_taken: 0.05713605880737305\n",
      "Epoch 2: iteration 338/2501 train_loss: 0.4856300354003906 time_taken: 0.057006120681762695\n",
      "Epoch 2: iteration 339/2501 train_loss: 0.48559755086898804 time_taken: 0.05717730522155762\n",
      "Epoch 2: iteration 340/2501 train_loss: 0.48560571670532227 time_taken: 0.05640268325805664\n",
      "Epoch 2: iteration 341/2501 train_loss: 0.48563888669013977 time_taken: 0.056452035903930664\n",
      "Epoch 2: iteration 342/2501 train_loss: 0.4856530427932739 time_taken: 0.056618452072143555\n",
      "Epoch 2: iteration 343/2501 train_loss: 0.48568832874298096 time_taken: 0.057177066802978516\n",
      "Epoch 2: iteration 344/2501 train_loss: 0.4856884479522705 time_taken: 0.057150840759277344\n",
      "Epoch 2: iteration 345/2501 train_loss: 0.48571133613586426 time_taken: 0.05734705924987793\n",
      "Epoch 2: iteration 346/2501 train_loss: 0.4856966733932495 time_taken: 0.05720639228820801\n",
      "Epoch 2: iteration 347/2501 train_loss: 0.48569926619529724 time_taken: 0.05652141571044922\n",
      "Epoch 2: iteration 348/2501 train_loss: 0.48568812012672424 time_taken: 0.056952714920043945\n",
      "Epoch 2: iteration 349/2501 train_loss: 0.4857255816459656 time_taken: 0.05674862861633301\n",
      "Epoch 2: iteration 350/2501 train_loss: 0.4857872724533081 time_taken: 0.05701160430908203\n",
      "Epoch 2: iteration 351/2501 train_loss: 0.4858471155166626 time_taken: 0.05689740180969238\n",
      "Epoch 2: iteration 352/2501 train_loss: 0.4859013557434082 time_taken: 0.056552886962890625\n",
      "Epoch 2: iteration 353/2501 train_loss: 0.4860076904296875 time_taken: 0.05636000633239746\n",
      "Epoch 2: iteration 354/2501 train_loss: 0.4861200153827667 time_taken: 0.05635499954223633\n",
      "Epoch 2: iteration 355/2501 train_loss: 0.4862719774246216 time_taken: 0.056816816329956055\n",
      "Epoch 2: iteration 356/2501 train_loss: 0.486364483833313 time_taken: 0.05712461471557617\n",
      "Epoch 2: iteration 357/2501 train_loss: 0.48650893568992615 time_taken: 0.05767965316772461\n",
      "Epoch 2: iteration 358/2501 train_loss: 0.48662233352661133 time_taken: 0.05684924125671387\n",
      "Epoch 2: iteration 359/2501 train_loss: 0.4867815375328064 time_taken: 0.05732560157775879\n",
      "Epoch 2: iteration 360/2501 train_loss: 0.4868635833263397 time_taken: 0.056656837463378906\n",
      "Epoch 2: iteration 361/2501 train_loss: 0.4869694709777832 time_taken: 0.0564272403717041\n",
      "Epoch 2: iteration 362/2501 train_loss: 0.48696839809417725 time_taken: 0.057127952575683594\n",
      "Epoch 2: iteration 363/2501 train_loss: 0.4870394468307495 time_taken: 0.05788254737854004\n",
      "Epoch 2: iteration 364/2501 train_loss: 0.48709094524383545 time_taken: 0.05759406089782715\n",
      "Epoch 2: iteration 365/2501 train_loss: 0.487195760011673 time_taken: 0.057231903076171875\n",
      "Epoch 2: iteration 366/2501 train_loss: 0.4872762858867645 time_taken: 0.057589054107666016\n",
      "Epoch 2: iteration 367/2501 train_loss: 0.4873812198638916 time_taken: 0.05646347999572754\n",
      "Epoch 2: iteration 368/2501 train_loss: 0.4874540865421295 time_taken: 0.05688214302062988\n",
      "Epoch 2: iteration 369/2501 train_loss: 0.4875510632991791 time_taken: 0.05694723129272461\n",
      "Epoch 2: iteration 370/2501 train_loss: 0.48763853311538696 time_taken: 0.05692338943481445\n",
      "Epoch 2: iteration 371/2501 train_loss: 0.4877188801765442 time_taken: 0.057791709899902344\n",
      "Epoch 2: iteration 372/2501 train_loss: 0.48783859610557556 time_taken: 0.05810713768005371\n",
      "Epoch 2: iteration 373/2501 train_loss: 0.4879346191883087 time_taken: 0.056856632232666016\n",
      "Epoch 2: iteration 374/2501 train_loss: 0.4879932403564453 time_taken: 0.05669760704040527\n",
      "Epoch 2: iteration 375/2501 train_loss: 0.4880840480327606 time_taken: 0.05676865577697754\n",
      "Epoch 2: iteration 376/2501 train_loss: 0.4881744086742401 time_taken: 0.05701780319213867\n",
      "Epoch 2: iteration 377/2501 train_loss: 0.488251656293869 time_taken: 0.05659079551696777\n",
      "Epoch 2: iteration 378/2501 train_loss: 0.4883187711238861 time_taken: 0.057707786560058594\n",
      "Epoch 2: iteration 379/2501 train_loss: 0.4883774220943451 time_taken: 0.057022809982299805\n",
      "Epoch 2: iteration 380/2501 train_loss: 0.4883722960948944 time_taken: 0.05689644813537598\n",
      "Epoch 2: iteration 381/2501 train_loss: 0.4884117543697357 time_taken: 0.056355953216552734\n",
      "Epoch 2: iteration 382/2501 train_loss: 0.48847201466560364 time_taken: 0.056870460510253906\n",
      "Epoch 2: iteration 383/2501 train_loss: 0.48850372433662415 time_taken: 0.05679917335510254\n",
      "Epoch 2: iteration 384/2501 train_loss: 0.48859935998916626 time_taken: 0.05648207664489746\n",
      "Epoch 2: iteration 385/2501 train_loss: 0.48868662118911743 time_taken: 0.05638003349304199\n",
      "Epoch 2: iteration 386/2501 train_loss: 0.48877620697021484 time_taken: 0.05659937858581543\n",
      "Epoch 2: iteration 387/2501 train_loss: 0.4888108968734741 time_taken: 0.05660057067871094\n",
      "Epoch 2: iteration 388/2501 train_loss: 0.48885083198547363 time_taken: 0.056452035903930664\n",
      "Epoch 2: iteration 389/2501 train_loss: 0.48887962102890015 time_taken: 0.05649304389953613\n",
      "Epoch 2: iteration 390/2501 train_loss: 0.4889078438282013 time_taken: 0.056446075439453125\n",
      "Epoch 2: iteration 391/2501 train_loss: 0.4889589846134186 time_taken: 0.05623674392700195\n",
      "Epoch 2: iteration 392/2501 train_loss: 0.4890093207359314 time_taken: 0.05739283561706543\n",
      "Epoch 2: iteration 393/2501 train_loss: 0.48901796340942383 time_taken: 0.057047367095947266\n",
      "Epoch 2: iteration 394/2501 train_loss: 0.4890025854110718 time_taken: 0.05937933921813965\n",
      "Epoch 2: iteration 395/2501 train_loss: 0.48897668719291687 time_taken: 0.056772708892822266\n",
      "Epoch 2: iteration 396/2501 train_loss: 0.4889160990715027 time_taken: 0.05683159828186035\n",
      "Epoch 2: iteration 397/2501 train_loss: 0.48887863755226135 time_taken: 0.05672931671142578\n",
      "Epoch 2: iteration 398/2501 train_loss: 0.48880907893180847 time_taken: 0.0566558837890625\n",
      "Epoch 2: iteration 399/2501 train_loss: 0.48869040608406067 time_taken: 0.05643105506896973\n",
      "Epoch 2: iteration 400/2501 train_loss: 0.488586962223053 time_taken: 0.056462764739990234\n",
      "Epoch 2: iteration 401/2501 train_loss: 0.48845309019088745 time_taken: 0.05686497688293457\n",
      "Epoch 2: iteration 402/2501 train_loss: 0.4883469045162201 time_taken: 0.05641913414001465\n",
      "Epoch 2: iteration 403/2501 train_loss: 0.48818713426589966 time_taken: 0.05659627914428711\n",
      "Epoch 2: iteration 404/2501 train_loss: 0.4880583584308624 time_taken: 0.056481122970581055\n",
      "Epoch 2: iteration 405/2501 train_loss: 0.48793455958366394 time_taken: 0.05644512176513672\n",
      "Epoch 2: iteration 406/2501 train_loss: 0.48784658312797546 time_taken: 0.05684685707092285\n",
      "Epoch 2: iteration 407/2501 train_loss: 0.48772844672203064 time_taken: 0.0561981201171875\n",
      "Epoch 2: iteration 408/2501 train_loss: 0.48768556118011475 time_taken: 0.05642962455749512\n",
      "Epoch 2: iteration 409/2501 train_loss: 0.4876111149787903 time_taken: 0.05709981918334961\n",
      "Epoch 2: iteration 410/2501 train_loss: 0.48756182193756104 time_taken: 0.05627584457397461\n",
      "Epoch 2: iteration 411/2501 train_loss: 0.4875129759311676 time_taken: 0.05624556541442871\n",
      "Epoch 2: iteration 412/2501 train_loss: 0.4874333441257477 time_taken: 0.05647635459899902\n",
      "Epoch 2: iteration 413/2501 train_loss: 0.4873434901237488 time_taken: 0.05644392967224121\n",
      "Epoch 2: iteration 414/2501 train_loss: 0.4872431457042694 time_taken: 0.056725502014160156\n",
      "Epoch 2: iteration 415/2501 train_loss: 0.4871710240840912 time_taken: 0.05660820007324219\n",
      "Epoch 2: iteration 416/2501 train_loss: 0.4870990514755249 time_taken: 0.05632472038269043\n",
      "Epoch 2: iteration 417/2501 train_loss: 0.48701316118240356 time_taken: 0.05674576759338379\n",
      "Epoch 2: iteration 418/2501 train_loss: 0.4869195520877838 time_taken: 0.05711078643798828\n",
      "Epoch 2: iteration 419/2501 train_loss: 0.4868756830692291 time_taken: 0.07131004333496094\n",
      "Epoch 2: iteration 420/2501 train_loss: 0.4868386387825012 time_taken: 0.05622982978820801\n",
      "Epoch 2: iteration 421/2501 train_loss: 0.4867748022079468 time_taken: 0.0566861629486084\n",
      "Epoch 2: iteration 422/2501 train_loss: 0.4867154359817505 time_taken: 0.05681657791137695\n",
      "Epoch 2: iteration 423/2501 train_loss: 0.4866711497306824 time_taken: 0.05700325965881348\n",
      "Epoch 2: iteration 424/2501 train_loss: 0.48658519983291626 time_taken: 0.05651140213012695\n",
      "Epoch 2: iteration 425/2501 train_loss: 0.4865127205848694 time_taken: 0.05726480484008789\n",
      "Epoch 2: iteration 426/2501 train_loss: 0.48642387986183167 time_taken: 0.056963205337524414\n",
      "Epoch 2: iteration 427/2501 train_loss: 0.4863777160644531 time_taken: 0.05625486373901367\n",
      "Epoch 2: iteration 428/2501 train_loss: 0.4863738417625427 time_taken: 0.061026811599731445\n",
      "Epoch 2: iteration 429/2501 train_loss: 0.4863700568675995 time_taken: 0.05666303634643555\n",
      "Epoch 2: iteration 430/2501 train_loss: 0.48638880252838135 time_taken: 0.057067155838012695\n",
      "Epoch 2: iteration 431/2501 train_loss: 0.48637092113494873 time_taken: 0.05666851997375488\n",
      "Epoch 2: iteration 432/2501 train_loss: 0.4863865077495575 time_taken: 0.05637645721435547\n",
      "Epoch 2: iteration 433/2501 train_loss: 0.48643213510513306 time_taken: 0.05717968940734863\n",
      "Epoch 2: iteration 434/2501 train_loss: 0.4864829182624817 time_taken: 0.05712771415710449\n",
      "Epoch 2: iteration 435/2501 train_loss: 0.48657017946243286 time_taken: 0.0564422607421875\n",
      "Epoch 2: iteration 436/2501 train_loss: 0.4866258203983307 time_taken: 0.06308507919311523\n",
      "Epoch 2: iteration 437/2501 train_loss: 0.4867059290409088 time_taken: 0.05638575553894043\n",
      "Epoch 2: iteration 438/2501 train_loss: 0.4867880344390869 time_taken: 0.05743718147277832\n",
      "Epoch 2: iteration 439/2501 train_loss: 0.48688533902168274 time_taken: 0.0568537712097168\n",
      "Epoch 2: iteration 440/2501 train_loss: 0.48699936270713806 time_taken: 0.056714534759521484\n",
      "Epoch 2: iteration 441/2501 train_loss: 0.4871163070201874 time_taken: 0.05691719055175781\n",
      "Epoch 2: iteration 442/2501 train_loss: 0.4872118830680847 time_taken: 0.05790400505065918\n",
      "Epoch 2: iteration 443/2501 train_loss: 0.4872950315475464 time_taken: 0.05689811706542969\n",
      "Epoch 2: iteration 444/2501 train_loss: 0.4873383343219757 time_taken: 0.057656049728393555\n",
      "Epoch 2: iteration 445/2501 train_loss: 0.4874311089515686 time_taken: 0.05677485466003418\n",
      "Epoch 2: iteration 446/2501 train_loss: 0.48753422498703003 time_taken: 0.05679655075073242\n",
      "Epoch 2: iteration 447/2501 train_loss: 0.4876044690608978 time_taken: 0.05697441101074219\n",
      "Epoch 2: iteration 448/2501 train_loss: 0.4876769483089447 time_taken: 0.05659914016723633\n",
      "Epoch 2: iteration 449/2501 train_loss: 0.4878116548061371 time_taken: 0.05673718452453613\n",
      "Epoch 2: iteration 450/2501 train_loss: 0.487838476896286 time_taken: 0.05671381950378418\n",
      "Epoch 2: iteration 451/2501 train_loss: 0.4878844618797302 time_taken: 0.05623269081115723\n",
      "Epoch 2: iteration 452/2501 train_loss: 0.4879388213157654 time_taken: 0.05607485771179199\n",
      "Epoch 2: iteration 453/2501 train_loss: 0.48798248171806335 time_taken: 0.05648469924926758\n",
      "Epoch 2: iteration 454/2501 train_loss: 0.4879909157752991 time_taken: 0.05658388137817383\n",
      "Epoch 2: iteration 455/2501 train_loss: 0.4879753291606903 time_taken: 0.06209397315979004\n",
      "Epoch 2: iteration 456/2501 train_loss: 0.4879469573497772 time_taken: 0.057240962982177734\n",
      "Epoch 2: iteration 457/2501 train_loss: 0.48790478706359863 time_taken: 0.0566558837890625\n",
      "Epoch 2: iteration 458/2501 train_loss: 0.48780617117881775 time_taken: 0.05633068084716797\n",
      "Epoch 2: iteration 459/2501 train_loss: 0.4877084493637085 time_taken: 0.05653786659240723\n",
      "Epoch 2: iteration 460/2501 train_loss: 0.48759812116622925 time_taken: 0.05625557899475098\n",
      "Epoch 2: iteration 461/2501 train_loss: 0.48746633529663086 time_taken: 0.056159019470214844\n",
      "Epoch 2: iteration 462/2501 train_loss: 0.48729783296585083 time_taken: 0.05672144889831543\n",
      "Epoch 2: iteration 463/2501 train_loss: 0.48711615800857544 time_taken: 0.056482553482055664\n",
      "Epoch 2: iteration 464/2501 train_loss: 0.4869314730167389 time_taken: 0.05720925331115723\n",
      "Epoch 2: iteration 465/2501 train_loss: 0.48681873083114624 time_taken: 0.05686640739440918\n",
      "Epoch 2: iteration 466/2501 train_loss: 0.4866791069507599 time_taken: 0.05684089660644531\n",
      "Epoch 2: iteration 467/2501 train_loss: 0.4865541458129883 time_taken: 0.05680418014526367\n",
      "Epoch 2: iteration 468/2501 train_loss: 0.48646795749664307 time_taken: 0.05702400207519531\n",
      "Epoch 2: iteration 469/2501 train_loss: 0.4863712191581726 time_taken: 0.057230472564697266\n",
      "Epoch 2: iteration 470/2501 train_loss: 0.4862733483314514 time_taken: 0.05681443214416504\n",
      "Epoch 2: iteration 471/2501 train_loss: 0.4862253665924072 time_taken: 0.057119131088256836\n",
      "Epoch 2: iteration 472/2501 train_loss: 0.48620036244392395 time_taken: 0.05696725845336914\n",
      "Epoch 2: iteration 473/2501 train_loss: 0.48615938425064087 time_taken: 0.05701899528503418\n",
      "Epoch 2: iteration 474/2501 train_loss: 0.48613885045051575 time_taken: 0.05703234672546387\n",
      "Epoch 2: iteration 475/2501 train_loss: 0.48614397644996643 time_taken: 0.05682682991027832\n",
      "Epoch 2: iteration 476/2501 train_loss: 0.48617392778396606 time_taken: 0.05791521072387695\n",
      "Epoch 2: iteration 477/2501 train_loss: 0.4862261414527893 time_taken: 0.05647706985473633\n",
      "Epoch 2: iteration 478/2501 train_loss: 0.48625147342681885 time_taken: 0.056929588317871094\n",
      "Epoch 2: iteration 479/2501 train_loss: 0.486284464597702 time_taken: 0.05590701103210449\n",
      "Epoch 2: iteration 480/2501 train_loss: 0.48633164167404175 time_taken: 0.05616617202758789\n",
      "Epoch 2: iteration 481/2501 train_loss: 0.48642897605895996 time_taken: 0.05610823631286621\n",
      "Epoch 2: iteration 482/2501 train_loss: 0.48649343848228455 time_taken: 0.05676746368408203\n",
      "Epoch 2: iteration 483/2501 train_loss: 0.4865553379058838 time_taken: 0.05678153038024902\n",
      "Epoch 2: iteration 484/2501 train_loss: 0.4866439402103424 time_taken: 0.05646872520446777\n",
      "Epoch 2: iteration 485/2501 train_loss: 0.48671403527259827 time_taken: 0.056458234786987305\n",
      "Epoch 2: iteration 486/2501 train_loss: 0.48678624629974365 time_taken: 0.05762815475463867\n",
      "Epoch 2: iteration 487/2501 train_loss: 0.48687100410461426 time_taken: 0.05711722373962402\n",
      "Epoch 2: iteration 488/2501 train_loss: 0.48694470524787903 time_taken: 0.05702090263366699\n",
      "Epoch 2: iteration 489/2501 train_loss: 0.4869946539402008 time_taken: 0.05651044845581055\n",
      "Epoch 2: iteration 490/2501 train_loss: 0.48704156279563904 time_taken: 0.05694866180419922\n",
      "Epoch 2: iteration 491/2501 train_loss: 0.48715412616729736 time_taken: 0.05696511268615723\n",
      "Epoch 2: iteration 492/2501 train_loss: 0.4872162342071533 time_taken: 0.05693507194519043\n",
      "Epoch 2: iteration 493/2501 train_loss: 0.48732197284698486 time_taken: 0.05702066421508789\n",
      "Epoch 2: iteration 494/2501 train_loss: 0.48736080527305603 time_taken: 0.05695772171020508\n",
      "Epoch 2: iteration 495/2501 train_loss: 0.48745882511138916 time_taken: 0.056971073150634766\n",
      "Epoch 2: iteration 496/2501 train_loss: 0.4875248372554779 time_taken: 0.05712080001831055\n",
      "Epoch 2: iteration 497/2501 train_loss: 0.48757851123809814 time_taken: 0.05638551712036133\n",
      "Epoch 2: iteration 498/2501 train_loss: 0.4876164495944977 time_taken: 0.05659818649291992\n",
      "Epoch 2: iteration 499/2501 train_loss: 0.4876697063446045 time_taken: 0.05681967735290527\n",
      "Epoch 2: iteration 500/2501 train_loss: 0.4876917898654938 time_taken: 0.05680537223815918\n",
      "Epoch 2: iteration 501/2501 train_loss: 0.4877392649650574 time_taken: 0.057515859603881836\n",
      "Epoch 2: iteration 502/2501 train_loss: 0.48771047592163086 time_taken: 0.05696249008178711\n",
      "Epoch 2: iteration 503/2501 train_loss: 0.4877321422100067 time_taken: 0.056305646896362305\n",
      "Epoch 2: iteration 504/2501 train_loss: 0.4877614378929138 time_taken: 0.056870460510253906\n",
      "Epoch 2: iteration 505/2501 train_loss: 0.4877670705318451 time_taken: 0.056455373764038086\n",
      "Epoch 2: iteration 506/2501 train_loss: 0.4878111779689789 time_taken: 0.056867361068725586\n",
      "Epoch 2: iteration 507/2501 train_loss: 0.48784273862838745 time_taken: 0.05724477767944336\n",
      "Epoch 2: iteration 508/2501 train_loss: 0.4878707230091095 time_taken: 0.05681920051574707\n",
      "Epoch 2: iteration 509/2501 train_loss: 0.4878976047039032 time_taken: 0.05745816230773926\n",
      "Epoch 2: iteration 510/2501 train_loss: 0.4879319965839386 time_taken: 0.056925058364868164\n",
      "Epoch 2: iteration 511/2501 train_loss: 0.4880145192146301 time_taken: 0.05792689323425293\n",
      "Epoch 2: iteration 512/2501 train_loss: 0.48806557059288025 time_taken: 0.05692028999328613\n",
      "Epoch 2: iteration 513/2501 train_loss: 0.4881574213504791 time_taken: 0.05638837814331055\n",
      "Epoch 2: iteration 514/2501 train_loss: 0.4882422685623169 time_taken: 0.056919097900390625\n",
      "Epoch 2: iteration 515/2501 train_loss: 0.48830345273017883 time_taken: 0.05617403984069824\n",
      "Epoch 2: iteration 516/2501 train_loss: 0.48840853571891785 time_taken: 0.05679893493652344\n",
      "Epoch 2: iteration 517/2501 train_loss: 0.488476425409317 time_taken: 0.05687856674194336\n",
      "Epoch 2: iteration 518/2501 train_loss: 0.488525390625 time_taken: 0.057158708572387695\n",
      "Epoch 2: iteration 519/2501 train_loss: 0.48860394954681396 time_taken: 0.05715608596801758\n",
      "Epoch 2: iteration 520/2501 train_loss: 0.48868951201438904 time_taken: 0.056681156158447266\n",
      "Epoch 2: iteration 521/2501 train_loss: 0.48875799775123596 time_taken: 0.05728483200073242\n",
      "Epoch 2: iteration 522/2501 train_loss: 0.48885905742645264 time_taken: 0.057535648345947266\n",
      "Epoch 2: iteration 523/2501 train_loss: 0.48894256353378296 time_taken: 0.056394338607788086\n",
      "Epoch 2: iteration 524/2501 train_loss: 0.4890088438987732 time_taken: 0.05676770210266113\n",
      "Epoch 2: iteration 525/2501 train_loss: 0.4890460968017578 time_taken: 0.05659079551696777\n",
      "Epoch 2: iteration 526/2501 train_loss: 0.48907625675201416 time_taken: 0.057082414627075195\n",
      "Epoch 2: iteration 527/2501 train_loss: 0.4891327917575836 time_taken: 0.05692148208618164\n",
      "Epoch 2: iteration 528/2501 train_loss: 0.48919031023979187 time_taken: 0.056794166564941406\n",
      "Epoch 2: iteration 529/2501 train_loss: 0.4892408847808838 time_taken: 0.05657529830932617\n",
      "Epoch 2: iteration 530/2501 train_loss: 0.48927751183509827 time_taken: 0.05743598937988281\n",
      "Epoch 2: iteration 531/2501 train_loss: 0.48931077122688293 time_taken: 0.05707216262817383\n",
      "Epoch 2: iteration 532/2501 train_loss: 0.489319771528244 time_taken: 0.05686831474304199\n",
      "Epoch 2: iteration 533/2501 train_loss: 0.48933926224708557 time_taken: 0.05731391906738281\n",
      "Epoch 2: iteration 534/2501 train_loss: 0.48936358094215393 time_taken: 0.05662393569946289\n",
      "Epoch 2: iteration 535/2501 train_loss: 0.4893628656864166 time_taken: 0.0578455924987793\n",
      "Epoch 2: iteration 536/2501 train_loss: 0.4893399178981781 time_taken: 0.05685234069824219\n",
      "Epoch 2: iteration 537/2501 train_loss: 0.48928186297416687 time_taken: 0.056861162185668945\n",
      "Epoch 2: iteration 538/2501 train_loss: 0.48922672867774963 time_taken: 0.05650496482849121\n",
      "Epoch 2: iteration 539/2501 train_loss: 0.48915451765060425 time_taken: 0.056879281997680664\n",
      "Epoch 2: iteration 540/2501 train_loss: 0.489066481590271 time_taken: 0.05678367614746094\n",
      "Epoch 2: iteration 541/2501 train_loss: 0.48899412155151367 time_taken: 0.05677199363708496\n",
      "Epoch 2: iteration 542/2501 train_loss: 0.48893842101097107 time_taken: 0.05653500556945801\n",
      "Epoch 2: iteration 543/2501 train_loss: 0.4889242649078369 time_taken: 0.05678701400756836\n",
      "Epoch 2: iteration 544/2501 train_loss: 0.4888911545276642 time_taken: 0.056639671325683594\n",
      "Epoch 2: iteration 545/2501 train_loss: 0.48892009258270264 time_taken: 0.056525230407714844\n",
      "Epoch 2: iteration 546/2501 train_loss: 0.4889124035835266 time_taken: 0.057309865951538086\n",
      "Epoch 2: iteration 547/2501 train_loss: 0.4889366030693054 time_taken: 0.0567319393157959\n",
      "Epoch 2: iteration 548/2501 train_loss: 0.48893946409225464 time_taken: 0.05685138702392578\n",
      "Epoch 2: iteration 549/2501 train_loss: 0.48893237113952637 time_taken: 0.05674457550048828\n",
      "Epoch 2: iteration 550/2501 train_loss: 0.4889175295829773 time_taken: 0.05685019493103027\n",
      "Epoch 2: iteration 551/2501 train_loss: 0.48889943957328796 time_taken: 0.057091712951660156\n",
      "Epoch 2: iteration 552/2501 train_loss: 0.4888806641101837 time_taken: 0.05722522735595703\n",
      "Epoch 2: iteration 553/2501 train_loss: 0.48884493112564087 time_taken: 0.05692172050476074\n",
      "Epoch 2: iteration 554/2501 train_loss: 0.48881885409355164 time_taken: 0.056862831115722656\n",
      "Epoch 2: iteration 555/2501 train_loss: 0.4888123869895935 time_taken: 0.0568540096282959\n",
      "Epoch 2: iteration 556/2501 train_loss: 0.4888077676296234 time_taken: 0.05688285827636719\n",
      "Epoch 2: iteration 557/2501 train_loss: 0.4887617230415344 time_taken: 0.05686473846435547\n",
      "Epoch 2: iteration 558/2501 train_loss: 0.48872679471969604 time_taken: 0.0571291446685791\n",
      "Epoch 2: iteration 559/2501 train_loss: 0.48866114020347595 time_taken: 0.05682373046875\n",
      "Epoch 2: iteration 560/2501 train_loss: 0.48855939507484436 time_taken: 0.05726027488708496\n",
      "Epoch 2: iteration 561/2501 train_loss: 0.4884681701660156 time_taken: 0.05724143981933594\n",
      "Epoch 2: iteration 562/2501 train_loss: 0.4883508086204529 time_taken: 0.05678224563598633\n",
      "Epoch 2: iteration 563/2501 train_loss: 0.48824411630630493 time_taken: 0.05674338340759277\n",
      "Epoch 2: iteration 564/2501 train_loss: 0.4881393015384674 time_taken: 0.059786081314086914\n",
      "Epoch 2: iteration 565/2501 train_loss: 0.48801466822624207 time_taken: 0.05707263946533203\n",
      "Epoch 2: iteration 566/2501 train_loss: 0.48789072036743164 time_taken: 0.05625748634338379\n",
      "Epoch 2: iteration 567/2501 train_loss: 0.48778602480888367 time_taken: 0.05631518363952637\n",
      "Epoch 2: iteration 568/2501 train_loss: 0.4876856505870819 time_taken: 0.05588960647583008\n",
      "Epoch 2: iteration 569/2501 train_loss: 0.48762768507003784 time_taken: 0.05663132667541504\n",
      "Epoch 2: iteration 570/2501 train_loss: 0.48756155371665955 time_taken: 0.05633068084716797\n",
      "Epoch 2: iteration 571/2501 train_loss: 0.48754003643989563 time_taken: 0.05668926239013672\n",
      "Epoch 2: iteration 572/2501 train_loss: 0.4875156581401825 time_taken: 0.05716824531555176\n",
      "Epoch 2: iteration 573/2501 train_loss: 0.48748576641082764 time_taken: 0.05652761459350586\n",
      "Epoch 2: iteration 574/2501 train_loss: 0.48748546838760376 time_taken: 0.056140899658203125\n",
      "Epoch 2: iteration 575/2501 train_loss: 0.48748329281806946 time_taken: 0.05963897705078125\n",
      "Epoch 2: iteration 576/2501 train_loss: 0.48748505115509033 time_taken: 0.05614447593688965\n",
      "Epoch 2: iteration 577/2501 train_loss: 0.4874713122844696 time_taken: 0.05616879463195801\n",
      "Epoch 2: iteration 578/2501 train_loss: 0.48747286200523376 time_taken: 0.05612778663635254\n",
      "Epoch 2: iteration 579/2501 train_loss: 0.4874598979949951 time_taken: 0.05725693702697754\n",
      "Epoch 2: iteration 580/2501 train_loss: 0.48744919896125793 time_taken: 0.05612611770629883\n",
      "Epoch 2: iteration 581/2501 train_loss: 0.4874321520328522 time_taken: 0.06350159645080566\n",
      "Epoch 2: iteration 582/2501 train_loss: 0.48738032579421997 time_taken: 0.05648541450500488\n",
      "Epoch 2: iteration 583/2501 train_loss: 0.4873311221599579 time_taken: 0.05626845359802246\n",
      "Epoch 2: iteration 584/2501 train_loss: 0.4872726500034332 time_taken: 0.05618906021118164\n",
      "Epoch 2: iteration 585/2501 train_loss: 0.4872080683708191 time_taken: 0.056387901306152344\n",
      "Epoch 2: iteration 586/2501 train_loss: 0.4871133267879486 time_taken: 0.05747270584106445\n",
      "Epoch 2: iteration 587/2501 train_loss: 0.4870571792125702 time_taken: 0.05628681182861328\n",
      "Epoch 2: iteration 588/2501 train_loss: 0.48699185252189636 time_taken: 0.056794166564941406\n",
      "Epoch 2: iteration 589/2501 train_loss: 0.48690351843833923 time_taken: 0.05663347244262695\n",
      "Epoch 2: iteration 590/2501 train_loss: 0.48679307103157043 time_taken: 0.06252312660217285\n",
      "Epoch 2: iteration 591/2501 train_loss: 0.4866608679294586 time_taken: 0.05649876594543457\n",
      "Epoch 2: iteration 592/2501 train_loss: 0.4865280091762543 time_taken: 0.05698370933532715\n",
      "Epoch 2: iteration 593/2501 train_loss: 0.48637282848358154 time_taken: 0.056600093841552734\n",
      "Epoch 2: iteration 594/2501 train_loss: 0.48623189330101013 time_taken: 0.05642557144165039\n",
      "Epoch 2: iteration 595/2501 train_loss: 0.48604410886764526 time_taken: 0.056601524353027344\n",
      "Epoch 2: iteration 596/2501 train_loss: 0.48585498332977295 time_taken: 0.05666804313659668\n",
      "Epoch 2: iteration 597/2501 train_loss: 0.4856507182121277 time_taken: 0.05661797523498535\n",
      "Epoch 2: iteration 598/2501 train_loss: 0.4854999780654907 time_taken: 0.05666017532348633\n",
      "Epoch 2: iteration 599/2501 train_loss: 0.48535025119781494 time_taken: 0.0563817024230957\n",
      "Epoch 2: iteration 600/2501 train_loss: 0.48524269461631775 time_taken: 0.057442426681518555\n",
      "Epoch 2: iteration 601/2501 train_loss: 0.4851348102092743 time_taken: 0.056824684143066406\n",
      "Epoch 2: iteration 602/2501 train_loss: 0.48504748940467834 time_taken: 0.057027339935302734\n",
      "Epoch 2: iteration 603/2501 train_loss: 0.48497626185417175 time_taken: 0.05694317817687988\n",
      "Epoch 2: iteration 604/2501 train_loss: 0.4849158525466919 time_taken: 0.056528568267822266\n",
      "Epoch 2: iteration 605/2501 train_loss: 0.48488613963127136 time_taken: 0.05682635307312012\n",
      "Epoch 2: iteration 606/2501 train_loss: 0.48485177755355835 time_taken: 0.05683398246765137\n",
      "Epoch 2: iteration 607/2501 train_loss: 0.4848334789276123 time_taken: 0.05645871162414551\n",
      "Epoch 2: iteration 608/2501 train_loss: 0.4848399758338928 time_taken: 0.05642366409301758\n",
      "Epoch 2: iteration 609/2501 train_loss: 0.48485156893730164 time_taken: 0.06906628608703613\n",
      "Epoch 2: iteration 610/2501 train_loss: 0.4848034977912903 time_taken: 0.05717349052429199\n",
      "Epoch 2: iteration 611/2501 train_loss: 0.48479941487312317 time_taken: 0.05576157569885254\n",
      "Epoch 2: iteration 612/2501 train_loss: 0.4847702383995056 time_taken: 0.05639481544494629\n",
      "Epoch 2: iteration 613/2501 train_loss: 0.48472675681114197 time_taken: 0.05643105506896973\n",
      "Epoch 2: iteration 614/2501 train_loss: 0.4846743643283844 time_taken: 0.05697131156921387\n",
      "Epoch 2: iteration 615/2501 train_loss: 0.4846601188182831 time_taken: 0.056282758712768555\n",
      "Epoch 2: iteration 616/2501 train_loss: 0.48460888862609863 time_taken: 0.05649709701538086\n",
      "Epoch 2: iteration 617/2501 train_loss: 0.4845244288444519 time_taken: 0.05659937858581543\n",
      "Epoch 2: iteration 618/2501 train_loss: 0.48444733023643494 time_taken: 0.05642557144165039\n",
      "Epoch 2: iteration 619/2501 train_loss: 0.4843490719795227 time_taken: 0.05634331703186035\n",
      "Epoch 2: iteration 620/2501 train_loss: 0.4842607080936432 time_taken: 0.056925058364868164\n",
      "Epoch 2: iteration 621/2501 train_loss: 0.4842180013656616 time_taken: 0.05685091018676758\n",
      "Epoch 2: iteration 622/2501 train_loss: 0.48417189717292786 time_taken: 0.05669569969177246\n",
      "Epoch 2: iteration 623/2501 train_loss: 0.4841178357601166 time_taken: 0.056548357009887695\n",
      "Epoch 2: iteration 624/2501 train_loss: 0.48407354950904846 time_taken: 0.05694913864135742\n",
      "Epoch 2: iteration 625/2501 train_loss: 0.4840242862701416 time_taken: 0.057210683822631836\n",
      "Epoch 2: iteration 626/2501 train_loss: 0.48398557305336 time_taken: 0.05651283264160156\n",
      "Epoch 2: iteration 627/2501 train_loss: 0.4839271008968353 time_taken: 0.05728936195373535\n",
      "Epoch 2: iteration 628/2501 train_loss: 0.4838758409023285 time_taken: 0.05624103546142578\n",
      "Epoch 2: iteration 629/2501 train_loss: 0.48382484912872314 time_taken: 0.05816388130187988\n",
      "Epoch 2: iteration 630/2501 train_loss: 0.48376643657684326 time_taken: 0.05752897262573242\n",
      "Epoch 2: iteration 631/2501 train_loss: 0.4837281405925751 time_taken: 0.05641674995422363\n",
      "Epoch 2: iteration 632/2501 train_loss: 0.4837111830711365 time_taken: 0.057586669921875\n",
      "Epoch 2: iteration 633/2501 train_loss: 0.48368099331855774 time_taken: 0.05711960792541504\n",
      "Epoch 2: iteration 634/2501 train_loss: 0.4836580455303192 time_taken: 0.056710243225097656\n",
      "Epoch 2: iteration 635/2501 train_loss: 0.48361364006996155 time_taken: 0.05676078796386719\n",
      "Epoch 2: iteration 636/2501 train_loss: 0.4835328161716461 time_taken: 0.05690121650695801\n",
      "Epoch 2: iteration 637/2501 train_loss: 0.48345986008644104 time_taken: 0.05693864822387695\n",
      "Epoch 2: iteration 638/2501 train_loss: 0.4833860695362091 time_taken: 0.05661511421203613\n",
      "Epoch 2: iteration 639/2501 train_loss: 0.48329800367355347 time_taken: 0.05645322799682617\n",
      "Epoch 2: iteration 640/2501 train_loss: 0.48318544030189514 time_taken: 0.0568845272064209\n",
      "Epoch 2: iteration 641/2501 train_loss: 0.4830840528011322 time_taken: 0.056557416915893555\n",
      "Epoch 2: iteration 642/2501 train_loss: 0.48296919465065 time_taken: 0.05771136283874512\n",
      "Epoch 2: iteration 643/2501 train_loss: 0.48283717036247253 time_taken: 0.056761980056762695\n",
      "Epoch 2: iteration 644/2501 train_loss: 0.4827173948287964 time_taken: 0.05601787567138672\n",
      "Epoch 2: iteration 645/2501 train_loss: 0.48255684971809387 time_taken: 0.05640864372253418\n",
      "Epoch 2: iteration 646/2501 train_loss: 0.482429563999176 time_taken: 0.056081533432006836\n",
      "Epoch 2: iteration 647/2501 train_loss: 0.48229721188545227 time_taken: 0.0566558837890625\n",
      "Epoch 2: iteration 648/2501 train_loss: 0.4821901023387909 time_taken: 0.05669450759887695\n",
      "Epoch 2: iteration 649/2501 train_loss: 0.48212337493896484 time_taken: 0.05649209022521973\n",
      "Epoch 2: iteration 650/2501 train_loss: 0.48208415508270264 time_taken: 0.056986093521118164\n",
      "Epoch 2: iteration 651/2501 train_loss: 0.48206624388694763 time_taken: 0.06299066543579102\n",
      "Epoch 2: iteration 652/2501 train_loss: 0.48204711079597473 time_taken: 0.05678367614746094\n",
      "Epoch 2: iteration 653/2501 train_loss: 0.48203831911087036 time_taken: 0.05598258972167969\n",
      "Epoch 2: iteration 654/2501 train_loss: 0.4820317029953003 time_taken: 0.06214714050292969\n",
      "Epoch 2: iteration 655/2501 train_loss: 0.48203524947166443 time_taken: 0.056020259857177734\n",
      "Epoch 2: iteration 656/2501 train_loss: 0.48204097151756287 time_taken: 0.05588173866271973\n",
      "Epoch 2: iteration 657/2501 train_loss: 0.4820660650730133 time_taken: 0.062230825424194336\n",
      "Epoch 2: iteration 658/2501 train_loss: 0.4821067452430725 time_taken: 0.056613922119140625\n",
      "Epoch 2: iteration 659/2501 train_loss: 0.48214074969291687 time_taken: 0.05632209777832031\n",
      "Epoch 2: iteration 660/2501 train_loss: 0.4821452796459198 time_taken: 0.056418657302856445\n",
      "Epoch 2: iteration 661/2501 train_loss: 0.48214980959892273 time_taken: 0.05605673789978027\n",
      "Epoch 2: iteration 662/2501 train_loss: 0.48217689990997314 time_taken: 0.056075096130371094\n",
      "Epoch 2: iteration 663/2501 train_loss: 0.4821767807006836 time_taken: 0.06244707107543945\n",
      "Epoch 2: iteration 664/2501 train_loss: 0.4821862280368805 time_taken: 0.05656695365905762\n",
      "Epoch 2: iteration 665/2501 train_loss: 0.4822440445423126 time_taken: 0.05673408508300781\n",
      "Epoch 2: iteration 666/2501 train_loss: 0.4822924733161926 time_taken: 0.0565035343170166\n",
      "Epoch 2: iteration 667/2501 train_loss: 0.48234823346138 time_taken: 0.056043148040771484\n",
      "Epoch 2: iteration 668/2501 train_loss: 0.48236891627311707 time_taken: 0.05675554275512695\n",
      "Epoch 2: iteration 669/2501 train_loss: 0.4823930561542511 time_taken: 0.056509971618652344\n",
      "Epoch 2: iteration 670/2501 train_loss: 0.48245003819465637 time_taken: 0.05643296241760254\n",
      "Epoch 2: iteration 671/2501 train_loss: 0.48251107335090637 time_taken: 0.05683135986328125\n",
      "Epoch 2: iteration 672/2501 train_loss: 0.4825648069381714 time_taken: 0.05603337287902832\n",
      "Epoch 2: iteration 673/2501 train_loss: 0.4826418459415436 time_taken: 0.056394338607788086\n",
      "Epoch 2: iteration 674/2501 train_loss: 0.4827006459236145 time_taken: 0.05641889572143555\n",
      "Epoch 2: iteration 675/2501 train_loss: 0.48276597261428833 time_taken: 0.05602574348449707\n",
      "Epoch 2: iteration 676/2501 train_loss: 0.48282289505004883 time_taken: 0.05687880516052246\n",
      "Epoch 2: iteration 677/2501 train_loss: 0.4828657805919647 time_taken: 0.056304931640625\n",
      "Epoch 2: iteration 678/2501 train_loss: 0.482902467250824 time_taken: 0.0570523738861084\n",
      "Epoch 2: iteration 679/2501 train_loss: 0.4829423725605011 time_taken: 0.056958913803100586\n",
      "Epoch 2: iteration 680/2501 train_loss: 0.4829617738723755 time_taken: 0.05777740478515625\n",
      "Epoch 2: iteration 681/2501 train_loss: 0.4829750061035156 time_taken: 0.056641340255737305\n",
      "Epoch 2: iteration 682/2501 train_loss: 0.48296627402305603 time_taken: 0.05591082572937012\n",
      "Epoch 2: iteration 683/2501 train_loss: 0.48293060064315796 time_taken: 0.05637383460998535\n",
      "Epoch 2: iteration 684/2501 train_loss: 0.4829075336456299 time_taken: 0.057188987731933594\n",
      "Epoch 2: iteration 685/2501 train_loss: 0.48287081718444824 time_taken: 0.05677914619445801\n",
      "Epoch 2: iteration 686/2501 train_loss: 0.48281848430633545 time_taken: 0.0565037727355957\n",
      "Epoch 2: iteration 687/2501 train_loss: 0.4827597737312317 time_taken: 0.05643749237060547\n",
      "Epoch 2: iteration 688/2501 train_loss: 0.48269379138946533 time_taken: 0.05637025833129883\n",
      "Epoch 2: iteration 689/2501 train_loss: 0.4826105833053589 time_taken: 0.057192325592041016\n",
      "Epoch 2: iteration 690/2501 train_loss: 0.4825279116630554 time_taken: 0.059630393981933594\n",
      "Epoch 2: iteration 691/2501 train_loss: 0.48245367407798767 time_taken: 0.0564112663269043\n",
      "Epoch 2: iteration 692/2501 train_loss: 0.4823855459690094 time_taken: 0.056404829025268555\n",
      "Epoch 2: iteration 693/2501 train_loss: 0.48231929540634155 time_taken: 0.06264257431030273\n",
      "Epoch 2: iteration 694/2501 train_loss: 0.48227086663246155 time_taken: 0.056210994720458984\n",
      "Epoch 2: iteration 695/2501 train_loss: 0.4822366535663605 time_taken: 0.056040048599243164\n",
      "Epoch 2: iteration 696/2501 train_loss: 0.4821993112564087 time_taken: 0.05624985694885254\n",
      "Epoch 2: iteration 697/2501 train_loss: 0.48216742277145386 time_taken: 0.056165456771850586\n",
      "Epoch 2: iteration 698/2501 train_loss: 0.48214221000671387 time_taken: 0.06150531768798828\n",
      "Epoch 2: iteration 699/2501 train_loss: 0.48214325308799744 time_taken: 0.056241512298583984\n",
      "Epoch 2: iteration 700/2501 train_loss: 0.48214635252952576 time_taken: 0.056543588638305664\n",
      "Epoch 2: iteration 701/2501 train_loss: 0.4821719229221344 time_taken: 0.056224822998046875\n",
      "Epoch 2: iteration 702/2501 train_loss: 0.4821881949901581 time_taken: 0.057271718978881836\n",
      "Epoch 2: iteration 703/2501 train_loss: 0.48221471905708313 time_taken: 0.057076454162597656\n",
      "Epoch 2: iteration 704/2501 train_loss: 0.4822850525379181 time_taken: 0.05634951591491699\n",
      "Epoch 2: iteration 705/2501 train_loss: 0.4823509752750397 time_taken: 0.05616354942321777\n",
      "Epoch 2: iteration 706/2501 train_loss: 0.48240649700164795 time_taken: 0.05585837364196777\n",
      "Epoch 2: iteration 707/2501 train_loss: 0.48247212171554565 time_taken: 0.05589890480041504\n",
      "Epoch 2: iteration 708/2501 train_loss: 0.48253706097602844 time_taken: 0.07175612449645996\n",
      "Epoch 2: iteration 709/2501 train_loss: 0.4826345145702362 time_taken: 0.05590033531188965\n",
      "Epoch 2: iteration 710/2501 train_loss: 0.48275285959243774 time_taken: 0.055826663970947266\n",
      "Epoch 2: iteration 711/2501 train_loss: 0.48283031582832336 time_taken: 0.056378841400146484\n",
      "Epoch 2: iteration 712/2501 train_loss: 0.48289820551872253 time_taken: 0.05635809898376465\n",
      "Epoch 2: iteration 713/2501 train_loss: 0.4829779863357544 time_taken: 0.056543588638305664\n",
      "Epoch 2: iteration 714/2501 train_loss: 0.48304662108421326 time_taken: 0.056444644927978516\n",
      "Epoch 2: iteration 715/2501 train_loss: 0.48312821984291077 time_taken: 0.05629563331604004\n",
      "Epoch 2: iteration 716/2501 train_loss: 0.4832102954387665 time_taken: 0.055832862854003906\n",
      "Epoch 2: iteration 717/2501 train_loss: 0.4832835793495178 time_taken: 0.056304216384887695\n",
      "Epoch 2: iteration 718/2501 train_loss: 0.4833521246910095 time_taken: 0.05639910697937012\n",
      "Epoch 2: iteration 719/2501 train_loss: 0.4834088981151581 time_taken: 0.05612683296203613\n",
      "Epoch 2: iteration 720/2501 train_loss: 0.48349469900131226 time_taken: 0.05998373031616211\n",
      "Epoch 2: iteration 721/2501 train_loss: 0.4835897982120514 time_taken: 0.05634784698486328\n",
      "Epoch 2: iteration 722/2501 train_loss: 0.4836598038673401 time_taken: 0.055913448333740234\n",
      "Epoch 2: iteration 723/2501 train_loss: 0.4837428629398346 time_taken: 0.06276774406433105\n",
      "Epoch 2: iteration 724/2501 train_loss: 0.4838426411151886 time_taken: 0.057276248931884766\n",
      "Epoch 2: iteration 725/2501 train_loss: 0.48391786217689514 time_taken: 0.05623650550842285\n",
      "Epoch 2: iteration 726/2501 train_loss: 0.48398518562316895 time_taken: 0.05938005447387695\n",
      "Epoch 2: iteration 727/2501 train_loss: 0.48403891921043396 time_taken: 0.06112790107727051\n",
      "Epoch 2: iteration 728/2501 train_loss: 0.484070748090744 time_taken: 0.05667424201965332\n",
      "Epoch 2: iteration 729/2501 train_loss: 0.484073668718338 time_taken: 0.05641460418701172\n",
      "Epoch 2: iteration 730/2501 train_loss: 0.48406484723091125 time_taken: 0.05644559860229492\n",
      "Epoch 2: iteration 731/2501 train_loss: 0.48405006527900696 time_taken: 0.056256771087646484\n",
      "Epoch 2: iteration 732/2501 train_loss: 0.4840153157711029 time_taken: 0.06116437911987305\n",
      "Epoch 2: iteration 733/2501 train_loss: 0.48398688435554504 time_taken: 0.0564877986907959\n",
      "Epoch 2: iteration 734/2501 train_loss: 0.48393580317497253 time_taken: 0.056107282638549805\n",
      "Epoch 2: iteration 735/2501 train_loss: 0.48388248682022095 time_taken: 0.057204484939575195\n",
      "Epoch 2: iteration 736/2501 train_loss: 0.4838235676288605 time_taken: 0.055895328521728516\n",
      "Epoch 2: iteration 737/2501 train_loss: 0.48377305269241333 time_taken: 0.059157609939575195\n",
      "Epoch 2: iteration 738/2501 train_loss: 0.48372504115104675 time_taken: 0.05577516555786133\n",
      "Epoch 2: iteration 739/2501 train_loss: 0.4836825728416443 time_taken: 0.05896711349487305\n",
      "Epoch 2: iteration 740/2501 train_loss: 0.4836643636226654 time_taken: 0.05584001541137695\n",
      "Epoch 2: iteration 741/2501 train_loss: 0.48366260528564453 time_taken: 0.05661606788635254\n",
      "Epoch 2: iteration 742/2501 train_loss: 0.4836525321006775 time_taken: 0.05714130401611328\n",
      "Epoch 2: iteration 743/2501 train_loss: 0.48365360498428345 time_taken: 0.05758929252624512\n",
      "Epoch 2: iteration 744/2501 train_loss: 0.4836370050907135 time_taken: 0.05763077735900879\n",
      "Epoch 2: iteration 745/2501 train_loss: 0.48360195755958557 time_taken: 0.057000160217285156\n",
      "Epoch 2: iteration 746/2501 train_loss: 0.4835573136806488 time_taken: 0.0573728084564209\n",
      "Epoch 2: iteration 747/2501 train_loss: 0.4835185110569 time_taken: 0.057665109634399414\n",
      "Epoch 2: iteration 748/2501 train_loss: 0.4834926724433899 time_taken: 0.05706000328063965\n",
      "Epoch 2: iteration 749/2501 train_loss: 0.4834729731082916 time_taken: 0.05751299858093262\n",
      "Epoch 2: iteration 750/2501 train_loss: 0.4834156334400177 time_taken: 0.056940555572509766\n",
      "Epoch 2: iteration 751/2501 train_loss: 0.48334985971450806 time_taken: 0.05679583549499512\n",
      "Epoch 2: iteration 752/2501 train_loss: 0.483293741941452 time_taken: 0.05663633346557617\n",
      "Epoch 2: iteration 753/2501 train_loss: 0.48325905203819275 time_taken: 0.056329965591430664\n",
      "Epoch 2: iteration 754/2501 train_loss: 0.48319733142852783 time_taken: 0.05633687973022461\n",
      "Epoch 2: iteration 755/2501 train_loss: 0.4831233024597168 time_taken: 0.056031227111816406\n",
      "Epoch 2: iteration 756/2501 train_loss: 0.4830484390258789 time_taken: 0.056511640548706055\n",
      "Epoch 2: iteration 757/2501 train_loss: 0.48296570777893066 time_taken: 0.05661129951477051\n",
      "Epoch 2: iteration 758/2501 train_loss: 0.48288828134536743 time_taken: 0.05685091018676758\n",
      "Epoch 2: iteration 759/2501 train_loss: 0.48282381892204285 time_taken: 0.056392669677734375\n",
      "Epoch 2: iteration 760/2501 train_loss: 0.4828000068664551 time_taken: 0.056304931640625\n",
      "Epoch 2: iteration 761/2501 train_loss: 0.48274949193000793 time_taken: 0.05643773078918457\n",
      "Epoch 2: iteration 762/2501 train_loss: 0.4827151298522949 time_taken: 0.057373046875\n",
      "Epoch 2: iteration 763/2501 train_loss: 0.4827031195163727 time_taken: 0.0565950870513916\n",
      "Epoch 2: iteration 764/2501 train_loss: 0.4826948046684265 time_taken: 0.05691218376159668\n",
      "Epoch 2: iteration 765/2501 train_loss: 0.48268526792526245 time_taken: 0.05634927749633789\n",
      "Epoch 2: iteration 766/2501 train_loss: 0.4826886057853699 time_taken: 0.056610822677612305\n",
      "Epoch 2: iteration 767/2501 train_loss: 0.48269787430763245 time_taken: 0.05632376670837402\n",
      "Epoch 2: iteration 768/2501 train_loss: 0.48272067308425903 time_taken: 0.06182289123535156\n",
      "Epoch 2: iteration 769/2501 train_loss: 0.48276081681251526 time_taken: 0.05659627914428711\n",
      "Epoch 2: iteration 770/2501 train_loss: 0.48279762268066406 time_taken: 0.05591940879821777\n",
      "Epoch 2: iteration 771/2501 train_loss: 0.4828515350818634 time_taken: 0.10395169258117676\n",
      "Epoch 2: iteration 772/2501 train_loss: 0.4829028844833374 time_taken: 0.05634140968322754\n",
      "Epoch 2: iteration 773/2501 train_loss: 0.48293665051460266 time_taken: 0.05617213249206543\n",
      "Epoch 2: iteration 774/2501 train_loss: 0.48300549387931824 time_taken: 0.05675959587097168\n",
      "Epoch 2: iteration 775/2501 train_loss: 0.48307883739471436 time_taken: 0.05688619613647461\n",
      "Epoch 2: iteration 776/2501 train_loss: 0.48316290974617004 time_taken: 0.05615091323852539\n",
      "Epoch 2: iteration 777/2501 train_loss: 0.4832400977611542 time_taken: 0.05640840530395508\n",
      "Epoch 2: iteration 778/2501 train_loss: 0.4832873046398163 time_taken: 0.0557861328125\n",
      "Epoch 2: iteration 779/2501 train_loss: 0.48334741592407227 time_taken: 0.056182861328125\n",
      "Epoch 2: iteration 780/2501 train_loss: 0.4834015369415283 time_taken: 0.05570578575134277\n",
      "Epoch 2: iteration 781/2501 train_loss: 0.48345762491226196 time_taken: 0.05622220039367676\n",
      "Epoch 2: iteration 782/2501 train_loss: 0.4835161566734314 time_taken: 0.056679487228393555\n",
      "Epoch 2: iteration 783/2501 train_loss: 0.48354628682136536 time_taken: 0.05706906318664551\n",
      "Epoch 2: iteration 784/2501 train_loss: 0.4835856556892395 time_taken: 0.05690145492553711\n",
      "Epoch 2: iteration 785/2501 train_loss: 0.4836024343967438 time_taken: 0.056375741958618164\n",
      "Epoch 2: iteration 786/2501 train_loss: 0.48360830545425415 time_taken: 0.056539297103881836\n",
      "Epoch 2: iteration 787/2501 train_loss: 0.48361921310424805 time_taken: 0.06266236305236816\n",
      "Epoch 2: iteration 788/2501 train_loss: 0.48362845182418823 time_taken: 0.0559537410736084\n",
      "Epoch 2: iteration 789/2501 train_loss: 0.4836233854293823 time_taken: 0.05591464042663574\n",
      "Epoch 2: iteration 790/2501 train_loss: 0.4836141765117645 time_taken: 0.0623016357421875\n",
      "Epoch 2: iteration 791/2501 train_loss: 0.4836304783821106 time_taken: 0.05655169486999512\n",
      "Epoch 2: iteration 792/2501 train_loss: 0.4836503565311432 time_taken: 0.056313276290893555\n",
      "Epoch 2: iteration 793/2501 train_loss: 0.48368021845817566 time_taken: 0.05614137649536133\n",
      "Epoch 2: iteration 794/2501 train_loss: 0.48371949791908264 time_taken: 0.05575871467590332\n",
      "Epoch 2: iteration 795/2501 train_loss: 0.48376038670539856 time_taken: 0.059343576431274414\n",
      "Epoch 2: iteration 796/2501 train_loss: 0.4838041663169861 time_taken: 0.05574154853820801\n",
      "Epoch 2: iteration 797/2501 train_loss: 0.4838198721408844 time_taken: 0.056261539459228516\n",
      "Epoch 2: iteration 798/2501 train_loss: 0.4838195741176605 time_taken: 0.05737042427062988\n",
      "Epoch 2: iteration 799/2501 train_loss: 0.4838210642337799 time_taken: 0.062348127365112305\n",
      "Epoch 2: iteration 800/2501 train_loss: 0.48385000228881836 time_taken: 0.05642127990722656\n",
      "Epoch 2: iteration 801/2501 train_loss: 0.4838576018810272 time_taken: 0.05640912055969238\n",
      "Epoch 2: iteration 802/2501 train_loss: 0.48385873436927795 time_taken: 0.0562286376953125\n",
      "Epoch 2: iteration 803/2501 train_loss: 0.48385247588157654 time_taken: 0.056783199310302734\n",
      "Epoch 2: iteration 804/2501 train_loss: 0.4838595688343048 time_taken: 0.05680227279663086\n",
      "Epoch 2: iteration 805/2501 train_loss: 0.48386672139167786 time_taken: 0.05614137649536133\n",
      "Epoch 2: iteration 806/2501 train_loss: 0.48386210203170776 time_taken: 0.06834816932678223\n",
      "Epoch 2: iteration 807/2501 train_loss: 0.48388952016830444 time_taken: 0.056856632232666016\n",
      "Epoch 2: iteration 808/2501 train_loss: 0.4839312732219696 time_taken: 0.05605459213256836\n",
      "Epoch 2: iteration 809/2501 train_loss: 0.4839699864387512 time_taken: 0.056516408920288086\n",
      "Epoch 2: iteration 810/2501 train_loss: 0.4840199947357178 time_taken: 0.05729365348815918\n",
      "Epoch 2: iteration 811/2501 train_loss: 0.48406603932380676 time_taken: 0.05673980712890625\n",
      "Epoch 2: iteration 812/2501 train_loss: 0.4841417074203491 time_taken: 0.056550025939941406\n",
      "Epoch 2: iteration 813/2501 train_loss: 0.48416152596473694 time_taken: 0.05680704116821289\n",
      "Epoch 2: iteration 814/2501 train_loss: 0.4842223823070526 time_taken: 0.05739951133728027\n",
      "Epoch 2: iteration 815/2501 train_loss: 0.4842608869075775 time_taken: 0.057138919830322266\n",
      "Epoch 2: iteration 816/2501 train_loss: 0.484312504529953 time_taken: 0.056832313537597656\n",
      "Epoch 2: iteration 817/2501 train_loss: 0.48438897728919983 time_taken: 0.05707573890686035\n",
      "Epoch 2: iteration 818/2501 train_loss: 0.484462708234787 time_taken: 0.056844234466552734\n",
      "Epoch 2: iteration 819/2501 train_loss: 0.4845561981201172 time_taken: 0.05697131156921387\n",
      "Epoch 2: iteration 820/2501 train_loss: 0.484638512134552 time_taken: 0.05738019943237305\n",
      "Epoch 2: iteration 821/2501 train_loss: 0.4847099781036377 time_taken: 0.05630660057067871\n",
      "Epoch 2: iteration 822/2501 train_loss: 0.4847797751426697 time_taken: 0.056353092193603516\n",
      "Epoch 2: iteration 823/2501 train_loss: 0.48485109210014343 time_taken: 0.056105613708496094\n",
      "Epoch 2: iteration 824/2501 train_loss: 0.4848862886428833 time_taken: 0.05649733543395996\n",
      "Epoch 2: iteration 825/2501 train_loss: 0.4849281311035156 time_taken: 0.05617260932922363\n",
      "Epoch 2: iteration 826/2501 train_loss: 0.48497265577316284 time_taken: 0.056548357009887695\n",
      "Epoch 2: iteration 827/2501 train_loss: 0.4850064814090729 time_taken: 0.05604672431945801\n",
      "Epoch 2: iteration 828/2501 train_loss: 0.48504722118377686 time_taken: 0.056551456451416016\n",
      "Epoch 2: iteration 829/2501 train_loss: 0.4850987493991852 time_taken: 0.056430816650390625\n",
      "Epoch 2: iteration 830/2501 train_loss: 0.48513272404670715 time_taken: 0.056496620178222656\n",
      "Epoch 2: iteration 831/2501 train_loss: 0.4851362407207489 time_taken: 0.05633831024169922\n",
      "Epoch 2: iteration 832/2501 train_loss: 0.48513343930244446 time_taken: 0.05620837211608887\n",
      "Epoch 2: iteration 833/2501 train_loss: 0.4851360619068146 time_taken: 0.05599379539489746\n",
      "Epoch 2: iteration 834/2501 train_loss: 0.485141783952713 time_taken: 0.06115293502807617\n",
      "Epoch 2: iteration 835/2501 train_loss: 0.4851565957069397 time_taken: 0.05658411979675293\n",
      "Epoch 2: iteration 836/2501 train_loss: 0.4851735234260559 time_taken: 0.05642437934875488\n",
      "Epoch 2: iteration 837/2501 train_loss: 0.48518869280815125 time_taken: 0.05659198760986328\n",
      "Epoch 2: iteration 838/2501 train_loss: 0.4852164089679718 time_taken: 0.056984901428222656\n",
      "Epoch 2: iteration 839/2501 train_loss: 0.4852374196052551 time_taken: 0.0561673641204834\n",
      "Epoch 2: iteration 840/2501 train_loss: 0.48525652289390564 time_taken: 0.056386470794677734\n",
      "Epoch 2: iteration 841/2501 train_loss: 0.4852575361728668 time_taken: 0.056215524673461914\n",
      "Epoch 2: iteration 842/2501 train_loss: 0.48528969287872314 time_taken: 0.0560307502746582\n",
      "Epoch 2: iteration 843/2501 train_loss: 0.48529207706451416 time_taken: 0.05744647979736328\n",
      "Epoch 2: iteration 844/2501 train_loss: 0.48530685901641846 time_taken: 0.056646108627319336\n",
      "Epoch 2: iteration 845/2501 train_loss: 0.48533669114112854 time_taken: 0.056185245513916016\n",
      "Epoch 2: iteration 846/2501 train_loss: 0.4853636920452118 time_taken: 0.05647397041320801\n",
      "Epoch 2: iteration 847/2501 train_loss: 0.4853709638118744 time_taken: 0.05656743049621582\n",
      "Epoch 2: iteration 848/2501 train_loss: 0.4853871762752533 time_taken: 0.056841373443603516\n",
      "Epoch 2: iteration 849/2501 train_loss: 0.48540979623794556 time_taken: 0.05709433555603027\n",
      "Epoch 2: iteration 850/2501 train_loss: 0.48543781042099 time_taken: 0.056433916091918945\n",
      "Epoch 2: iteration 851/2501 train_loss: 0.4854549467563629 time_taken: 0.05678296089172363\n",
      "Epoch 2: iteration 852/2501 train_loss: 0.48549482226371765 time_taken: 0.056679725646972656\n",
      "Epoch 2: iteration 853/2501 train_loss: 0.48552143573760986 time_taken: 0.05687260627746582\n",
      "Epoch 2: iteration 854/2501 train_loss: 0.48555293679237366 time_taken: 0.05640983581542969\n",
      "Epoch 2: iteration 855/2501 train_loss: 0.4855767786502838 time_taken: 0.0562744140625\n",
      "Epoch 2: iteration 856/2501 train_loss: 0.4856075644493103 time_taken: 0.056662559509277344\n",
      "Epoch 2: iteration 857/2501 train_loss: 0.4856412410736084 time_taken: 0.0570988655090332\n",
      "Epoch 2: iteration 858/2501 train_loss: 0.4856623411178589 time_taken: 0.05723738670349121\n",
      "Epoch 2: iteration 859/2501 train_loss: 0.48570236563682556 time_taken: 0.0568995475769043\n",
      "Epoch 2: iteration 860/2501 train_loss: 0.48575398325920105 time_taken: 0.05681633949279785\n",
      "Epoch 2: iteration 861/2501 train_loss: 0.48582884669303894 time_taken: 0.0569767951965332\n",
      "Epoch 2: iteration 862/2501 train_loss: 0.48589804768562317 time_taken: 0.05688905715942383\n",
      "Epoch 2: iteration 863/2501 train_loss: 0.4859595000743866 time_taken: 0.05689239501953125\n",
      "Epoch 2: iteration 864/2501 train_loss: 0.4860152304172516 time_taken: 0.056519269943237305\n",
      "Epoch 2: iteration 865/2501 train_loss: 0.4860694706439972 time_taken: 0.05671429634094238\n",
      "Epoch 2: iteration 866/2501 train_loss: 0.48612216114997864 time_taken: 0.05635190010070801\n",
      "Epoch 2: iteration 867/2501 train_loss: 0.48616689443588257 time_taken: 0.056731224060058594\n",
      "Epoch 2: iteration 868/2501 train_loss: 0.4862125515937805 time_taken: 0.05653834342956543\n",
      "Epoch 2: iteration 869/2501 train_loss: 0.48625102639198303 time_taken: 0.05703377723693848\n",
      "Epoch 2: iteration 870/2501 train_loss: 0.48630285263061523 time_taken: 0.05644416809082031\n",
      "Epoch 2: iteration 871/2501 train_loss: 0.48636046051979065 time_taken: 0.0569455623626709\n",
      "Epoch 2: iteration 872/2501 train_loss: 0.48642295598983765 time_taken: 0.056738853454589844\n",
      "Epoch 2: iteration 873/2501 train_loss: 0.48647481203079224 time_taken: 0.05662679672241211\n",
      "Epoch 2: iteration 874/2501 train_loss: 0.48652583360671997 time_taken: 0.05617547035217285\n",
      "Epoch 2: iteration 875/2501 train_loss: 0.48657742142677307 time_taken: 0.05658149719238281\n",
      "Epoch 2: iteration 876/2501 train_loss: 0.4866456091403961 time_taken: 0.05654335021972656\n",
      "Epoch 2: iteration 877/2501 train_loss: 0.4867067039012909 time_taken: 0.05640459060668945\n",
      "Epoch 2: iteration 878/2501 train_loss: 0.4867404103279114 time_taken: 0.05663251876831055\n",
      "Epoch 2: iteration 879/2501 train_loss: 0.48678940534591675 time_taken: 0.05662393569946289\n",
      "Epoch 2: iteration 880/2501 train_loss: 0.4868282079696655 time_taken: 0.0559694766998291\n",
      "Epoch 2: iteration 881/2501 train_loss: 0.4868851900100708 time_taken: 0.05841398239135742\n",
      "Epoch 2: iteration 882/2501 train_loss: 0.48695579171180725 time_taken: 0.06181955337524414\n",
      "Epoch 2: iteration 883/2501 train_loss: 0.48700621724128723 time_taken: 0.05715179443359375\n",
      "Epoch 2: iteration 884/2501 train_loss: 0.4870569705963135 time_taken: 0.05640554428100586\n",
      "Epoch 2: iteration 885/2501 train_loss: 0.48713481426239014 time_taken: 0.056832313537597656\n",
      "Epoch 2: iteration 886/2501 train_loss: 0.48718398809432983 time_taken: 0.056478023529052734\n",
      "Epoch 2: iteration 887/2501 train_loss: 0.4872239828109741 time_taken: 0.05686187744140625\n",
      "Epoch 2: iteration 888/2501 train_loss: 0.4872838258743286 time_taken: 0.06181740760803223\n",
      "Epoch 2: iteration 889/2501 train_loss: 0.487346887588501 time_taken: 0.05671215057373047\n",
      "Epoch 2: iteration 890/2501 train_loss: 0.4874410033226013 time_taken: 0.05734705924987793\n",
      "Epoch 2: iteration 891/2501 train_loss: 0.48750588297843933 time_taken: 0.05654335021972656\n",
      "Epoch 2: iteration 892/2501 train_loss: 0.4875849783420563 time_taken: 0.05648016929626465\n",
      "Epoch 2: iteration 893/2501 train_loss: 0.48761361837387085 time_taken: 0.056058645248413086\n",
      "Epoch 2: iteration 894/2501 train_loss: 0.48766466975212097 time_taken: 0.057322025299072266\n",
      "Epoch 2: iteration 895/2501 train_loss: 0.4876916706562042 time_taken: 0.056272268295288086\n",
      "Epoch 2: iteration 896/2501 train_loss: 0.4877178966999054 time_taken: 0.0560002326965332\n",
      "Epoch 2: iteration 897/2501 train_loss: 0.4877614974975586 time_taken: 0.05662369728088379\n",
      "Epoch 2: iteration 898/2501 train_loss: 0.4877588152885437 time_taken: 0.05632948875427246\n",
      "Epoch 2: iteration 899/2501 train_loss: 0.4877622127532959 time_taken: 0.056030988693237305\n",
      "Epoch 2: iteration 900/2501 train_loss: 0.48778530955314636 time_taken: 0.0575253963470459\n",
      "Epoch 2: iteration 901/2501 train_loss: 0.4878022074699402 time_taken: 0.05670809745788574\n",
      "Epoch 2: iteration 902/2501 train_loss: 0.4878281056880951 time_taken: 0.06061911582946777\n",
      "Epoch 2: iteration 903/2501 train_loss: 0.48783719539642334 time_taken: 0.057160377502441406\n",
      "Epoch 2: iteration 904/2501 train_loss: 0.4878486692905426 time_taken: 0.0561375617980957\n",
      "Epoch 2: iteration 905/2501 train_loss: 0.48784127831459045 time_taken: 0.056398630142211914\n",
      "Epoch 2: iteration 906/2501 train_loss: 0.4878295958042145 time_taken: 0.05635952949523926\n",
      "Epoch 2: iteration 907/2501 train_loss: 0.48781442642211914 time_taken: 0.0569310188293457\n",
      "Epoch 2: iteration 908/2501 train_loss: 0.4878190755844116 time_taken: 0.05658721923828125\n",
      "Epoch 2: iteration 909/2501 train_loss: 0.48781710863113403 time_taken: 0.057019710540771484\n",
      "Epoch 2: iteration 910/2501 train_loss: 0.4878610372543335 time_taken: 0.056198835372924805\n",
      "Epoch 2: iteration 911/2501 train_loss: 0.4879032075405121 time_taken: 0.056533098220825195\n",
      "Epoch 2: iteration 912/2501 train_loss: 0.48795071244239807 time_taken: 0.055735111236572266\n",
      "Epoch 2: iteration 913/2501 train_loss: 0.4880317151546478 time_taken: 0.05602765083312988\n",
      "Epoch 2: iteration 914/2501 train_loss: 0.4880887269973755 time_taken: 0.05607199668884277\n",
      "Epoch 2: iteration 915/2501 train_loss: 0.48815494775772095 time_taken: 0.057138919830322266\n",
      "Epoch 2: iteration 916/2501 train_loss: 0.4882281422615051 time_taken: 0.056891441345214844\n",
      "Epoch 2: iteration 917/2501 train_loss: 0.4883149564266205 time_taken: 0.056746721267700195\n",
      "Epoch 2: iteration 918/2501 train_loss: 0.48842594027519226 time_taken: 0.05689573287963867\n",
      "Epoch 2: iteration 919/2501 train_loss: 0.4885110855102539 time_taken: 0.05671429634094238\n",
      "Epoch 2: iteration 920/2501 train_loss: 0.4885565936565399 time_taken: 0.057907819747924805\n",
      "Epoch 2: iteration 921/2501 train_loss: 0.4886034429073334 time_taken: 0.05727720260620117\n",
      "Epoch 2: iteration 922/2501 train_loss: 0.4886471629142761 time_taken: 0.05697989463806152\n",
      "Epoch 2: iteration 923/2501 train_loss: 0.4886687397956848 time_taken: 0.05676412582397461\n",
      "Epoch 2: iteration 924/2501 train_loss: 0.4886666536331177 time_taken: 0.05687308311462402\n",
      "Epoch 2: iteration 925/2501 train_loss: 0.48867276310920715 time_taken: 0.056867122650146484\n",
      "Epoch 2: iteration 926/2501 train_loss: 0.4886406660079956 time_taken: 0.056593894958496094\n",
      "Epoch 2: iteration 927/2501 train_loss: 0.48859792947769165 time_taken: 0.05747056007385254\n",
      "Epoch 2: iteration 928/2501 train_loss: 0.4885680675506592 time_taken: 0.05736970901489258\n",
      "Epoch 2: iteration 929/2501 train_loss: 0.4884962737560272 time_taken: 0.057219743728637695\n",
      "Epoch 2: iteration 930/2501 train_loss: 0.48843538761138916 time_taken: 0.05666971206665039\n",
      "Epoch 2: iteration 931/2501 train_loss: 0.4883645474910736 time_taken: 0.0562441349029541\n",
      "Epoch 2: iteration 932/2501 train_loss: 0.48830369114875793 time_taken: 0.0565035343170166\n",
      "Epoch 2: iteration 933/2501 train_loss: 0.4882308542728424 time_taken: 0.056448936462402344\n",
      "Epoch 2: iteration 934/2501 train_loss: 0.48816171288490295 time_taken: 0.0564572811126709\n",
      "Epoch 2: iteration 935/2501 train_loss: 0.4880950152873993 time_taken: 0.05786633491516113\n",
      "Epoch 2: iteration 936/2501 train_loss: 0.48803654313087463 time_taken: 0.05696702003479004\n",
      "Epoch 2: iteration 937/2501 train_loss: 0.48797792196273804 time_taken: 0.05735635757446289\n",
      "Epoch 2: iteration 938/2501 train_loss: 0.4879350960254669 time_taken: 0.056218862533569336\n",
      "Epoch 2: iteration 939/2501 train_loss: 0.4878838360309601 time_taken: 0.05620408058166504\n",
      "Epoch 2: iteration 940/2501 train_loss: 0.48785698413848877 time_taken: 0.056874752044677734\n",
      "Epoch 2: iteration 941/2501 train_loss: 0.4878365397453308 time_taken: 0.05714583396911621\n",
      "Epoch 2: iteration 942/2501 train_loss: 0.4877796173095703 time_taken: 0.05733466148376465\n",
      "Epoch 2: iteration 943/2501 train_loss: 0.4877356290817261 time_taken: 0.05634164810180664\n",
      "Epoch 2: iteration 944/2501 train_loss: 0.4876940846443176 time_taken: 0.05667424201965332\n",
      "Epoch 2: iteration 945/2501 train_loss: 0.4876335859298706 time_taken: 0.05687570571899414\n",
      "Epoch 2: iteration 946/2501 train_loss: 0.4875859022140503 time_taken: 0.05681490898132324\n",
      "Epoch 2: iteration 947/2501 train_loss: 0.4875527620315552 time_taken: 0.05645585060119629\n",
      "Epoch 2: iteration 948/2501 train_loss: 0.48754140734672546 time_taken: 0.05691337585449219\n",
      "Epoch 2: iteration 949/2501 train_loss: 0.4875108003616333 time_taken: 0.055942535400390625\n",
      "Epoch 2: iteration 950/2501 train_loss: 0.48750337958335876 time_taken: 0.05626988410949707\n",
      "Epoch 2: iteration 951/2501 train_loss: 0.487498939037323 time_taken: 0.05804634094238281\n",
      "Epoch 2: iteration 952/2501 train_loss: 0.4874911308288574 time_taken: 0.057386159896850586\n",
      "Epoch 2: iteration 953/2501 train_loss: 0.4874885380268097 time_taken: 0.056444644927978516\n",
      "Epoch 2: iteration 954/2501 train_loss: 0.4874917268753052 time_taken: 0.056870460510253906\n",
      "Epoch 2: iteration 955/2501 train_loss: 0.4874928891658783 time_taken: 0.05682730674743652\n",
      "Epoch 2: iteration 956/2501 train_loss: 0.4875108599662781 time_taken: 0.056123971939086914\n",
      "Epoch 2: iteration 957/2501 train_loss: 0.4875263273715973 time_taken: 0.056517839431762695\n",
      "Epoch 2: iteration 958/2501 train_loss: 0.48753345012664795 time_taken: 0.056044816970825195\n",
      "Epoch 2: iteration 959/2501 train_loss: 0.487547367811203 time_taken: 0.05643177032470703\n",
      "Epoch 2: iteration 960/2501 train_loss: 0.48754656314849854 time_taken: 0.05590534210205078\n",
      "Epoch 2: iteration 961/2501 train_loss: 0.48754915595054626 time_taken: 0.06441116333007812\n",
      "Epoch 2: iteration 962/2501 train_loss: 0.4875877797603607 time_taken: 0.05710721015930176\n",
      "Epoch 2: iteration 963/2501 train_loss: 0.4876279830932617 time_taken: 0.056226491928100586\n",
      "Epoch 2: iteration 964/2501 train_loss: 0.48763570189476013 time_taken: 0.05684018135070801\n",
      "Epoch 2: iteration 965/2501 train_loss: 0.48767659068107605 time_taken: 0.05661916732788086\n",
      "Epoch 2: iteration 966/2501 train_loss: 0.4877178966999054 time_taken: 0.056535959243774414\n",
      "Epoch 2: iteration 967/2501 train_loss: 0.4877741038799286 time_taken: 0.05602765083312988\n",
      "Epoch 2: iteration 968/2501 train_loss: 0.4878380596637726 time_taken: 0.05640053749084473\n",
      "Epoch 2: iteration 969/2501 train_loss: 0.48788347840309143 time_taken: 0.05655646324157715\n",
      "Epoch 2: iteration 970/2501 train_loss: 0.4879382252693176 time_taken: 0.057779550552368164\n",
      "Epoch 2: iteration 971/2501 train_loss: 0.4879971444606781 time_taken: 0.05592751502990723\n",
      "Epoch 2: iteration 972/2501 train_loss: 0.48803582787513733 time_taken: 0.059095144271850586\n",
      "Epoch 2: iteration 973/2501 train_loss: 0.4880611002445221 time_taken: 0.05591464042663574\n",
      "Epoch 2: iteration 974/2501 train_loss: 0.4880928099155426 time_taken: 0.05595898628234863\n",
      "Epoch 2: iteration 975/2501 train_loss: 0.48812952637672424 time_taken: 0.056377410888671875\n",
      "Epoch 2: iteration 976/2501 train_loss: 0.4881502091884613 time_taken: 0.056487083435058594\n",
      "Epoch 2: iteration 977/2501 train_loss: 0.48815152049064636 time_taken: 0.0617368221282959\n",
      "Epoch 2: iteration 978/2501 train_loss: 0.48815956711769104 time_taken: 0.05614113807678223\n",
      "Epoch 2: iteration 979/2501 train_loss: 0.48814767599105835 time_taken: 0.05644679069519043\n",
      "Epoch 2: iteration 980/2501 train_loss: 0.4881543517112732 time_taken: 0.06129860877990723\n",
      "Epoch 2: iteration 981/2501 train_loss: 0.48816218972206116 time_taken: 0.05604290962219238\n",
      "Epoch 2: iteration 982/2501 train_loss: 0.4881816804409027 time_taken: 0.05605125427246094\n",
      "Epoch 2: iteration 983/2501 train_loss: 0.4881897270679474 time_taken: 0.05667710304260254\n",
      "Epoch 2: iteration 984/2501 train_loss: 0.4881787598133087 time_taken: 0.05696249008178711\n",
      "Epoch 2: iteration 985/2501 train_loss: 0.48816823959350586 time_taken: 0.05716204643249512\n",
      "Epoch 2: iteration 986/2501 train_loss: 0.4881711006164551 time_taken: 0.057488441467285156\n",
      "Epoch 2: iteration 987/2501 train_loss: 0.48820266127586365 time_taken: 0.05678248405456543\n",
      "Epoch 2: iteration 988/2501 train_loss: 0.48820438981056213 time_taken: 0.057508230209350586\n",
      "Epoch 2: iteration 989/2501 train_loss: 0.48821350932121277 time_taken: 0.0568537712097168\n",
      "Epoch 2: iteration 990/2501 train_loss: 0.48822668194770813 time_taken: 0.057425498962402344\n",
      "Epoch 2: iteration 991/2501 train_loss: 0.4882458448410034 time_taken: 0.0569303035736084\n",
      "Epoch 2: iteration 992/2501 train_loss: 0.48828399181365967 time_taken: 0.05668067932128906\n",
      "Epoch 2: iteration 993/2501 train_loss: 0.4883243441581726 time_taken: 0.05668330192565918\n",
      "Epoch 2: iteration 994/2501 train_loss: 0.4883636236190796 time_taken: 0.07129621505737305\n",
      "Epoch 2: iteration 995/2501 train_loss: 0.48841172456741333 time_taken: 0.07147812843322754\n",
      "Epoch 2: iteration 996/2501 train_loss: 0.4884684681892395 time_taken: 0.05721712112426758\n",
      "Epoch 2: iteration 997/2501 train_loss: 0.48851317167282104 time_taken: 0.056526899337768555\n",
      "Epoch 2: iteration 998/2501 train_loss: 0.48853668570518494 time_taken: 0.05599784851074219\n",
      "Epoch 2: iteration 999/2501 train_loss: 0.48855289816856384 time_taken: 0.05648493766784668\n",
      "Epoch 2: iteration 1000/2501 train_loss: 0.48857614398002625 time_taken: 0.05704307556152344\n",
      "Epoch 2: iteration 1001/2501 train_loss: 0.48857030272483826 time_taken: 0.05637693405151367\n",
      "Epoch 2: iteration 1002/2501 train_loss: 0.48857229948043823 time_taken: 0.05666470527648926\n",
      "Epoch 2: iteration 1003/2501 train_loss: 0.4885615408420563 time_taken: 0.05669379234313965\n",
      "Epoch 2: iteration 1004/2501 train_loss: 0.4885528087615967 time_taken: 0.056452035903930664\n",
      "Epoch 2: iteration 1005/2501 train_loss: 0.4885353147983551 time_taken: 0.056644439697265625\n",
      "Epoch 2: iteration 1006/2501 train_loss: 0.48850658535957336 time_taken: 0.057172536849975586\n",
      "Epoch 2: iteration 1007/2501 train_loss: 0.4884873628616333 time_taken: 0.056677818298339844\n",
      "Epoch 2: iteration 1008/2501 train_loss: 0.48843464255332947 time_taken: 0.057093143463134766\n",
      "Epoch 2: iteration 1009/2501 train_loss: 0.4883725643157959 time_taken: 0.0567471981048584\n",
      "Epoch 2: iteration 1010/2501 train_loss: 0.48832690715789795 time_taken: 0.05811190605163574\n",
      "Epoch 2: iteration 1011/2501 train_loss: 0.4882526397705078 time_taken: 0.05637383460998535\n",
      "Epoch 2: iteration 1012/2501 train_loss: 0.4881773889064789 time_taken: 0.05677938461303711\n",
      "Epoch 2: iteration 1013/2501 train_loss: 0.4880927503108978 time_taken: 0.05713009834289551\n",
      "Epoch 2: iteration 1014/2501 train_loss: 0.48800474405288696 time_taken: 0.056783437728881836\n",
      "Epoch 2: iteration 1015/2501 train_loss: 0.48793792724609375 time_taken: 0.05720877647399902\n",
      "Epoch 2: iteration 1016/2501 train_loss: 0.4878850281238556 time_taken: 0.055997371673583984\n",
      "Epoch 2: iteration 1017/2501 train_loss: 0.48784542083740234 time_taken: 0.05617523193359375\n",
      "Epoch 2: iteration 1018/2501 train_loss: 0.4878033399581909 time_taken: 0.057050228118896484\n",
      "Epoch 2: iteration 1019/2501 train_loss: 0.4877716898918152 time_taken: 0.0562739372253418\n",
      "Epoch 2: iteration 1020/2501 train_loss: 0.4877680540084839 time_taken: 0.05637526512145996\n",
      "Epoch 2: iteration 1021/2501 train_loss: 0.4877660870552063 time_taken: 0.05693697929382324\n",
      "Epoch 2: iteration 1022/2501 train_loss: 0.4877823293209076 time_taken: 0.0561978816986084\n",
      "Epoch 2: iteration 1023/2501 train_loss: 0.4877919852733612 time_taken: 0.0568079948425293\n",
      "Epoch 2: iteration 1024/2501 train_loss: 0.48783478140830994 time_taken: 0.05690169334411621\n",
      "Epoch 2: iteration 1025/2501 train_loss: 0.48786795139312744 time_taken: 0.08800578117370605\n",
      "Epoch 2: iteration 1026/2501 train_loss: 0.4878949522972107 time_taken: 0.056830406188964844\n",
      "Epoch 2: iteration 1027/2501 train_loss: 0.48790255188941956 time_taken: 0.0711824893951416\n",
      "Epoch 2: iteration 1028/2501 train_loss: 0.4879195988178253 time_taken: 0.0641169548034668\n",
      "Epoch 2: iteration 1029/2501 train_loss: 0.48792046308517456 time_taken: 0.057010650634765625\n",
      "Epoch 2: iteration 1030/2501 train_loss: 0.48791417479515076 time_taken: 0.05761098861694336\n",
      "Epoch 2: iteration 1031/2501 train_loss: 0.4879021942615509 time_taken: 0.05692291259765625\n",
      "Epoch 2: iteration 1032/2501 train_loss: 0.4878964424133301 time_taken: 0.05670595169067383\n",
      "Epoch 2: iteration 1033/2501 train_loss: 0.48789286613464355 time_taken: 0.0572056770324707\n",
      "Epoch 2: iteration 1034/2501 train_loss: 0.48787036538124084 time_taken: 0.05677175521850586\n",
      "Epoch 2: iteration 1035/2501 train_loss: 0.48783114552497864 time_taken: 0.05741620063781738\n",
      "Epoch 2: iteration 1036/2501 train_loss: 0.4877859055995941 time_taken: 0.056067466735839844\n",
      "Epoch 2: iteration 1037/2501 train_loss: 0.4877331256866455 time_taken: 0.05694866180419922\n",
      "Epoch 2: iteration 1038/2501 train_loss: 0.4876752495765686 time_taken: 0.056217193603515625\n",
      "Epoch 2: iteration 1039/2501 train_loss: 0.4876091778278351 time_taken: 0.05711722373962402\n",
      "Epoch 2: iteration 1040/2501 train_loss: 0.48754072189331055 time_taken: 0.05696749687194824\n",
      "Epoch 2: iteration 1041/2501 train_loss: 0.48747512698173523 time_taken: 0.056772708892822266\n",
      "Epoch 2: iteration 1042/2501 train_loss: 0.48740628361701965 time_taken: 0.0565030574798584\n",
      "Epoch 2: iteration 1043/2501 train_loss: 0.4873405396938324 time_taken: 0.05671548843383789\n",
      "Epoch 2: iteration 1044/2501 train_loss: 0.4872967004776001 time_taken: 0.05720233917236328\n",
      "Epoch 2: iteration 1045/2501 train_loss: 0.48723793029785156 time_taken: 0.05666971206665039\n",
      "Epoch 2: iteration 1046/2501 train_loss: 0.487191766500473 time_taken: 0.0561833381652832\n",
      "Epoch 2: iteration 1047/2501 train_loss: 0.4871453046798706 time_taken: 0.05690598487854004\n",
      "Epoch 2: iteration 1048/2501 train_loss: 0.48712342977523804 time_taken: 0.056452035903930664\n",
      "Epoch 2: iteration 1049/2501 train_loss: 0.48708605766296387 time_taken: 0.05690193176269531\n",
      "Epoch 2: iteration 1050/2501 train_loss: 0.48705336451530457 time_taken: 0.05652499198913574\n",
      "Epoch 2: iteration 1051/2501 train_loss: 0.4870169162750244 time_taken: 0.0562281608581543\n",
      "Epoch 2: iteration 1052/2501 train_loss: 0.48699575662612915 time_taken: 0.057149648666381836\n",
      "Epoch 2: iteration 1053/2501 train_loss: 0.48698440194129944 time_taken: 0.057038307189941406\n",
      "Epoch 2: iteration 1054/2501 train_loss: 0.4869864881038666 time_taken: 0.05788087844848633\n",
      "Epoch 2: iteration 1055/2501 train_loss: 0.48699888586997986 time_taken: 0.05712461471557617\n",
      "Epoch 2: iteration 1056/2501 train_loss: 0.4870184659957886 time_taken: 0.05711555480957031\n",
      "Epoch 2: iteration 1057/2501 train_loss: 0.4870424270629883 time_taken: 0.05725288391113281\n",
      "Epoch 2: iteration 1058/2501 train_loss: 0.48707103729248047 time_taken: 0.05609893798828125\n",
      "Epoch 2: iteration 1059/2501 train_loss: 0.4870925545692444 time_taken: 0.056396484375\n",
      "Epoch 2: iteration 1060/2501 train_loss: 0.48710551857948303 time_taken: 0.05626034736633301\n",
      "Epoch 2: iteration 1061/2501 train_loss: 0.48713019490242004 time_taken: 0.05675148963928223\n",
      "Epoch 2: iteration 1062/2501 train_loss: 0.487150639295578 time_taken: 0.05650925636291504\n",
      "Epoch 2: iteration 1063/2501 train_loss: 0.4871870279312134 time_taken: 0.056795597076416016\n",
      "Epoch 2: iteration 1064/2501 train_loss: 0.48722267150878906 time_taken: 0.0563349723815918\n",
      "Epoch 2: iteration 1065/2501 train_loss: 0.48725625872612 time_taken: 0.056508779525756836\n",
      "Epoch 2: iteration 1066/2501 train_loss: 0.48731034994125366 time_taken: 0.05645489692687988\n",
      "Epoch 2: iteration 1067/2501 train_loss: 0.4873642325401306 time_taken: 0.05649423599243164\n",
      "Epoch 2: iteration 1068/2501 train_loss: 0.4874114692211151 time_taken: 0.05669236183166504\n",
      "Epoch 2: iteration 1069/2501 train_loss: 0.48744404315948486 time_taken: 0.05645322799682617\n",
      "Epoch 2: iteration 1070/2501 train_loss: 0.48747724294662476 time_taken: 0.0564272403717041\n",
      "Epoch 2: iteration 1071/2501 train_loss: 0.4875093102455139 time_taken: 0.056864023208618164\n",
      "Epoch 2: iteration 1072/2501 train_loss: 0.48754650354385376 time_taken: 0.056563377380371094\n",
      "Epoch 2: iteration 1073/2501 train_loss: 0.487582802772522 time_taken: 0.0564875602722168\n",
      "Epoch 2: iteration 1074/2501 train_loss: 0.4876241087913513 time_taken: 0.05656766891479492\n",
      "Epoch 2: iteration 1075/2501 train_loss: 0.4876551926136017 time_taken: 0.05681180953979492\n",
      "Epoch 2: iteration 1076/2501 train_loss: 0.48771148920059204 time_taken: 0.05674433708190918\n",
      "Epoch 2: iteration 1077/2501 train_loss: 0.48775243759155273 time_taken: 0.05652618408203125\n",
      "Epoch 2: iteration 1078/2501 train_loss: 0.48778390884399414 time_taken: 0.05700564384460449\n",
      "Epoch 2: iteration 1079/2501 train_loss: 0.48784440755844116 time_taken: 0.05705881118774414\n",
      "Epoch 2: iteration 1080/2501 train_loss: 0.48787185549736023 time_taken: 0.05753588676452637\n",
      "Epoch 2: iteration 1081/2501 train_loss: 0.48794278502464294 time_taken: 0.05701398849487305\n",
      "Epoch 2: iteration 1082/2501 train_loss: 0.48800531029701233 time_taken: 0.056616783142089844\n",
      "Epoch 2: iteration 1083/2501 train_loss: 0.4880738854408264 time_taken: 0.05644869804382324\n",
      "Epoch 2: iteration 1084/2501 train_loss: 0.48814743757247925 time_taken: 0.0567927360534668\n",
      "Epoch 2: iteration 1085/2501 train_loss: 0.48821908235549927 time_taken: 0.05669450759887695\n",
      "Epoch 2: iteration 1086/2501 train_loss: 0.4882785677909851 time_taken: 0.05643033981323242\n",
      "Epoch 2: iteration 1087/2501 train_loss: 0.48835569620132446 time_taken: 0.05678367614746094\n",
      "Epoch 2: iteration 1088/2501 train_loss: 0.488431453704834 time_taken: 0.0569915771484375\n",
      "Epoch 2: iteration 1089/2501 train_loss: 0.48850104212760925 time_taken: 0.05711174011230469\n",
      "Epoch 2: iteration 1090/2501 train_loss: 0.488556832075119 time_taken: 0.05709099769592285\n",
      "Epoch 2: iteration 1091/2501 train_loss: 0.48861950635910034 time_taken: 0.05656075477600098\n",
      "Epoch 2: iteration 1092/2501 train_loss: 0.4886611998081207 time_taken: 0.05715656280517578\n",
      "Epoch 2: iteration 1093/2501 train_loss: 0.4887135624885559 time_taken: 0.0562283992767334\n",
      "Epoch 2: iteration 1094/2501 train_loss: 0.4887693226337433 time_taken: 0.061786651611328125\n",
      "Epoch 2: iteration 1095/2501 train_loss: 0.4888215959072113 time_taken: 0.05685901641845703\n",
      "Epoch 2: iteration 1096/2501 train_loss: 0.4888642728328705 time_taken: 0.05741572380065918\n",
      "Epoch 2: iteration 1097/2501 train_loss: 0.4889117181301117 time_taken: 0.056817054748535156\n",
      "Epoch 2: iteration 1098/2501 train_loss: 0.48893797397613525 time_taken: 0.05686068534851074\n",
      "Epoch 2: iteration 1099/2501 train_loss: 0.48898494243621826 time_taken: 0.05735611915588379\n",
      "Epoch 2: iteration 1100/2501 train_loss: 0.48903191089630127 time_taken: 0.05676865577697754\n",
      "Epoch 2: iteration 1101/2501 train_loss: 0.4890703856945038 time_taken: 0.05742597579956055\n",
      "Epoch 2: iteration 1102/2501 train_loss: 0.48909538984298706 time_taken: 0.05777549743652344\n",
      "Epoch 2: iteration 1103/2501 train_loss: 0.48911118507385254 time_taken: 0.057024240493774414\n",
      "Epoch 2: iteration 1104/2501 train_loss: 0.4891381859779358 time_taken: 0.05728459358215332\n",
      "Epoch 2: iteration 1105/2501 train_loss: 0.48915427923202515 time_taken: 0.057547807693481445\n",
      "Epoch 2: iteration 1106/2501 train_loss: 0.48918265104293823 time_taken: 0.056664228439331055\n",
      "Epoch 2: iteration 1107/2501 train_loss: 0.48920100927352905 time_taken: 0.0565190315246582\n",
      "Epoch 2: iteration 1108/2501 train_loss: 0.4892231523990631 time_taken: 0.05765056610107422\n",
      "Epoch 2: iteration 1109/2501 train_loss: 0.4892505407333374 time_taken: 0.057775020599365234\n",
      "Epoch 2: iteration 1110/2501 train_loss: 0.4892752170562744 time_taken: 0.057042837142944336\n",
      "Epoch 2: iteration 1111/2501 train_loss: 0.4893067181110382 time_taken: 0.05650806427001953\n",
      "Epoch 2: iteration 1112/2501 train_loss: 0.4893319606781006 time_taken: 0.0568242073059082\n",
      "Epoch 2: iteration 1113/2501 train_loss: 0.48936575651168823 time_taken: 0.05632185935974121\n",
      "Epoch 2: iteration 1114/2501 train_loss: 0.4893985092639923 time_taken: 0.05673575401306152\n",
      "Epoch 2: iteration 1115/2501 train_loss: 0.48941871523857117 time_taken: 0.05693554878234863\n",
      "Epoch 2: iteration 1116/2501 train_loss: 0.48945802450180054 time_taken: 0.057129859924316406\n",
      "Epoch 2: iteration 1117/2501 train_loss: 0.48948732018470764 time_taken: 0.05768394470214844\n",
      "Epoch 2: iteration 1118/2501 train_loss: 0.48951759934425354 time_taken: 0.05726742744445801\n",
      "Epoch 2: iteration 1119/2501 train_loss: 0.4895188510417938 time_taken: 0.05658125877380371\n",
      "Epoch 2: iteration 1120/2501 train_loss: 0.48954588174819946 time_taken: 0.057187557220458984\n",
      "Epoch 2: iteration 1121/2501 train_loss: 0.4895651042461395 time_taken: 0.056276559829711914\n",
      "Epoch 2: iteration 1122/2501 train_loss: 0.48959842324256897 time_taken: 0.05658602714538574\n",
      "Epoch 2: iteration 1123/2501 train_loss: 0.4896109998226166 time_taken: 0.05689096450805664\n",
      "Epoch 2: iteration 1124/2501 train_loss: 0.48963692784309387 time_taken: 0.05658221244812012\n",
      "Epoch 2: iteration 1125/2501 train_loss: 0.4896567165851593 time_taken: 0.056832313537597656\n",
      "Epoch 2: iteration 1126/2501 train_loss: 0.48968786001205444 time_taken: 0.05654311180114746\n",
      "Epoch 2: iteration 1127/2501 train_loss: 0.489717572927475 time_taken: 0.05684065818786621\n",
      "Epoch 2: iteration 1128/2501 train_loss: 0.48975956439971924 time_taken: 0.05711054801940918\n",
      "Epoch 2: iteration 1129/2501 train_loss: 0.48979634046554565 time_taken: 0.05628466606140137\n",
      "Epoch 2: iteration 1130/2501 train_loss: 0.4898417890071869 time_taken: 0.05746102333068848\n",
      "Epoch 2: iteration 1131/2501 train_loss: 0.4898710250854492 time_taken: 0.056601762771606445\n",
      "Epoch 2: iteration 1132/2501 train_loss: 0.4899075925350189 time_taken: 0.05641746520996094\n",
      "Epoch 2: iteration 1133/2501 train_loss: 0.48993387818336487 time_taken: 0.05625009536743164\n",
      "Epoch 2: iteration 1134/2501 train_loss: 0.4899827539920807 time_taken: 0.05613517761230469\n",
      "Epoch 2: iteration 1135/2501 train_loss: 0.4900330603122711 time_taken: 0.05692028999328613\n",
      "Epoch 2: iteration 1136/2501 train_loss: 0.49008703231811523 time_taken: 0.05608654022216797\n",
      "Epoch 2: iteration 1137/2501 train_loss: 0.4901331663131714 time_taken: 0.056437015533447266\n",
      "Epoch 2: iteration 1138/2501 train_loss: 0.4901716709136963 time_taken: 0.056554555892944336\n",
      "Epoch 2: iteration 1139/2501 train_loss: 0.49018731713294983 time_taken: 0.05681920051574707\n",
      "Epoch 2: iteration 1140/2501 train_loss: 0.4901989698410034 time_taken: 0.05632472038269043\n",
      "Epoch 2: iteration 1141/2501 train_loss: 0.49020999670028687 time_taken: 0.05680346488952637\n",
      "Epoch 2: iteration 1142/2501 train_loss: 0.4902150332927704 time_taken: 0.056536197662353516\n",
      "Epoch 2: iteration 1143/2501 train_loss: 0.4902022182941437 time_taken: 0.057468414306640625\n",
      "Epoch 2: iteration 1144/2501 train_loss: 0.49017301201820374 time_taken: 0.05675506591796875\n",
      "Epoch 2: iteration 1145/2501 train_loss: 0.4901316463947296 time_taken: 0.05668926239013672\n",
      "Epoch 2: iteration 1146/2501 train_loss: 0.4900750517845154 time_taken: 0.05709409713745117\n",
      "Epoch 2: iteration 1147/2501 train_loss: 0.4900205433368683 time_taken: 0.05771613121032715\n",
      "Epoch 2: iteration 1148/2501 train_loss: 0.48996788263320923 time_taken: 0.056310415267944336\n",
      "Epoch 2: iteration 1149/2501 train_loss: 0.4898931086063385 time_taken: 0.05622673034667969\n",
      "Epoch 2: iteration 1150/2501 train_loss: 0.4898098409175873 time_taken: 0.056903839111328125\n",
      "Epoch 2: iteration 1151/2501 train_loss: 0.48971590399742126 time_taken: 0.05672955513000488\n",
      "Epoch 2: iteration 1152/2501 train_loss: 0.4896133244037628 time_taken: 0.057179927825927734\n",
      "Epoch 2: iteration 1153/2501 train_loss: 0.4895206093788147 time_taken: 0.0561060905456543\n",
      "Epoch 2: iteration 1154/2501 train_loss: 0.4894280731678009 time_taken: 0.05631446838378906\n",
      "Epoch 2: iteration 1155/2501 train_loss: 0.4893364906311035 time_taken: 0.05612468719482422\n",
      "Epoch 2: iteration 1156/2501 train_loss: 0.489270955324173 time_taken: 0.057176828384399414\n",
      "Epoch 2: iteration 1157/2501 train_loss: 0.48922377824783325 time_taken: 0.05628800392150879\n",
      "Epoch 2: iteration 1158/2501 train_loss: 0.4891863465309143 time_taken: 0.057822227478027344\n",
      "Epoch 2: iteration 1159/2501 train_loss: 0.48916536569595337 time_taken: 0.0563204288482666\n",
      "Epoch 2: iteration 1160/2501 train_loss: 0.4891626536846161 time_taken: 0.057251691818237305\n",
      "Epoch 2: iteration 1161/2501 train_loss: 0.48914235830307007 time_taken: 0.05749392509460449\n",
      "Epoch 2: iteration 1162/2501 train_loss: 0.48912954330444336 time_taken: 0.05806398391723633\n",
      "Epoch 2: iteration 1163/2501 train_loss: 0.48911145329475403 time_taken: 0.05676102638244629\n",
      "Epoch 2: iteration 1164/2501 train_loss: 0.4891035854816437 time_taken: 0.056850433349609375\n",
      "Epoch 2: iteration 1165/2501 train_loss: 0.48909416794776917 time_taken: 0.05676746368408203\n",
      "Epoch 2: iteration 1166/2501 train_loss: 0.48907989263534546 time_taken: 0.056859493255615234\n",
      "Epoch 2: iteration 1167/2501 train_loss: 0.4890631139278412 time_taken: 0.056452035903930664\n",
      "Epoch 2: iteration 1168/2501 train_loss: 0.48908132314682007 time_taken: 0.05675768852233887\n",
      "Epoch 2: iteration 1169/2501 train_loss: 0.48910555243492126 time_taken: 0.056984901428222656\n",
      "Epoch 2: iteration 1170/2501 train_loss: 0.4891189634799957 time_taken: 0.05821967124938965\n",
      "Epoch 2: iteration 1171/2501 train_loss: 0.4891314208507538 time_taken: 0.05685853958129883\n",
      "Epoch 2: iteration 1172/2501 train_loss: 0.4891594648361206 time_taken: 0.0569303035736084\n",
      "Epoch 2: iteration 1173/2501 train_loss: 0.48919713497161865 time_taken: 0.05678534507751465\n",
      "Epoch 2: iteration 1174/2501 train_loss: 0.48922690749168396 time_taken: 0.05657649040222168\n",
      "Epoch 2: iteration 1175/2501 train_loss: 0.48928189277648926 time_taken: 0.05637979507446289\n",
      "Epoch 2: iteration 1176/2501 train_loss: 0.4893382489681244 time_taken: 0.05677366256713867\n",
      "Epoch 2: iteration 1177/2501 train_loss: 0.4893987476825714 time_taken: 0.057381391525268555\n",
      "Epoch 2: iteration 1178/2501 train_loss: 0.4894340932369232 time_taken: 0.056435585021972656\n",
      "Epoch 2: iteration 1179/2501 train_loss: 0.4894724190235138 time_taken: 0.05659341812133789\n",
      "Epoch 2: iteration 1180/2501 train_loss: 0.4894903898239136 time_taken: 0.057940006256103516\n",
      "Epoch 2: iteration 1181/2501 train_loss: 0.4895073175430298 time_taken: 0.05723142623901367\n",
      "Epoch 2: iteration 1182/2501 train_loss: 0.4895259439945221 time_taken: 0.05679178237915039\n",
      "Epoch 2: iteration 1183/2501 train_loss: 0.4895356595516205 time_taken: 0.05696582794189453\n",
      "Epoch 2: iteration 1184/2501 train_loss: 0.4895448684692383 time_taken: 0.05716395378112793\n",
      "Epoch 2: iteration 1185/2501 train_loss: 0.48956865072250366 time_taken: 0.07085990905761719\n",
      "Epoch 2: iteration 1186/2501 train_loss: 0.48960036039352417 time_taken: 0.07320833206176758\n",
      "Epoch 2: iteration 1187/2501 train_loss: 0.489628404378891 time_taken: 0.05659914016723633\n",
      "Epoch 2: iteration 1188/2501 train_loss: 0.48964646458625793 time_taken: 0.056766510009765625\n",
      "Epoch 2: iteration 1189/2501 train_loss: 0.48967140913009644 time_taken: 0.05669426918029785\n",
      "Epoch 2: iteration 1190/2501 train_loss: 0.48968127369880676 time_taken: 0.05736064910888672\n",
      "Epoch 2: iteration 1191/2501 train_loss: 0.4896847903728485 time_taken: 0.05699419975280762\n",
      "Epoch 2: iteration 1192/2501 train_loss: 0.4896806478500366 time_taken: 0.056659698486328125\n",
      "Epoch 2: iteration 1193/2501 train_loss: 0.48968014121055603 time_taken: 0.05644583702087402\n",
      "Epoch 2: iteration 1194/2501 train_loss: 0.4896692633628845 time_taken: 0.0569310188293457\n",
      "Epoch 2: iteration 1195/2501 train_loss: 0.4896427094936371 time_taken: 0.057347774505615234\n",
      "Epoch 2: iteration 1196/2501 train_loss: 0.48962146043777466 time_taken: 0.05704998970031738\n",
      "Epoch 2: iteration 1197/2501 train_loss: 0.4895954430103302 time_taken: 0.056441307067871094\n",
      "Epoch 2: iteration 1198/2501 train_loss: 0.4895741939544678 time_taken: 0.056197166442871094\n",
      "Epoch 2: iteration 1199/2501 train_loss: 0.48956307768821716 time_taken: 0.0567326545715332\n",
      "Epoch 2: iteration 1200/2501 train_loss: 0.48955291509628296 time_taken: 0.056638240814208984\n",
      "Epoch 2: iteration 1201/2501 train_loss: 0.4895440936088562 time_taken: 0.0568089485168457\n",
      "Epoch 2: iteration 1202/2501 train_loss: 0.489531546831131 time_taken: 0.056676626205444336\n",
      "Epoch 2: iteration 1203/2501 train_loss: 0.4895363748073578 time_taken: 0.056691884994506836\n",
      "Epoch 2: iteration 1204/2501 train_loss: 0.48952749371528625 time_taken: 0.056902408599853516\n",
      "Epoch 2: iteration 1205/2501 train_loss: 0.4895482063293457 time_taken: 0.05637216567993164\n",
      "Epoch 2: iteration 1206/2501 train_loss: 0.4895707368850708 time_taken: 0.05666971206665039\n",
      "Epoch 2: iteration 1207/2501 train_loss: 0.48958972096443176 time_taken: 0.056524038314819336\n",
      "Epoch 2: iteration 1208/2501 train_loss: 0.4896200895309448 time_taken: 0.05666685104370117\n",
      "Epoch 2: iteration 1209/2501 train_loss: 0.4896458685398102 time_taken: 0.056734323501586914\n",
      "Epoch 2: iteration 1210/2501 train_loss: 0.489670991897583 time_taken: 0.05646157264709473\n",
      "Epoch 2: iteration 1211/2501 train_loss: 0.4896911382675171 time_taken: 0.05612516403198242\n",
      "Epoch 2: iteration 1212/2501 train_loss: 0.48971253633499146 time_taken: 0.05646371841430664\n",
      "Epoch 2: iteration 1213/2501 train_loss: 0.4897438883781433 time_taken: 0.05609941482543945\n",
      "Epoch 2: iteration 1214/2501 train_loss: 0.4897993803024292 time_taken: 0.056183576583862305\n",
      "Epoch 2: iteration 1215/2501 train_loss: 0.4898556172847748 time_taken: 0.05630946159362793\n",
      "Epoch 2: iteration 1216/2501 train_loss: 0.489915668964386 time_taken: 0.05649209022521973\n",
      "Epoch 2: iteration 1217/2501 train_loss: 0.48997941613197327 time_taken: 0.05706071853637695\n",
      "Epoch 2: iteration 1218/2501 train_loss: 0.49005287885665894 time_taken: 0.05641031265258789\n",
      "Epoch 2: iteration 1219/2501 train_loss: 0.4901033043861389 time_taken: 0.05768179893493652\n",
      "Epoch 2: iteration 1220/2501 train_loss: 0.49015185236930847 time_taken: 0.05672430992126465\n",
      "Epoch 2: iteration 1221/2501 train_loss: 0.4901913106441498 time_taken: 0.056644439697265625\n",
      "Epoch 2: iteration 1222/2501 train_loss: 0.49023768305778503 time_taken: 0.05671429634094238\n",
      "Epoch 2: iteration 1223/2501 train_loss: 0.49027350544929504 time_taken: 0.05626273155212402\n",
      "Epoch 2: iteration 1224/2501 train_loss: 0.4903021454811096 time_taken: 0.05685305595397949\n",
      "Epoch 2: iteration 1225/2501 train_loss: 0.4903421103954315 time_taken: 0.05720806121826172\n",
      "Epoch 2: iteration 1226/2501 train_loss: 0.4903887212276459 time_taken: 0.0565645694732666\n",
      "Epoch 2: iteration 1227/2501 train_loss: 0.4904419481754303 time_taken: 0.05620884895324707\n",
      "Epoch 2: iteration 1228/2501 train_loss: 0.4904869496822357 time_taken: 0.05633735656738281\n",
      "Epoch 2: iteration 1229/2501 train_loss: 0.4905473291873932 time_taken: 0.05636739730834961\n",
      "Epoch 2: iteration 1230/2501 train_loss: 0.4905892312526703 time_taken: 0.05656838417053223\n",
      "Epoch 2: iteration 1231/2501 train_loss: 0.4906380772590637 time_taken: 0.05626058578491211\n",
      "Epoch 2: iteration 1232/2501 train_loss: 0.4906914234161377 time_taken: 0.056531667709350586\n",
      "Epoch 2: iteration 1233/2501 train_loss: 0.49073129892349243 time_taken: 0.05606412887573242\n",
      "Epoch 2: iteration 1234/2501 train_loss: 0.4907897114753723 time_taken: 0.05624651908874512\n",
      "Epoch 2: iteration 1235/2501 train_loss: 0.4908562898635864 time_taken: 0.05659294128417969\n",
      "Epoch 2: iteration 1236/2501 train_loss: 0.4909193217754364 time_taken: 0.0567629337310791\n",
      "Epoch 2: iteration 1237/2501 train_loss: 0.4909821152687073 time_taken: 0.05650973320007324\n",
      "Epoch 2: iteration 1238/2501 train_loss: 0.49104011058807373 time_taken: 0.057279109954833984\n",
      "Epoch 2: iteration 1239/2501 train_loss: 0.49109044671058655 time_taken: 0.05685544013977051\n",
      "Epoch 2: iteration 1240/2501 train_loss: 0.4911341667175293 time_taken: 0.05841779708862305\n",
      "Epoch 2: iteration 1241/2501 train_loss: 0.4911704361438751 time_taken: 0.05652022361755371\n",
      "Epoch 2: iteration 1242/2501 train_loss: 0.49120989441871643 time_taken: 0.05823230743408203\n",
      "Epoch 2: iteration 1243/2501 train_loss: 0.4912381172180176 time_taken: 0.05670976638793945\n",
      "Epoch 2: iteration 1244/2501 train_loss: 0.49125584959983826 time_taken: 0.05654406547546387\n",
      "Epoch 2: iteration 1245/2501 train_loss: 0.4912817180156708 time_taken: 0.056130170822143555\n",
      "Epoch 2: iteration 1246/2501 train_loss: 0.49129918217658997 time_taken: 0.056092023849487305\n",
      "Epoch 2: iteration 1247/2501 train_loss: 0.49131426215171814 time_taken: 0.06267762184143066\n",
      "Epoch 2: iteration 1248/2501 train_loss: 0.4913308918476105 time_taken: 0.05654716491699219\n",
      "Epoch 2: iteration 1249/2501 train_loss: 0.49136361479759216 time_taken: 0.056291818618774414\n",
      "Epoch 2: iteration 1250/2501 train_loss: 0.49138355255126953 time_taken: 0.056322336196899414\n",
      "Epoch 2: iteration 1251/2501 train_loss: 0.4914119243621826 time_taken: 0.05656027793884277\n",
      "Epoch 2: iteration 1252/2501 train_loss: 0.49144062399864197 time_taken: 0.05629920959472656\n",
      "Epoch 2: iteration 1253/2501 train_loss: 0.4914805293083191 time_taken: 0.05620622634887695\n",
      "Epoch 2: iteration 1254/2501 train_loss: 0.4915086328983307 time_taken: 0.05639362335205078\n",
      "Epoch 2: iteration 1255/2501 train_loss: 0.4915287494659424 time_taken: 0.05992388725280762\n",
      "Epoch 2: iteration 1256/2501 train_loss: 0.49155592918395996 time_taken: 0.05605363845825195\n",
      "Epoch 2: iteration 1257/2501 train_loss: 0.4915660321712494 time_taken: 0.059099674224853516\n",
      "Epoch 2: iteration 1258/2501 train_loss: 0.4915710389614105 time_taken: 0.0560307502746582\n",
      "Epoch 2: iteration 1259/2501 train_loss: 0.49156978726387024 time_taken: 0.05785083770751953\n",
      "Epoch 2: iteration 1260/2501 train_loss: 0.4915688633918762 time_taken: 0.05745387077331543\n",
      "Epoch 2: iteration 1261/2501 train_loss: 0.4915551543235779 time_taken: 0.05902242660522461\n",
      "Epoch 2: iteration 1262/2501 train_loss: 0.4915408492088318 time_taken: 0.056725502014160156\n",
      "Epoch 2: iteration 1263/2501 train_loss: 0.49151238799095154 time_taken: 0.05811667442321777\n",
      "Epoch 2: iteration 1264/2501 train_loss: 0.4914935827255249 time_taken: 0.0568234920501709\n",
      "Epoch 2: iteration 1265/2501 train_loss: 0.49146920442581177 time_taken: 0.05708622932434082\n",
      "Epoch 2: iteration 1266/2501 train_loss: 0.4914396107196808 time_taken: 0.05718517303466797\n",
      "Epoch 2: iteration 1267/2501 train_loss: 0.49140188097953796 time_taken: 0.056676387786865234\n",
      "Epoch 2: iteration 1268/2501 train_loss: 0.4913604259490967 time_taken: 0.05643177032470703\n",
      "Epoch 2: iteration 1269/2501 train_loss: 0.4913276135921478 time_taken: 0.05642533302307129\n",
      "Epoch 2: iteration 1270/2501 train_loss: 0.4912855625152588 time_taken: 0.0573880672454834\n",
      "Epoch 2: iteration 1271/2501 train_loss: 0.4912586808204651 time_taken: 0.056441545486450195\n",
      "Epoch 2: iteration 1272/2501 train_loss: 0.4912351369857788 time_taken: 0.05628466606140137\n",
      "Epoch 2: iteration 1273/2501 train_loss: 0.49122270941734314 time_taken: 0.05598783493041992\n",
      "Epoch 2: iteration 1274/2501 train_loss: 0.49120184779167175 time_taken: 0.05654025077819824\n",
      "Epoch 2: iteration 1275/2501 train_loss: 0.49120277166366577 time_taken: 0.05688667297363281\n",
      "Epoch 2: iteration 1276/2501 train_loss: 0.4912247061729431 time_taken: 0.056752681732177734\n",
      "Epoch 2: iteration 1277/2501 train_loss: 0.491252064704895 time_taken: 0.05650472640991211\n",
      "Epoch 2: iteration 1278/2501 train_loss: 0.49126380681991577 time_taken: 0.060979366302490234\n",
      "Epoch 2: iteration 1279/2501 train_loss: 0.49128246307373047 time_taken: 0.05606722831726074\n",
      "Epoch 2: iteration 1280/2501 train_loss: 0.4913049340248108 time_taken: 0.05660057067871094\n",
      "Epoch 2: iteration 1281/2501 train_loss: 0.49131372570991516 time_taken: 0.05632901191711426\n",
      "Epoch 2: iteration 1282/2501 train_loss: 0.4913157522678375 time_taken: 0.05652189254760742\n",
      "Epoch 2: iteration 1283/2501 train_loss: 0.49132344126701355 time_taken: 0.05609297752380371\n",
      "Epoch 2: iteration 1284/2501 train_loss: 0.4913104474544525 time_taken: 0.05663323402404785\n",
      "Epoch 2: iteration 1285/2501 train_loss: 0.4913022518157959 time_taken: 0.05622434616088867\n",
      "Epoch 2: iteration 1286/2501 train_loss: 0.4912964999675751 time_taken: 0.056794166564941406\n",
      "Epoch 2: iteration 1287/2501 train_loss: 0.4912802278995514 time_taken: 0.05701017379760742\n",
      "Epoch 2: iteration 1288/2501 train_loss: 0.49126794934272766 time_taken: 0.05640530586242676\n",
      "Epoch 2: iteration 1289/2501 train_loss: 0.4912568926811218 time_taken: 0.056972503662109375\n",
      "Epoch 2: iteration 1290/2501 train_loss: 0.4912414848804474 time_taken: 0.057029008865356445\n",
      "Epoch 2: iteration 1291/2501 train_loss: 0.4912319481372833 time_taken: 0.0568697452545166\n",
      "Epoch 2: iteration 1292/2501 train_loss: 0.4912116527557373 time_taken: 0.05710005760192871\n",
      "Epoch 2: iteration 1293/2501 train_loss: 0.4912114143371582 time_taken: 0.05724835395812988\n",
      "Epoch 2: iteration 1294/2501 train_loss: 0.49120616912841797 time_taken: 0.05706167221069336\n",
      "Epoch 2: iteration 1295/2501 train_loss: 0.491209477186203 time_taken: 0.05709409713745117\n",
      "Epoch 2: iteration 1296/2501 train_loss: 0.49121248722076416 time_taken: 0.05638480186462402\n",
      "Epoch 2: iteration 1297/2501 train_loss: 0.4912260174751282 time_taken: 0.05715012550354004\n",
      "Epoch 2: iteration 1298/2501 train_loss: 0.491254061460495 time_taken: 0.0565180778503418\n",
      "Epoch 2: iteration 1299/2501 train_loss: 0.4912755489349365 time_taken: 0.05695915222167969\n",
      "Epoch 2: iteration 1300/2501 train_loss: 0.4912984371185303 time_taken: 0.057012319564819336\n",
      "Epoch 2: iteration 1301/2501 train_loss: 0.49132630228996277 time_taken: 0.05688667297363281\n",
      "Epoch 2: iteration 1302/2501 train_loss: 0.49135980010032654 time_taken: 0.05692648887634277\n",
      "Epoch 2: iteration 1303/2501 train_loss: 0.4913754463195801 time_taken: 0.057611942291259766\n",
      "Epoch 2: iteration 1304/2501 train_loss: 0.4913879632949829 time_taken: 0.05615425109863281\n",
      "Epoch 2: iteration 1305/2501 train_loss: 0.49138739705085754 time_taken: 0.056601762771606445\n",
      "Epoch 2: iteration 1306/2501 train_loss: 0.49139225482940674 time_taken: 0.056246042251586914\n",
      "Epoch 2: iteration 1307/2501 train_loss: 0.4914063513278961 time_taken: 0.056329965591430664\n",
      "Epoch 2: iteration 1308/2501 train_loss: 0.4914202094078064 time_taken: 0.05591297149658203\n",
      "Epoch 2: iteration 1309/2501 train_loss: 0.4914446771144867 time_taken: 0.05666685104370117\n",
      "Epoch 2: iteration 1310/2501 train_loss: 0.4914596974849701 time_taken: 0.056006431579589844\n",
      "Epoch 2: iteration 1311/2501 train_loss: 0.49147069454193115 time_taken: 0.0562748908996582\n",
      "Epoch 2: iteration 1312/2501 train_loss: 0.49149593710899353 time_taken: 0.05612587928771973\n",
      "Epoch 2: iteration 1313/2501 train_loss: 0.4915342330932617 time_taken: 0.056886911392211914\n",
      "Epoch 2: iteration 1314/2501 train_loss: 0.4915817081928253 time_taken: 0.05658221244812012\n",
      "Epoch 2: iteration 1315/2501 train_loss: 0.49161532521247864 time_taken: 0.05802464485168457\n",
      "Epoch 2: iteration 1316/2501 train_loss: 0.49163782596588135 time_taken: 0.056217193603515625\n",
      "Epoch 2: iteration 1317/2501 train_loss: 0.4916595220565796 time_taken: 0.05666708946228027\n",
      "Epoch 2: iteration 1318/2501 train_loss: 0.4916786849498749 time_taken: 0.07576608657836914\n",
      "Epoch 2: iteration 1319/2501 train_loss: 0.49169450998306274 time_taken: 0.05672454833984375\n",
      "Epoch 2: iteration 1320/2501 train_loss: 0.491710364818573 time_taken: 0.055977582931518555\n",
      "Epoch 2: iteration 1321/2501 train_loss: 0.49171745777130127 time_taken: 0.056272268295288086\n",
      "Epoch 2: iteration 1322/2501 train_loss: 0.4917179048061371 time_taken: 0.05585026741027832\n",
      "Epoch 2: iteration 1323/2501 train_loss: 0.49171558022499084 time_taken: 0.05649209022521973\n",
      "Epoch 2: iteration 1324/2501 train_loss: 0.49170756340026855 time_taken: 0.05642843246459961\n",
      "Epoch 2: iteration 1325/2501 train_loss: 0.49168696999549866 time_taken: 0.056674957275390625\n",
      "Epoch 2: iteration 1326/2501 train_loss: 0.49166542291641235 time_taken: 0.05623197555541992\n",
      "Epoch 2: iteration 1327/2501 train_loss: 0.49165278673171997 time_taken: 0.057462215423583984\n",
      "Epoch 2: iteration 1328/2501 train_loss: 0.4916283190250397 time_taken: 0.056471824645996094\n",
      "Epoch 2: iteration 1329/2501 train_loss: 0.49160581827163696 time_taken: 0.05611228942871094\n",
      "Epoch 2: iteration 1330/2501 train_loss: 0.4915899932384491 time_taken: 0.05798768997192383\n",
      "Epoch 2: iteration 1331/2501 train_loss: 0.49157750606536865 time_taken: 0.05714559555053711\n",
      "Epoch 2: iteration 1332/2501 train_loss: 0.4915551245212555 time_taken: 0.0601348876953125\n",
      "Epoch 2: iteration 1333/2501 train_loss: 0.4915458858013153 time_taken: 0.05697774887084961\n",
      "Epoch 2: iteration 1334/2501 train_loss: 0.49152979254722595 time_taken: 0.05672717094421387\n",
      "Epoch 2: iteration 1335/2501 train_loss: 0.49151647090911865 time_taken: 0.060311079025268555\n",
      "Epoch 2: iteration 1336/2501 train_loss: 0.49151602387428284 time_taken: 0.056571245193481445\n",
      "Epoch 2: iteration 1337/2501 train_loss: 0.4915241301059723 time_taken: 0.056653738021850586\n",
      "Epoch 2: iteration 1338/2501 train_loss: 0.4915302097797394 time_taken: 0.057558298110961914\n",
      "Epoch 2: iteration 1339/2501 train_loss: 0.4915412962436676 time_taken: 0.05644655227661133\n",
      "Epoch 2: iteration 1340/2501 train_loss: 0.491556316614151 time_taken: 0.05805706977844238\n",
      "Epoch 2: iteration 1341/2501 train_loss: 0.49157682061195374 time_taken: 0.057030677795410156\n",
      "Epoch 2: iteration 1342/2501 train_loss: 0.49158427119255066 time_taken: 0.05631399154663086\n",
      "Epoch 2: iteration 1343/2501 train_loss: 0.49161505699157715 time_taken: 0.05621623992919922\n",
      "Epoch 2: iteration 1344/2501 train_loss: 0.49164649844169617 time_taken: 0.056915998458862305\n",
      "Epoch 2: iteration 1345/2501 train_loss: 0.49168461561203003 time_taken: 0.05724906921386719\n",
      "Epoch 2: iteration 1346/2501 train_loss: 0.4917148947715759 time_taken: 0.05662274360656738\n",
      "Epoch 2: iteration 1347/2501 train_loss: 0.49176687002182007 time_taken: 0.05689835548400879\n",
      "Epoch 2: iteration 1348/2501 train_loss: 0.49180757999420166 time_taken: 0.057244062423706055\n",
      "Epoch 2: iteration 1349/2501 train_loss: 0.49183565378189087 time_taken: 0.05713343620300293\n",
      "Epoch 2: iteration 1350/2501 train_loss: 0.49187445640563965 time_taken: 0.05692005157470703\n",
      "Epoch 2: iteration 1351/2501 train_loss: 0.49190619587898254 time_taken: 0.05653071403503418\n",
      "Epoch 2: iteration 1352/2501 train_loss: 0.49192702770233154 time_taken: 0.06235671043395996\n",
      "Epoch 2: iteration 1353/2501 train_loss: 0.49198293685913086 time_taken: 0.06614518165588379\n",
      "Epoch 2: iteration 1354/2501 train_loss: 0.4920274019241333 time_taken: 0.0671699047088623\n",
      "Epoch 2: iteration 1355/2501 train_loss: 0.4920867681503296 time_taken: 0.05583643913269043\n",
      "Epoch 2: iteration 1356/2501 train_loss: 0.4921228587627411 time_taken: 0.05660581588745117\n",
      "Epoch 2: iteration 1357/2501 train_loss: 0.49216386675834656 time_taken: 0.05604410171508789\n",
      "Epoch 2: iteration 1358/2501 train_loss: 0.49220600724220276 time_taken: 0.05641651153564453\n",
      "Epoch 2: iteration 1359/2501 train_loss: 0.4922555685043335 time_taken: 0.05616140365600586\n",
      "Epoch 2: iteration 1360/2501 train_loss: 0.4923049211502075 time_taken: 0.0559391975402832\n",
      "Epoch 2: iteration 1361/2501 train_loss: 0.49234744906425476 time_taken: 0.05684852600097656\n",
      "Epoch 2: iteration 1362/2501 train_loss: 0.49239611625671387 time_taken: 0.05724382400512695\n",
      "Epoch 2: iteration 1363/2501 train_loss: 0.49243903160095215 time_taken: 0.05656862258911133\n",
      "Epoch 2: iteration 1364/2501 train_loss: 0.4924805164337158 time_taken: 0.06107044219970703\n",
      "Epoch 2: iteration 1365/2501 train_loss: 0.49252060055732727 time_taken: 0.05652189254760742\n",
      "Epoch 2: iteration 1366/2501 train_loss: 0.4925677180290222 time_taken: 0.05651450157165527\n",
      "Epoch 2: iteration 1367/2501 train_loss: 0.4926023781299591 time_taken: 0.05645346641540527\n",
      "Epoch 2: iteration 1368/2501 train_loss: 0.49264973402023315 time_taken: 0.05608367919921875\n",
      "Epoch 2: iteration 1369/2501 train_loss: 0.4927007257938385 time_taken: 0.05710577964782715\n",
      "Epoch 2: iteration 1370/2501 train_loss: 0.4927436411380768 time_taken: 0.0568692684173584\n",
      "Epoch 2: iteration 1371/2501 train_loss: 0.4927903711795807 time_taken: 0.0565948486328125\n",
      "Epoch 2: iteration 1372/2501 train_loss: 0.492842435836792 time_taken: 0.05644583702087402\n",
      "Epoch 2: iteration 1373/2501 train_loss: 0.4929008185863495 time_taken: 0.056702375411987305\n",
      "Epoch 2: iteration 1374/2501 train_loss: 0.49296823143959045 time_taken: 0.05629754066467285\n",
      "Epoch 2: iteration 1375/2501 train_loss: 0.49304234981536865 time_taken: 0.060694217681884766\n",
      "Epoch 2: iteration 1376/2501 train_loss: 0.4931069314479828 time_taken: 0.05638909339904785\n",
      "Epoch 2: iteration 1377/2501 train_loss: 0.49318763613700867 time_taken: 0.056664466857910156\n",
      "Epoch 2: iteration 1378/2501 train_loss: 0.4932605028152466 time_taken: 0.05678296089172363\n",
      "Epoch 2: iteration 1379/2501 train_loss: 0.4933609664440155 time_taken: 0.0566401481628418\n",
      "Epoch 2: iteration 1380/2501 train_loss: 0.49345943331718445 time_taken: 0.05635190010070801\n",
      "Epoch 2: iteration 1381/2501 train_loss: 0.4935397207736969 time_taken: 0.056490421295166016\n",
      "Epoch 2: iteration 1382/2501 train_loss: 0.49362125992774963 time_taken: 0.056229352951049805\n",
      "Epoch 2: iteration 1383/2501 train_loss: 0.4937024712562561 time_taken: 0.05621838569641113\n",
      "Epoch 2: iteration 1384/2501 train_loss: 0.4937916100025177 time_taken: 0.056096553802490234\n",
      "Epoch 2: iteration 1385/2501 train_loss: 0.4938584864139557 time_taken: 0.05639290809631348\n",
      "Epoch 2: iteration 1386/2501 train_loss: 0.4939366579055786 time_taken: 0.07153916358947754\n",
      "Epoch 2: iteration 1387/2501 train_loss: 0.4939996898174286 time_taken: 0.07262325286865234\n",
      "Epoch 2: iteration 1388/2501 train_loss: 0.49406003952026367 time_taken: 0.055698394775390625\n",
      "Epoch 2: iteration 1389/2501 train_loss: 0.49413248896598816 time_taken: 0.05583381652832031\n",
      "Epoch 2: iteration 1390/2501 train_loss: 0.4941941201686859 time_taken: 0.05623006820678711\n",
      "Epoch 2: iteration 1391/2501 train_loss: 0.49424120783805847 time_taken: 0.05637383460998535\n",
      "Epoch 2: iteration 1392/2501 train_loss: 0.4942781329154968 time_taken: 0.0559239387512207\n",
      "Epoch 2: iteration 1393/2501 train_loss: 0.4943222403526306 time_taken: 0.05631828308105469\n",
      "Epoch 2: iteration 1394/2501 train_loss: 0.49436232447624207 time_taken: 0.056496381759643555\n",
      "Epoch 2: iteration 1395/2501 train_loss: 0.4943956136703491 time_taken: 0.05599021911621094\n",
      "Epoch 2: iteration 1396/2501 train_loss: 0.494413822889328 time_taken: 0.056246280670166016\n",
      "Epoch 2: iteration 1397/2501 train_loss: 0.4944418668746948 time_taken: 0.059192657470703125\n",
      "Epoch 2: iteration 1398/2501 train_loss: 0.49446630477905273 time_taken: 0.057419776916503906\n",
      "Epoch 2: iteration 1399/2501 train_loss: 0.49449917674064636 time_taken: 0.056177616119384766\n",
      "Epoch 2: iteration 1400/2501 train_loss: 0.4945257306098938 time_taken: 0.056023359298706055\n",
      "Epoch 2: iteration 1401/2501 train_loss: 0.49454885721206665 time_taken: 0.056616783142089844\n",
      "Epoch 2: iteration 1402/2501 train_loss: 0.49457716941833496 time_taken: 0.0560760498046875\n",
      "Epoch 2: iteration 1403/2501 train_loss: 0.49459052085876465 time_taken: 0.05645442008972168\n",
      "Epoch 2: iteration 1404/2501 train_loss: 0.4946128726005554 time_taken: 0.056504011154174805\n",
      "Epoch 2: iteration 1405/2501 train_loss: 0.49464839696884155 time_taken: 0.05590057373046875\n",
      "Epoch 2: iteration 1406/2501 train_loss: 0.49467557668685913 time_taken: 0.0561063289642334\n",
      "Epoch 2: iteration 1407/2501 train_loss: 0.4946991205215454 time_taken: 0.05589437484741211\n",
      "Epoch 2: iteration 1408/2501 train_loss: 0.4947122037410736 time_taken: 0.05595850944519043\n",
      "Epoch 2: iteration 1409/2501 train_loss: 0.49473100900650024 time_taken: 0.056189775466918945\n",
      "Epoch 2: iteration 1410/2501 train_loss: 0.4947323203086853 time_taken: 0.05650782585144043\n",
      "Epoch 2: iteration 1411/2501 train_loss: 0.49474573135375977 time_taken: 0.05588126182556152\n",
      "Epoch 2: iteration 1412/2501 train_loss: 0.4947451055049896 time_taken: 0.05639028549194336\n",
      "Epoch 2: iteration 1413/2501 train_loss: 0.49473875761032104 time_taken: 0.0561981201171875\n",
      "Epoch 2: iteration 1414/2501 train_loss: 0.4947268068790436 time_taken: 0.05646038055419922\n",
      "Epoch 2: iteration 1415/2501 train_loss: 0.4947323203086853 time_taken: 0.05583333969116211\n",
      "Epoch 2: iteration 1416/2501 train_loss: 0.4947347044944763 time_taken: 0.056148529052734375\n",
      "Epoch 2: iteration 1417/2501 train_loss: 0.4947413206100464 time_taken: 0.05642890930175781\n",
      "Epoch 2: iteration 1418/2501 train_loss: 0.49474599957466125 time_taken: 0.056850433349609375\n",
      "Epoch 2: iteration 1419/2501 train_loss: 0.4947464168071747 time_taken: 0.05581927299499512\n",
      "Epoch 2: iteration 1420/2501 train_loss: 0.4947620928287506 time_taken: 0.055863142013549805\n",
      "Epoch 2: iteration 1421/2501 train_loss: 0.49478307366371155 time_taken: 0.05574512481689453\n",
      "Epoch 2: iteration 1422/2501 train_loss: 0.49481767416000366 time_taken: 0.05653786659240723\n",
      "Epoch 2: iteration 1423/2501 train_loss: 0.4948500692844391 time_taken: 0.05603671073913574\n",
      "Epoch 2: iteration 1424/2501 train_loss: 0.4948877692222595 time_taken: 0.056815147399902344\n",
      "Epoch 2: iteration 1425/2501 train_loss: 0.49492183327674866 time_taken: 0.05671286582946777\n",
      "Epoch 2: iteration 1426/2501 train_loss: 0.49494871497154236 time_taken: 0.05699896812438965\n",
      "Epoch 2: iteration 1427/2501 train_loss: 0.4949856996536255 time_taken: 0.05694246292114258\n",
      "Epoch 2: iteration 1428/2501 train_loss: 0.49501127004623413 time_taken: 0.05643296241760254\n",
      "Epoch 2: iteration 1429/2501 train_loss: 0.4950335621833801 time_taken: 0.05695343017578125\n",
      "Epoch 2: iteration 1430/2501 train_loss: 0.49505484104156494 time_taken: 0.05723452568054199\n",
      "Epoch 2: iteration 1431/2501 train_loss: 0.4950815439224243 time_taken: 0.056641340255737305\n",
      "Epoch 2: iteration 1432/2501 train_loss: 0.49509313702583313 time_taken: 0.05656313896179199\n",
      "Epoch 2: iteration 1433/2501 train_loss: 0.4950971007347107 time_taken: 0.05631709098815918\n",
      "Epoch 2: iteration 1434/2501 train_loss: 0.4951137900352478 time_taken: 0.05641603469848633\n",
      "Epoch 2: iteration 1435/2501 train_loss: 0.4951370656490326 time_taken: 0.06436443328857422\n",
      "Epoch 2: iteration 1436/2501 train_loss: 0.49517279863357544 time_taken: 0.056166887283325195\n",
      "Epoch 2: iteration 1437/2501 train_loss: 0.49520304799079895 time_taken: 0.05588555335998535\n",
      "Epoch 2: iteration 1438/2501 train_loss: 0.49523937702178955 time_taken: 0.05726361274719238\n",
      "Epoch 2: iteration 1439/2501 train_loss: 0.49528956413269043 time_taken: 0.056466102600097656\n",
      "Epoch 2: iteration 1440/2501 train_loss: 0.4953393042087555 time_taken: 0.056275367736816406\n",
      "Epoch 2: iteration 1441/2501 train_loss: 0.4953852891921997 time_taken: 0.059232234954833984\n",
      "Epoch 2: iteration 1442/2501 train_loss: 0.4954308271408081 time_taken: 0.056531429290771484\n",
      "Epoch 2: iteration 1443/2501 train_loss: 0.49548429250717163 time_taken: 0.05652332305908203\n",
      "Epoch 2: iteration 1444/2501 train_loss: 0.49553728103637695 time_taken: 0.05584406852722168\n",
      "Epoch 2: iteration 1445/2501 train_loss: 0.49558600783348083 time_taken: 0.056282758712768555\n",
      "Epoch 2: iteration 1446/2501 train_loss: 0.495627224445343 time_taken: 0.061748504638671875\n",
      "Epoch 2: iteration 1447/2501 train_loss: 0.4956819415092468 time_taken: 0.05577516555786133\n",
      "Epoch 2: iteration 1448/2501 train_loss: 0.4957126975059509 time_taken: 0.1020808219909668\n",
      "Epoch 2: iteration 1449/2501 train_loss: 0.49575379490852356 time_taken: 0.05578017234802246\n",
      "Epoch 2: iteration 1450/2501 train_loss: 0.4957774579524994 time_taken: 0.05585122108459473\n",
      "Epoch 2: iteration 1451/2501 train_loss: 0.495819091796875 time_taken: 0.05610322952270508\n",
      "Epoch 2: iteration 1452/2501 train_loss: 0.49587133526802063 time_taken: 0.05643916130065918\n",
      "Epoch 2: iteration 1453/2501 train_loss: 0.4959169328212738 time_taken: 0.05624747276306152\n",
      "Epoch 2: iteration 1454/2501 train_loss: 0.49597057700157166 time_taken: 0.06067776679992676\n",
      "Epoch 2: iteration 1455/2501 train_loss: 0.4960235059261322 time_taken: 0.056235313415527344\n",
      "Epoch 2: iteration 1456/2501 train_loss: 0.49608105421066284 time_taken: 0.05586385726928711\n",
      "Epoch 2: iteration 1457/2501 train_loss: 0.496157169342041 time_taken: 0.05616164207458496\n",
      "Epoch 2: iteration 1458/2501 train_loss: 0.49622321128845215 time_taken: 0.05950045585632324\n",
      "Epoch 2: iteration 1459/2501 train_loss: 0.4962901175022125 time_taken: 0.056293487548828125\n",
      "Epoch 2: iteration 1460/2501 train_loss: 0.49636515974998474 time_taken: 0.0568242073059082\n",
      "Epoch 2: iteration 1461/2501 train_loss: 0.49643778800964355 time_taken: 0.05623030662536621\n",
      "Epoch 2: iteration 1462/2501 train_loss: 0.4965125322341919 time_taken: 0.05593276023864746\n",
      "Epoch 2: iteration 1463/2501 train_loss: 0.4965665638446808 time_taken: 0.055979013442993164\n",
      "Epoch 2: iteration 1464/2501 train_loss: 0.49663132429122925 time_taken: 0.056482791900634766\n",
      "Epoch 2: iteration 1465/2501 train_loss: 0.49668562412261963 time_taken: 0.0565183162689209\n",
      "Epoch 2: iteration 1466/2501 train_loss: 0.49674078822135925 time_taken: 0.05654454231262207\n",
      "Epoch 2: iteration 1467/2501 train_loss: 0.4967938959598541 time_taken: 0.05640721321105957\n",
      "Epoch 2: iteration 1468/2501 train_loss: 0.496847540140152 time_taken: 0.05699896812438965\n",
      "Epoch 2: iteration 1469/2501 train_loss: 0.4969005286693573 time_taken: 0.05622434616088867\n",
      "Epoch 2: iteration 1470/2501 train_loss: 0.49695271253585815 time_taken: 0.056128740310668945\n",
      "Epoch 2: iteration 1471/2501 train_loss: 0.49699774384498596 time_taken: 0.056186676025390625\n",
      "Epoch 2: iteration 1472/2501 train_loss: 0.49704304337501526 time_taken: 0.056539058685302734\n",
      "Epoch 2: iteration 1473/2501 train_loss: 0.49710479378700256 time_taken: 0.05617094039916992\n",
      "Epoch 2: iteration 1474/2501 train_loss: 0.497164785861969 time_taken: 0.05637097358703613\n",
      "Epoch 2: iteration 1475/2501 train_loss: 0.49723300337791443 time_taken: 0.05684351921081543\n",
      "Epoch 2: iteration 1476/2501 train_loss: 0.4973050355911255 time_taken: 0.05628013610839844\n",
      "Epoch 2: iteration 1477/2501 train_loss: 0.49736496806144714 time_taken: 0.08696389198303223\n",
      "Epoch 2: iteration 1478/2501 train_loss: 0.49743297696113586 time_taken: 0.07289695739746094\n",
      "Epoch 2: iteration 1479/2501 train_loss: 0.4975113272666931 time_taken: 0.060324668884277344\n",
      "Epoch 2: iteration 1480/2501 train_loss: 0.4975743889808655 time_taken: 0.05598926544189453\n",
      "Epoch 2: iteration 1481/2501 train_loss: 0.49765142798423767 time_taken: 0.05594277381896973\n",
      "Epoch 2: iteration 1482/2501 train_loss: 0.49771827459335327 time_taken: 0.05627083778381348\n",
      "Epoch 2: iteration 1483/2501 train_loss: 0.4977538287639618 time_taken: 0.05619096755981445\n",
      "Epoch 2: iteration 1484/2501 train_loss: 0.49779483675956726 time_taken: 0.05648493766784668\n",
      "Epoch 2: iteration 1485/2501 train_loss: 0.4978339970111847 time_taken: 0.05691862106323242\n",
      "Epoch 2: iteration 1486/2501 train_loss: 0.4978668987751007 time_taken: 0.056755781173706055\n",
      "Epoch 2: iteration 1487/2501 train_loss: 0.4978865385055542 time_taken: 0.05790519714355469\n",
      "Epoch 2: iteration 1488/2501 train_loss: 0.49790647625923157 time_taken: 0.05677914619445801\n",
      "Epoch 2: iteration 1489/2501 train_loss: 0.4979216158390045 time_taken: 0.05641746520996094\n",
      "Epoch 2: iteration 1490/2501 train_loss: 0.4979274272918701 time_taken: 0.05665087699890137\n",
      "Epoch 2: iteration 1491/2501 train_loss: 0.49793532490730286 time_taken: 0.05617690086364746\n",
      "Epoch 2: iteration 1492/2501 train_loss: 0.49793776869773865 time_taken: 0.056885719299316406\n",
      "Epoch 2: iteration 1493/2501 train_loss: 0.49794286489486694 time_taken: 0.0564577579498291\n",
      "Epoch 2: iteration 1494/2501 train_loss: 0.497943252325058 time_taken: 0.057526350021362305\n",
      "Epoch 2: iteration 1495/2501 train_loss: 0.4979475438594818 time_taken: 0.05693817138671875\n",
      "Epoch 2: iteration 1496/2501 train_loss: 0.49795761704444885 time_taken: 0.056400299072265625\n",
      "Epoch 2: iteration 1497/2501 train_loss: 0.49797141551971436 time_taken: 0.056859731674194336\n",
      "Epoch 2: iteration 1498/2501 train_loss: 0.4979814887046814 time_taken: 0.05637860298156738\n",
      "Epoch 2: iteration 1499/2501 train_loss: 0.49800044298171997 time_taken: 0.056511878967285156\n",
      "Epoch 2: iteration 1500/2501 train_loss: 0.4980159401893616 time_taken: 0.057340383529663086\n",
      "Epoch 2: iteration 1501/2501 train_loss: 0.49803438782691956 time_taken: 0.05625104904174805\n",
      "Epoch 2: iteration 1502/2501 train_loss: 0.49805089831352234 time_taken: 0.056296348571777344\n",
      "Epoch 2: iteration 1503/2501 train_loss: 0.49807706475257874 time_taken: 0.056392669677734375\n",
      "Epoch 2: iteration 1504/2501 train_loss: 0.49809855222702026 time_taken: 0.056153297424316406\n",
      "Epoch 2: iteration 1505/2501 train_loss: 0.4981212913990021 time_taken: 0.05636954307556152\n",
      "Epoch 2: iteration 1506/2501 train_loss: 0.4981555938720703 time_taken: 0.05628657341003418\n",
      "Epoch 2: iteration 1507/2501 train_loss: 0.49819502234458923 time_taken: 0.056305885314941406\n",
      "Epoch 2: iteration 1508/2501 train_loss: 0.4982248842716217 time_taken: 0.056998491287231445\n",
      "Epoch 2: iteration 1509/2501 train_loss: 0.49824345111846924 time_taken: 0.05614328384399414\n",
      "Epoch 2: iteration 1510/2501 train_loss: 0.4982793927192688 time_taken: 0.056357383728027344\n",
      "Epoch 2: iteration 1511/2501 train_loss: 0.49831119179725647 time_taken: 0.056046247482299805\n",
      "Epoch 2: iteration 1512/2501 train_loss: 0.49834033846855164 time_taken: 0.059348106384277344\n",
      "Epoch 2: iteration 1513/2501 train_loss: 0.49837857484817505 time_taken: 0.05625724792480469\n",
      "Epoch 2: iteration 1514/2501 train_loss: 0.49840956926345825 time_taken: 0.056836843490600586\n",
      "Epoch 2: iteration 1515/2501 train_loss: 0.49843648076057434 time_taken: 0.056595563888549805\n",
      "Epoch 2: iteration 1516/2501 train_loss: 0.49845921993255615 time_taken: 0.056809425354003906\n",
      "Epoch 2: iteration 1517/2501 train_loss: 0.49848461151123047 time_taken: 0.05675148963928223\n",
      "Epoch 2: iteration 1518/2501 train_loss: 0.4985187351703644 time_taken: 0.057333946228027344\n",
      "Epoch 2: iteration 1519/2501 train_loss: 0.4985511004924774 time_taken: 0.05663585662841797\n",
      "Epoch 2: iteration 1520/2501 train_loss: 0.4986059367656708 time_taken: 0.057259321212768555\n",
      "Epoch 2: iteration 1521/2501 train_loss: 0.4986514151096344 time_taken: 0.05603456497192383\n",
      "Epoch 2: iteration 1522/2501 train_loss: 0.49868130683898926 time_taken: 0.05601978302001953\n",
      "Epoch 2: iteration 1523/2501 train_loss: 0.4987218976020813 time_taken: 0.056458234786987305\n",
      "Epoch 2: iteration 1524/2501 train_loss: 0.4987447261810303 time_taken: 0.05598282814025879\n",
      "Epoch 2: iteration 1525/2501 train_loss: 0.4987504184246063 time_taken: 0.05677938461303711\n",
      "Epoch 2: iteration 1526/2501 train_loss: 0.49875161051750183 time_taken: 0.056535959243774414\n",
      "Epoch 2: iteration 1527/2501 train_loss: 0.49875566363334656 time_taken: 0.05640435218811035\n",
      "Epoch 2: iteration 1528/2501 train_loss: 0.49876669049263 time_taken: 0.05618476867675781\n",
      "Epoch 2: iteration 1529/2501 train_loss: 0.4987602233886719 time_taken: 0.05669260025024414\n",
      "Epoch 2: iteration 1530/2501 train_loss: 0.4987572431564331 time_taken: 0.05659222602844238\n",
      "Epoch 2: iteration 1531/2501 train_loss: 0.4987543523311615 time_taken: 0.05688309669494629\n",
      "Epoch 2: iteration 1532/2501 train_loss: 0.4987376630306244 time_taken: 0.05650472640991211\n",
      "Epoch 2: iteration 1533/2501 train_loss: 0.49872419238090515 time_taken: 0.05664944648742676\n",
      "Epoch 2: iteration 1534/2501 train_loss: 0.4987247884273529 time_taken: 0.0567173957824707\n",
      "Epoch 2: iteration 1535/2501 train_loss: 0.49871909618377686 time_taken: 0.05643320083618164\n",
      "Epoch 2: iteration 1536/2501 train_loss: 0.4987229108810425 time_taken: 0.05655717849731445\n",
      "Epoch 2: iteration 1537/2501 train_loss: 0.4987303912639618 time_taken: 0.05740714073181152\n",
      "Epoch 2: iteration 1538/2501 train_loss: 0.4987371861934662 time_taken: 0.057289838790893555\n",
      "Epoch 2: iteration 1539/2501 train_loss: 0.49875298142433167 time_taken: 0.0564417839050293\n",
      "Epoch 2: iteration 1540/2501 train_loss: 0.4987679719924927 time_taken: 0.0564570426940918\n",
      "Epoch 2: iteration 1541/2501 train_loss: 0.49878907203674316 time_taken: 0.07122230529785156\n",
      "Epoch 2: iteration 1542/2501 train_loss: 0.49880337715148926 time_taken: 0.05647921562194824\n",
      "Epoch 2: iteration 1543/2501 train_loss: 0.4988172948360443 time_taken: 0.0565342903137207\n",
      "Epoch 2: iteration 1544/2501 train_loss: 0.49883437156677246 time_taken: 0.05727648735046387\n",
      "Epoch 2: iteration 1545/2501 train_loss: 0.4988354444503784 time_taken: 0.05668950080871582\n",
      "Epoch 2: iteration 1546/2501 train_loss: 0.4988425374031067 time_taken: 0.05658292770385742\n",
      "Epoch 2: iteration 1547/2501 train_loss: 0.498857706785202 time_taken: 0.05678105354309082\n",
      "Epoch 2: iteration 1548/2501 train_loss: 0.49886688590049744 time_taken: 0.05666637420654297\n",
      "Epoch 2: iteration 1549/2501 train_loss: 0.49889686703681946 time_taken: 0.05662250518798828\n",
      "Epoch 2: iteration 1550/2501 train_loss: 0.498919814825058 time_taken: 0.05632591247558594\n",
      "Epoch 2: iteration 1551/2501 train_loss: 0.4989388883113861 time_taken: 0.0570681095123291\n",
      "Epoch 2: iteration 1552/2501 train_loss: 0.49896562099456787 time_taken: 0.05637502670288086\n",
      "Epoch 2: iteration 1553/2501 train_loss: 0.49898165464401245 time_taken: 0.05621027946472168\n",
      "Epoch 2: iteration 1554/2501 train_loss: 0.49901464581489563 time_taken: 0.05684161186218262\n",
      "Epoch 2: iteration 1555/2501 train_loss: 0.4990440607070923 time_taken: 0.05712318420410156\n",
      "Epoch 2: iteration 1556/2501 train_loss: 0.4990512430667877 time_taken: 0.05685877799987793\n",
      "Epoch 2: iteration 1557/2501 train_loss: 0.4990793466567993 time_taken: 0.05732560157775879\n",
      "Epoch 2: iteration 1558/2501 train_loss: 0.4990926682949066 time_taken: 0.05643463134765625\n",
      "Epoch 2: iteration 1559/2501 train_loss: 0.499101847410202 time_taken: 0.056603193283081055\n",
      "Epoch 2: iteration 1560/2501 train_loss: 0.49911659955978394 time_taken: 0.0563807487487793\n",
      "Epoch 2: iteration 1561/2501 train_loss: 0.4991306960582733 time_taken: 0.0565032958984375\n",
      "Epoch 2: iteration 1562/2501 train_loss: 0.4991343319416046 time_taken: 0.05747365951538086\n",
      "Epoch 2: iteration 1563/2501 train_loss: 0.49914106726646423 time_taken: 0.056680917739868164\n",
      "Epoch 2: iteration 1564/2501 train_loss: 0.49913665652275085 time_taken: 0.05647444725036621\n",
      "Epoch 2: iteration 1565/2501 train_loss: 0.4991401433944702 time_taken: 0.05715775489807129\n",
      "Epoch 2: iteration 1566/2501 train_loss: 0.49913784861564636 time_taken: 0.056761741638183594\n",
      "Epoch 2: iteration 1567/2501 train_loss: 0.4991372525691986 time_taken: 0.05680274963378906\n",
      "Epoch 2: iteration 1568/2501 train_loss: 0.49912917613983154 time_taken: 0.05751681327819824\n",
      "Epoch 2: iteration 1569/2501 train_loss: 0.4991298019886017 time_taken: 0.056551456451416016\n",
      "Epoch 2: iteration 1570/2501 train_loss: 0.4991414248943329 time_taken: 0.056572675704956055\n",
      "Epoch 2: iteration 1571/2501 train_loss: 0.49914804100990295 time_taken: 0.06489682197570801\n",
      "Epoch 2: iteration 1572/2501 train_loss: 0.49916890263557434 time_taken: 0.05640125274658203\n",
      "Epoch 2: iteration 1573/2501 train_loss: 0.49918147921562195 time_taken: 0.05648398399353027\n",
      "Epoch 2: iteration 1574/2501 train_loss: 0.49920153617858887 time_taken: 0.05597209930419922\n",
      "Epoch 2: iteration 1575/2501 train_loss: 0.49922695755958557 time_taken: 0.056421518325805664\n",
      "Epoch 2: iteration 1576/2501 train_loss: 0.4992484152317047 time_taken: 0.05640983581542969\n",
      "Epoch 2: iteration 1577/2501 train_loss: 0.4992627501487732 time_taken: 0.05672144889831543\n",
      "Epoch 2: iteration 1578/2501 train_loss: 0.4992739260196686 time_taken: 0.05616569519042969\n",
      "Epoch 2: iteration 1579/2501 train_loss: 0.4993011951446533 time_taken: 0.05666184425354004\n",
      "Epoch 2: iteration 1580/2501 train_loss: 0.4993067979812622 time_taken: 0.055786848068237305\n",
      "Epoch 2: iteration 1581/2501 train_loss: 0.49930599331855774 time_taken: 0.05612683296203613\n",
      "Epoch 2: iteration 1582/2501 train_loss: 0.49930843710899353 time_taken: 0.05665135383605957\n",
      "Epoch 2: iteration 1583/2501 train_loss: 0.4993094503879547 time_taken: 0.056596994400024414\n",
      "Epoch 2: iteration 1584/2501 train_loss: 0.4993191361427307 time_taken: 0.05713391304016113\n",
      "Epoch 2: iteration 1585/2501 train_loss: 0.4993268549442291 time_taken: 0.05717825889587402\n",
      "Epoch 2: iteration 1586/2501 train_loss: 0.49934718012809753 time_taken: 0.0571134090423584\n",
      "Epoch 2: iteration 1587/2501 train_loss: 0.49936121702194214 time_taken: 0.05677628517150879\n",
      "Epoch 2: iteration 1588/2501 train_loss: 0.4993780553340912 time_taken: 0.05732464790344238\n",
      "Epoch 2: iteration 1589/2501 train_loss: 0.4993983507156372 time_taken: 0.057256460189819336\n",
      "Epoch 2: iteration 1590/2501 train_loss: 0.49942120909690857 time_taken: 0.05696582794189453\n",
      "Epoch 2: iteration 1591/2501 train_loss: 0.4994524419307709 time_taken: 0.05686783790588379\n",
      "Epoch 2: iteration 1592/2501 train_loss: 0.49947452545166016 time_taken: 0.05722165107727051\n",
      "Epoch 2: iteration 1593/2501 train_loss: 0.4995003342628479 time_taken: 0.05701899528503418\n",
      "Epoch 2: iteration 1594/2501 train_loss: 0.4995371997356415 time_taken: 0.05704641342163086\n",
      "Epoch 2: iteration 1595/2501 train_loss: 0.4995821714401245 time_taken: 0.056722164154052734\n",
      "Epoch 2: iteration 1596/2501 train_loss: 0.4996300935745239 time_taken: 0.0566861629486084\n",
      "Epoch 2: iteration 1597/2501 train_loss: 0.49966850876808167 time_taken: 0.05674552917480469\n",
      "Epoch 2: iteration 1598/2501 train_loss: 0.4997226595878601 time_taken: 0.05664563179016113\n",
      "Epoch 2: iteration 1599/2501 train_loss: 0.49976757168769836 time_taken: 0.05648636817932129\n",
      "Epoch 2: iteration 1600/2501 train_loss: 0.4998069107532501 time_taken: 0.05644702911376953\n",
      "Epoch 2: iteration 1601/2501 train_loss: 0.49985238909721375 time_taken: 0.056324005126953125\n",
      "Epoch 2: iteration 1602/2501 train_loss: 0.4998971223831177 time_taken: 0.05627942085266113\n",
      "Epoch 2: iteration 1603/2501 train_loss: 0.49993661046028137 time_taken: 0.05626058578491211\n",
      "Epoch 2: iteration 1604/2501 train_loss: 0.4999767243862152 time_taken: 0.056430816650390625\n",
      "Epoch 2: iteration 1605/2501 train_loss: 0.5000067353248596 time_taken: 0.05653643608093262\n",
      "Epoch 2: iteration 1606/2501 train_loss: 0.5000430941581726 time_taken: 0.05721139907836914\n",
      "Epoch 2: iteration 1607/2501 train_loss: 0.5000811815261841 time_taken: 0.05742478370666504\n",
      "Epoch 2: iteration 1608/2501 train_loss: 0.5001134276390076 time_taken: 0.05680489540100098\n",
      "Epoch 2: iteration 1609/2501 train_loss: 0.5001235008239746 time_taken: 0.0563817024230957\n",
      "Epoch 2: iteration 1610/2501 train_loss: 0.5001435875892639 time_taken: 0.0576939582824707\n",
      "Epoch 2: iteration 1611/2501 train_loss: 0.5001733899116516 time_taken: 0.05643653869628906\n",
      "Epoch 2: iteration 1612/2501 train_loss: 0.5002009272575378 time_taken: 0.05646777153015137\n",
      "Epoch 2: iteration 1613/2501 train_loss: 0.500244677066803 time_taken: 0.056780338287353516\n",
      "Epoch 2: iteration 1614/2501 train_loss: 0.500288724899292 time_taken: 0.05686140060424805\n",
      "Epoch 2: iteration 1615/2501 train_loss: 0.5003171563148499 time_taken: 0.056845664978027344\n",
      "Epoch 2: iteration 1616/2501 train_loss: 0.500352144241333 time_taken: 0.05708813667297363\n",
      "Epoch 2: iteration 1617/2501 train_loss: 0.5003861784934998 time_taken: 0.05644631385803223\n",
      "Epoch 2: iteration 1618/2501 train_loss: 0.5004033446311951 time_taken: 0.05694007873535156\n",
      "Epoch 2: iteration 1619/2501 train_loss: 0.5004146099090576 time_taken: 0.05720067024230957\n",
      "Epoch 2: iteration 1620/2501 train_loss: 0.5004532933235168 time_taken: 0.05682706832885742\n",
      "Epoch 2: iteration 1621/2501 train_loss: 0.5004744529724121 time_taken: 0.057152509689331055\n",
      "Epoch 2: iteration 1622/2501 train_loss: 0.5004975199699402 time_taken: 0.05716681480407715\n",
      "Epoch 2: iteration 1623/2501 train_loss: 0.5005202889442444 time_taken: 0.056929588317871094\n",
      "Epoch 2: iteration 1624/2501 train_loss: 0.5005176663398743 time_taken: 0.05643153190612793\n",
      "Epoch 2: iteration 1625/2501 train_loss: 0.5005141496658325 time_taken: 0.05673503875732422\n",
      "Epoch 2: iteration 1626/2501 train_loss: 0.5005087852478027 time_taken: 0.05643415451049805\n",
      "Epoch 2: iteration 1627/2501 train_loss: 0.5004977583885193 time_taken: 0.05629301071166992\n",
      "Epoch 2: iteration 1628/2501 train_loss: 0.5004810690879822 time_taken: 0.056946754455566406\n",
      "Epoch 2: iteration 1629/2501 train_loss: 0.500466525554657 time_taken: 0.0750277042388916\n",
      "Epoch 2: iteration 1630/2501 train_loss: 0.500443160533905 time_taken: 0.0567169189453125\n",
      "Epoch 2: iteration 1631/2501 train_loss: 0.500414252281189 time_taken: 0.05591869354248047\n",
      "Epoch 2: iteration 1632/2501 train_loss: 0.5003936290740967 time_taken: 0.05638694763183594\n",
      "Epoch 2: iteration 1633/2501 train_loss: 0.5003796815872192 time_taken: 0.05694770812988281\n",
      "Epoch 2: iteration 1634/2501 train_loss: 0.5003868341445923 time_taken: 0.056932687759399414\n",
      "Epoch 2: iteration 1635/2501 train_loss: 0.5003823637962341 time_taken: 0.057079315185546875\n",
      "Epoch 2: iteration 1636/2501 train_loss: 0.5003894567489624 time_taken: 0.0567629337310791\n",
      "Epoch 2: iteration 1637/2501 train_loss: 0.5004115700721741 time_taken: 0.056791067123413086\n",
      "Epoch 2: iteration 1638/2501 train_loss: 0.5004388093948364 time_taken: 0.05731987953186035\n",
      "Epoch 2: iteration 1639/2501 train_loss: 0.5004748702049255 time_taken: 0.05741548538208008\n",
      "Epoch 2: iteration 1640/2501 train_loss: 0.5005083084106445 time_taken: 0.057353973388671875\n",
      "Epoch 2: iteration 1641/2501 train_loss: 0.5005301833152771 time_taken: 0.057578086853027344\n",
      "Epoch 2: iteration 1642/2501 train_loss: 0.5005584359169006 time_taken: 0.056511640548706055\n",
      "Epoch 2: iteration 1643/2501 train_loss: 0.5005763173103333 time_taken: 0.05644416809082031\n",
      "Epoch 2: iteration 1644/2501 train_loss: 0.5005891919136047 time_taken: 0.056290626525878906\n",
      "Epoch 2: iteration 1645/2501 train_loss: 0.500599205493927 time_taken: 0.05748462677001953\n",
      "Epoch 2: iteration 1646/2501 train_loss: 0.5006049275398254 time_taken: 0.058255910873413086\n",
      "Epoch 2: iteration 1647/2501 train_loss: 0.500615656375885 time_taken: 0.056319475173950195\n",
      "Epoch 2: iteration 1648/2501 train_loss: 0.5006116628646851 time_taken: 0.05622744560241699\n",
      "Epoch 2: iteration 1649/2501 train_loss: 0.5006081461906433 time_taken: 0.05617570877075195\n",
      "Epoch 2: iteration 1650/2501 train_loss: 0.5006018280982971 time_taken: 0.05747103691101074\n",
      "Epoch 2: iteration 1651/2501 train_loss: 0.5005922317504883 time_taken: 0.0564572811126709\n",
      "Epoch 2: iteration 1652/2501 train_loss: 0.5005751848220825 time_taken: 0.05658435821533203\n",
      "Epoch 2: iteration 1653/2501 train_loss: 0.5005560517311096 time_taken: 0.05701303482055664\n",
      "Epoch 2: iteration 1654/2501 train_loss: 0.5005362033843994 time_taken: 0.05644726753234863\n",
      "Epoch 2: iteration 1655/2501 train_loss: 0.500525951385498 time_taken: 0.05677676200866699\n",
      "Epoch 2: iteration 1656/2501 train_loss: 0.5005149245262146 time_taken: 0.05658125877380371\n",
      "Epoch 2: iteration 1657/2501 train_loss: 0.5005040168762207 time_taken: 0.05669546127319336\n",
      "Epoch 2: iteration 1658/2501 train_loss: 0.5005009174346924 time_taken: 0.056406259536743164\n",
      "Epoch 2: iteration 1659/2501 train_loss: 0.500490128993988 time_taken: 0.05623936653137207\n",
      "Epoch 2: iteration 1660/2501 train_loss: 0.5004864931106567 time_taken: 0.05594992637634277\n",
      "Epoch 2: iteration 1661/2501 train_loss: 0.5004879832267761 time_taken: 0.05635190010070801\n",
      "Epoch 2: iteration 1662/2501 train_loss: 0.5004862546920776 time_taken: 0.05655527114868164\n",
      "Epoch 2: iteration 1663/2501 train_loss: 0.500482976436615 time_taken: 0.05636954307556152\n",
      "Epoch 2: iteration 1664/2501 train_loss: 0.5004881620407104 time_taken: 0.05604958534240723\n",
      "Epoch 2: iteration 1665/2501 train_loss: 0.5004939436912537 time_taken: 0.0566558837890625\n",
      "Epoch 2: iteration 1666/2501 train_loss: 0.5004945397377014 time_taken: 0.0567927360534668\n",
      "Epoch 2: iteration 1667/2501 train_loss: 0.5004979372024536 time_taken: 0.056609153747558594\n",
      "Epoch 2: iteration 1668/2501 train_loss: 0.5005161762237549 time_taken: 0.05708575248718262\n",
      "Epoch 2: iteration 1669/2501 train_loss: 0.5005321502685547 time_taken: 0.0569155216217041\n",
      "Epoch 2: iteration 1670/2501 train_loss: 0.5005604028701782 time_taken: 0.05669879913330078\n",
      "Epoch 2: iteration 1671/2501 train_loss: 0.5005890130996704 time_taken: 0.05716538429260254\n",
      "Epoch 2: iteration 1672/2501 train_loss: 0.5006178021430969 time_taken: 0.05691862106323242\n",
      "Epoch 2: iteration 1673/2501 train_loss: 0.5006575584411621 time_taken: 0.05737423896789551\n",
      "Epoch 2: iteration 1674/2501 train_loss: 0.5007041096687317 time_taken: 0.05735898017883301\n",
      "Epoch 2: iteration 1675/2501 train_loss: 0.500761091709137 time_taken: 0.05723381042480469\n",
      "Epoch 2: iteration 1676/2501 train_loss: 0.500795304775238 time_taken: 0.057791709899902344\n",
      "Epoch 2: iteration 1677/2501 train_loss: 0.5008419156074524 time_taken: 0.05637621879577637\n",
      "Epoch 2: iteration 1678/2501 train_loss: 0.5008795261383057 time_taken: 0.05630064010620117\n",
      "Epoch 2: iteration 1679/2501 train_loss: 0.500923216342926 time_taken: 0.05618691444396973\n",
      "Epoch 2: iteration 1680/2501 train_loss: 0.5009558796882629 time_taken: 0.05702686309814453\n",
      "Epoch 2: iteration 1681/2501 train_loss: 0.5009874701499939 time_taken: 0.0566859245300293\n",
      "Epoch 2: iteration 1682/2501 train_loss: 0.5010153651237488 time_taken: 0.05726170539855957\n",
      "Epoch 2: iteration 1683/2501 train_loss: 0.5010437369346619 time_taken: 0.05663633346557617\n",
      "Epoch 2: iteration 1684/2501 train_loss: 0.5010708570480347 time_taken: 0.05689430236816406\n",
      "Epoch 2: iteration 1685/2501 train_loss: 0.5010865926742554 time_taken: 0.056607961654663086\n",
      "Epoch 2: iteration 1686/2501 train_loss: 0.5011033415794373 time_taken: 0.05621790885925293\n",
      "Epoch 2: iteration 1687/2501 train_loss: 0.5011141300201416 time_taken: 0.05644655227661133\n",
      "Epoch 2: iteration 1688/2501 train_loss: 0.5011342167854309 time_taken: 0.05672192573547363\n",
      "Epoch 2: iteration 1689/2501 train_loss: 0.5011606812477112 time_taken: 0.05788373947143555\n",
      "Epoch 2: iteration 1690/2501 train_loss: 0.5011960864067078 time_taken: 0.05634737014770508\n",
      "Epoch 2: iteration 1691/2501 train_loss: 0.5012155175209045 time_taken: 0.05649375915527344\n",
      "Epoch 2: iteration 1692/2501 train_loss: 0.5012421011924744 time_taken: 0.058502197265625\n",
      "Epoch 2: iteration 1693/2501 train_loss: 0.5012658834457397 time_taken: 0.057013511657714844\n",
      "Epoch 2: iteration 1694/2501 train_loss: 0.5012907385826111 time_taken: 0.05785179138183594\n",
      "Epoch 2: iteration 1695/2501 train_loss: 0.5013130903244019 time_taken: 0.05763578414916992\n",
      "Epoch 2: iteration 1696/2501 train_loss: 0.5013543963432312 time_taken: 0.05653858184814453\n",
      "Epoch 2: iteration 1697/2501 train_loss: 0.5013974905014038 time_taken: 0.05659604072570801\n",
      "Epoch 2: iteration 1698/2501 train_loss: 0.5014434456825256 time_taken: 0.05667853355407715\n",
      "Epoch 2: iteration 1699/2501 train_loss: 0.501491904258728 time_taken: 0.05656743049621582\n",
      "Epoch 2: iteration 1700/2501 train_loss: 0.5015459656715393 time_taken: 0.056520938873291016\n",
      "Epoch 2: iteration 1701/2501 train_loss: 0.5015857815742493 time_taken: 0.05685710906982422\n",
      "Epoch 2: iteration 1702/2501 train_loss: 0.5016281008720398 time_taken: 0.05754518508911133\n",
      "Epoch 2: iteration 1703/2501 train_loss: 0.5016856789588928 time_taken: 0.05679893493652344\n",
      "Epoch 2: iteration 1704/2501 train_loss: 0.5017322897911072 time_taken: 0.05767059326171875\n",
      "Epoch 2: iteration 1705/2501 train_loss: 0.5017827749252319 time_taken: 0.05656027793884277\n",
      "Epoch 2: iteration 1706/2501 train_loss: 0.501833975315094 time_taken: 0.056799888610839844\n",
      "Epoch 2: iteration 1707/2501 train_loss: 0.5018737316131592 time_taken: 0.057524681091308594\n",
      "Epoch 2: iteration 1708/2501 train_loss: 0.5019196271896362 time_taken: 0.056592702865600586\n",
      "Epoch 2: iteration 1709/2501 train_loss: 0.5019612908363342 time_taken: 0.061293840408325195\n",
      "Epoch 2: iteration 1710/2501 train_loss: 0.5020005702972412 time_taken: 0.056321144104003906\n",
      "Epoch 2: iteration 1711/2501 train_loss: 0.5020385980606079 time_taken: 0.05644631385803223\n",
      "Epoch 2: iteration 1712/2501 train_loss: 0.5020874738693237 time_taken: 0.05656027793884277\n",
      "Epoch 2: iteration 1713/2501 train_loss: 0.5021265149116516 time_taken: 0.056134700775146484\n",
      "Epoch 2: iteration 1714/2501 train_loss: 0.5021681785583496 time_taken: 0.05644941329956055\n",
      "Epoch 2: iteration 1715/2501 train_loss: 0.5022212862968445 time_taken: 0.056561946868896484\n",
      "Epoch 2: iteration 1716/2501 train_loss: 0.502268373966217 time_taken: 0.056887149810791016\n",
      "Epoch 2: iteration 1717/2501 train_loss: 0.5023117065429688 time_taken: 0.05737709999084473\n",
      "Epoch 2: iteration 1718/2501 train_loss: 0.5023536086082458 time_taken: 0.05666327476501465\n",
      "Epoch 2: iteration 1719/2501 train_loss: 0.5024003386497498 time_taken: 0.05649304389953613\n",
      "Epoch 2: iteration 1720/2501 train_loss: 0.5024431347846985 time_taken: 0.056766510009765625\n",
      "Epoch 2: iteration 1721/2501 train_loss: 0.5024842619895935 time_taken: 0.05791521072387695\n",
      "Epoch 2: iteration 1722/2501 train_loss: 0.5025111436843872 time_taken: 0.05691957473754883\n",
      "Epoch 2: iteration 1723/2501 train_loss: 0.5025580525398254 time_taken: 0.057106733322143555\n",
      "Epoch 2: iteration 1724/2501 train_loss: 0.5025947690010071 time_taken: 0.05674004554748535\n",
      "Epoch 2: iteration 1725/2501 train_loss: 0.502638578414917 time_taken: 0.05708885192871094\n",
      "Epoch 2: iteration 1726/2501 train_loss: 0.5026873350143433 time_taken: 0.05714583396911621\n",
      "Epoch 2: iteration 1727/2501 train_loss: 0.502739667892456 time_taken: 0.05686545372009277\n",
      "Epoch 2: iteration 1728/2501 train_loss: 0.5027951002120972 time_taken: 0.05702400207519531\n",
      "Epoch 2: iteration 1729/2501 train_loss: 0.502842128276825 time_taken: 0.05681586265563965\n",
      "Epoch 2: iteration 1730/2501 train_loss: 0.5028924942016602 time_taken: 0.05661177635192871\n",
      "Epoch 2: iteration 1731/2501 train_loss: 0.5029472708702087 time_taken: 0.05713939666748047\n",
      "Epoch 2: iteration 1732/2501 train_loss: 0.5029968619346619 time_taken: 0.056555986404418945\n",
      "Epoch 2: iteration 1733/2501 train_loss: 0.5030487179756165 time_taken: 0.05666804313659668\n",
      "Epoch 2: iteration 1734/2501 train_loss: 0.5031091570854187 time_taken: 0.0568997859954834\n",
      "Epoch 2: iteration 1735/2501 train_loss: 0.5031525492668152 time_taken: 0.05704140663146973\n",
      "Epoch 2: iteration 1736/2501 train_loss: 0.5031959414482117 time_taken: 0.05679655075073242\n",
      "Epoch 2: iteration 1737/2501 train_loss: 0.5032442212104797 time_taken: 0.05720663070678711\n",
      "Epoch 2: iteration 1738/2501 train_loss: 0.5032894611358643 time_taken: 0.05676007270812988\n",
      "Epoch 2: iteration 1739/2501 train_loss: 0.5033321380615234 time_taken: 0.05676388740539551\n",
      "Epoch 2: iteration 1740/2501 train_loss: 0.5033825039863586 time_taken: 0.05730843544006348\n",
      "Epoch 2: iteration 1741/2501 train_loss: 0.5034368634223938 time_taken: 0.05752968788146973\n",
      "Epoch 2: iteration 1742/2501 train_loss: 0.5034878253936768 time_taken: 0.057277679443359375\n",
      "Epoch 2: iteration 1743/2501 train_loss: 0.5035354495048523 time_taken: 0.05784440040588379\n",
      "Epoch 2: iteration 1744/2501 train_loss: 0.5035893321037292 time_taken: 0.05715203285217285\n",
      "Epoch 2: iteration 1745/2501 train_loss: 0.5036308169364929 time_taken: 0.0573725700378418\n",
      "Epoch 2: iteration 1746/2501 train_loss: 0.5036863088607788 time_taken: 0.05650162696838379\n",
      "Epoch 2: iteration 1747/2501 train_loss: 0.5037306547164917 time_taken: 0.05664682388305664\n",
      "Epoch 2: iteration 1748/2501 train_loss: 0.5037824511528015 time_taken: 0.0564420223236084\n",
      "Epoch 2: iteration 1749/2501 train_loss: 0.5038242936134338 time_taken: 0.056307077407836914\n",
      "Epoch 2: iteration 1750/2501 train_loss: 0.503868043422699 time_taken: 0.05629563331604004\n",
      "Epoch 2: iteration 1751/2501 train_loss: 0.5038954615592957 time_taken: 0.056844472885131836\n",
      "Epoch 2: iteration 1752/2501 train_loss: 0.5039136409759521 time_taken: 0.056853532791137695\n",
      "Epoch 2: iteration 1753/2501 train_loss: 0.5039381384849548 time_taken: 0.05654263496398926\n",
      "Epoch 2: iteration 1754/2501 train_loss: 0.5039395689964294 time_taken: 0.05673575401306152\n",
      "Epoch 2: iteration 1755/2501 train_loss: 0.5039311051368713 time_taken: 0.056681156158447266\n",
      "Epoch 2: iteration 1756/2501 train_loss: 0.5039253830909729 time_taken: 0.056731224060058594\n",
      "Epoch 2: iteration 1757/2501 train_loss: 0.5039126873016357 time_taken: 0.05624890327453613\n",
      "Epoch 2: iteration 1758/2501 train_loss: 0.503915011882782 time_taken: 0.056493520736694336\n",
      "Epoch 2: iteration 1759/2501 train_loss: 0.5039108991622925 time_taken: 0.05663585662841797\n",
      "Epoch 2: iteration 1760/2501 train_loss: 0.5039007663726807 time_taken: 0.06063222885131836\n",
      "Epoch 2: iteration 1761/2501 train_loss: 0.5038901567459106 time_taken: 0.05719614028930664\n",
      "Epoch 2: iteration 1762/2501 train_loss: 0.5038857460021973 time_taken: 0.056368350982666016\n",
      "Epoch 2: iteration 1763/2501 train_loss: 0.5038711428642273 time_taken: 0.05648946762084961\n",
      "Epoch 2: iteration 1764/2501 train_loss: 0.5038575530052185 time_taken: 0.05758976936340332\n",
      "Epoch 2: iteration 1765/2501 train_loss: 0.5038440823554993 time_taken: 0.056580305099487305\n",
      "Epoch 2: iteration 1766/2501 train_loss: 0.5038396120071411 time_taken: 0.05628824234008789\n",
      "Epoch 2: iteration 1767/2501 train_loss: 0.5038394331932068 time_taken: 0.05733752250671387\n",
      "Epoch 2: iteration 1768/2501 train_loss: 0.5038414001464844 time_taken: 0.05755805969238281\n",
      "Epoch 2: iteration 1769/2501 train_loss: 0.503853440284729 time_taken: 0.05650067329406738\n",
      "Epoch 2: iteration 1770/2501 train_loss: 0.5038647055625916 time_taken: 0.05652880668640137\n",
      "Epoch 2: iteration 1771/2501 train_loss: 0.5038810968399048 time_taken: 0.05662202835083008\n",
      "Epoch 2: iteration 1772/2501 train_loss: 0.503904402256012 time_taken: 0.056386709213256836\n",
      "Epoch 2: iteration 1773/2501 train_loss: 0.5039260387420654 time_taken: 0.05710291862487793\n",
      "Epoch 2: iteration 1774/2501 train_loss: 0.50394207239151 time_taken: 0.057724952697753906\n",
      "Epoch 2: iteration 1775/2501 train_loss: 0.5039533972740173 time_taken: 0.05682802200317383\n",
      "Epoch 2: iteration 1776/2501 train_loss: 0.5039673447608948 time_taken: 0.056583404541015625\n",
      "Epoch 2: iteration 1777/2501 train_loss: 0.503986120223999 time_taken: 0.06420254707336426\n",
      "Epoch 2: iteration 1778/2501 train_loss: 0.5040075182914734 time_taken: 0.056485891342163086\n",
      "Epoch 2: iteration 1779/2501 train_loss: 0.5040296316146851 time_taken: 0.0570068359375\n",
      "Epoch 2: iteration 1780/2501 train_loss: 0.5040498375892639 time_taken: 0.056884765625\n",
      "Epoch 2: iteration 1781/2501 train_loss: 0.5040651559829712 time_taken: 0.05631709098815918\n",
      "Epoch 2: iteration 1782/2501 train_loss: 0.5040832757949829 time_taken: 0.056961774826049805\n",
      "Epoch 2: iteration 1783/2501 train_loss: 0.50410395860672 time_taken: 0.05717754364013672\n",
      "Epoch 2: iteration 1784/2501 train_loss: 0.5041293501853943 time_taken: 0.05681014060974121\n",
      "Epoch 2: iteration 1785/2501 train_loss: 0.5041580200195312 time_taken: 0.05657005310058594\n",
      "Epoch 2: iteration 1786/2501 train_loss: 0.5041804313659668 time_taken: 0.057730913162231445\n",
      "Epoch 2: iteration 1787/2501 train_loss: 0.5042060613632202 time_taken: 0.05713486671447754\n",
      "Epoch 2: iteration 1788/2501 train_loss: 0.5042440295219421 time_taken: 0.05768442153930664\n",
      "Epoch 2: iteration 1789/2501 train_loss: 0.5042787790298462 time_taken: 0.057213783264160156\n",
      "Epoch 2: iteration 1790/2501 train_loss: 0.5043023228645325 time_taken: 0.05745077133178711\n",
      "Epoch 2: iteration 1791/2501 train_loss: 0.5043351054191589 time_taken: 0.05772209167480469\n",
      "Epoch 2: iteration 1792/2501 train_loss: 0.5043655633926392 time_taken: 0.056944847106933594\n",
      "Epoch 2: iteration 1793/2501 train_loss: 0.5044002532958984 time_taken: 0.05648922920227051\n",
      "Epoch 2: iteration 1794/2501 train_loss: 0.504439115524292 time_taken: 0.05682873725891113\n",
      "Epoch 2: iteration 1795/2501 train_loss: 0.5044689178466797 time_taken: 0.05711174011230469\n",
      "Epoch 2: iteration 1796/2501 train_loss: 0.5045077800750732 time_taken: 0.05679464340209961\n",
      "Epoch 2: iteration 1797/2501 train_loss: 0.5045378804206848 time_taken: 0.05697488784790039\n",
      "Epoch 2: iteration 1798/2501 train_loss: 0.5045614242553711 time_taken: 0.0568699836730957\n",
      "Epoch 2: iteration 1799/2501 train_loss: 0.504595935344696 time_taken: 0.056969642639160156\n",
      "Epoch 2: iteration 1800/2501 train_loss: 0.5046324133872986 time_taken: 0.057155609130859375\n",
      "Epoch 2: iteration 1801/2501 train_loss: 0.5046643018722534 time_taken: 0.056531429290771484\n",
      "Epoch 2: iteration 1802/2501 train_loss: 0.5046929717063904 time_taken: 0.05718398094177246\n",
      "Epoch 2: iteration 1803/2501 train_loss: 0.5047234892845154 time_taken: 0.07494473457336426\n",
      "Epoch 2: iteration 1804/2501 train_loss: 0.5047617554664612 time_taken: 0.057997703552246094\n",
      "Epoch 2: iteration 1805/2501 train_loss: 0.5048018097877502 time_taken: 0.07121491432189941\n",
      "Epoch 2: iteration 1806/2501 train_loss: 0.5048361420631409 time_taken: 0.06205892562866211\n",
      "Epoch 2: iteration 1807/2501 train_loss: 0.5048633813858032 time_taken: 0.05670428276062012\n",
      "Epoch 2: iteration 1808/2501 train_loss: 0.5048836469650269 time_taken: 0.05705070495605469\n",
      "Epoch 2: iteration 1809/2501 train_loss: 0.5049046277999878 time_taken: 0.05627274513244629\n",
      "Epoch 2: iteration 1810/2501 train_loss: 0.50493323802948 time_taken: 0.05660533905029297\n",
      "Epoch 2: iteration 1811/2501 train_loss: 0.5049605965614319 time_taken: 0.05703878402709961\n",
      "Epoch 2: iteration 1812/2501 train_loss: 0.5049830079078674 time_taken: 0.058173179626464844\n",
      "Epoch 2: iteration 1813/2501 train_loss: 0.5050053596496582 time_taken: 0.057183027267456055\n",
      "Epoch 2: iteration 1814/2501 train_loss: 0.5050345063209534 time_taken: 0.05736088752746582\n",
      "Epoch 2: iteration 1815/2501 train_loss: 0.5050573945045471 time_taken: 0.057273149490356445\n",
      "Epoch 2: iteration 1816/2501 train_loss: 0.5050826668739319 time_taken: 0.057450294494628906\n",
      "Epoch 2: iteration 1817/2501 train_loss: 0.5051103234291077 time_taken: 0.05721592903137207\n",
      "Epoch 2: iteration 1818/2501 train_loss: 0.5051396489143372 time_taken: 0.056638240814208984\n",
      "Epoch 2: iteration 1819/2501 train_loss: 0.505162239074707 time_taken: 0.05726361274719238\n",
      "Epoch 2: iteration 1820/2501 train_loss: 0.505185067653656 time_taken: 0.05668926239013672\n",
      "Epoch 2: iteration 1821/2501 train_loss: 0.5052075386047363 time_taken: 0.056789398193359375\n",
      "Epoch 2: iteration 1822/2501 train_loss: 0.5052204132080078 time_taken: 0.056932926177978516\n",
      "Epoch 2: iteration 1823/2501 train_loss: 0.5052341818809509 time_taken: 0.05714702606201172\n",
      "Epoch 2: iteration 1824/2501 train_loss: 0.5052511692047119 time_taken: 0.057331085205078125\n",
      "Epoch 2: iteration 1825/2501 train_loss: 0.5052726864814758 time_taken: 0.05673789978027344\n",
      "Epoch 2: iteration 1826/2501 train_loss: 0.5052914619445801 time_taken: 0.05728650093078613\n",
      "Epoch 2: iteration 1827/2501 train_loss: 0.5053287744522095 time_taken: 0.05688047409057617\n",
      "Epoch 2: iteration 1828/2501 train_loss: 0.5053616166114807 time_taken: 0.05663108825683594\n",
      "Epoch 2: iteration 1829/2501 train_loss: 0.505397379398346 time_taken: 0.057621002197265625\n",
      "Epoch 2: iteration 1830/2501 train_loss: 0.505433976650238 time_taken: 0.05666923522949219\n",
      "Epoch 2: iteration 1831/2501 train_loss: 0.5054835081100464 time_taken: 0.05693173408508301\n",
      "Epoch 2: iteration 1832/2501 train_loss: 0.5055327415466309 time_taken: 0.0573122501373291\n",
      "Epoch 2: iteration 1833/2501 train_loss: 0.5055844783782959 time_taken: 0.05682730674743652\n",
      "Epoch 2: iteration 1834/2501 train_loss: 0.5056368112564087 time_taken: 0.05692315101623535\n",
      "Epoch 2: iteration 1835/2501 train_loss: 0.5056976675987244 time_taken: 0.05721163749694824\n",
      "Epoch 2: iteration 1836/2501 train_loss: 0.5057421326637268 time_taken: 0.05640268325805664\n",
      "Epoch 2: iteration 1837/2501 train_loss: 0.5057895183563232 time_taken: 0.05716896057128906\n",
      "Epoch 2: iteration 1838/2501 train_loss: 0.5058329701423645 time_taken: 0.05631232261657715\n",
      "Epoch 2: iteration 1839/2501 train_loss: 0.5058618187904358 time_taken: 0.056952714920043945\n",
      "Epoch 2: iteration 1840/2501 train_loss: 0.5059046745300293 time_taken: 0.05693936347961426\n",
      "Epoch 2: iteration 1841/2501 train_loss: 0.5059432983398438 time_taken: 0.05682849884033203\n",
      "Epoch 2: iteration 1842/2501 train_loss: 0.5059815049171448 time_taken: 0.05677914619445801\n",
      "Epoch 2: iteration 1843/2501 train_loss: 0.50602787733078 time_taken: 0.056581974029541016\n",
      "Epoch 2: iteration 1844/2501 train_loss: 0.5060624480247498 time_taken: 0.05658411979675293\n",
      "Epoch 2: iteration 1845/2501 train_loss: 0.5061038136482239 time_taken: 0.057358741760253906\n",
      "Epoch 2: iteration 1846/2501 train_loss: 0.5061318874359131 time_taken: 0.0565342903137207\n",
      "Epoch 2: iteration 1847/2501 train_loss: 0.5061623454093933 time_taken: 0.05692005157470703\n",
      "Epoch 2: iteration 1848/2501 train_loss: 0.5061874389648438 time_taken: 0.057813167572021484\n",
      "Epoch 2: iteration 1849/2501 train_loss: 0.5062049627304077 time_taken: 0.057363271713256836\n",
      "Epoch 2: iteration 1850/2501 train_loss: 0.5062181949615479 time_taken: 0.05640602111816406\n",
      "Epoch 2: iteration 1851/2501 train_loss: 0.5062307715415955 time_taken: 0.05729985237121582\n",
      "Epoch 2: iteration 1852/2501 train_loss: 0.5062422156333923 time_taken: 0.05678987503051758\n",
      "Epoch 2: iteration 1853/2501 train_loss: 0.5062474012374878 time_taken: 0.05733656883239746\n",
      "Epoch 2: iteration 1854/2501 train_loss: 0.5062479376792908 time_taken: 0.05722165107727051\n",
      "Epoch 2: iteration 1855/2501 train_loss: 0.5062463879585266 time_taken: 0.05672430992126465\n",
      "Epoch 2: iteration 1856/2501 train_loss: 0.5062572956085205 time_taken: 0.05720233917236328\n",
      "Epoch 2: iteration 1857/2501 train_loss: 0.5062519907951355 time_taken: 0.05679941177368164\n",
      "Epoch 2: iteration 1858/2501 train_loss: 0.5062410831451416 time_taken: 0.0576934814453125\n",
      "Epoch 2: iteration 1859/2501 train_loss: 0.5062150359153748 time_taken: 0.05675959587097168\n",
      "Epoch 2: iteration 1860/2501 train_loss: 0.5062024593353271 time_taken: 0.05712437629699707\n",
      "Epoch 2: iteration 1861/2501 train_loss: 0.5061886310577393 time_taken: 0.05719327926635742\n",
      "Epoch 2: iteration 1862/2501 train_loss: 0.5061770081520081 time_taken: 0.057547569274902344\n",
      "Epoch 2: iteration 1863/2501 train_loss: 0.5061534643173218 time_taken: 0.05691123008728027\n",
      "Epoch 2: iteration 1864/2501 train_loss: 0.5061308145523071 time_taken: 0.05690646171569824\n",
      "Epoch 2: iteration 1865/2501 train_loss: 0.5061129927635193 time_taken: 0.056856632232666016\n",
      "Epoch 2: iteration 1866/2501 train_loss: 0.5060974955558777 time_taken: 0.057159423828125\n",
      "Epoch 2: iteration 1867/2501 train_loss: 0.506095290184021 time_taken: 0.056867122650146484\n",
      "Epoch 2: iteration 1868/2501 train_loss: 0.5060946941375732 time_taken: 0.057538747787475586\n",
      "Epoch 2: iteration 1869/2501 train_loss: 0.506095826625824 time_taken: 0.05683159828186035\n",
      "Epoch 2: iteration 1870/2501 train_loss: 0.5061011910438538 time_taken: 0.056903839111328125\n",
      "Epoch 2: iteration 1871/2501 train_loss: 0.5061116218566895 time_taken: 0.05651092529296875\n",
      "Epoch 2: iteration 1872/2501 train_loss: 0.5061233043670654 time_taken: 0.05723929405212402\n",
      "Epoch 2: iteration 1873/2501 train_loss: 0.5061332583427429 time_taken: 0.05633544921875\n",
      "Epoch 2: iteration 1874/2501 train_loss: 0.5061447024345398 time_taken: 0.05715584754943848\n",
      "Epoch 2: iteration 1875/2501 train_loss: 0.5061489939689636 time_taken: 0.0579681396484375\n",
      "Epoch 2: iteration 1876/2501 train_loss: 0.5061575770378113 time_taken: 0.05727648735046387\n",
      "Epoch 2: iteration 1877/2501 train_loss: 0.5061653852462769 time_taken: 0.05737614631652832\n",
      "Epoch 2: iteration 1878/2501 train_loss: 0.5061730146408081 time_taken: 0.056897878646850586\n",
      "Epoch 2: iteration 1879/2501 train_loss: 0.506188690662384 time_taken: 0.056821346282958984\n",
      "Epoch 2: iteration 1880/2501 train_loss: 0.5061926245689392 time_taken: 0.05766940116882324\n",
      "Epoch 2: iteration 1881/2501 train_loss: 0.506206214427948 time_taken: 0.05672264099121094\n",
      "Epoch 2: iteration 1882/2501 train_loss: 0.5062274932861328 time_taken: 0.05682373046875\n",
      "Epoch 2: iteration 1883/2501 train_loss: 0.5062352418899536 time_taken: 0.05646824836730957\n",
      "Epoch 2: iteration 1884/2501 train_loss: 0.5062430500984192 time_taken: 0.056532859802246094\n",
      "Epoch 2: iteration 1885/2501 train_loss: 0.5062623023986816 time_taken: 0.05668950080871582\n",
      "Epoch 2: iteration 1886/2501 train_loss: 0.506275475025177 time_taken: 0.05693173408508301\n",
      "Epoch 2: iteration 1887/2501 train_loss: 0.5062905550003052 time_taken: 0.057274818420410156\n",
      "Epoch 2: iteration 1888/2501 train_loss: 0.5063036680221558 time_taken: 0.05666613578796387\n",
      "Epoch 2: iteration 1889/2501 train_loss: 0.5063170790672302 time_taken: 0.05716085433959961\n",
      "Epoch 2: iteration 1890/2501 train_loss: 0.5063355565071106 time_taken: 0.056461334228515625\n",
      "Epoch 2: iteration 1891/2501 train_loss: 0.5063602924346924 time_taken: 0.05728435516357422\n",
      "Epoch 2: iteration 1892/2501 train_loss: 0.5063838362693787 time_taken: 0.05939292907714844\n",
      "Epoch 2: iteration 1893/2501 train_loss: 0.5064184069633484 time_taken: 0.057364702224731445\n",
      "Epoch 2: iteration 1894/2501 train_loss: 0.5064598917961121 time_taken: 0.05692291259765625\n",
      "Epoch 2: iteration 1895/2501 train_loss: 0.5064926743507385 time_taken: 0.05948138236999512\n",
      "Epoch 2: iteration 1896/2501 train_loss: 0.5065487027168274 time_taken: 0.05608773231506348\n",
      "Epoch 2: iteration 1897/2501 train_loss: 0.5065930485725403 time_taken: 0.05624842643737793\n",
      "Epoch 2: iteration 1898/2501 train_loss: 0.5066474080085754 time_taken: 0.05626177787780762\n",
      "Epoch 2: iteration 1899/2501 train_loss: 0.5066956877708435 time_taken: 0.0565800666809082\n",
      "Epoch 2: iteration 1900/2501 train_loss: 0.5067494511604309 time_taken: 0.056253910064697266\n",
      "Epoch 2: iteration 1901/2501 train_loss: 0.506786048412323 time_taken: 0.05703544616699219\n",
      "Epoch 2: iteration 1902/2501 train_loss: 0.5068162679672241 time_taken: 0.05675506591796875\n",
      "Epoch 2: iteration 1903/2501 train_loss: 0.5068545937538147 time_taken: 0.056865692138671875\n",
      "Epoch 2: iteration 1904/2501 train_loss: 0.5068978667259216 time_taken: 0.05665922164916992\n",
      "Epoch 2: iteration 1905/2501 train_loss: 0.50693279504776 time_taken: 0.05867743492126465\n",
      "Epoch 2: iteration 1906/2501 train_loss: 0.5069770812988281 time_taken: 0.05690956115722656\n",
      "Epoch 2: iteration 1907/2501 train_loss: 0.5070192217826843 time_taken: 0.05667304992675781\n",
      "Epoch 2: iteration 1908/2501 train_loss: 0.5070596933364868 time_taken: 0.056754112243652344\n",
      "Epoch 2: iteration 1909/2501 train_loss: 0.5070934295654297 time_taken: 0.056595563888549805\n",
      "Epoch 2: iteration 1910/2501 train_loss: 0.507136881351471 time_taken: 0.057149648666381836\n",
      "Epoch 2: iteration 1911/2501 train_loss: 0.5071629881858826 time_taken: 0.05666661262512207\n",
      "Epoch 2: iteration 1912/2501 train_loss: 0.5071902275085449 time_taken: 0.05664324760437012\n",
      "Epoch 2: iteration 1913/2501 train_loss: 0.507224977016449 time_taken: 0.05665874481201172\n",
      "Epoch 2: iteration 1914/2501 train_loss: 0.5072582960128784 time_taken: 0.05674242973327637\n",
      "Epoch 2: iteration 1915/2501 train_loss: 0.5073004961013794 time_taken: 0.05662941932678223\n",
      "Epoch 2: iteration 1916/2501 train_loss: 0.5073330402374268 time_taken: 0.057047367095947266\n",
      "Epoch 2: iteration 1917/2501 train_loss: 0.5073760747909546 time_taken: 0.05654025077819824\n",
      "Epoch 2: iteration 1918/2501 train_loss: 0.5074188113212585 time_taken: 0.05669045448303223\n",
      "Epoch 2: iteration 1919/2501 train_loss: 0.5074530839920044 time_taken: 0.056488037109375\n",
      "Epoch 2: iteration 1920/2501 train_loss: 0.507483720779419 time_taken: 0.05703330039978027\n",
      "Epoch 2: iteration 1921/2501 train_loss: 0.507527232170105 time_taken: 0.05657315254211426\n",
      "Epoch 2: iteration 1922/2501 train_loss: 0.5075643062591553 time_taken: 0.05666017532348633\n",
      "Epoch 2: iteration 1923/2501 train_loss: 0.5076075196266174 time_taken: 0.05670738220214844\n",
      "Epoch 2: iteration 1924/2501 train_loss: 0.5076555609703064 time_taken: 0.05645608901977539\n",
      "Epoch 2: iteration 1925/2501 train_loss: 0.5076961517333984 time_taken: 0.05587267875671387\n",
      "Epoch 2: iteration 1926/2501 train_loss: 0.5077409148216248 time_taken: 0.05586695671081543\n",
      "Epoch 2: iteration 1927/2501 train_loss: 0.5077805519104004 time_taken: 0.05606555938720703\n",
      "Epoch 2: iteration 1928/2501 train_loss: 0.5078337788581848 time_taken: 0.05662417411804199\n",
      "Epoch 2: iteration 1929/2501 train_loss: 0.5078954696655273 time_taken: 0.05611753463745117\n",
      "Epoch 2: iteration 1930/2501 train_loss: 0.5079467296600342 time_taken: 0.056764841079711914\n",
      "Epoch 2: iteration 1931/2501 train_loss: 0.5080072283744812 time_taken: 0.05688643455505371\n",
      "Epoch 2: iteration 1932/2501 train_loss: 0.5080676674842834 time_taken: 0.05666685104370117\n",
      "Epoch 2: iteration 1933/2501 train_loss: 0.5081247687339783 time_taken: 0.056797027587890625\n",
      "Epoch 2: iteration 1934/2501 train_loss: 0.5081664323806763 time_taken: 0.05717825889587402\n",
      "Epoch 2: iteration 1935/2501 train_loss: 0.5082229971885681 time_taken: 0.05664944648742676\n",
      "Epoch 2: iteration 1936/2501 train_loss: 0.5082704424858093 time_taken: 0.05631399154663086\n",
      "Epoch 2: iteration 1937/2501 train_loss: 0.5083122849464417 time_taken: 0.0568547248840332\n",
      "Epoch 2: iteration 1938/2501 train_loss: 0.5083492398262024 time_taken: 0.05638766288757324\n",
      "Epoch 2: iteration 1939/2501 train_loss: 0.5083712935447693 time_taken: 0.05706381797790527\n",
      "Epoch 2: iteration 1940/2501 train_loss: 0.5083947777748108 time_taken: 0.056897640228271484\n",
      "Epoch 2: iteration 1941/2501 train_loss: 0.508419930934906 time_taken: 0.0567474365234375\n",
      "Epoch 2: iteration 1942/2501 train_loss: 0.5084337592124939 time_taken: 0.05619549751281738\n",
      "Epoch 2: iteration 1943/2501 train_loss: 0.5084450244903564 time_taken: 0.05822873115539551\n",
      "Epoch 2: iteration 1944/2501 train_loss: 0.5084397792816162 time_taken: 0.05703425407409668\n",
      "Epoch 2: iteration 1945/2501 train_loss: 0.5084425210952759 time_taken: 0.05765080451965332\n",
      "Epoch 2: iteration 1946/2501 train_loss: 0.5084255337715149 time_taken: 0.05701780319213867\n",
      "Epoch 2: iteration 1947/2501 train_loss: 0.5084015130996704 time_taken: 0.05743908882141113\n",
      "Epoch 2: iteration 1948/2501 train_loss: 0.5083797574043274 time_taken: 0.056581974029541016\n",
      "Epoch 2: iteration 1949/2501 train_loss: 0.5083761811256409 time_taken: 0.056427001953125\n",
      "Epoch 2: iteration 1950/2501 train_loss: 0.508369505405426 time_taken: 0.05700516700744629\n",
      "Epoch 2: iteration 1951/2501 train_loss: 0.5083667635917664 time_taken: 0.05649685859680176\n",
      "Epoch 2: iteration 1952/2501 train_loss: 0.5083755850791931 time_taken: 0.057668209075927734\n",
      "Epoch 2: iteration 1953/2501 train_loss: 0.5083860754966736 time_taken: 0.06102728843688965\n",
      "Epoch 2: iteration 1954/2501 train_loss: 0.5084000825881958 time_taken: 0.05719757080078125\n",
      "Epoch 2: iteration 1955/2501 train_loss: 0.508410632610321 time_taken: 0.057622432708740234\n",
      "Epoch 2: iteration 1956/2501 train_loss: 0.5084244012832642 time_taken: 0.05993843078613281\n",
      "Epoch 2: iteration 1957/2501 train_loss: 0.5084400773048401 time_taken: 0.05704951286315918\n",
      "Epoch 2: iteration 1958/2501 train_loss: 0.5084502100944519 time_taken: 0.05690360069274902\n",
      "Epoch 2: iteration 1959/2501 train_loss: 0.5084683299064636 time_taken: 0.056488752365112305\n",
      "Epoch 2: iteration 1960/2501 train_loss: 0.5084603428840637 time_taken: 0.05637788772583008\n",
      "Epoch 2: iteration 1961/2501 train_loss: 0.5084608197212219 time_taken: 0.05641460418701172\n",
      "Epoch 2: iteration 1962/2501 train_loss: 0.5084590911865234 time_taken: 0.05721116065979004\n",
      "Epoch 2: iteration 1963/2501 train_loss: 0.5084531307220459 time_taken: 0.05719637870788574\n",
      "Epoch 2: iteration 1964/2501 train_loss: 0.5084471106529236 time_taken: 0.05679917335510254\n",
      "Epoch 2: iteration 1965/2501 train_loss: 0.50843745470047 time_taken: 0.056972503662109375\n",
      "Epoch 2: iteration 1966/2501 train_loss: 0.5084266662597656 time_taken: 0.057033538818359375\n",
      "Epoch 2: iteration 1967/2501 train_loss: 0.5084150433540344 time_taken: 0.05635476112365723\n",
      "Epoch 2: iteration 1968/2501 train_loss: 0.5084092020988464 time_taken: 0.05662274360656738\n",
      "Epoch 2: iteration 1969/2501 train_loss: 0.508402943611145 time_taken: 0.056569814682006836\n",
      "Epoch 2: iteration 1970/2501 train_loss: 0.5083797574043274 time_taken: 0.056679487228393555\n",
      "Epoch 2: iteration 1971/2501 train_loss: 0.508367121219635 time_taken: 0.060811519622802734\n",
      "Epoch 2: iteration 1972/2501 train_loss: 0.5083574056625366 time_taken: 0.05623030662536621\n",
      "Epoch 2: iteration 1973/2501 train_loss: 0.5083541870117188 time_taken: 0.05624985694885254\n",
      "Epoch 2: iteration 1974/2501 train_loss: 0.5083637237548828 time_taken: 0.056459903717041016\n",
      "Epoch 2: iteration 1975/2501 train_loss: 0.5083658695220947 time_taken: 0.056421756744384766\n",
      "Epoch 2: iteration 1976/2501 train_loss: 0.5083591938018799 time_taken: 0.05608415603637695\n",
      "Epoch 2: iteration 1977/2501 train_loss: 0.508357584476471 time_taken: 0.05576634407043457\n",
      "Epoch 2: iteration 1978/2501 train_loss: 0.5083501935005188 time_taken: 0.0560762882232666\n",
      "Epoch 2: iteration 1979/2501 train_loss: 0.5083358883857727 time_taken: 0.05619215965270996\n",
      "Epoch 2: iteration 1980/2501 train_loss: 0.5083234310150146 time_taken: 0.05598878860473633\n",
      "Epoch 2: iteration 1981/2501 train_loss: 0.5083084106445312 time_taken: 0.056314945220947266\n",
      "Epoch 2: iteration 1982/2501 train_loss: 0.5082919597625732 time_taken: 0.05597996711730957\n",
      "Epoch 2: iteration 1983/2501 train_loss: 0.5082778334617615 time_taken: 0.05641937255859375\n",
      "Epoch 2: iteration 1984/2501 train_loss: 0.5082710385322571 time_taken: 0.05630826950073242\n",
      "Epoch 2: iteration 1985/2501 train_loss: 0.5082637071609497 time_taken: 0.057158470153808594\n",
      "Epoch 2: iteration 1986/2501 train_loss: 0.5082616806030273 time_taken: 0.05670356750488281\n",
      "Epoch 2: iteration 1987/2501 train_loss: 0.5082570910453796 time_taken: 0.056212425231933594\n",
      "Epoch 2: iteration 1988/2501 train_loss: 0.5082585215568542 time_taken: 0.05649995803833008\n",
      "Epoch 2: iteration 1989/2501 train_loss: 0.5082529187202454 time_taken: 0.056346893310546875\n",
      "Epoch 2: iteration 1990/2501 train_loss: 0.5082491040229797 time_taken: 0.05683326721191406\n",
      "Epoch 2: iteration 1991/2501 train_loss: 0.5082488059997559 time_taken: 0.05777740478515625\n",
      "Epoch 2: iteration 1992/2501 train_loss: 0.5082533955574036 time_taken: 0.05641770362854004\n",
      "Epoch 2: iteration 1993/2501 train_loss: 0.5082559585571289 time_taken: 0.056322574615478516\n",
      "Epoch 2: iteration 1994/2501 train_loss: 0.5082681179046631 time_taken: 0.05645442008972168\n",
      "Epoch 2: iteration 1995/2501 train_loss: 0.5082772970199585 time_taken: 0.05651283264160156\n",
      "Epoch 2: iteration 1996/2501 train_loss: 0.5082904100418091 time_taken: 0.05661654472351074\n",
      "Epoch 2: iteration 1997/2501 train_loss: 0.5083135366439819 time_taken: 0.057196855545043945\n",
      "Epoch 2: iteration 1998/2501 train_loss: 0.5083302855491638 time_taken: 0.0569005012512207\n",
      "Epoch 2: iteration 1999/2501 train_loss: 0.5083500742912292 time_taken: 0.05640983581542969\n",
      "Epoch 2: iteration 2000/2501 train_loss: 0.5083665251731873 time_taken: 0.05705738067626953\n",
      "Epoch 2: iteration 2001/2501 train_loss: 0.5083820223808289 time_taken: 0.0563051700592041\n",
      "Epoch 2: iteration 2002/2501 train_loss: 0.5083953142166138 time_taken: 0.056618452072143555\n",
      "Epoch 2: iteration 2003/2501 train_loss: 0.5084131956100464 time_taken: 0.05646967887878418\n",
      "Epoch 2: iteration 2004/2501 train_loss: 0.5084322094917297 time_taken: 0.05663633346557617\n",
      "Epoch 2: iteration 2005/2501 train_loss: 0.5084461569786072 time_taken: 0.056684017181396484\n",
      "Epoch 2: iteration 2006/2501 train_loss: 0.5084672570228577 time_taken: 0.0571141242980957\n",
      "Epoch 2: iteration 2007/2501 train_loss: 0.5084900259971619 time_taken: 0.05664706230163574\n",
      "Epoch 2: iteration 2008/2501 train_loss: 0.5085099339485168 time_taken: 0.05969381332397461\n",
      "Epoch 2: iteration 2009/2501 train_loss: 0.5085431337356567 time_taken: 0.0571293830871582\n",
      "Epoch 2: iteration 2010/2501 train_loss: 0.5085570216178894 time_taken: 0.0570073127746582\n",
      "Epoch 2: iteration 2011/2501 train_loss: 0.5085835456848145 time_taken: 0.05676984786987305\n",
      "Epoch 2: iteration 2012/2501 train_loss: 0.5086126327514648 time_taken: 0.05672311782836914\n",
      "Epoch 2: iteration 2013/2501 train_loss: 0.5086411237716675 time_taken: 0.05643105506896973\n",
      "Epoch 2: iteration 2014/2501 train_loss: 0.5086644887924194 time_taken: 0.056478261947631836\n",
      "Epoch 2: iteration 2015/2501 train_loss: 0.5086949467658997 time_taken: 0.05606532096862793\n",
      "Epoch 2: iteration 2016/2501 train_loss: 0.508736252784729 time_taken: 0.07087254524230957\n",
      "Epoch 2: iteration 2017/2501 train_loss: 0.5087714195251465 time_taken: 0.07115697860717773\n",
      "Epoch 2: iteration 2018/2501 train_loss: 0.5088139772415161 time_taken: 0.05662417411804199\n",
      "Epoch 2: iteration 2019/2501 train_loss: 0.5088661909103394 time_taken: 0.057001590728759766\n",
      "Epoch 2: iteration 2020/2501 train_loss: 0.5089118480682373 time_taken: 0.05711030960083008\n",
      "Epoch 2: iteration 2021/2501 train_loss: 0.5089501142501831 time_taken: 0.05682730674743652\n",
      "Epoch 2: iteration 2022/2501 train_loss: 0.508993923664093 time_taken: 0.05672430992126465\n",
      "Epoch 2: iteration 2023/2501 train_loss: 0.5090415477752686 time_taken: 0.05655097961425781\n",
      "Epoch 2: iteration 2024/2501 train_loss: 0.5090770125389099 time_taken: 0.05632376670837402\n",
      "Epoch 2: iteration 2025/2501 train_loss: 0.5091142058372498 time_taken: 0.05654120445251465\n",
      "Epoch 2: iteration 2026/2501 train_loss: 0.5091505646705627 time_taken: 0.057245492935180664\n",
      "Epoch 2: iteration 2027/2501 train_loss: 0.5091868042945862 time_taken: 0.056923627853393555\n",
      "Epoch 2: iteration 2028/2501 train_loss: 0.509223222732544 time_taken: 0.056734323501586914\n",
      "Epoch 2: iteration 2029/2501 train_loss: 0.5092561841011047 time_taken: 0.058243513107299805\n",
      "Epoch 2: iteration 2030/2501 train_loss: 0.5092955231666565 time_taken: 0.05714249610900879\n",
      "Epoch 2: iteration 2031/2501 train_loss: 0.5093348026275635 time_taken: 0.05637526512145996\n",
      "Epoch 2: iteration 2032/2501 train_loss: 0.509371817111969 time_taken: 0.05685019493103027\n",
      "Epoch 2: iteration 2033/2501 train_loss: 0.5094065070152283 time_taken: 0.0567629337310791\n",
      "Epoch 2: iteration 2034/2501 train_loss: 0.5094500780105591 time_taken: 0.05675625801086426\n",
      "Epoch 2: iteration 2035/2501 train_loss: 0.5094969272613525 time_taken: 0.05643153190612793\n",
      "Epoch 2: iteration 2036/2501 train_loss: 0.5095306634902954 time_taken: 0.05674028396606445\n",
      "Epoch 2: iteration 2037/2501 train_loss: 0.5095711350440979 time_taken: 0.05667304992675781\n",
      "Epoch 2: iteration 2038/2501 train_loss: 0.5096107125282288 time_taken: 0.056591033935546875\n",
      "Epoch 2: iteration 2039/2501 train_loss: 0.5096468925476074 time_taken: 0.05660891532897949\n",
      "Epoch 2: iteration 2040/2501 train_loss: 0.5096874833106995 time_taken: 0.056429147720336914\n",
      "Epoch 2: iteration 2041/2501 train_loss: 0.5097403526306152 time_taken: 0.05618476867675781\n",
      "Epoch 2: iteration 2042/2501 train_loss: 0.5097877979278564 time_taken: 0.12101149559020996\n",
      "Epoch 2: iteration 2043/2501 train_loss: 0.5098243951797485 time_taken: 0.05594754219055176\n",
      "Epoch 2: iteration 2044/2501 train_loss: 0.5098579525947571 time_taken: 0.05585336685180664\n",
      "Epoch 2: iteration 2045/2501 train_loss: 0.5098821520805359 time_taken: 0.05674552917480469\n",
      "Epoch 2: iteration 2046/2501 train_loss: 0.5099049806594849 time_taken: 0.05662417411804199\n",
      "Epoch 2: iteration 2047/2501 train_loss: 0.5099222660064697 time_taken: 0.05656886100769043\n",
      "Epoch 2: iteration 2048/2501 train_loss: 0.5099454522132874 time_taken: 0.057131052017211914\n",
      "Epoch 2: iteration 2049/2501 train_loss: 0.5099738240242004 time_taken: 0.057117462158203125\n",
      "Epoch 2: iteration 2050/2501 train_loss: 0.5100043416023254 time_taken: 0.05662107467651367\n",
      "Epoch 2: iteration 2051/2501 train_loss: 0.5100389719009399 time_taken: 0.056365966796875\n",
      "Epoch 2: iteration 2052/2501 train_loss: 0.5100685954093933 time_taken: 0.05753302574157715\n",
      "Epoch 2: iteration 2053/2501 train_loss: 0.5100951790809631 time_taken: 0.05597686767578125\n",
      "Epoch 2: iteration 2054/2501 train_loss: 0.5101245045661926 time_taken: 0.05695819854736328\n",
      "Epoch 2: iteration 2055/2501 train_loss: 0.5101474523544312 time_taken: 0.05634665489196777\n",
      "Epoch 2: iteration 2056/2501 train_loss: 0.5101760029792786 time_taken: 0.05657148361206055\n",
      "Epoch 2: iteration 2057/2501 train_loss: 0.5101978778839111 time_taken: 0.05654287338256836\n",
      "Epoch 2: iteration 2058/2501 train_loss: 0.510231077671051 time_taken: 0.05624246597290039\n",
      "Epoch 2: iteration 2059/2501 train_loss: 0.5102503895759583 time_taken: 0.056138038635253906\n",
      "Epoch 2: iteration 2060/2501 train_loss: 0.5102766156196594 time_taken: 0.0566401481628418\n",
      "Epoch 2: iteration 2061/2501 train_loss: 0.5103097558021545 time_taken: 0.056429147720336914\n",
      "Epoch 2: iteration 2062/2501 train_loss: 0.5103485584259033 time_taken: 0.056293487548828125\n",
      "Epoch 2: iteration 2063/2501 train_loss: 0.5103858709335327 time_taken: 0.056532859802246094\n",
      "Epoch 2: iteration 2064/2501 train_loss: 0.5104324817657471 time_taken: 0.05658984184265137\n",
      "Epoch 2: iteration 2065/2501 train_loss: 0.510479211807251 time_taken: 0.055971384048461914\n",
      "Epoch 2: iteration 2066/2501 train_loss: 0.510521411895752 time_taken: 0.056966304779052734\n",
      "Epoch 2: iteration 2067/2501 train_loss: 0.5105528831481934 time_taken: 0.056418657302856445\n",
      "Epoch 2: iteration 2068/2501 train_loss: 0.5105748176574707 time_taken: 0.056748151779174805\n",
      "Epoch 2: iteration 2069/2501 train_loss: 0.5105962753295898 time_taken: 0.056307315826416016\n",
      "Epoch 2: iteration 2070/2501 train_loss: 0.5106116533279419 time_taken: 0.0567169189453125\n",
      "Epoch 2: iteration 2071/2501 train_loss: 0.5106335878372192 time_taken: 0.05719113349914551\n",
      "Epoch 2: iteration 2072/2501 train_loss: 0.5106474161148071 time_taken: 0.05680251121520996\n",
      "Epoch 2: iteration 2073/2501 train_loss: 0.5106649398803711 time_taken: 0.05639529228210449\n",
      "Epoch 2: iteration 2074/2501 train_loss: 0.5106723308563232 time_taken: 0.05644822120666504\n",
      "Epoch 2: iteration 2075/2501 train_loss: 0.5106756687164307 time_taken: 0.056862592697143555\n",
      "Epoch 2: iteration 2076/2501 train_loss: 0.5106719136238098 time_taken: 0.05619359016418457\n",
      "Epoch 2: iteration 2077/2501 train_loss: 0.5106611847877502 time_taken: 0.05611300468444824\n",
      "Epoch 2: iteration 2078/2501 train_loss: 0.5106652975082397 time_taken: 0.05705595016479492\n",
      "Epoch 2: iteration 2079/2501 train_loss: 0.5106704831123352 time_taken: 0.05622982978820801\n",
      "Epoch 2: iteration 2080/2501 train_loss: 0.5106821656227112 time_taken: 0.05661821365356445\n",
      "Epoch 2: iteration 2081/2501 train_loss: 0.5106971263885498 time_taken: 0.05640125274658203\n",
      "Epoch 2: iteration 2082/2501 train_loss: 0.5107083320617676 time_taken: 0.05680227279663086\n",
      "Epoch 2: iteration 2083/2501 train_loss: 0.5107237696647644 time_taken: 0.056584835052490234\n",
      "Epoch 2: iteration 2084/2501 train_loss: 0.5107433795928955 time_taken: 0.05710268020629883\n",
      "Epoch 2: iteration 2085/2501 train_loss: 0.5107527375221252 time_taken: 0.05632591247558594\n",
      "Epoch 2: iteration 2086/2501 train_loss: 0.5107636451721191 time_taken: 0.05698037147521973\n",
      "Epoch 2: iteration 2087/2501 train_loss: 0.5107694864273071 time_taken: 0.05698680877685547\n",
      "Epoch 2: iteration 2088/2501 train_loss: 0.510765016078949 time_taken: 0.05653977394104004\n",
      "Epoch 2: iteration 2089/2501 train_loss: 0.5107596516609192 time_taken: 0.05632734298706055\n",
      "Epoch 2: iteration 2090/2501 train_loss: 0.5107520818710327 time_taken: 0.05652427673339844\n",
      "Epoch 2: iteration 2091/2501 train_loss: 0.5107314586639404 time_taken: 0.05655527114868164\n",
      "Epoch 2: iteration 2092/2501 train_loss: 0.510715126991272 time_taken: 0.05648446083068848\n",
      "Epoch 2: iteration 2093/2501 train_loss: 0.5106914639472961 time_taken: 0.05653214454650879\n",
      "Epoch 2: iteration 2094/2501 train_loss: 0.5106754899024963 time_taken: 0.05702853202819824\n",
      "Epoch 2: iteration 2095/2501 train_loss: 0.5106517672538757 time_taken: 0.05676722526550293\n",
      "Epoch 2: iteration 2096/2501 train_loss: 0.5106197595596313 time_taken: 0.0568544864654541\n",
      "Epoch 2: iteration 2097/2501 train_loss: 0.5105851888656616 time_taken: 0.05677032470703125\n",
      "Epoch 2: iteration 2098/2501 train_loss: 0.510547399520874 time_taken: 0.057108163833618164\n",
      "Epoch 2: iteration 2099/2501 train_loss: 0.5105136036872864 time_taken: 0.058618783950805664\n",
      "Epoch 2: iteration 2100/2501 train_loss: 0.5104802846908569 time_taken: 0.05717873573303223\n",
      "Epoch 2: iteration 2101/2501 train_loss: 0.5104562640190125 time_taken: 0.05683016777038574\n",
      "Epoch 2: iteration 2102/2501 train_loss: 0.5104300379753113 time_taken: 0.0569608211517334\n",
      "Epoch 2: iteration 2103/2501 train_loss: 0.5103976130485535 time_taken: 0.05630850791931152\n",
      "Epoch 2: iteration 2104/2501 train_loss: 0.5103655457496643 time_taken: 0.056514739990234375\n",
      "Epoch 2: iteration 2105/2501 train_loss: 0.5103321671485901 time_taken: 0.05659914016723633\n",
      "Epoch 2: iteration 2106/2501 train_loss: 0.5102993249893188 time_taken: 0.057186126708984375\n",
      "Epoch 2: iteration 2107/2501 train_loss: 0.5102764964103699 time_taken: 0.05635261535644531\n",
      "Epoch 2: iteration 2108/2501 train_loss: 0.5102471113204956 time_taken: 0.056136369705200195\n",
      "Epoch 2: iteration 2109/2501 train_loss: 0.5102223753929138 time_taken: 0.0561373233795166\n",
      "Epoch 2: iteration 2110/2501 train_loss: 0.5101941823959351 time_taken: 0.05661320686340332\n",
      "Epoch 2: iteration 2111/2501 train_loss: 0.5101720094680786 time_taken: 0.05652976036071777\n",
      "Epoch 2: iteration 2112/2501 train_loss: 0.5101516246795654 time_taken: 0.056123971939086914\n",
      "Epoch 2: iteration 2113/2501 train_loss: 0.5101426243782043 time_taken: 0.05602312088012695\n",
      "Epoch 2: iteration 2114/2501 train_loss: 0.5101370215415955 time_taken: 0.05618429183959961\n",
      "Epoch 2: iteration 2115/2501 train_loss: 0.510125458240509 time_taken: 0.05618619918823242\n",
      "Epoch 2: iteration 2116/2501 train_loss: 0.5101273655891418 time_taken: 0.05621790885925293\n",
      "Epoch 2: iteration 2117/2501 train_loss: 0.510140061378479 time_taken: 0.05666518211364746\n",
      "Epoch 2: iteration 2118/2501 train_loss: 0.5101487040519714 time_taken: 0.06047868728637695\n",
      "Epoch 2: iteration 2119/2501 train_loss: 0.510148823261261 time_taken: 0.05607867240905762\n",
      "Epoch 2: iteration 2120/2501 train_loss: 0.5101571083068848 time_taken: 0.056154727935791016\n",
      "Epoch 2: iteration 2121/2501 train_loss: 0.5101733207702637 time_taken: 0.057103872299194336\n",
      "Epoch 2: iteration 2122/2501 train_loss: 0.5101869106292725 time_taken: 0.057094573974609375\n",
      "Epoch 2: iteration 2123/2501 train_loss: 0.510200560092926 time_taken: 0.05664944648742676\n",
      "Epoch 2: iteration 2124/2501 train_loss: 0.5102123618125916 time_taken: 0.0565030574798584\n",
      "Epoch 2: iteration 2125/2501 train_loss: 0.5102265477180481 time_taken: 0.055849552154541016\n",
      "Epoch 2: iteration 2126/2501 train_loss: 0.5102494955062866 time_taken: 0.05626630783081055\n",
      "Epoch 2: iteration 2127/2501 train_loss: 0.5102798342704773 time_taken: 0.056542396545410156\n",
      "Epoch 2: iteration 2128/2501 train_loss: 0.5103058218955994 time_taken: 0.05639839172363281\n",
      "Epoch 2: iteration 2129/2501 train_loss: 0.5103392601013184 time_taken: 0.056423187255859375\n",
      "Epoch 2: iteration 2130/2501 train_loss: 0.5103665590286255 time_taken: 0.05658864974975586\n",
      "Epoch 2: iteration 2131/2501 train_loss: 0.5104008316993713 time_taken: 0.05722999572753906\n",
      "Epoch 2: iteration 2132/2501 train_loss: 0.5104291439056396 time_taken: 0.05647087097167969\n",
      "Epoch 2: iteration 2133/2501 train_loss: 0.5104636549949646 time_taken: 0.05641818046569824\n",
      "Epoch 2: iteration 2134/2501 train_loss: 0.5104935765266418 time_taken: 0.0685892105102539\n",
      "Epoch 2: iteration 2135/2501 train_loss: 0.5105321407318115 time_taken: 0.05618619918823242\n",
      "Epoch 2: iteration 2136/2501 train_loss: 0.5105653405189514 time_taken: 0.05607771873474121\n",
      "Epoch 2: iteration 2137/2501 train_loss: 0.5105898380279541 time_taken: 0.0560150146484375\n",
      "Epoch 2: iteration 2138/2501 train_loss: 0.5106150507926941 time_taken: 0.05631208419799805\n",
      "Epoch 2: iteration 2139/2501 train_loss: 0.5106433629989624 time_taken: 0.05641460418701172\n",
      "Epoch 2: iteration 2140/2501 train_loss: 0.5106722712516785 time_taken: 0.05620908737182617\n",
      "Epoch 2: iteration 2141/2501 train_loss: 0.5106943845748901 time_taken: 0.056206703186035156\n",
      "Epoch 2: iteration 2142/2501 train_loss: 0.5107225179672241 time_taken: 0.056502342224121094\n",
      "Epoch 2: iteration 2143/2501 train_loss: 0.5107545852661133 time_taken: 0.05718111991882324\n",
      "Epoch 2: iteration 2144/2501 train_loss: 0.5107729434967041 time_taken: 0.05689215660095215\n",
      "Epoch 2: iteration 2145/2501 train_loss: 0.5107941627502441 time_taken: 0.05679464340209961\n",
      "Epoch 2: iteration 2146/2501 train_loss: 0.5108190178871155 time_taken: 0.05704355239868164\n",
      "Epoch 2: iteration 2147/2501 train_loss: 0.5108428597450256 time_taken: 0.059272050857543945\n",
      "Epoch 2: iteration 2148/2501 train_loss: 0.510863184928894 time_taken: 0.056519508361816406\n",
      "Epoch 2: iteration 2149/2501 train_loss: 0.5108837485313416 time_taken: 0.05648231506347656\n",
      "Epoch 2: iteration 2150/2501 train_loss: 0.5108987092971802 time_taken: 0.056079864501953125\n",
      "Epoch 2: iteration 2151/2501 train_loss: 0.5109072327613831 time_taken: 0.05633115768432617\n",
      "Epoch 2: iteration 2152/2501 train_loss: 0.5109206438064575 time_taken: 0.05666375160217285\n",
      "Epoch 2: iteration 2153/2501 train_loss: 0.5109259486198425 time_taken: 0.05617189407348633\n",
      "Epoch 2: iteration 2154/2501 train_loss: 0.5109257102012634 time_taken: 0.056999921798706055\n",
      "Epoch 2: iteration 2155/2501 train_loss: 0.5109186172485352 time_taken: 0.057497501373291016\n",
      "Epoch 2: iteration 2156/2501 train_loss: 0.5109148025512695 time_taken: 0.06152677536010742\n",
      "Epoch 2: iteration 2157/2501 train_loss: 0.5109021663665771 time_taken: 0.05665421485900879\n",
      "Epoch 2: iteration 2158/2501 train_loss: 0.5108895897865295 time_taken: 0.05725550651550293\n",
      "Epoch 2: iteration 2159/2501 train_loss: 0.5108826160430908 time_taken: 0.05629587173461914\n",
      "Epoch 2: iteration 2160/2501 train_loss: 0.5108951926231384 time_taken: 0.05684804916381836\n",
      "Epoch 2: iteration 2161/2501 train_loss: 0.5109027624130249 time_taken: 0.056592702865600586\n",
      "Epoch 2: iteration 2162/2501 train_loss: 0.5109038949012756 time_taken: 0.060143232345581055\n",
      "Epoch 2: iteration 2163/2501 train_loss: 0.5109078884124756 time_taken: 0.05668997764587402\n",
      "Epoch 2: iteration 2164/2501 train_loss: 0.5109130144119263 time_taken: 0.05642580986022949\n",
      "Epoch 2: iteration 2165/2501 train_loss: 0.5109192132949829 time_taken: 0.05752062797546387\n",
      "Epoch 2: iteration 2166/2501 train_loss: 0.5109230875968933 time_taken: 0.05827212333679199\n",
      "Epoch 2: iteration 2167/2501 train_loss: 0.5109266042709351 time_taken: 0.05717897415161133\n",
      "Epoch 2: iteration 2168/2501 train_loss: 0.5109272003173828 time_taken: 0.05660104751586914\n",
      "Epoch 2: iteration 2169/2501 train_loss: 0.5109221935272217 time_taken: 0.05703568458557129\n",
      "Epoch 2: iteration 2170/2501 train_loss: 0.5109164714813232 time_taken: 0.05680704116821289\n",
      "Epoch 2: iteration 2171/2501 train_loss: 0.5109100937843323 time_taken: 0.05771684646606445\n",
      "Epoch 2: iteration 2172/2501 train_loss: 0.5109036564826965 time_taken: 0.057207345962524414\n",
      "Epoch 2: iteration 2173/2501 train_loss: 0.5109027028083801 time_taken: 0.05770730972290039\n",
      "Epoch 2: iteration 2174/2501 train_loss: 0.5108897089958191 time_taken: 0.056649208068847656\n",
      "Epoch 2: iteration 2175/2501 train_loss: 0.5108740925788879 time_taken: 0.056951284408569336\n",
      "Epoch 2: iteration 2176/2501 train_loss: 0.5108663439750671 time_taken: 0.05679130554199219\n",
      "Epoch 2: iteration 2177/2501 train_loss: 0.5108505487442017 time_taken: 0.056830644607543945\n",
      "Epoch 2: iteration 2178/2501 train_loss: 0.5108344554901123 time_taken: 0.056205034255981445\n",
      "Epoch 2: iteration 2179/2501 train_loss: 0.5108141303062439 time_taken: 0.05661582946777344\n",
      "Epoch 2: iteration 2180/2501 train_loss: 0.5107926726341248 time_taken: 0.05658698081970215\n",
      "Epoch 2: iteration 2181/2501 train_loss: 0.5107706189155579 time_taken: 0.056432247161865234\n",
      "Epoch 2: iteration 2182/2501 train_loss: 0.5107532143592834 time_taken: 0.056273460388183594\n",
      "Epoch 2: iteration 2183/2501 train_loss: 0.5107386112213135 time_taken: 0.05611896514892578\n",
      "Epoch 2: iteration 2184/2501 train_loss: 0.5107331275939941 time_taken: 0.056113481521606445\n",
      "Epoch 2: iteration 2185/2501 train_loss: 0.5107362866401672 time_taken: 0.056388139724731445\n",
      "Epoch 2: iteration 2186/2501 train_loss: 0.5107373595237732 time_taken: 0.05601048469543457\n",
      "Epoch 2: iteration 2187/2501 train_loss: 0.5107497572898865 time_taken: 0.0560305118560791\n",
      "Epoch 2: iteration 2188/2501 train_loss: 0.5107505321502686 time_taken: 0.05678963661193848\n",
      "Epoch 2: iteration 2189/2501 train_loss: 0.5107605457305908 time_taken: 0.056893348693847656\n",
      "Epoch 2: iteration 2190/2501 train_loss: 0.5107686519622803 time_taken: 0.05637478828430176\n",
      "Epoch 2: iteration 2191/2501 train_loss: 0.5107705593109131 time_taken: 0.05655312538146973\n",
      "Epoch 2: iteration 2192/2501 train_loss: 0.5107656121253967 time_taken: 0.05611109733581543\n",
      "Epoch 2: iteration 2193/2501 train_loss: 0.5107551217079163 time_taken: 0.056526899337768555\n",
      "Epoch 2: iteration 2194/2501 train_loss: 0.5107431411743164 time_taken: 0.05621695518493652\n",
      "Epoch 2: iteration 2195/2501 train_loss: 0.5107294321060181 time_taken: 0.056685686111450195\n",
      "Epoch 2: iteration 2196/2501 train_loss: 0.510707437992096 time_taken: 0.05756354331970215\n",
      "Epoch 2: iteration 2197/2501 train_loss: 0.5106956362724304 time_taken: 0.056528329849243164\n",
      "Epoch 2: iteration 2198/2501 train_loss: 0.5106753706932068 time_taken: 0.05696296691894531\n",
      "Epoch 2: iteration 2199/2501 train_loss: 0.5106756687164307 time_taken: 0.056914567947387695\n",
      "Epoch 2: iteration 2200/2501 train_loss: 0.510728657245636 time_taken: 0.057006120681762695\n",
      "Epoch 2: iteration 2201/2501 train_loss: 0.5107201337814331 time_taken: 0.05646324157714844\n",
      "Epoch 2: iteration 2202/2501 train_loss: 0.5107002854347229 time_taken: 0.05644488334655762\n",
      "Epoch 2: iteration 2203/2501 train_loss: 0.5107080936431885 time_taken: 0.05614209175109863\n",
      "Epoch 2: iteration 2204/2501 train_loss: 0.5106794834136963 time_taken: 0.0560762882232666\n",
      "Epoch 2: iteration 2205/2501 train_loss: 0.5106917023658752 time_taken: 0.0576629638671875\n",
      "Epoch 2: iteration 2206/2501 train_loss: 0.510659396648407 time_taken: 0.05680418014526367\n",
      "Epoch 2: iteration 2207/2501 train_loss: 0.5106531977653503 time_taken: 0.05623888969421387\n",
      "Epoch 2: iteration 2208/2501 train_loss: 0.5106335282325745 time_taken: 0.05658769607543945\n",
      "Epoch 2: iteration 2209/2501 train_loss: 0.510628342628479 time_taken: 0.05701613426208496\n",
      "Epoch 2: iteration 2210/2501 train_loss: 0.5106272101402283 time_taken: 0.05639290809631348\n",
      "Epoch 2: iteration 2211/2501 train_loss: 0.5106262564659119 time_taken: 0.05658769607543945\n",
      "Epoch 2: iteration 2212/2501 train_loss: 0.5106387734413147 time_taken: 0.056087493896484375\n",
      "Epoch 2: iteration 2213/2501 train_loss: 0.510650098323822 time_taken: 0.05684518814086914\n",
      "Epoch 2: iteration 2214/2501 train_loss: 0.5106592178344727 time_taken: 0.056684255599975586\n",
      "Epoch 2: iteration 2215/2501 train_loss: 0.510674238204956 time_taken: 0.056313514709472656\n",
      "Epoch 2: iteration 2216/2501 train_loss: 0.5106898546218872 time_taken: 0.05660748481750488\n",
      "Epoch 2: iteration 2217/2501 train_loss: 0.510718584060669 time_taken: 0.05655026435852051\n",
      "Epoch 2: iteration 2218/2501 train_loss: 0.5107452869415283 time_taken: 0.056429386138916016\n",
      "Epoch 2: iteration 2219/2501 train_loss: 0.5107719302177429 time_taken: 0.05731821060180664\n",
      "Epoch 2: iteration 2220/2501 train_loss: 0.5107921957969666 time_taken: 0.05753493309020996\n",
      "Epoch 2: iteration 2221/2501 train_loss: 0.510823130607605 time_taken: 0.0568697452545166\n",
      "Epoch 2: iteration 2222/2501 train_loss: 0.5108485817909241 time_taken: 0.05661463737487793\n",
      "Epoch 2: iteration 2223/2501 train_loss: 0.5108751654624939 time_taken: 0.056838035583496094\n",
      "Epoch 2: iteration 2224/2501 train_loss: 0.5109080076217651 time_taken: 0.05591607093811035\n",
      "Epoch 2: iteration 2225/2501 train_loss: 0.510928750038147 time_taken: 0.0559535026550293\n",
      "Epoch 2: iteration 2226/2501 train_loss: 0.5109527707099915 time_taken: 0.05710315704345703\n",
      "Epoch 2: iteration 2227/2501 train_loss: 0.5109724402427673 time_taken: 0.05656147003173828\n",
      "Epoch 2: iteration 2228/2501 train_loss: 0.5110003352165222 time_taken: 0.056685686111450195\n",
      "Epoch 2: iteration 2229/2501 train_loss: 0.5110236406326294 time_taken: 0.0570216178894043\n",
      "Epoch 2: iteration 2230/2501 train_loss: 0.5110546946525574 time_taken: 0.05677914619445801\n",
      "Epoch 2: iteration 2231/2501 train_loss: 0.5110861659049988 time_taken: 0.05643200874328613\n",
      "Epoch 2: iteration 2232/2501 train_loss: 0.511122465133667 time_taken: 0.05681967735290527\n",
      "Epoch 2: iteration 2233/2501 train_loss: 0.5111498236656189 time_taken: 0.05632591247558594\n",
      "Epoch 2: iteration 2234/2501 train_loss: 0.5111804604530334 time_taken: 0.058641672134399414\n",
      "Epoch 2: iteration 2235/2501 train_loss: 0.5112199187278748 time_taken: 0.05698275566101074\n",
      "Epoch 2: iteration 2236/2501 train_loss: 0.5112517476081848 time_taken: 0.056131839752197266\n",
      "Epoch 2: iteration 2237/2501 train_loss: 0.5112888216972351 time_taken: 0.05669832229614258\n",
      "Epoch 2: iteration 2238/2501 train_loss: 0.5113382935523987 time_taken: 0.05693769454956055\n",
      "Epoch 2: iteration 2239/2501 train_loss: 0.5113840103149414 time_taken: 0.05657029151916504\n",
      "Epoch 2: iteration 2240/2501 train_loss: 0.5114269852638245 time_taken: 0.05684518814086914\n",
      "Epoch 2: iteration 2241/2501 train_loss: 0.5114712715148926 time_taken: 0.05644679069519043\n",
      "Epoch 2: iteration 2242/2501 train_loss: 0.5115253925323486 time_taken: 0.05782032012939453\n",
      "Epoch 2: iteration 2243/2501 train_loss: 0.5115717053413391 time_taken: 0.05704998970031738\n",
      "Epoch 2: iteration 2244/2501 train_loss: 0.5116153955459595 time_taken: 0.0564572811126709\n",
      "Epoch 2: iteration 2245/2501 train_loss: 0.5116544961929321 time_taken: 0.05760765075683594\n",
      "Epoch 2: iteration 2246/2501 train_loss: 0.5116957426071167 time_taken: 0.0562589168548584\n",
      "Epoch 2: iteration 2247/2501 train_loss: 0.5117318034172058 time_taken: 0.05626106262207031\n",
      "Epoch 2: iteration 2248/2501 train_loss: 0.5117761492729187 time_taken: 0.06088614463806152\n",
      "Epoch 2: iteration 2249/2501 train_loss: 0.5118371844291687 time_taken: 0.05628561973571777\n",
      "Epoch 2: iteration 2250/2501 train_loss: 0.5118982195854187 time_taken: 0.05633091926574707\n",
      "Epoch 2: iteration 2251/2501 train_loss: 0.5119530558586121 time_taken: 0.05585646629333496\n",
      "Epoch 2: iteration 2252/2501 train_loss: 0.5119987726211548 time_taken: 0.06047224998474121\n",
      "Epoch 2: iteration 2253/2501 train_loss: 0.5120406150817871 time_taken: 0.05597281455993652\n",
      "Epoch 2: iteration 2254/2501 train_loss: 0.5120887160301208 time_taken: 0.056035757064819336\n",
      "Epoch 2: iteration 2255/2501 train_loss: 0.5121262073516846 time_taken: 0.056409597396850586\n",
      "Epoch 2: iteration 2256/2501 train_loss: 0.512161374092102 time_taken: 0.05707049369812012\n",
      "Epoch 2: iteration 2257/2501 train_loss: 0.51219242811203 time_taken: 0.05765962600708008\n",
      "Epoch 2: iteration 2258/2501 train_loss: 0.5122219920158386 time_taken: 0.05691933631896973\n",
      "Epoch 2: iteration 2259/2501 train_loss: 0.5122373104095459 time_taken: 0.057450294494628906\n",
      "Epoch 2: iteration 2260/2501 train_loss: 0.5122566223144531 time_taken: 0.05675220489501953\n",
      "Epoch 2: iteration 2261/2501 train_loss: 0.5122652649879456 time_taken: 0.05605435371398926\n",
      "Epoch 2: iteration 2262/2501 train_loss: 0.512273907661438 time_taken: 0.05700826644897461\n",
      "Epoch 2: iteration 2263/2501 train_loss: 0.5122736096382141 time_taken: 0.05731678009033203\n",
      "Epoch 2: iteration 2264/2501 train_loss: 0.5122731924057007 time_taken: 0.056401968002319336\n",
      "Epoch 2: iteration 2265/2501 train_loss: 0.5122786164283752 time_taken: 0.05677032470703125\n",
      "Epoch 2: iteration 2266/2501 train_loss: 0.512276291847229 time_taken: 0.05683493614196777\n",
      "Epoch 2: iteration 2267/2501 train_loss: 0.5122789144515991 time_taken: 0.05722856521606445\n",
      "Epoch 2: iteration 2268/2501 train_loss: 0.5122801661491394 time_taken: 0.056600332260131836\n",
      "Epoch 2: iteration 2269/2501 train_loss: 0.5122892260551453 time_taken: 0.05648541450500488\n",
      "Epoch 2: iteration 2270/2501 train_loss: 0.5122879147529602 time_taken: 0.056893348693847656\n",
      "Epoch 2: iteration 2271/2501 train_loss: 0.5122891664505005 time_taken: 0.0570826530456543\n",
      "Epoch 2: iteration 2272/2501 train_loss: 0.5122959017753601 time_taken: 0.05643033981323242\n",
      "Epoch 2: iteration 2273/2501 train_loss: 0.5123001933097839 time_taken: 0.056397199630737305\n",
      "Epoch 2: iteration 2274/2501 train_loss: 0.5123049020767212 time_taken: 0.0573422908782959\n",
      "Epoch 2: iteration 2275/2501 train_loss: 0.512310266494751 time_taken: 0.05696439743041992\n",
      "Epoch 2: iteration 2276/2501 train_loss: 0.5123205780982971 time_taken: 0.056037187576293945\n",
      "Epoch 2: iteration 2277/2501 train_loss: 0.5123377442359924 time_taken: 0.05616593360900879\n",
      "Epoch 2: iteration 2278/2501 train_loss: 0.5123554468154907 time_taken: 0.056928396224975586\n",
      "Epoch 2: iteration 2279/2501 train_loss: 0.5123700499534607 time_taken: 0.0565180778503418\n",
      "Epoch 2: iteration 2280/2501 train_loss: 0.5123899579048157 time_taken: 0.05637669563293457\n",
      "Epoch 2: iteration 2281/2501 train_loss: 0.5124143958091736 time_taken: 0.05594325065612793\n",
      "Epoch 2: iteration 2282/2501 train_loss: 0.5124366879463196 time_taken: 0.05581355094909668\n",
      "Epoch 2: iteration 2283/2501 train_loss: 0.5124644041061401 time_taken: 0.05639052391052246\n",
      "Epoch 2: iteration 2284/2501 train_loss: 0.5124800801277161 time_taken: 0.05639195442199707\n",
      "Epoch 2: iteration 2285/2501 train_loss: 0.5125015377998352 time_taken: 0.056203603744506836\n",
      "Epoch 2: iteration 2286/2501 train_loss: 0.512520968914032 time_taken: 0.05672049522399902\n",
      "Epoch 2: iteration 2287/2501 train_loss: 0.5125478506088257 time_taken: 0.05735015869140625\n",
      "Epoch 2: iteration 2288/2501 train_loss: 0.5125753879547119 time_taken: 0.056060075759887695\n",
      "Epoch 2: iteration 2289/2501 train_loss: 0.512610912322998 time_taken: 0.05684399604797363\n",
      "Epoch 2: iteration 2290/2501 train_loss: 0.5126568675041199 time_taken: 0.05675458908081055\n",
      "Epoch 2: iteration 2291/2501 train_loss: 0.512704610824585 time_taken: 0.05665922164916992\n",
      "Epoch 2: iteration 2292/2501 train_loss: 0.5127564668655396 time_taken: 0.05718636512756348\n",
      "Epoch 2: iteration 2293/2501 train_loss: 0.5128036737442017 time_taken: 0.05646538734436035\n",
      "Epoch 2: iteration 2294/2501 train_loss: 0.5128515958786011 time_taken: 0.05673861503601074\n",
      "Epoch 2: iteration 2295/2501 train_loss: 0.5129033327102661 time_taken: 0.056764841079711914\n",
      "Epoch 2: iteration 2296/2501 train_loss: 0.5129465460777283 time_taken: 0.056591033935546875\n",
      "Epoch 2: iteration 2297/2501 train_loss: 0.5129886269569397 time_taken: 0.05747079849243164\n",
      "Epoch 2: iteration 2298/2501 train_loss: 0.513039767742157 time_taken: 0.05775594711303711\n",
      "Epoch 2: iteration 2299/2501 train_loss: 0.5130840539932251 time_taken: 0.05723309516906738\n",
      "Epoch 2: iteration 2300/2501 train_loss: 0.5131393074989319 time_taken: 0.0564730167388916\n",
      "Epoch 2: iteration 2301/2501 train_loss: 0.5131875276565552 time_taken: 0.05757856369018555\n",
      "Epoch 2: iteration 2302/2501 train_loss: 0.5132340788841248 time_taken: 0.05656290054321289\n",
      "Epoch 2: iteration 2303/2501 train_loss: 0.5132784843444824 time_taken: 0.05687546730041504\n",
      "Epoch 2: iteration 2304/2501 train_loss: 0.5133194327354431 time_taken: 0.05647468566894531\n",
      "Epoch 2: iteration 2305/2501 train_loss: 0.5133621096611023 time_taken: 0.0573275089263916\n",
      "Epoch 2: iteration 2306/2501 train_loss: 0.5133963823318481 time_taken: 0.05670046806335449\n",
      "Epoch 2: iteration 2307/2501 train_loss: 0.513431966304779 time_taken: 0.05655622482299805\n",
      "Epoch 2: iteration 2308/2501 train_loss: 0.5134690403938293 time_taken: 0.0561830997467041\n",
      "Epoch 2: iteration 2309/2501 train_loss: 0.5135111808776855 time_taken: 0.05617117881774902\n",
      "Epoch 2: iteration 2310/2501 train_loss: 0.5135611891746521 time_taken: 0.05674552917480469\n",
      "Epoch 2: iteration 2311/2501 train_loss: 0.5136081576347351 time_taken: 0.058496952056884766\n",
      "Epoch 2: iteration 2312/2501 train_loss: 0.5136501789093018 time_taken: 0.05668973922729492\n",
      "Epoch 2: iteration 2313/2501 train_loss: 0.5136927962303162 time_taken: 0.056281328201293945\n",
      "Epoch 2: iteration 2314/2501 train_loss: 0.5137364268302917 time_taken: 0.06106400489807129\n",
      "Epoch 2: iteration 2315/2501 train_loss: 0.5137761235237122 time_taken: 0.0573575496673584\n",
      "Epoch 2: iteration 2316/2501 train_loss: 0.5138136744499207 time_taken: 0.05766868591308594\n",
      "Epoch 2: iteration 2317/2501 train_loss: 0.5138569474220276 time_taken: 0.05656313896179199\n",
      "Epoch 2: iteration 2318/2501 train_loss: 0.5139011740684509 time_taken: 0.05610966682434082\n",
      "Epoch 2: iteration 2319/2501 train_loss: 0.5139512419700623 time_taken: 0.05646252632141113\n",
      "Epoch 2: iteration 2320/2501 train_loss: 0.5140033960342407 time_taken: 0.05716824531555176\n",
      "Epoch 2: iteration 2321/2501 train_loss: 0.5140401124954224 time_taken: 0.056345224380493164\n",
      "Epoch 2: iteration 2322/2501 train_loss: 0.5140811800956726 time_taken: 0.056606292724609375\n",
      "Epoch 2: iteration 2323/2501 train_loss: 0.5141165852546692 time_taken: 0.05652356147766113\n",
      "Epoch 2: iteration 2324/2501 train_loss: 0.5141540169715881 time_taken: 0.056081295013427734\n",
      "Epoch 2: iteration 2325/2501 train_loss: 0.5141956210136414 time_taken: 0.05646681785583496\n",
      "Epoch 2: iteration 2326/2501 train_loss: 0.5142242312431335 time_taken: 0.05669713020324707\n",
      "Epoch 2: iteration 2327/2501 train_loss: 0.5142580270767212 time_taken: 0.05646848678588867\n",
      "Epoch 2: iteration 2328/2501 train_loss: 0.5142890214920044 time_taken: 0.056510210037231445\n",
      "Epoch 2: iteration 2329/2501 train_loss: 0.514324963092804 time_taken: 0.05678057670593262\n",
      "Epoch 2: iteration 2330/2501 train_loss: 0.5143653750419617 time_taken: 0.05669856071472168\n",
      "Epoch 2: iteration 2331/2501 train_loss: 0.514394223690033 time_taken: 0.057152509689331055\n",
      "Epoch 2: iteration 2332/2501 train_loss: 0.5144222974777222 time_taken: 0.057633399963378906\n",
      "Epoch 2: iteration 2333/2501 train_loss: 0.5144460201263428 time_taken: 0.05660438537597656\n",
      "Epoch 2: iteration 2334/2501 train_loss: 0.5144721269607544 time_taken: 0.09291410446166992\n",
      "Epoch 2: iteration 2335/2501 train_loss: 0.5145055055618286 time_taken: 0.05742144584655762\n",
      "Epoch 2: iteration 2336/2501 train_loss: 0.5145336389541626 time_taken: 0.07563304901123047\n",
      "Epoch 2: iteration 2337/2501 train_loss: 0.5145568251609802 time_taken: 0.056673526763916016\n",
      "Epoch 2: iteration 2338/2501 train_loss: 0.5145808458328247 time_taken: 0.057042598724365234\n",
      "Epoch 2: iteration 2339/2501 train_loss: 0.5146085619926453 time_taken: 0.05680513381958008\n",
      "Epoch 2: iteration 2340/2501 train_loss: 0.5146398544311523 time_taken: 0.05700373649597168\n",
      "Epoch 2: iteration 2341/2501 train_loss: 0.5146594047546387 time_taken: 0.056745052337646484\n",
      "Epoch 2: iteration 2342/2501 train_loss: 0.5146870017051697 time_taken: 0.05718851089477539\n",
      "Epoch 2: iteration 2343/2501 train_loss: 0.5147092938423157 time_taken: 0.057099342346191406\n",
      "Epoch 2: iteration 2344/2501 train_loss: 0.5147318840026855 time_taken: 0.05702543258666992\n",
      "Epoch 2: iteration 2345/2501 train_loss: 0.5147461295127869 time_taken: 0.05696582794189453\n",
      "Epoch 2: iteration 2346/2501 train_loss: 0.514763593673706 time_taken: 0.05698132514953613\n",
      "Epoch 2: iteration 2347/2501 train_loss: 0.5147755146026611 time_taken: 0.05666208267211914\n",
      "Epoch 2: iteration 2348/2501 train_loss: 0.5147897005081177 time_taken: 0.05665469169616699\n",
      "Epoch 2: iteration 2349/2501 train_loss: 0.514802873134613 time_taken: 0.056319236755371094\n",
      "Epoch 2: iteration 2350/2501 train_loss: 0.5148142576217651 time_taken: 0.056528568267822266\n",
      "Epoch 2: iteration 2351/2501 train_loss: 0.5148173570632935 time_taken: 0.05657672882080078\n",
      "Epoch 2: iteration 2352/2501 train_loss: 0.5148199796676636 time_taken: 0.05673050880432129\n",
      "Epoch 2: iteration 2353/2501 train_loss: 0.5148195028305054 time_taken: 0.05675005912780762\n",
      "Epoch 2: iteration 2354/2501 train_loss: 0.5148152709007263 time_taken: 0.05648350715637207\n",
      "Epoch 2: iteration 2355/2501 train_loss: 0.5147994756698608 time_taken: 0.05765104293823242\n",
      "Epoch 2: iteration 2356/2501 train_loss: 0.514789342880249 time_taken: 0.056416988372802734\n",
      "Epoch 2: iteration 2357/2501 train_loss: 0.5147785544395447 time_taken: 0.05720210075378418\n",
      "Epoch 2: iteration 2358/2501 train_loss: 0.5147580504417419 time_taken: 0.05621623992919922\n",
      "Epoch 2: iteration 2359/2501 train_loss: 0.5147448182106018 time_taken: 0.056463003158569336\n",
      "Epoch 2: iteration 2360/2501 train_loss: 0.5147278904914856 time_taken: 0.05674242973327637\n",
      "Epoch 2: iteration 2361/2501 train_loss: 0.5147058367729187 time_taken: 0.05663633346557617\n",
      "Epoch 2: iteration 2362/2501 train_loss: 0.5146811604499817 time_taken: 0.0593416690826416\n",
      "Epoch 2: iteration 2363/2501 train_loss: 0.5146531462669373 time_taken: 0.05617356300354004\n",
      "Epoch 2: iteration 2364/2501 train_loss: 0.5146272778511047 time_taken: 0.05602407455444336\n",
      "Epoch 2: iteration 2365/2501 train_loss: 0.51461261510849 time_taken: 0.056064605712890625\n",
      "Epoch 2: iteration 2366/2501 train_loss: 0.5145937204360962 time_taken: 0.05606865882873535\n",
      "Epoch 2: iteration 2367/2501 train_loss: 0.5145771503448486 time_taken: 0.05714893341064453\n",
      "Epoch 2: iteration 2368/2501 train_loss: 0.5145581364631653 time_taken: 0.056206464767456055\n",
      "Epoch 2: iteration 2369/2501 train_loss: 0.5145400166511536 time_taken: 0.057851552963256836\n",
      "Epoch 2: iteration 2370/2501 train_loss: 0.5145167112350464 time_taken: 0.0567626953125\n",
      "Epoch 2: iteration 2371/2501 train_loss: 0.5145067572593689 time_taken: 0.0560152530670166\n",
      "Epoch 2: iteration 2372/2501 train_loss: 0.5144950747489929 time_taken: 0.05614805221557617\n",
      "Epoch 2: iteration 2373/2501 train_loss: 0.5144838690757751 time_taken: 0.05611228942871094\n",
      "Epoch 2: iteration 2374/2501 train_loss: 0.5144809484481812 time_taken: 0.0563967227935791\n",
      "Epoch 2: iteration 2375/2501 train_loss: 0.5144709348678589 time_taken: 0.05650806427001953\n",
      "Epoch 2: iteration 2376/2501 train_loss: 0.5144557356834412 time_taken: 0.05619311332702637\n",
      "Epoch 2: iteration 2377/2501 train_loss: 0.5144421458244324 time_taken: 0.0573732852935791\n",
      "Epoch 2: iteration 2378/2501 train_loss: 0.5144292116165161 time_taken: 0.056542396545410156\n",
      "Epoch 2: iteration 2379/2501 train_loss: 0.5144307017326355 time_taken: 0.05632805824279785\n",
      "Epoch 2: iteration 2380/2501 train_loss: 0.5144299268722534 time_taken: 0.0560145378112793\n",
      "Epoch 2: iteration 2381/2501 train_loss: 0.514430820941925 time_taken: 0.0594637393951416\n",
      "Epoch 2: iteration 2382/2501 train_loss: 0.5144359469413757 time_taken: 0.05635261535644531\n",
      "Epoch 2: iteration 2383/2501 train_loss: 0.5144398212432861 time_taken: 0.05663013458251953\n",
      "Epoch 2: iteration 2384/2501 train_loss: 0.5144377946853638 time_taken: 0.0569150447845459\n",
      "Epoch 2: iteration 2385/2501 train_loss: 0.5144427418708801 time_taken: 0.0578763484954834\n",
      "Epoch 2: iteration 2386/2501 train_loss: 0.5144384503364563 time_taken: 0.056345224380493164\n",
      "Epoch 2: iteration 2387/2501 train_loss: 0.5144428610801697 time_taken: 0.057065725326538086\n",
      "Epoch 2: iteration 2388/2501 train_loss: 0.5144431591033936 time_taken: 0.05640673637390137\n",
      "Epoch 2: iteration 2389/2501 train_loss: 0.5144344568252563 time_taken: 0.05660891532897949\n",
      "Epoch 2: iteration 2390/2501 train_loss: 0.5144275426864624 time_taken: 0.05625796318054199\n",
      "Epoch 2: iteration 2391/2501 train_loss: 0.5144191980361938 time_taken: 0.05588078498840332\n",
      "Epoch 2: iteration 2392/2501 train_loss: 0.5144100785255432 time_taken: 0.05668187141418457\n",
      "Epoch 2: iteration 2393/2501 train_loss: 0.5144058465957642 time_taken: 0.05578923225402832\n",
      "Epoch 2: iteration 2394/2501 train_loss: 0.5144023895263672 time_taken: 0.05625033378601074\n",
      "Epoch 2: iteration 2395/2501 train_loss: 0.514398455619812 time_taken: 0.056177616119384766\n",
      "Epoch 2: iteration 2396/2501 train_loss: 0.5144080519676208 time_taken: 0.056931495666503906\n",
      "Epoch 2: iteration 2397/2501 train_loss: 0.5144135355949402 time_taken: 0.05658149719238281\n",
      "Epoch 2: iteration 2398/2501 train_loss: 0.5144204497337341 time_taken: 0.05584597587585449\n",
      "Epoch 2: iteration 2399/2501 train_loss: 0.5144246220588684 time_taken: 0.056058406829833984\n",
      "Epoch 2: iteration 2400/2501 train_loss: 0.5144355297088623 time_taken: 0.05693984031677246\n",
      "Epoch 2: iteration 2401/2501 train_loss: 0.514443039894104 time_taken: 0.05654096603393555\n",
      "Epoch 2: iteration 2402/2501 train_loss: 0.5144410133361816 time_taken: 0.05600285530090332\n",
      "Epoch 2: iteration 2403/2501 train_loss: 0.5144400596618652 time_taken: 0.055757761001586914\n",
      "Epoch 2: iteration 2404/2501 train_loss: 0.5144432187080383 time_taken: 0.056505680084228516\n",
      "Epoch 2: iteration 2405/2501 train_loss: 0.514447033405304 time_taken: 0.05649375915527344\n",
      "Epoch 2: iteration 2406/2501 train_loss: 0.5144481062889099 time_taken: 0.0568389892578125\n",
      "Epoch 2: iteration 2407/2501 train_loss: 0.5144539475440979 time_taken: 0.056467533111572266\n",
      "Epoch 2: iteration 2408/2501 train_loss: 0.5144562125205994 time_taken: 0.056940555572509766\n",
      "Epoch 2: iteration 2409/2501 train_loss: 0.514463484287262 time_taken: 0.05639958381652832\n",
      "Epoch 2: iteration 2410/2501 train_loss: 0.5144683718681335 time_taken: 0.05656766891479492\n",
      "Epoch 2: iteration 2411/2501 train_loss: 0.5144754648208618 time_taken: 0.05712890625\n",
      "Epoch 2: iteration 2412/2501 train_loss: 0.5144797563552856 time_taken: 0.05669736862182617\n",
      "Epoch 2: iteration 2413/2501 train_loss: 0.5144920349121094 time_taken: 0.056153059005737305\n",
      "Epoch 2: iteration 2414/2501 train_loss: 0.5145102739334106 time_taken: 0.05608725547790527\n",
      "Epoch 2: iteration 2415/2501 train_loss: 0.5145223736763 time_taken: 0.05656909942626953\n",
      "Epoch 2: iteration 2416/2501 train_loss: 0.5145440101623535 time_taken: 0.05596637725830078\n",
      "Epoch 2: iteration 2417/2501 train_loss: 0.5145648121833801 time_taken: 0.0608210563659668\n",
      "Epoch 2: iteration 2418/2501 train_loss: 0.5145866870880127 time_taken: 0.056604623794555664\n",
      "Epoch 2: iteration 2419/2501 train_loss: 0.5146047472953796 time_taken: 0.05629754066467285\n",
      "Epoch 2: iteration 2420/2501 train_loss: 0.5146186351776123 time_taken: 0.05625724792480469\n",
      "Epoch 2: iteration 2421/2501 train_loss: 0.5146396160125732 time_taken: 0.05597209930419922\n",
      "Epoch 2: iteration 2422/2501 train_loss: 0.5146655440330505 time_taken: 0.056961774826049805\n",
      "Epoch 2: iteration 2423/2501 train_loss: 0.5146973729133606 time_taken: 0.05664992332458496\n",
      "Epoch 2: iteration 2424/2501 train_loss: 0.5147232413291931 time_taken: 0.05602455139160156\n",
      "Epoch 2: iteration 2425/2501 train_loss: 0.5147452354431152 time_taken: 0.07770562171936035\n",
      "Epoch 2: iteration 2426/2501 train_loss: 0.5147720575332642 time_taken: 0.07009339332580566\n",
      "Epoch 2: iteration 2427/2501 train_loss: 0.5148082971572876 time_taken: 0.05632519721984863\n",
      "Epoch 2: iteration 2428/2501 train_loss: 0.514839231967926 time_taken: 0.06435418128967285\n",
      "Epoch 2: iteration 2429/2501 train_loss: 0.5148797035217285 time_taken: 0.05597853660583496\n",
      "Epoch 2: iteration 2430/2501 train_loss: 0.5149057507514954 time_taken: 0.05607724189758301\n",
      "Epoch 2: iteration 2431/2501 train_loss: 0.5149537920951843 time_taken: 0.05676603317260742\n",
      "Epoch 2: iteration 2432/2501 train_loss: 0.5149965882301331 time_taken: 0.05723857879638672\n",
      "Epoch 2: iteration 2433/2501 train_loss: 0.5150377154350281 time_taken: 0.05715012550354004\n",
      "Epoch 2: iteration 2434/2501 train_loss: 0.5150672793388367 time_taken: 0.056845903396606445\n",
      "Epoch 2: iteration 2435/2501 train_loss: 0.5151059031486511 time_taken: 0.05698060989379883\n",
      "Epoch 2: iteration 2436/2501 train_loss: 0.515143096446991 time_taken: 0.05639314651489258\n",
      "Epoch 2: iteration 2437/2501 train_loss: 0.5151814222335815 time_taken: 0.061373233795166016\n",
      "Epoch 2: iteration 2438/2501 train_loss: 0.5152150988578796 time_taken: 0.05607032775878906\n",
      "Epoch 2: iteration 2439/2501 train_loss: 0.5152518153190613 time_taken: 0.05615353584289551\n",
      "Epoch 2: iteration 2440/2501 train_loss: 0.5152917504310608 time_taken: 0.05636405944824219\n",
      "Epoch 2: iteration 2441/2501 train_loss: 0.5153375267982483 time_taken: 0.06215691566467285\n",
      "Epoch 2: iteration 2442/2501 train_loss: 0.515379786491394 time_taken: 0.0569608211517334\n",
      "Epoch 2: iteration 2443/2501 train_loss: 0.515414297580719 time_taken: 0.056059837341308594\n",
      "Epoch 2: iteration 2444/2501 train_loss: 0.5154551267623901 time_taken: 0.059508323669433594\n",
      "Epoch 2: iteration 2445/2501 train_loss: 0.5154950618743896 time_taken: 0.05635428428649902\n",
      "Epoch 2: iteration 2446/2501 train_loss: 0.5155242085456848 time_taken: 0.056221723556518555\n",
      "Epoch 2: iteration 2447/2501 train_loss: 0.5155537724494934 time_taken: 0.055800676345825195\n",
      "Epoch 2: iteration 2448/2501 train_loss: 0.5155874490737915 time_taken: 0.05615973472595215\n",
      "Epoch 2: iteration 2449/2501 train_loss: 0.515608549118042 time_taken: 0.05608677864074707\n",
      "Epoch 2: iteration 2450/2501 train_loss: 0.5156281590461731 time_taken: 0.05655336380004883\n",
      "Epoch 2: iteration 2451/2501 train_loss: 0.5156517624855042 time_taken: 0.05659174919128418\n",
      "Epoch 2: iteration 2452/2501 train_loss: 0.515663743019104 time_taken: 0.056589603424072266\n",
      "Epoch 2: iteration 2453/2501 train_loss: 0.5156753659248352 time_taken: 0.05667448043823242\n",
      "Epoch 2: iteration 2454/2501 train_loss: 0.5156876444816589 time_taken: 0.056218862533569336\n",
      "Epoch 2: iteration 2455/2501 train_loss: 0.5156949758529663 time_taken: 0.05723428726196289\n",
      "Epoch 2: iteration 2456/2501 train_loss: 0.5157027840614319 time_taken: 0.0565946102142334\n",
      "Epoch 2: iteration 2457/2501 train_loss: 0.5157055258750916 time_taken: 0.05688905715942383\n",
      "Epoch 2: iteration 2458/2501 train_loss: 0.5157015919685364 time_taken: 0.05676531791687012\n",
      "Epoch 2: iteration 2459/2501 train_loss: 0.5156995058059692 time_taken: 0.0565342903137207\n",
      "Epoch 2: iteration 2460/2501 train_loss: 0.5156965255737305 time_taken: 0.05665254592895508\n",
      "Epoch 2: iteration 2461/2501 train_loss: 0.5156894326210022 time_taken: 0.056885480880737305\n",
      "Epoch 2: iteration 2462/2501 train_loss: 0.5156909823417664 time_taken: 0.05678081512451172\n",
      "Epoch 2: iteration 2463/2501 train_loss: 0.5156950354576111 time_taken: 0.057411909103393555\n",
      "Epoch 2: iteration 2464/2501 train_loss: 0.515707790851593 time_taken: 0.05704903602600098\n",
      "Epoch 2: iteration 2465/2501 train_loss: 0.5157108306884766 time_taken: 0.05671095848083496\n",
      "Epoch 2: iteration 2466/2501 train_loss: 0.515724241733551 time_taken: 0.057283878326416016\n",
      "Epoch 2: iteration 2467/2501 train_loss: 0.515738308429718 time_taken: 0.057033538818359375\n",
      "Epoch 2: iteration 2468/2501 train_loss: 0.5157460570335388 time_taken: 0.05675983428955078\n",
      "Epoch 2: iteration 2469/2501 train_loss: 0.5157565474510193 time_taken: 0.05685877799987793\n",
      "Epoch 2: iteration 2470/2501 train_loss: 0.5157675743103027 time_taken: 0.05686759948730469\n",
      "Epoch 2: iteration 2471/2501 train_loss: 0.5157786011695862 time_taken: 0.056902170181274414\n",
      "Epoch 2: iteration 2472/2501 train_loss: 0.5157868266105652 time_taken: 0.05711722373962402\n",
      "Epoch 2: iteration 2473/2501 train_loss: 0.5157865881919861 time_taken: 0.05681419372558594\n",
      "Epoch 2: iteration 2474/2501 train_loss: 0.5157922506332397 time_taken: 0.05740642547607422\n",
      "Epoch 2: iteration 2475/2501 train_loss: 0.5157980918884277 time_taken: 0.05760002136230469\n",
      "Epoch 2: iteration 2476/2501 train_loss: 0.5158194899559021 time_taken: 0.05663156509399414\n",
      "Epoch 2: iteration 2477/2501 train_loss: 0.5158379077911377 time_taken: 0.056475162506103516\n",
      "Epoch 2: iteration 2478/2501 train_loss: 0.5158488154411316 time_taken: 0.05659985542297363\n",
      "Epoch 2: iteration 2479/2501 train_loss: 0.5158730745315552 time_taken: 0.05684971809387207\n",
      "Epoch 2: iteration 2480/2501 train_loss: 0.5159100294113159 time_taken: 0.056411027908325195\n",
      "Epoch 2: iteration 2481/2501 train_loss: 0.5159314870834351 time_taken: 0.05638480186462402\n",
      "Epoch 2: iteration 2482/2501 train_loss: 0.5159600973129272 time_taken: 0.05637550354003906\n",
      "Epoch 2: iteration 2483/2501 train_loss: 0.5159851908683777 time_taken: 0.05684661865234375\n",
      "Epoch 2: iteration 2484/2501 train_loss: 0.5160230398178101 time_taken: 0.0565187931060791\n",
      "Epoch 2: iteration 2485/2501 train_loss: 0.5160699486732483 time_taken: 0.056644439697265625\n",
      "Epoch 2: iteration 2486/2501 train_loss: 0.516122043132782 time_taken: 0.05655217170715332\n",
      "Epoch 2: iteration 2487/2501 train_loss: 0.5161788463592529 time_taken: 0.06727933883666992\n",
      "Epoch 2: iteration 2488/2501 train_loss: 0.5162389874458313 time_taken: 0.055640220642089844\n",
      "Epoch 2: iteration 2489/2501 train_loss: 0.5162867903709412 time_taken: 0.055997610092163086\n",
      "Epoch 2: iteration 2490/2501 train_loss: 0.5163222551345825 time_taken: 0.07766413688659668\n",
      "Epoch 2: iteration 2491/2501 train_loss: 0.5163459777832031 time_taken: 0.05595660209655762\n",
      "Epoch 2: iteration 2492/2501 train_loss: 0.5163809061050415 time_taken: 0.055542945861816406\n",
      "Epoch 2: iteration 2493/2501 train_loss: 0.5164016485214233 time_taken: 0.05546736717224121\n",
      "Epoch 2: iteration 2494/2501 train_loss: 0.516433835029602 time_taken: 0.055922746658325195\n",
      "Epoch 2: iteration 2495/2501 train_loss: 0.5164608359336853 time_taken: 0.05745553970336914\n",
      "Epoch 2: iteration 2496/2501 train_loss: 0.5164894461631775 time_taken: 0.056307315826416016\n",
      "Epoch 2: iteration 2497/2501 train_loss: 0.5165150165557861 time_taken: 0.05595278739929199\n",
      "Epoch 2: iteration 2498/2501 train_loss: 0.5165430903434753 time_taken: 0.055938005447387695\n",
      "Epoch 2: iteration 2499/2501 train_loss: 0.5165659189224243 time_taken: 0.05594921112060547\n",
      "Epoch 2: iteration 2500/2501 train_loss: 0.5165767073631287 time_taken: 0.05541515350341797\n",
      "Finished epoch 2 took 445.57687520980835\n",
      "Starting epoch 3/5\n",
      "Epoch 3: iteration 0/2501 train_loss: 0.676906406879425 time_taken: 0.05646324157714844\n",
      "Epoch 3: iteration 1/2501 train_loss: 0.6723836660385132 time_taken: 0.05585741996765137\n",
      "Epoch 3: iteration 2/2501 train_loss: 0.651675283908844 time_taken: 0.056774139404296875\n",
      "Epoch 3: iteration 3/2501 train_loss: 0.6411010026931763 time_taken: 0.06128096580505371\n",
      "Epoch 3: iteration 4/2501 train_loss: 0.6296620965003967 time_taken: 0.057260751724243164\n",
      "Epoch 3: iteration 5/2501 train_loss: 0.617824137210846 time_taken: 0.05678701400756836\n",
      "Epoch 3: iteration 6/2501 train_loss: 0.6072177886962891 time_taken: 0.055963993072509766\n",
      "Epoch 3: iteration 7/2501 train_loss: 0.5975046753883362 time_taken: 0.056215524673461914\n",
      "Epoch 3: iteration 8/2501 train_loss: 0.586665689945221 time_taken: 0.05606961250305176\n",
      "Epoch 3: iteration 9/2501 train_loss: 0.5766781568527222 time_taken: 0.056584835052490234\n",
      "Epoch 3: iteration 10/2501 train_loss: 0.5677018761634827 time_taken: 0.05652570724487305\n",
      "Epoch 3: iteration 11/2501 train_loss: 0.5613262057304382 time_taken: 0.0565791130065918\n",
      "Epoch 3: iteration 12/2501 train_loss: 0.5536153316497803 time_taken: 0.057314395904541016\n",
      "Epoch 3: iteration 13/2501 train_loss: 0.5483844876289368 time_taken: 0.056594133377075195\n",
      "Epoch 3: iteration 14/2501 train_loss: 0.5424831509590149 time_taken: 0.05604410171508789\n",
      "Epoch 3: iteration 15/2501 train_loss: 0.5374756455421448 time_taken: 0.05642962455749512\n",
      "Epoch 3: iteration 16/2501 train_loss: 0.5324429869651794 time_taken: 0.0697774887084961\n",
      "Epoch 3: iteration 17/2501 train_loss: 0.5291682481765747 time_taken: 0.056946754455566406\n",
      "Epoch 3: iteration 18/2501 train_loss: 0.5261141657829285 time_taken: 0.05665254592895508\n",
      "Epoch 3: iteration 19/2501 train_loss: 0.5237458944320679 time_taken: 0.05674099922180176\n",
      "Epoch 3: iteration 20/2501 train_loss: 0.522167444229126 time_taken: 0.05610013008117676\n",
      "Epoch 3: iteration 21/2501 train_loss: 0.5202889442443848 time_taken: 0.05667757987976074\n",
      "Epoch 3: iteration 22/2501 train_loss: 0.5178655385971069 time_taken: 0.056192874908447266\n",
      "Epoch 3: iteration 23/2501 train_loss: 0.515914261341095 time_taken: 0.056504249572753906\n",
      "Epoch 3: iteration 24/2501 train_loss: 0.5151228904724121 time_taken: 0.05633735656738281\n",
      "Epoch 3: iteration 25/2501 train_loss: 0.5143167972564697 time_taken: 0.05629587173461914\n",
      "Epoch 3: iteration 26/2501 train_loss: 0.5124390125274658 time_taken: 0.05643796920776367\n",
      "Epoch 3: iteration 27/2501 train_loss: 0.5108688473701477 time_taken: 0.05658435821533203\n",
      "Epoch 3: iteration 28/2501 train_loss: 0.5097649097442627 time_taken: 0.057216644287109375\n",
      "Epoch 3: iteration 29/2501 train_loss: 0.5087486505508423 time_taken: 0.056882381439208984\n",
      "Epoch 3: iteration 30/2501 train_loss: 0.5081373453140259 time_taken: 0.05688619613647461\n",
      "Epoch 3: iteration 31/2501 train_loss: 0.5076329112052917 time_taken: 0.056975364685058594\n",
      "Epoch 3: iteration 32/2501 train_loss: 0.5073787569999695 time_taken: 0.05687761306762695\n",
      "Epoch 3: iteration 33/2501 train_loss: 0.5073366761207581 time_taken: 0.05655264854431152\n",
      "Epoch 3: iteration 34/2501 train_loss: 0.5078131556510925 time_taken: 0.05589771270751953\n",
      "Epoch 3: iteration 35/2501 train_loss: 0.5083198547363281 time_taken: 0.05614519119262695\n",
      "Epoch 3: iteration 36/2501 train_loss: 0.5088542103767395 time_taken: 0.05666041374206543\n",
      "Epoch 3: iteration 37/2501 train_loss: 0.5087169408798218 time_taken: 0.05718111991882324\n",
      "Epoch 3: iteration 38/2501 train_loss: 0.5086646676063538 time_taken: 0.0571439266204834\n",
      "Epoch 3: iteration 39/2501 train_loss: 0.5087746381759644 time_taken: 0.05635833740234375\n",
      "Epoch 3: iteration 40/2501 train_loss: 0.5093957185745239 time_taken: 0.05630660057067871\n",
      "Epoch 3: iteration 41/2501 train_loss: 0.5092841982841492 time_taken: 0.05662798881530762\n",
      "Epoch 3: iteration 42/2501 train_loss: 0.5094791650772095 time_taken: 0.056151390075683594\n",
      "Epoch 3: iteration 43/2501 train_loss: 0.5100774765014648 time_taken: 0.05643439292907715\n",
      "Epoch 3: iteration 44/2501 train_loss: 0.5103135108947754 time_taken: 0.05652809143066406\n",
      "Epoch 3: iteration 45/2501 train_loss: 0.5108285546302795 time_taken: 0.056027889251708984\n",
      "Epoch 3: iteration 46/2501 train_loss: 0.510915994644165 time_taken: 0.05677294731140137\n",
      "Epoch 3: iteration 47/2501 train_loss: 0.5109983682632446 time_taken: 0.056345224380493164\n",
      "Epoch 3: iteration 48/2501 train_loss: 0.5108322501182556 time_taken: 0.05742239952087402\n",
      "Epoch 3: iteration 49/2501 train_loss: 0.5105618834495544 time_taken: 0.05745530128479004\n",
      "Epoch 3: iteration 50/2501 train_loss: 0.5099189877510071 time_taken: 0.057428836822509766\n",
      "Epoch 3: iteration 51/2501 train_loss: 0.509432315826416 time_taken: 0.057291507720947266\n",
      "Epoch 3: iteration 52/2501 train_loss: 0.5087996125221252 time_taken: 0.05673789978027344\n",
      "Epoch 3: iteration 53/2501 train_loss: 0.508058488368988 time_taken: 0.05673384666442871\n",
      "Epoch 3: iteration 54/2501 train_loss: 0.5072519779205322 time_taken: 0.05658364295959473\n",
      "Epoch 3: iteration 55/2501 train_loss: 0.5061838030815125 time_taken: 0.056853294372558594\n",
      "Epoch 3: iteration 56/2501 train_loss: 0.5052391886711121 time_taken: 0.056406259536743164\n",
      "Epoch 3: iteration 57/2501 train_loss: 0.5044302344322205 time_taken: 0.05714678764343262\n",
      "Epoch 3: iteration 58/2501 train_loss: 0.5036739706993103 time_taken: 0.05665087699890137\n",
      "Epoch 3: iteration 59/2501 train_loss: 0.5033567547798157 time_taken: 0.057196855545043945\n",
      "Epoch 3: iteration 60/2501 train_loss: 0.5025568008422852 time_taken: 0.05703020095825195\n",
      "Epoch 3: iteration 61/2501 train_loss: 0.5021744966506958 time_taken: 0.05669426918029785\n",
      "Epoch 3: iteration 62/2501 train_loss: 0.5015981197357178 time_taken: 0.056427955627441406\n",
      "Epoch 3: iteration 63/2501 train_loss: 0.5009927153587341 time_taken: 0.05655074119567871\n",
      "Epoch 3: iteration 64/2501 train_loss: 0.5001621842384338 time_taken: 0.05638623237609863\n",
      "Epoch 3: iteration 65/2501 train_loss: 0.4992739260196686 time_taken: 0.057524681091308594\n",
      "Epoch 3: iteration 66/2501 train_loss: 0.49827420711517334 time_taken: 0.0573573112487793\n",
      "Epoch 3: iteration 67/2501 train_loss: 0.4971671402454376 time_taken: 0.05701494216918945\n",
      "Epoch 3: iteration 68/2501 train_loss: 0.4962594509124756 time_taken: 0.05643796920776367\n",
      "Epoch 3: iteration 69/2501 train_loss: 0.49515271186828613 time_taken: 0.05676412582397461\n",
      "Epoch 3: iteration 70/2501 train_loss: 0.49390122294425964 time_taken: 0.056494712829589844\n",
      "Epoch 3: iteration 71/2501 train_loss: 0.49263322353363037 time_taken: 0.056490421295166016\n",
      "Epoch 3: iteration 72/2501 train_loss: 0.49144884943962097 time_taken: 0.05764627456665039\n",
      "Epoch 3: iteration 73/2501 train_loss: 0.49013909697532654 time_taken: 0.056778907775878906\n",
      "Epoch 3: iteration 74/2501 train_loss: 0.4894220530986786 time_taken: 0.0563502311706543\n",
      "Epoch 3: iteration 75/2501 train_loss: 0.4888431131839752 time_taken: 0.05700278282165527\n",
      "Epoch 3: iteration 76/2501 train_loss: 0.48774734139442444 time_taken: 0.05669212341308594\n",
      "Epoch 3: iteration 77/2501 train_loss: 0.48669180274009705 time_taken: 0.05752992630004883\n",
      "Epoch 3: iteration 78/2501 train_loss: 0.4856407046318054 time_taken: 0.05653810501098633\n",
      "Epoch 3: iteration 79/2501 train_loss: 0.4844764769077301 time_taken: 0.05795001983642578\n",
      "Epoch 3: iteration 80/2501 train_loss: 0.48331111669540405 time_taken: 0.0569148063659668\n",
      "Epoch 3: iteration 81/2501 train_loss: 0.4822502136230469 time_taken: 0.05678129196166992\n",
      "Epoch 3: iteration 82/2501 train_loss: 0.48126018047332764 time_taken: 0.05709409713745117\n",
      "Epoch 3: iteration 83/2501 train_loss: 0.48039963841438293 time_taken: 0.0563504695892334\n",
      "Epoch 3: iteration 84/2501 train_loss: 0.47938936948776245 time_taken: 0.05644083023071289\n",
      "Epoch 3: iteration 85/2501 train_loss: 0.4788365960121155 time_taken: 0.05693340301513672\n",
      "Epoch 3: iteration 86/2501 train_loss: 0.47850745916366577 time_taken: 0.0565342903137207\n",
      "Epoch 3: iteration 87/2501 train_loss: 0.4779524505138397 time_taken: 0.057135820388793945\n",
      "Epoch 3: iteration 88/2501 train_loss: 0.4775819778442383 time_taken: 0.056533098220825195\n",
      "Epoch 3: iteration 89/2501 train_loss: 0.4774031639099121 time_taken: 0.0576169490814209\n",
      "Epoch 3: iteration 90/2501 train_loss: 0.4772086441516876 time_taken: 0.057289838790893555\n",
      "Epoch 3: iteration 91/2501 train_loss: 0.47701892256736755 time_taken: 0.05786323547363281\n",
      "Epoch 3: iteration 92/2501 train_loss: 0.47689250111579895 time_taken: 0.05708193778991699\n",
      "Epoch 3: iteration 93/2501 train_loss: 0.47658225893974304 time_taken: 0.05656552314758301\n",
      "Epoch 3: iteration 94/2501 train_loss: 0.47622010111808777 time_taken: 0.05707669258117676\n",
      "Epoch 3: iteration 95/2501 train_loss: 0.47594037652015686 time_taken: 0.05824637413024902\n",
      "Epoch 3: iteration 96/2501 train_loss: 0.4755292534828186 time_taken: 0.05644345283508301\n",
      "Epoch 3: iteration 97/2501 train_loss: 0.47508832812309265 time_taken: 0.057494163513183594\n",
      "Epoch 3: iteration 98/2501 train_loss: 0.4748258590698242 time_taken: 0.05731463432312012\n",
      "Epoch 3: iteration 99/2501 train_loss: 0.4743851125240326 time_taken: 0.05659937858581543\n",
      "Epoch 3: iteration 100/2501 train_loss: 0.47416165471076965 time_taken: 0.05708599090576172\n",
      "Epoch 3: iteration 101/2501 train_loss: 0.47383278608322144 time_taken: 0.05647611618041992\n",
      "Epoch 3: iteration 102/2501 train_loss: 0.47354525327682495 time_taken: 0.05679965019226074\n",
      "Epoch 3: iteration 103/2501 train_loss: 0.47352269291877747 time_taken: 0.05688810348510742\n",
      "Epoch 3: iteration 104/2501 train_loss: 0.47349897027015686 time_taken: 0.056441307067871094\n",
      "Epoch 3: iteration 105/2501 train_loss: 0.4734228253364563 time_taken: 0.056910037994384766\n",
      "Epoch 3: iteration 106/2501 train_loss: 0.4734230041503906 time_taken: 0.056976318359375\n",
      "Epoch 3: iteration 107/2501 train_loss: 0.473431259393692 time_taken: 0.05661749839782715\n",
      "Epoch 3: iteration 108/2501 train_loss: 0.4735274314880371 time_taken: 0.06383013725280762\n",
      "Epoch 3: iteration 109/2501 train_loss: 0.47358641028404236 time_taken: 0.05697798728942871\n",
      "Epoch 3: iteration 110/2501 train_loss: 0.4737771153450012 time_taken: 0.057042598724365234\n",
      "Epoch 3: iteration 111/2501 train_loss: 0.473908007144928 time_taken: 0.05654716491699219\n",
      "Epoch 3: iteration 112/2501 train_loss: 0.47402894496917725 time_taken: 0.05652642250061035\n",
      "Epoch 3: iteration 113/2501 train_loss: 0.4742368757724762 time_taken: 0.057129621505737305\n",
      "Epoch 3: iteration 114/2501 train_loss: 0.4745516777038574 time_taken: 0.05721783638000488\n",
      "Epoch 3: iteration 115/2501 train_loss: 0.47466862201690674 time_taken: 0.0566866397857666\n",
      "Epoch 3: iteration 116/2501 train_loss: 0.4747636914253235 time_taken: 0.05699515342712402\n",
      "Epoch 3: iteration 117/2501 train_loss: 0.4748264253139496 time_taken: 0.0567774772644043\n",
      "Epoch 3: iteration 118/2501 train_loss: 0.4748087525367737 time_taken: 0.05684089660644531\n",
      "Epoch 3: iteration 119/2501 train_loss: 0.47479215264320374 time_taken: 0.05646944046020508\n",
      "Epoch 3: iteration 120/2501 train_loss: 0.47486135363578796 time_taken: 0.05640006065368652\n",
      "Epoch 3: iteration 121/2501 train_loss: 0.47486168146133423 time_taken: 0.05646467208862305\n",
      "Epoch 3: iteration 122/2501 train_loss: 0.47488683462142944 time_taken: 0.05683755874633789\n",
      "Epoch 3: iteration 123/2501 train_loss: 0.4749114215373993 time_taken: 0.05712437629699707\n",
      "Epoch 3: iteration 124/2501 train_loss: 0.47473254799842834 time_taken: 0.056764841079711914\n",
      "Epoch 3: iteration 125/2501 train_loss: 0.47459569573402405 time_taken: 0.0566401481628418\n",
      "Epoch 3: iteration 126/2501 train_loss: 0.47439250349998474 time_taken: 0.05646705627441406\n",
      "Epoch 3: iteration 127/2501 train_loss: 0.4742191731929779 time_taken: 0.0571286678314209\n",
      "Epoch 3: iteration 128/2501 train_loss: 0.47417035698890686 time_taken: 0.05704998970031738\n",
      "Epoch 3: iteration 129/2501 train_loss: 0.4742569923400879 time_taken: 0.05678582191467285\n",
      "Epoch 3: iteration 130/2501 train_loss: 0.4743209779262543 time_taken: 0.05624103546142578\n",
      "Epoch 3: iteration 131/2501 train_loss: 0.47424304485321045 time_taken: 0.05705118179321289\n",
      "Epoch 3: iteration 132/2501 train_loss: 0.47417402267456055 time_taken: 0.05719280242919922\n",
      "Epoch 3: iteration 133/2501 train_loss: 0.47400590777397156 time_taken: 0.05734968185424805\n",
      "Epoch 3: iteration 134/2501 train_loss: 0.4739663004875183 time_taken: 0.05678081512451172\n",
      "Epoch 3: iteration 135/2501 train_loss: 0.47380003333091736 time_taken: 0.05673336982727051\n",
      "Epoch 3: iteration 136/2501 train_loss: 0.47355884313583374 time_taken: 0.056952476501464844\n",
      "Epoch 3: iteration 137/2501 train_loss: 0.4733433425426483 time_taken: 0.05763578414916992\n",
      "Epoch 3: iteration 138/2501 train_loss: 0.47302180528640747 time_taken: 0.05675220489501953\n",
      "Epoch 3: iteration 139/2501 train_loss: 0.47277629375457764 time_taken: 0.057964324951171875\n",
      "Epoch 3: iteration 140/2501 train_loss: 0.4725882411003113 time_taken: 0.05669069290161133\n",
      "Epoch 3: iteration 141/2501 train_loss: 0.47235092520713806 time_taken: 0.05624842643737793\n",
      "Epoch 3: iteration 142/2501 train_loss: 0.47224971652030945 time_taken: 0.05628204345703125\n",
      "Epoch 3: iteration 143/2501 train_loss: 0.4720515012741089 time_taken: 0.056295156478881836\n",
      "Epoch 3: iteration 144/2501 train_loss: 0.471857488155365 time_taken: 0.05675792694091797\n",
      "Epoch 3: iteration 145/2501 train_loss: 0.47176527976989746 time_taken: 0.057152748107910156\n",
      "Epoch 3: iteration 146/2501 train_loss: 0.4716351628303528 time_taken: 0.05619382858276367\n",
      "Epoch 3: iteration 147/2501 train_loss: 0.47155874967575073 time_taken: 0.05626392364501953\n",
      "Epoch 3: iteration 148/2501 train_loss: 0.4715469777584076 time_taken: 0.05626249313354492\n",
      "Epoch 3: iteration 149/2501 train_loss: 0.4714105725288391 time_taken: 0.05715203285217285\n",
      "Epoch 3: iteration 150/2501 train_loss: 0.471264511346817 time_taken: 0.056525468826293945\n",
      "Epoch 3: iteration 151/2501 train_loss: 0.471350759267807 time_taken: 0.05810141563415527\n",
      "Epoch 3: iteration 152/2501 train_loss: 0.47134384512901306 time_taken: 0.056725263595581055\n",
      "Epoch 3: iteration 153/2501 train_loss: 0.47130563855171204 time_taken: 0.056995391845703125\n",
      "Epoch 3: iteration 154/2501 train_loss: 0.47133439779281616 time_taken: 0.05666184425354004\n",
      "Epoch 3: iteration 155/2501 train_loss: 0.47126075625419617 time_taken: 0.05707406997680664\n",
      "Epoch 3: iteration 156/2501 train_loss: 0.47118571400642395 time_taken: 0.05660080909729004\n",
      "Epoch 3: iteration 157/2501 train_loss: 0.471049964427948 time_taken: 0.05655074119567871\n",
      "Epoch 3: iteration 158/2501 train_loss: 0.4708259105682373 time_taken: 0.0575098991394043\n",
      "Epoch 3: iteration 159/2501 train_loss: 0.47068190574645996 time_taken: 0.057109832763671875\n",
      "Epoch 3: iteration 160/2501 train_loss: 0.47044920921325684 time_taken: 0.056784629821777344\n",
      "Epoch 3: iteration 161/2501 train_loss: 0.470283567905426 time_taken: 0.05644726753234863\n",
      "Epoch 3: iteration 162/2501 train_loss: 0.47011682391166687 time_taken: 0.05706214904785156\n",
      "Epoch 3: iteration 163/2501 train_loss: 0.4698336124420166 time_taken: 0.05684304237365723\n",
      "Epoch 3: iteration 164/2501 train_loss: 0.4695918560028076 time_taken: 0.056600093841552734\n",
      "Epoch 3: iteration 165/2501 train_loss: 0.4692462384700775 time_taken: 0.05732274055480957\n",
      "Epoch 3: iteration 166/2501 train_loss: 0.46895667910575867 time_taken: 0.05675458908081055\n",
      "Epoch 3: iteration 167/2501 train_loss: 0.46862655878067017 time_taken: 0.05651092529296875\n",
      "Epoch 3: iteration 168/2501 train_loss: 0.46841222047805786 time_taken: 0.05720186233520508\n",
      "Epoch 3: iteration 169/2501 train_loss: 0.46813932061195374 time_taken: 0.05798506736755371\n",
      "Epoch 3: iteration 170/2501 train_loss: 0.467896044254303 time_taken: 0.05696368217468262\n",
      "Epoch 3: iteration 171/2501 train_loss: 0.46768635511398315 time_taken: 0.0566403865814209\n",
      "Epoch 3: iteration 172/2501 train_loss: 0.46743738651275635 time_taken: 0.062296390533447266\n",
      "Epoch 3: iteration 173/2501 train_loss: 0.46718570590019226 time_taken: 0.07809233665466309\n",
      "Epoch 3: iteration 174/2501 train_loss: 0.4669666886329651 time_taken: 0.11835050582885742\n",
      "Epoch 3: iteration 175/2501 train_loss: 0.4667358100414276 time_taken: 0.059624671936035156\n",
      "Epoch 3: iteration 176/2501 train_loss: 0.4665653705596924 time_taken: 0.0563967227935791\n",
      "Epoch 3: iteration 177/2501 train_loss: 0.46630388498306274 time_taken: 0.056670188903808594\n",
      "Epoch 3: iteration 178/2501 train_loss: 0.4659384489059448 time_taken: 0.05639243125915527\n",
      "Epoch 3: iteration 179/2501 train_loss: 0.4655607342720032 time_taken: 0.05689382553100586\n",
      "Epoch 3: iteration 180/2501 train_loss: 0.4652865529060364 time_taken: 0.0569002628326416\n",
      "Epoch 3: iteration 181/2501 train_loss: 0.4651104807853699 time_taken: 0.0566098690032959\n",
      "Epoch 3: iteration 182/2501 train_loss: 0.4649820029735565 time_taken: 0.056182146072387695\n",
      "Epoch 3: iteration 183/2501 train_loss: 0.4649794101715088 time_taken: 0.05672812461853027\n",
      "Epoch 3: iteration 184/2501 train_loss: 0.4649133086204529 time_taken: 0.05676722526550293\n",
      "Epoch 3: iteration 185/2501 train_loss: 0.46482956409454346 time_taken: 0.056062936782836914\n",
      "Epoch 3: iteration 186/2501 train_loss: 0.46476349234580994 time_taken: 0.05649304389953613\n",
      "Epoch 3: iteration 187/2501 train_loss: 0.4647180140018463 time_taken: 0.05620884895324707\n",
      "Epoch 3: iteration 188/2501 train_loss: 0.4646754860877991 time_taken: 0.05711627006530762\n",
      "Epoch 3: iteration 189/2501 train_loss: 0.4645405113697052 time_taken: 0.057073354721069336\n",
      "Epoch 3: iteration 190/2501 train_loss: 0.4643787145614624 time_taken: 0.058220863342285156\n",
      "Epoch 3: iteration 191/2501 train_loss: 0.4642123878002167 time_taken: 0.05777406692504883\n",
      "Epoch 3: iteration 192/2501 train_loss: 0.4639977514743805 time_taken: 0.05621838569641113\n",
      "Epoch 3: iteration 193/2501 train_loss: 0.4637086093425751 time_taken: 0.05660438537597656\n",
      "Epoch 3: iteration 194/2501 train_loss: 0.46357491612434387 time_taken: 0.05817389488220215\n",
      "Epoch 3: iteration 195/2501 train_loss: 0.4634977877140045 time_taken: 0.056806325912475586\n",
      "Epoch 3: iteration 196/2501 train_loss: 0.46344760060310364 time_taken: 0.05687236785888672\n",
      "Epoch 3: iteration 197/2501 train_loss: 0.46335139870643616 time_taken: 0.05711674690246582\n",
      "Epoch 3: iteration 198/2501 train_loss: 0.46323156356811523 time_taken: 0.056427717208862305\n",
      "Epoch 3: iteration 199/2501 train_loss: 0.4632215201854706 time_taken: 0.0568385124206543\n",
      "Epoch 3: iteration 200/2501 train_loss: 0.4631820321083069 time_taken: 0.057736873626708984\n",
      "Epoch 3: iteration 201/2501 train_loss: 0.46321189403533936 time_taken: 0.05700802803039551\n",
      "Epoch 3: iteration 202/2501 train_loss: 0.4632144272327423 time_taken: 0.05731701850891113\n",
      "Epoch 3: iteration 203/2501 train_loss: 0.4632556736469269 time_taken: 0.05715346336364746\n",
      "Epoch 3: iteration 204/2501 train_loss: 0.4633588194847107 time_taken: 0.05673861503601074\n",
      "Epoch 3: iteration 205/2501 train_loss: 0.4634016752243042 time_taken: 0.05639457702636719\n",
      "Epoch 3: iteration 206/2501 train_loss: 0.4634019732475281 time_taken: 0.0569767951965332\n",
      "Epoch 3: iteration 207/2501 train_loss: 0.4634787440299988 time_taken: 0.056620121002197266\n",
      "Epoch 3: iteration 208/2501 train_loss: 0.46358054876327515 time_taken: 0.0567319393157959\n",
      "Epoch 3: iteration 209/2501 train_loss: 0.46358954906463623 time_taken: 0.05683255195617676\n",
      "Epoch 3: iteration 210/2501 train_loss: 0.46360647678375244 time_taken: 0.057358503341674805\n",
      "Epoch 3: iteration 211/2501 train_loss: 0.46357011795043945 time_taken: 0.056204795837402344\n",
      "Epoch 3: iteration 212/2501 train_loss: 0.4635087251663208 time_taken: 0.05637526512145996\n",
      "Epoch 3: iteration 213/2501 train_loss: 0.4634447991847992 time_taken: 0.05726504325866699\n",
      "Epoch 3: iteration 214/2501 train_loss: 0.4633685350418091 time_taken: 0.05707240104675293\n",
      "Epoch 3: iteration 215/2501 train_loss: 0.46336624026298523 time_taken: 0.05684041976928711\n",
      "Epoch 3: iteration 216/2501 train_loss: 0.46338382363319397 time_taken: 0.056524038314819336\n",
      "Epoch 3: iteration 217/2501 train_loss: 0.46348434686660767 time_taken: 0.05715370178222656\n",
      "Epoch 3: iteration 218/2501 train_loss: 0.4636112153530121 time_taken: 0.05640101432800293\n",
      "Epoch 3: iteration 219/2501 train_loss: 0.46378087997436523 time_taken: 0.057218313217163086\n",
      "Epoch 3: iteration 220/2501 train_loss: 0.46397799253463745 time_taken: 0.05771660804748535\n",
      "Epoch 3: iteration 221/2501 train_loss: 0.4640907049179077 time_taken: 0.05676555633544922\n",
      "Epoch 3: iteration 222/2501 train_loss: 0.4643120765686035 time_taken: 0.0593416690826416\n",
      "Epoch 3: iteration 223/2501 train_loss: 0.46468403935432434 time_taken: 0.05675101280212402\n",
      "Epoch 3: iteration 224/2501 train_loss: 0.4649752080440521 time_taken: 0.05642104148864746\n",
      "Epoch 3: iteration 225/2501 train_loss: 0.4653053879737854 time_taken: 0.056940317153930664\n",
      "Epoch 3: iteration 226/2501 train_loss: 0.4655066728591919 time_taken: 0.05697464942932129\n",
      "Epoch 3: iteration 227/2501 train_loss: 0.46571463346481323 time_taken: 0.05665469169616699\n",
      "Epoch 3: iteration 228/2501 train_loss: 0.46589574217796326 time_taken: 0.0580899715423584\n",
      "Epoch 3: iteration 229/2501 train_loss: 0.46609801054000854 time_taken: 0.05665874481201172\n",
      "Epoch 3: iteration 230/2501 train_loss: 0.4662494361400604 time_taken: 0.05716705322265625\n",
      "Epoch 3: iteration 231/2501 train_loss: 0.46643954515457153 time_taken: 0.057797908782958984\n",
      "Epoch 3: iteration 232/2501 train_loss: 0.46658509969711304 time_taken: 0.05861520767211914\n",
      "Epoch 3: iteration 233/2501 train_loss: 0.4667382538318634 time_taken: 0.05774497985839844\n",
      "Epoch 3: iteration 234/2501 train_loss: 0.4669021964073181 time_taken: 0.05640673637390137\n",
      "Epoch 3: iteration 235/2501 train_loss: 0.4669937491416931 time_taken: 0.05634808540344238\n",
      "Epoch 3: iteration 236/2501 train_loss: 0.46706506609916687 time_taken: 0.05684661865234375\n",
      "Epoch 3: iteration 237/2501 train_loss: 0.46711382269859314 time_taken: 0.05699038505554199\n",
      "Epoch 3: iteration 238/2501 train_loss: 0.46715423464775085 time_taken: 0.056279897689819336\n",
      "Epoch 3: iteration 239/2501 train_loss: 0.46718543767929077 time_taken: 0.056684017181396484\n",
      "Epoch 3: iteration 240/2501 train_loss: 0.467212975025177 time_taken: 0.05615115165710449\n",
      "Epoch 3: iteration 241/2501 train_loss: 0.46747469902038574 time_taken: 0.05595755577087402\n",
      "Epoch 3: iteration 242/2501 train_loss: 0.4682091474533081 time_taken: 0.056474924087524414\n",
      "Epoch 3: iteration 243/2501 train_loss: 0.46843647956848145 time_taken: 0.05632591247558594\n",
      "Epoch 3: iteration 244/2501 train_loss: 0.4684201180934906 time_taken: 0.056571006774902344\n",
      "Epoch 3: iteration 245/2501 train_loss: 0.46841979026794434 time_taken: 0.05616188049316406\n",
      "Epoch 3: iteration 246/2501 train_loss: 0.468332976102829 time_taken: 0.05634164810180664\n",
      "Epoch 3: iteration 247/2501 train_loss: 0.46828916668891907 time_taken: 0.05798959732055664\n",
      "Epoch 3: iteration 248/2501 train_loss: 0.4682515263557434 time_taken: 0.05646562576293945\n",
      "Epoch 3: iteration 249/2501 train_loss: 0.4680449366569519 time_taken: 0.05651593208312988\n",
      "Epoch 3: iteration 250/2501 train_loss: 0.46788328886032104 time_taken: 0.056444644927978516\n",
      "Epoch 3: iteration 251/2501 train_loss: 0.4677356779575348 time_taken: 0.05693173408508301\n",
      "Epoch 3: iteration 252/2501 train_loss: 0.4675080478191376 time_taken: 0.056690216064453125\n",
      "Epoch 3: iteration 253/2501 train_loss: 0.46733346581459045 time_taken: 0.0573270320892334\n",
      "Epoch 3: iteration 254/2501 train_loss: 0.46716931462287903 time_taken: 0.056104421615600586\n",
      "Epoch 3: iteration 255/2501 train_loss: 0.467041552066803 time_taken: 0.05647468566894531\n",
      "Epoch 3: iteration 256/2501 train_loss: 0.4669227600097656 time_taken: 0.05611538887023926\n",
      "Epoch 3: iteration 257/2501 train_loss: 0.46678557991981506 time_taken: 0.05661487579345703\n",
      "Epoch 3: iteration 258/2501 train_loss: 0.4667355716228485 time_taken: 0.056525230407714844\n",
      "Epoch 3: iteration 259/2501 train_loss: 0.4666595458984375 time_taken: 0.05633974075317383\n",
      "Epoch 3: iteration 260/2501 train_loss: 0.4665816128253937 time_taken: 0.05610036849975586\n",
      "Epoch 3: iteration 261/2501 train_loss: 0.4665552079677582 time_taken: 0.055908203125\n",
      "Epoch 3: iteration 262/2501 train_loss: 0.4665694832801819 time_taken: 0.05626201629638672\n",
      "Epoch 3: iteration 263/2501 train_loss: 0.4664636552333832 time_taken: 0.05605649948120117\n",
      "Epoch 3: iteration 264/2501 train_loss: 0.4664212465286255 time_taken: 0.056391239166259766\n",
      "Epoch 3: iteration 265/2501 train_loss: 0.4663498103618622 time_taken: 0.056381940841674805\n",
      "Epoch 3: iteration 266/2501 train_loss: 0.46628397703170776 time_taken: 0.056087493896484375\n",
      "Epoch 3: iteration 267/2501 train_loss: 0.46621689200401306 time_taken: 0.0561370849609375\n",
      "Epoch 3: iteration 268/2501 train_loss: 0.4661419093608856 time_taken: 0.056311845779418945\n",
      "Epoch 3: iteration 269/2501 train_loss: 0.4660593271255493 time_taken: 0.05676555633544922\n",
      "Epoch 3: iteration 270/2501 train_loss: 0.4659469425678253 time_taken: 0.05727744102478027\n",
      "Epoch 3: iteration 271/2501 train_loss: 0.46583831310272217 time_taken: 0.05666518211364746\n",
      "Epoch 3: iteration 272/2501 train_loss: 0.4657052159309387 time_taken: 0.05684375762939453\n",
      "Epoch 3: iteration 273/2501 train_loss: 0.46560004353523254 time_taken: 0.05587291717529297\n",
      "Epoch 3: iteration 274/2501 train_loss: 0.4655163586139679 time_taken: 0.05601835250854492\n",
      "Epoch 3: iteration 275/2501 train_loss: 0.4654000997543335 time_taken: 0.05648446083068848\n",
      "Epoch 3: iteration 276/2501 train_loss: 0.465311199426651 time_taken: 0.056581735610961914\n",
      "Epoch 3: iteration 277/2501 train_loss: 0.46524640917778015 time_taken: 0.05630350112915039\n",
      "Epoch 3: iteration 278/2501 train_loss: 0.4651225507259369 time_taken: 0.0563349723815918\n",
      "Epoch 3: iteration 279/2501 train_loss: 0.4650743901729584 time_taken: 0.056775808334350586\n",
      "Epoch 3: iteration 280/2501 train_loss: 0.4650028944015503 time_taken: 0.05596494674682617\n",
      "Epoch 3: iteration 281/2501 train_loss: 0.4649788737297058 time_taken: 0.0569605827331543\n",
      "Epoch 3: iteration 282/2501 train_loss: 0.4649451673030853 time_taken: 0.05675506591796875\n",
      "Epoch 3: iteration 283/2501 train_loss: 0.46489855647087097 time_taken: 0.05660867691040039\n",
      "Epoch 3: iteration 284/2501 train_loss: 0.46486157178878784 time_taken: 0.05583906173706055\n",
      "Epoch 3: iteration 285/2501 train_loss: 0.4648286998271942 time_taken: 0.056575775146484375\n",
      "Epoch 3: iteration 286/2501 train_loss: 0.4648684859275818 time_taken: 0.0573122501373291\n",
      "Epoch 3: iteration 287/2501 train_loss: 0.46491989493370056 time_taken: 0.05703258514404297\n",
      "Epoch 3: iteration 288/2501 train_loss: 0.4650196135044098 time_taken: 0.05619239807128906\n",
      "Epoch 3: iteration 289/2501 train_loss: 0.465133398771286 time_taken: 0.056578636169433594\n",
      "Epoch 3: iteration 290/2501 train_loss: 0.4653365910053253 time_taken: 0.05634641647338867\n",
      "Epoch 3: iteration 291/2501 train_loss: 0.46550044417381287 time_taken: 0.05606579780578613\n",
      "Epoch 3: iteration 292/2501 train_loss: 0.46568533778190613 time_taken: 0.05700945854187012\n",
      "Epoch 3: iteration 293/2501 train_loss: 0.4658590853214264 time_taken: 0.05595588684082031\n",
      "Epoch 3: iteration 294/2501 train_loss: 0.46607667207717896 time_taken: 0.05698585510253906\n",
      "Epoch 3: iteration 295/2501 train_loss: 0.46632394194602966 time_taken: 0.05624532699584961\n",
      "Epoch 3: iteration 296/2501 train_loss: 0.4665030539035797 time_taken: 0.0576930046081543\n",
      "Epoch 3: iteration 297/2501 train_loss: 0.4667971730232239 time_taken: 0.0581669807434082\n",
      "Epoch 3: iteration 298/2501 train_loss: 0.467082142829895 time_taken: 0.0568995475769043\n",
      "Epoch 3: iteration 299/2501 train_loss: 0.46728408336639404 time_taken: 0.0566861629486084\n",
      "Epoch 3: iteration 300/2501 train_loss: 0.46751490235328674 time_taken: 0.05697059631347656\n",
      "Epoch 3: iteration 301/2501 train_loss: 0.46766626834869385 time_taken: 0.05738019943237305\n",
      "Epoch 3: iteration 302/2501 train_loss: 0.46784624457359314 time_taken: 0.05791449546813965\n",
      "Epoch 3: iteration 303/2501 train_loss: 0.4679345488548279 time_taken: 0.05774807929992676\n",
      "Epoch 3: iteration 304/2501 train_loss: 0.46798911690711975 time_taken: 0.05669522285461426\n",
      "Epoch 3: iteration 305/2501 train_loss: 0.46804171800613403 time_taken: 0.05728650093078613\n",
      "Epoch 3: iteration 306/2501 train_loss: 0.4681296944618225 time_taken: 0.05700826644897461\n",
      "Epoch 3: iteration 307/2501 train_loss: 0.46811720728874207 time_taken: 0.05696463584899902\n",
      "Epoch 3: iteration 308/2501 train_loss: 0.4680824279785156 time_taken: 0.0566401481628418\n",
      "Epoch 3: iteration 309/2501 train_loss: 0.46801793575286865 time_taken: 0.05720043182373047\n",
      "Epoch 3: iteration 310/2501 train_loss: 0.4679797887802124 time_taken: 0.056960344314575195\n",
      "Epoch 3: iteration 311/2501 train_loss: 0.4679032266139984 time_taken: 0.05686783790588379\n",
      "Epoch 3: iteration 312/2501 train_loss: 0.46782994270324707 time_taken: 0.056619882583618164\n",
      "Epoch 3: iteration 313/2501 train_loss: 0.46773791313171387 time_taken: 0.08246207237243652\n",
      "Epoch 3: iteration 314/2501 train_loss: 0.46760472655296326 time_taken: 0.07314515113830566\n",
      "Epoch 3: iteration 315/2501 train_loss: 0.4674445390701294 time_taken: 0.05657815933227539\n",
      "Epoch 3: iteration 316/2501 train_loss: 0.46731698513031006 time_taken: 0.05678224563598633\n",
      "Epoch 3: iteration 317/2501 train_loss: 0.4671946167945862 time_taken: 0.05679440498352051\n",
      "Epoch 3: iteration 318/2501 train_loss: 0.4670697748661041 time_taken: 0.05694770812988281\n",
      "Epoch 3: iteration 319/2501 train_loss: 0.46699023246765137 time_taken: 0.05686450004577637\n",
      "Epoch 3: iteration 320/2501 train_loss: 0.4669462740421295 time_taken: 0.05728745460510254\n",
      "Epoch 3: iteration 321/2501 train_loss: 0.4668838381767273 time_taken: 0.05701422691345215\n",
      "Epoch 3: iteration 322/2501 train_loss: 0.46685460209846497 time_taken: 0.056746482849121094\n",
      "Epoch 3: iteration 323/2501 train_loss: 0.4668166935443878 time_taken: 0.05663347244262695\n",
      "Epoch 3: iteration 324/2501 train_loss: 0.4667244851589203 time_taken: 0.05726933479309082\n",
      "Epoch 3: iteration 325/2501 train_loss: 0.46658799052238464 time_taken: 0.05700206756591797\n",
      "Epoch 3: iteration 326/2501 train_loss: 0.46647918224334717 time_taken: 0.057851314544677734\n",
      "Epoch 3: iteration 327/2501 train_loss: 0.466361403465271 time_taken: 0.05675458908081055\n",
      "Epoch 3: iteration 328/2501 train_loss: 0.46626874804496765 time_taken: 0.05656862258911133\n",
      "Epoch 3: iteration 329/2501 train_loss: 0.4661061465740204 time_taken: 0.0564117431640625\n",
      "Epoch 3: iteration 330/2501 train_loss: 0.46597820520401 time_taken: 0.05652308464050293\n",
      "Epoch 3: iteration 331/2501 train_loss: 0.4658108055591583 time_taken: 0.05776786804199219\n",
      "Epoch 3: iteration 332/2501 train_loss: 0.4656977355480194 time_taken: 0.056874990463256836\n",
      "Epoch 3: iteration 333/2501 train_loss: 0.4655742049217224 time_taken: 0.055934906005859375\n",
      "Epoch 3: iteration 334/2501 train_loss: 0.4654703736305237 time_taken: 0.05651593208312988\n",
      "Epoch 3: iteration 335/2501 train_loss: 0.46542713046073914 time_taken: 0.05698204040527344\n",
      "Epoch 3: iteration 336/2501 train_loss: 0.46536096930503845 time_taken: 0.05623769760131836\n",
      "Epoch 3: iteration 337/2501 train_loss: 0.46530723571777344 time_taken: 0.05665326118469238\n",
      "Epoch 3: iteration 338/2501 train_loss: 0.4652765691280365 time_taken: 0.056915283203125\n",
      "Epoch 3: iteration 339/2501 train_loss: 0.4652162492275238 time_taken: 0.056055307388305664\n",
      "Epoch 3: iteration 340/2501 train_loss: 0.4651791751384735 time_taken: 0.05659079551696777\n",
      "Epoch 3: iteration 341/2501 train_loss: 0.465118408203125 time_taken: 0.05659174919128418\n",
      "Epoch 3: iteration 342/2501 train_loss: 0.46513256430625916 time_taken: 0.05652451515197754\n",
      "Epoch 3: iteration 343/2501 train_loss: 0.4651111662387848 time_taken: 0.05674552917480469\n",
      "Epoch 3: iteration 344/2501 train_loss: 0.46511563658714294 time_taken: 0.05650138854980469\n",
      "Epoch 3: iteration 345/2501 train_loss: 0.4650787115097046 time_taken: 0.05691862106323242\n",
      "Epoch 3: iteration 346/2501 train_loss: 0.46503686904907227 time_taken: 0.05629372596740723\n",
      "Epoch 3: iteration 347/2501 train_loss: 0.46500256657600403 time_taken: 0.05591559410095215\n",
      "Epoch 3: iteration 348/2501 train_loss: 0.46503108739852905 time_taken: 0.055722713470458984\n",
      "Epoch 3: iteration 349/2501 train_loss: 0.46501976251602173 time_taken: 0.056253671646118164\n",
      "Epoch 3: iteration 350/2501 train_loss: 0.4650583267211914 time_taken: 0.05651044845581055\n",
      "Epoch 3: iteration 351/2501 train_loss: 0.4651097357273102 time_taken: 0.05663156509399414\n",
      "Epoch 3: iteration 352/2501 train_loss: 0.4651688039302826 time_taken: 0.05646014213562012\n",
      "Epoch 3: iteration 353/2501 train_loss: 0.46527165174484253 time_taken: 0.0568845272064209\n",
      "Epoch 3: iteration 354/2501 train_loss: 0.4653790593147278 time_taken: 0.056017398834228516\n",
      "Epoch 3: iteration 355/2501 train_loss: 0.46548452973365784 time_taken: 0.05650615692138672\n",
      "Epoch 3: iteration 356/2501 train_loss: 0.4655962884426117 time_taken: 0.056175947189331055\n",
      "Epoch 3: iteration 357/2501 train_loss: 0.46571439504623413 time_taken: 0.056482791900634766\n",
      "Epoch 3: iteration 358/2501 train_loss: 0.4658390283584595 time_taken: 0.056738853454589844\n",
      "Epoch 3: iteration 359/2501 train_loss: 0.46595484018325806 time_taken: 0.056343793869018555\n",
      "Epoch 3: iteration 360/2501 train_loss: 0.46608424186706543 time_taken: 0.05965590476989746\n",
      "Epoch 3: iteration 361/2501 train_loss: 0.4662032127380371 time_taken: 0.056403398513793945\n",
      "Epoch 3: iteration 362/2501 train_loss: 0.46631503105163574 time_taken: 0.05590343475341797\n",
      "Epoch 3: iteration 363/2501 train_loss: 0.4664100110530853 time_taken: 0.05622982978820801\n",
      "Epoch 3: iteration 364/2501 train_loss: 0.4665612280368805 time_taken: 0.05623149871826172\n",
      "Epoch 3: iteration 365/2501 train_loss: 0.46664535999298096 time_taken: 0.059789419174194336\n",
      "Epoch 3: iteration 366/2501 train_loss: 0.46672308444976807 time_taken: 0.05612540245056152\n",
      "Epoch 3: iteration 367/2501 train_loss: 0.46684765815734863 time_taken: 0.05661273002624512\n",
      "Epoch 3: iteration 368/2501 train_loss: 0.46696555614471436 time_taken: 0.05694389343261719\n",
      "Epoch 3: iteration 369/2501 train_loss: 0.46708253026008606 time_taken: 0.056537628173828125\n",
      "Epoch 3: iteration 370/2501 train_loss: 0.4672125279903412 time_taken: 0.05706596374511719\n",
      "Epoch 3: iteration 371/2501 train_loss: 0.46729668974876404 time_taken: 0.05641317367553711\n",
      "Epoch 3: iteration 372/2501 train_loss: 0.4673718512058258 time_taken: 0.05678987503051758\n",
      "Epoch 3: iteration 373/2501 train_loss: 0.46747320890426636 time_taken: 0.05631208419799805\n",
      "Epoch 3: iteration 374/2501 train_loss: 0.46753284335136414 time_taken: 0.059591054916381836\n",
      "Epoch 3: iteration 375/2501 train_loss: 0.4676415026187897 time_taken: 0.059177398681640625\n",
      "Epoch 3: iteration 376/2501 train_loss: 0.4677404463291168 time_taken: 0.056073904037475586\n",
      "Epoch 3: iteration 377/2501 train_loss: 0.4678097665309906 time_taken: 0.05621767044067383\n",
      "Epoch 3: iteration 378/2501 train_loss: 0.4679551422595978 time_taken: 0.05694293975830078\n",
      "Epoch 3: iteration 379/2501 train_loss: 0.468051016330719 time_taken: 0.05697226524353027\n",
      "Epoch 3: iteration 380/2501 train_loss: 0.46815210580825806 time_taken: 0.060169219970703125\n",
      "Epoch 3: iteration 381/2501 train_loss: 0.46825575828552246 time_taken: 0.07332801818847656\n",
      "Epoch 3: iteration 382/2501 train_loss: 0.46833768486976624 time_taken: 0.05628156661987305\n",
      "Epoch 3: iteration 383/2501 train_loss: 0.46844789385795593 time_taken: 0.05608415603637695\n",
      "Epoch 3: iteration 384/2501 train_loss: 0.4685635566711426 time_taken: 0.056951284408569336\n",
      "Epoch 3: iteration 385/2501 train_loss: 0.46872758865356445 time_taken: 0.05710601806640625\n",
      "Epoch 3: iteration 386/2501 train_loss: 0.46884670853614807 time_taken: 0.05679774284362793\n",
      "Epoch 3: iteration 387/2501 train_loss: 0.4689650535583496 time_taken: 0.0563814640045166\n",
      "Epoch 3: iteration 388/2501 train_loss: 0.46903741359710693 time_taken: 0.05640411376953125\n",
      "Epoch 3: iteration 389/2501 train_loss: 0.4690944254398346 time_taken: 0.05668020248413086\n",
      "Epoch 3: iteration 390/2501 train_loss: 0.4691845774650574 time_taken: 0.056099891662597656\n",
      "Epoch 3: iteration 391/2501 train_loss: 0.46926984190940857 time_taken: 0.05663108825683594\n",
      "Epoch 3: iteration 392/2501 train_loss: 0.4693533182144165 time_taken: 0.056592464447021484\n",
      "Epoch 3: iteration 393/2501 train_loss: 0.46944257616996765 time_taken: 0.05733203887939453\n",
      "Epoch 3: iteration 394/2501 train_loss: 0.4694863259792328 time_taken: 0.056870460510253906\n",
      "Epoch 3: iteration 395/2501 train_loss: 0.46953120827674866 time_taken: 0.05629158020019531\n",
      "Epoch 3: iteration 396/2501 train_loss: 0.4695315659046173 time_taken: 0.056374549865722656\n",
      "Epoch 3: iteration 397/2501 train_loss: 0.469573438167572 time_taken: 0.056175947189331055\n",
      "Epoch 3: iteration 398/2501 train_loss: 0.46956029534339905 time_taken: 0.05602717399597168\n",
      "Epoch 3: iteration 399/2501 train_loss: 0.46952497959136963 time_taken: 0.05758953094482422\n",
      "Epoch 3: iteration 400/2501 train_loss: 0.4694671928882599 time_taken: 0.05634427070617676\n",
      "Epoch 3: iteration 401/2501 train_loss: 0.4693829417228699 time_taken: 0.056711673736572266\n",
      "Epoch 3: iteration 402/2501 train_loss: 0.4693049490451813 time_taken: 0.05684471130371094\n",
      "Epoch 3: iteration 403/2501 train_loss: 0.46920475363731384 time_taken: 0.056062936782836914\n",
      "Epoch 3: iteration 404/2501 train_loss: 0.46910592913627625 time_taken: 0.05593752861022949\n",
      "Epoch 3: iteration 405/2501 train_loss: 0.4690157473087311 time_taken: 0.05659794807434082\n",
      "Epoch 3: iteration 406/2501 train_loss: 0.468978613615036 time_taken: 0.05613303184509277\n",
      "Epoch 3: iteration 407/2501 train_loss: 0.46893852949142456 time_taken: 0.05625724792480469\n",
      "Epoch 3: iteration 408/2501 train_loss: 0.46894121170043945 time_taken: 0.06180095672607422\n",
      "Epoch 3: iteration 409/2501 train_loss: 0.46892502903938293 time_taken: 0.056243181228637695\n",
      "Epoch 3: iteration 410/2501 train_loss: 0.46889975666999817 time_taken: 0.05614161491394043\n",
      "Epoch 3: iteration 411/2501 train_loss: 0.4688536524772644 time_taken: 0.05668997764587402\n",
      "Epoch 3: iteration 412/2501 train_loss: 0.46877849102020264 time_taken: 0.05641055107116699\n",
      "Epoch 3: iteration 413/2501 train_loss: 0.4687328636646271 time_taken: 0.05651354789733887\n",
      "Epoch 3: iteration 414/2501 train_loss: 0.46865999698638916 time_taken: 0.05666065216064453\n",
      "Epoch 3: iteration 415/2501 train_loss: 0.4685991406440735 time_taken: 0.05594134330749512\n",
      "Epoch 3: iteration 416/2501 train_loss: 0.4685393273830414 time_taken: 0.05580282211303711\n",
      "Epoch 3: iteration 417/2501 train_loss: 0.46847885847091675 time_taken: 0.0564875602722168\n",
      "Epoch 3: iteration 418/2501 train_loss: 0.4684339463710785 time_taken: 0.05715012550354004\n",
      "Epoch 3: iteration 419/2501 train_loss: 0.46837928891181946 time_taken: 0.056377410888671875\n",
      "Epoch 3: iteration 420/2501 train_loss: 0.46833816170692444 time_taken: 0.06286954879760742\n",
      "Epoch 3: iteration 421/2501 train_loss: 0.4682881534099579 time_taken: 0.05617642402648926\n",
      "Epoch 3: iteration 422/2501 train_loss: 0.4682365357875824 time_taken: 0.05637645721435547\n",
      "Epoch 3: iteration 423/2501 train_loss: 0.4682128131389618 time_taken: 0.05641293525695801\n",
      "Epoch 3: iteration 424/2501 train_loss: 0.4682139754295349 time_taken: 0.05640244483947754\n",
      "Epoch 3: iteration 425/2501 train_loss: 0.4681639075279236 time_taken: 0.056211233139038086\n",
      "Epoch 3: iteration 426/2501 train_loss: 0.46808716654777527 time_taken: 0.055999755859375\n",
      "Epoch 3: iteration 427/2501 train_loss: 0.46805340051651 time_taken: 0.056407928466796875\n",
      "Epoch 3: iteration 428/2501 train_loss: 0.4680540859699249 time_taken: 0.05596470832824707\n",
      "Epoch 3: iteration 429/2501 train_loss: 0.4680849313735962 time_taken: 0.0569453239440918\n",
      "Epoch 3: iteration 430/2501 train_loss: 0.46813422441482544 time_taken: 0.056922197341918945\n",
      "Epoch 3: iteration 431/2501 train_loss: 0.4681335687637329 time_taken: 0.058141231536865234\n",
      "Epoch 3: iteration 432/2501 train_loss: 0.468190461397171 time_taken: 0.0566859245300293\n",
      "Epoch 3: iteration 433/2501 train_loss: 0.46824172139167786 time_taken: 0.05798912048339844\n",
      "Epoch 3: iteration 434/2501 train_loss: 0.4683085083961487 time_taken: 0.05654597282409668\n",
      "Epoch 3: iteration 435/2501 train_loss: 0.46844616532325745 time_taken: 0.0565342903137207\n",
      "Epoch 3: iteration 436/2501 train_loss: 0.46856796741485596 time_taken: 0.056276798248291016\n",
      "Epoch 3: iteration 437/2501 train_loss: 0.46866440773010254 time_taken: 0.05619359016418457\n",
      "Epoch 3: iteration 438/2501 train_loss: 0.4687616229057312 time_taken: 0.05692934989929199\n",
      "Epoch 3: iteration 439/2501 train_loss: 0.468874454498291 time_taken: 0.05765390396118164\n",
      "Epoch 3: iteration 440/2501 train_loss: 0.4689961373806 time_taken: 0.056859493255615234\n",
      "Epoch 3: iteration 441/2501 train_loss: 0.4691334068775177 time_taken: 0.056862831115722656\n",
      "Epoch 3: iteration 442/2501 train_loss: 0.4692802429199219 time_taken: 0.05715441703796387\n",
      "Epoch 3: iteration 443/2501 train_loss: 0.46936753392219543 time_taken: 0.05711817741394043\n",
      "Epoch 3: iteration 444/2501 train_loss: 0.46949413418769836 time_taken: 0.05626630783081055\n",
      "Epoch 3: iteration 445/2501 train_loss: 0.46961745619773865 time_taken: 0.0569157600402832\n",
      "Epoch 3: iteration 446/2501 train_loss: 0.4697347581386566 time_taken: 0.05728626251220703\n",
      "Epoch 3: iteration 447/2501 train_loss: 0.4698408544063568 time_taken: 0.05693340301513672\n",
      "Epoch 3: iteration 448/2501 train_loss: 0.46994754672050476 time_taken: 0.07204937934875488\n",
      "Epoch 3: iteration 449/2501 train_loss: 0.4700718820095062 time_taken: 0.05653214454650879\n",
      "Epoch 3: iteration 450/2501 train_loss: 0.47017860412597656 time_taken: 0.0632021427154541\n",
      "Epoch 3: iteration 451/2501 train_loss: 0.47029581665992737 time_taken: 0.05715608596801758\n",
      "Epoch 3: iteration 452/2501 train_loss: 0.47042641043663025 time_taken: 0.05700325965881348\n",
      "Epoch 3: iteration 453/2501 train_loss: 0.4705233573913574 time_taken: 0.057019948959350586\n",
      "Epoch 3: iteration 454/2501 train_loss: 0.47059962153434753 time_taken: 0.05634331703186035\n",
      "Epoch 3: iteration 455/2501 train_loss: 0.470661461353302 time_taken: 0.05697154998779297\n",
      "Epoch 3: iteration 456/2501 train_loss: 0.47068265080451965 time_taken: 0.05649399757385254\n",
      "Epoch 3: iteration 457/2501 train_loss: 0.47069641947746277 time_taken: 0.05639457702636719\n",
      "Epoch 3: iteration 458/2501 train_loss: 0.470660001039505 time_taken: 0.0572512149810791\n",
      "Epoch 3: iteration 459/2501 train_loss: 0.4706245958805084 time_taken: 0.056322336196899414\n",
      "Epoch 3: iteration 460/2501 train_loss: 0.4705554246902466 time_taken: 0.05645179748535156\n",
      "Epoch 3: iteration 461/2501 train_loss: 0.47045016288757324 time_taken: 0.05636191368103027\n",
      "Epoch 3: iteration 462/2501 train_loss: 0.47033992409706116 time_taken: 0.05693173408508301\n",
      "Epoch 3: iteration 463/2501 train_loss: 0.47021710872650146 time_taken: 0.05654621124267578\n",
      "Epoch 3: iteration 464/2501 train_loss: 0.47010284662246704 time_taken: 0.056668758392333984\n",
      "Epoch 3: iteration 465/2501 train_loss: 0.4700033366680145 time_taken: 0.05698108673095703\n",
      "Epoch 3: iteration 466/2501 train_loss: 0.469946026802063 time_taken: 0.05706214904785156\n",
      "Epoch 3: iteration 467/2501 train_loss: 0.46984565258026123 time_taken: 0.05672812461853027\n",
      "Epoch 3: iteration 468/2501 train_loss: 0.4697516858577728 time_taken: 0.05654597282409668\n",
      "Epoch 3: iteration 469/2501 train_loss: 0.46968746185302734 time_taken: 0.05707716941833496\n",
      "Epoch 3: iteration 470/2501 train_loss: 0.46960872411727905 time_taken: 0.056915998458862305\n",
      "Epoch 3: iteration 471/2501 train_loss: 0.4695633351802826 time_taken: 0.056865692138671875\n",
      "Epoch 3: iteration 472/2501 train_loss: 0.46950751543045044 time_taken: 0.05653667449951172\n",
      "Epoch 3: iteration 473/2501 train_loss: 0.46946629881858826 time_taken: 0.05674123764038086\n",
      "Epoch 3: iteration 474/2501 train_loss: 0.46943578124046326 time_taken: 0.05637049674987793\n",
      "Epoch 3: iteration 475/2501 train_loss: 0.46941760182380676 time_taken: 0.05667591094970703\n",
      "Epoch 3: iteration 476/2501 train_loss: 0.46943867206573486 time_taken: 0.05649375915527344\n",
      "Epoch 3: iteration 477/2501 train_loss: 0.4694453477859497 time_taken: 0.0563807487487793\n",
      "Epoch 3: iteration 478/2501 train_loss: 0.4694724380970001 time_taken: 0.056890010833740234\n",
      "Epoch 3: iteration 479/2501 train_loss: 0.4695177674293518 time_taken: 0.05652952194213867\n",
      "Epoch 3: iteration 480/2501 train_loss: 0.4695603847503662 time_taken: 0.05647730827331543\n",
      "Epoch 3: iteration 481/2501 train_loss: 0.46962830424308777 time_taken: 0.05680680274963379\n",
      "Epoch 3: iteration 482/2501 train_loss: 0.469670832157135 time_taken: 0.0565183162689209\n",
      "Epoch 3: iteration 483/2501 train_loss: 0.46973127126693726 time_taken: 0.07227969169616699\n",
      "Epoch 3: iteration 484/2501 train_loss: 0.4698004424571991 time_taken: 0.05688595771789551\n",
      "Epoch 3: iteration 485/2501 train_loss: 0.4698798656463623 time_taken: 0.05670905113220215\n",
      "Epoch 3: iteration 486/2501 train_loss: 0.4699536859989166 time_taken: 0.056801795959472656\n",
      "Epoch 3: iteration 487/2501 train_loss: 0.47003814578056335 time_taken: 0.05702066421508789\n",
      "Epoch 3: iteration 488/2501 train_loss: 0.4701053500175476 time_taken: 0.05643033981323242\n",
      "Epoch 3: iteration 489/2501 train_loss: 0.4701739251613617 time_taken: 0.05637621879577637\n",
      "Epoch 3: iteration 490/2501 train_loss: 0.47022971510887146 time_taken: 0.05706596374511719\n",
      "Epoch 3: iteration 491/2501 train_loss: 0.4703145921230316 time_taken: 0.05721020698547363\n",
      "Epoch 3: iteration 492/2501 train_loss: 0.47041577100753784 time_taken: 0.05654025077819824\n",
      "Epoch 3: iteration 493/2501 train_loss: 0.4705025851726532 time_taken: 0.05623269081115723\n",
      "Epoch 3: iteration 494/2501 train_loss: 0.4705847203731537 time_taken: 0.056325674057006836\n",
      "Epoch 3: iteration 495/2501 train_loss: 0.47063127160072327 time_taken: 0.05669736862182617\n",
      "Epoch 3: iteration 496/2501 train_loss: 0.47066178917884827 time_taken: 0.0568232536315918\n",
      "Epoch 3: iteration 497/2501 train_loss: 0.4706936776638031 time_taken: 0.05636858940124512\n",
      "Epoch 3: iteration 498/2501 train_loss: 0.47071120142936707 time_taken: 0.056377410888671875\n",
      "Epoch 3: iteration 499/2501 train_loss: 0.470724880695343 time_taken: 0.05677914619445801\n",
      "Epoch 3: iteration 500/2501 train_loss: 0.47073256969451904 time_taken: 0.056793212890625\n",
      "Epoch 3: iteration 501/2501 train_loss: 0.4707513451576233 time_taken: 0.05623173713684082\n",
      "Epoch 3: iteration 502/2501 train_loss: 0.4707723557949066 time_taken: 0.05636310577392578\n",
      "Epoch 3: iteration 503/2501 train_loss: 0.4708024561405182 time_taken: 0.05695748329162598\n",
      "Epoch 3: iteration 504/2501 train_loss: 0.4708350598812103 time_taken: 0.056722402572631836\n",
      "Epoch 3: iteration 505/2501 train_loss: 0.4708356261253357 time_taken: 0.056238651275634766\n",
      "Epoch 3: iteration 506/2501 train_loss: 0.4708714783191681 time_taken: 0.056281089782714844\n",
      "Epoch 3: iteration 507/2501 train_loss: 0.4708762764930725 time_taken: 0.05629897117614746\n",
      "Epoch 3: iteration 508/2501 train_loss: 0.4708913266658783 time_taken: 0.05627751350402832\n",
      "Epoch 3: iteration 509/2501 train_loss: 0.4709430932998657 time_taken: 0.05645465850830078\n",
      "Epoch 3: iteration 510/2501 train_loss: 0.4709663391113281 time_taken: 0.05645275115966797\n",
      "Epoch 3: iteration 511/2501 train_loss: 0.4710230231285095 time_taken: 0.0572667121887207\n",
      "Epoch 3: iteration 512/2501 train_loss: 0.47109314799308777 time_taken: 0.05686068534851074\n",
      "Epoch 3: iteration 513/2501 train_loss: 0.471157431602478 time_taken: 0.056749820709228516\n",
      "Epoch 3: iteration 514/2501 train_loss: 0.4712049663066864 time_taken: 0.05638575553894043\n",
      "Epoch 3: iteration 515/2501 train_loss: 0.47125905752182007 time_taken: 0.05635952949523926\n",
      "Epoch 3: iteration 516/2501 train_loss: 0.4712951183319092 time_taken: 0.05742454528808594\n",
      "Epoch 3: iteration 517/2501 train_loss: 0.4713200032711029 time_taken: 0.05764007568359375\n",
      "Epoch 3: iteration 518/2501 train_loss: 0.47139570116996765 time_taken: 0.05639004707336426\n",
      "Epoch 3: iteration 519/2501 train_loss: 0.4714488983154297 time_taken: 0.05635380744934082\n",
      "Epoch 3: iteration 520/2501 train_loss: 0.47154533863067627 time_taken: 0.05699658393859863\n",
      "Epoch 3: iteration 521/2501 train_loss: 0.4716106355190277 time_taken: 0.05701470375061035\n",
      "Epoch 3: iteration 522/2501 train_loss: 0.47166335582733154 time_taken: 0.056859493255615234\n",
      "Epoch 3: iteration 523/2501 train_loss: 0.4717179536819458 time_taken: 0.056313514709472656\n",
      "Epoch 3: iteration 524/2501 train_loss: 0.47180458903312683 time_taken: 0.0567319393157959\n",
      "Epoch 3: iteration 525/2501 train_loss: 0.4718683958053589 time_taken: 0.05697321891784668\n",
      "Epoch 3: iteration 526/2501 train_loss: 0.47194671630859375 time_taken: 0.056961774826049805\n",
      "Epoch 3: iteration 527/2501 train_loss: 0.4719988703727722 time_taken: 0.05683612823486328\n",
      "Epoch 3: iteration 528/2501 train_loss: 0.4720796048641205 time_taken: 0.0567784309387207\n",
      "Epoch 3: iteration 529/2501 train_loss: 0.4721585512161255 time_taken: 0.05687999725341797\n",
      "Epoch 3: iteration 530/2501 train_loss: 0.47222039103507996 time_taken: 0.0566868782043457\n",
      "Epoch 3: iteration 531/2501 train_loss: 0.47230520844459534 time_taken: 0.05634880065917969\n",
      "Epoch 3: iteration 532/2501 train_loss: 0.47240662574768066 time_taken: 0.05617475509643555\n",
      "Epoch 3: iteration 533/2501 train_loss: 0.47247302532196045 time_taken: 0.05677342414855957\n",
      "Epoch 3: iteration 534/2501 train_loss: 0.47254323959350586 time_taken: 0.05630302429199219\n",
      "Epoch 3: iteration 535/2501 train_loss: 0.4725947380065918 time_taken: 0.056978464126586914\n",
      "Epoch 3: iteration 536/2501 train_loss: 0.4726291298866272 time_taken: 0.056756019592285156\n",
      "Epoch 3: iteration 537/2501 train_loss: 0.4726606607437134 time_taken: 0.05635404586791992\n",
      "Epoch 3: iteration 538/2501 train_loss: 0.47266867756843567 time_taken: 0.05633878707885742\n",
      "Epoch 3: iteration 539/2501 train_loss: 0.4726477861404419 time_taken: 0.05750751495361328\n",
      "Epoch 3: iteration 540/2501 train_loss: 0.47263020277023315 time_taken: 0.05633091926574707\n",
      "Epoch 3: iteration 541/2501 train_loss: 0.47262853384017944 time_taken: 0.05693364143371582\n",
      "Epoch 3: iteration 542/2501 train_loss: 0.47262096405029297 time_taken: 0.05622553825378418\n",
      "Epoch 3: iteration 543/2501 train_loss: 0.47264233231544495 time_taken: 0.05625724792480469\n",
      "Epoch 3: iteration 544/2501 train_loss: 0.47267159819602966 time_taken: 0.0562891960144043\n",
      "Epoch 3: iteration 545/2501 train_loss: 0.47270891070365906 time_taken: 0.056833744049072266\n",
      "Epoch 3: iteration 546/2501 train_loss: 0.4727170169353485 time_taken: 0.05640816688537598\n",
      "Epoch 3: iteration 547/2501 train_loss: 0.4727339446544647 time_taken: 0.05642127990722656\n",
      "Epoch 3: iteration 548/2501 train_loss: 0.47275909781455994 time_taken: 0.056311845779418945\n",
      "Epoch 3: iteration 549/2501 train_loss: 0.47278037667274475 time_taken: 0.07120728492736816\n",
      "Epoch 3: iteration 550/2501 train_loss: 0.4727862477302551 time_taken: 0.05626249313354492\n",
      "Epoch 3: iteration 551/2501 train_loss: 0.47279679775238037 time_taken: 0.05629682540893555\n",
      "Epoch 3: iteration 552/2501 train_loss: 0.47280529141426086 time_taken: 0.05632472038269043\n",
      "Epoch 3: iteration 553/2501 train_loss: 0.4727926552295685 time_taken: 0.05656790733337402\n",
      "Epoch 3: iteration 554/2501 train_loss: 0.4727749228477478 time_taken: 0.05668067932128906\n",
      "Epoch 3: iteration 555/2501 train_loss: 0.4727715253829956 time_taken: 0.05624055862426758\n",
      "Epoch 3: iteration 556/2501 train_loss: 0.47277727723121643 time_taken: 0.056305646896362305\n",
      "Epoch 3: iteration 557/2501 train_loss: 0.47277581691741943 time_taken: 0.05707359313964844\n",
      "Epoch 3: iteration 558/2501 train_loss: 0.4727318584918976 time_taken: 0.05720877647399902\n",
      "Epoch 3: iteration 559/2501 train_loss: 0.4727012515068054 time_taken: 0.05670928955078125\n",
      "Epoch 3: iteration 560/2501 train_loss: 0.47265902161598206 time_taken: 0.05723237991333008\n",
      "Epoch 3: iteration 561/2501 train_loss: 0.47258055210113525 time_taken: 0.056662797927856445\n",
      "Epoch 3: iteration 562/2501 train_loss: 0.47250598669052124 time_taken: 0.056730031967163086\n",
      "Epoch 3: iteration 563/2501 train_loss: 0.4724048674106598 time_taken: 0.05675864219665527\n",
      "Epoch 3: iteration 564/2501 train_loss: 0.47232213616371155 time_taken: 0.0565953254699707\n",
      "Epoch 3: iteration 565/2501 train_loss: 0.4722527265548706 time_taken: 0.05678272247314453\n",
      "Epoch 3: iteration 566/2501 train_loss: 0.4722793400287628 time_taken: 0.05684804916381836\n",
      "Epoch 3: iteration 567/2501 train_loss: 0.4724820554256439 time_taken: 0.05686521530151367\n",
      "Epoch 3: iteration 568/2501 train_loss: 0.47258248925209045 time_taken: 0.05775642395019531\n",
      "Epoch 3: iteration 569/2501 train_loss: 0.4726210832595825 time_taken: 0.05717325210571289\n",
      "Epoch 3: iteration 570/2501 train_loss: 0.4726414978504181 time_taken: 0.056526899337768555\n",
      "Epoch 3: iteration 571/2501 train_loss: 0.4726702868938446 time_taken: 0.057281494140625\n",
      "Epoch 3: iteration 572/2501 train_loss: 0.4726482033729553 time_taken: 0.056725502014160156\n",
      "Epoch 3: iteration 573/2501 train_loss: 0.4727163314819336 time_taken: 0.05651044845581055\n",
      "Epoch 3: iteration 574/2501 train_loss: 0.47276219725608826 time_taken: 0.05638766288757324\n",
      "Epoch 3: iteration 575/2501 train_loss: 0.47275304794311523 time_taken: 0.05652427673339844\n",
      "Epoch 3: iteration 576/2501 train_loss: 0.47279635071754456 time_taken: 0.05763697624206543\n",
      "Epoch 3: iteration 577/2501 train_loss: 0.47283950448036194 time_taken: 0.0560147762298584\n",
      "Epoch 3: iteration 578/2501 train_loss: 0.4728136956691742 time_taken: 0.057771921157836914\n",
      "Epoch 3: iteration 579/2501 train_loss: 0.4727843105792999 time_taken: 0.07200241088867188\n",
      "Epoch 3: iteration 580/2501 train_loss: 0.47278520464897156 time_taken: 0.057268619537353516\n",
      "Epoch 3: iteration 581/2501 train_loss: 0.4727610647678375 time_taken: 0.05689501762390137\n",
      "Epoch 3: iteration 582/2501 train_loss: 0.47275397181510925 time_taken: 0.056832313537597656\n",
      "Epoch 3: iteration 583/2501 train_loss: 0.47273939847946167 time_taken: 0.05674886703491211\n",
      "Epoch 3: iteration 584/2501 train_loss: 0.47271791100502014 time_taken: 0.05694246292114258\n",
      "Epoch 3: iteration 585/2501 train_loss: 0.4726669192314148 time_taken: 0.05682802200317383\n",
      "Epoch 3: iteration 586/2501 train_loss: 0.4726095199584961 time_taken: 0.056329965591430664\n",
      "Epoch 3: iteration 587/2501 train_loss: 0.47255778312683105 time_taken: 0.05686759948730469\n",
      "Epoch 3: iteration 588/2501 train_loss: 0.4725108742713928 time_taken: 0.056650400161743164\n",
      "Epoch 3: iteration 589/2501 train_loss: 0.4724248945713043 time_taken: 0.05689740180969238\n",
      "Epoch 3: iteration 590/2501 train_loss: 0.4723430573940277 time_taken: 0.05653047561645508\n",
      "Epoch 3: iteration 591/2501 train_loss: 0.4722506105899811 time_taken: 0.057076454162597656\n",
      "Epoch 3: iteration 592/2501 train_loss: 0.4721499979496002 time_taken: 0.05637526512145996\n",
      "Epoch 3: iteration 593/2501 train_loss: 0.47203999757766724 time_taken: 0.05719637870788574\n",
      "Epoch 3: iteration 594/2501 train_loss: 0.4719313681125641 time_taken: 0.0561976432800293\n",
      "Epoch 3: iteration 595/2501 train_loss: 0.4718014597892761 time_taken: 0.07079863548278809\n",
      "Epoch 3: iteration 596/2501 train_loss: 0.47166287899017334 time_taken: 0.05631613731384277\n",
      "Epoch 3: iteration 597/2501 train_loss: 0.47150418162345886 time_taken: 0.05705428123474121\n",
      "Epoch 3: iteration 598/2501 train_loss: 0.4713374674320221 time_taken: 0.05661344528198242\n",
      "Epoch 3: iteration 599/2501 train_loss: 0.47118377685546875 time_taken: 0.05709052085876465\n",
      "Epoch 3: iteration 600/2501 train_loss: 0.4710746109485626 time_taken: 0.05678296089172363\n",
      "Epoch 3: iteration 601/2501 train_loss: 0.4709438681602478 time_taken: 0.05624103546142578\n",
      "Epoch 3: iteration 602/2501 train_loss: 0.4708601236343384 time_taken: 0.057427167892456055\n",
      "Epoch 3: iteration 603/2501 train_loss: 0.47079184651374817 time_taken: 0.05663180351257324\n",
      "Epoch 3: iteration 604/2501 train_loss: 0.4707191288471222 time_taken: 0.057092905044555664\n",
      "Epoch 3: iteration 605/2501 train_loss: 0.4706392288208008 time_taken: 0.05639004707336426\n",
      "Epoch 3: iteration 606/2501 train_loss: 0.4705779254436493 time_taken: 0.0567624568939209\n",
      "Epoch 3: iteration 607/2501 train_loss: 0.4704981744289398 time_taken: 0.05708599090576172\n",
      "Epoch 3: iteration 608/2501 train_loss: 0.4704433083534241 time_taken: 0.056509971618652344\n",
      "Epoch 3: iteration 609/2501 train_loss: 0.4704056680202484 time_taken: 0.05684685707092285\n",
      "Epoch 3: iteration 610/2501 train_loss: 0.4703563451766968 time_taken: 0.056478023529052734\n",
      "Epoch 3: iteration 611/2501 train_loss: 0.4703017473220825 time_taken: 0.09241557121276855\n",
      "Epoch 3: iteration 612/2501 train_loss: 0.47024816274642944 time_taken: 0.07419800758361816\n",
      "Epoch 3: iteration 613/2501 train_loss: 0.4701833426952362 time_taken: 0.056266069412231445\n",
      "Epoch 3: iteration 614/2501 train_loss: 0.4701085388660431 time_taken: 0.05673956871032715\n",
      "Epoch 3: iteration 615/2501 train_loss: 0.47004076838493347 time_taken: 0.05650973320007324\n",
      "Epoch 3: iteration 616/2501 train_loss: 0.4699691832065582 time_taken: 0.05630087852478027\n",
      "Epoch 3: iteration 617/2501 train_loss: 0.469892680644989 time_taken: 0.05633258819580078\n",
      "Epoch 3: iteration 618/2501 train_loss: 0.4697997272014618 time_taken: 0.05654406547546387\n",
      "Epoch 3: iteration 619/2501 train_loss: 0.4697257876396179 time_taken: 0.05658245086669922\n",
      "Epoch 3: iteration 620/2501 train_loss: 0.46963465213775635 time_taken: 0.055930137634277344\n",
      "Epoch 3: iteration 621/2501 train_loss: 0.46956607699394226 time_taken: 0.05629563331604004\n",
      "Epoch 3: iteration 622/2501 train_loss: 0.46951672434806824 time_taken: 0.05648016929626465\n",
      "Epoch 3: iteration 623/2501 train_loss: 0.4694775938987732 time_taken: 0.05632901191711426\n",
      "Epoch 3: iteration 624/2501 train_loss: 0.46939927339553833 time_taken: 0.05645298957824707\n",
      "Epoch 3: iteration 625/2501 train_loss: 0.46932369470596313 time_taken: 0.05661463737487793\n",
      "Epoch 3: iteration 626/2501 train_loss: 0.46925318241119385 time_taken: 0.05655837059020996\n",
      "Epoch 3: iteration 627/2501 train_loss: 0.4691917300224304 time_taken: 0.05700945854187012\n",
      "Epoch 3: iteration 628/2501 train_loss: 0.46913042664527893 time_taken: 0.057013511657714844\n",
      "Epoch 3: iteration 629/2501 train_loss: 0.4690738320350647 time_taken: 0.05712437629699707\n",
      "Epoch 3: iteration 630/2501 train_loss: 0.4689994156360626 time_taken: 0.056475162506103516\n",
      "Epoch 3: iteration 631/2501 train_loss: 0.4689495861530304 time_taken: 0.05641913414001465\n",
      "Epoch 3: iteration 632/2501 train_loss: 0.46890509128570557 time_taken: 0.05700182914733887\n",
      "Epoch 3: iteration 633/2501 train_loss: 0.4688386619091034 time_taken: 0.05672001838684082\n",
      "Epoch 3: iteration 634/2501 train_loss: 0.4687512516975403 time_taken: 0.05699801445007324\n",
      "Epoch 3: iteration 635/2501 train_loss: 0.46864649653434753 time_taken: 0.05636858940124512\n",
      "Epoch 3: iteration 636/2501 train_loss: 0.4685366749763489 time_taken: 0.05700063705444336\n",
      "Epoch 3: iteration 637/2501 train_loss: 0.46842899918556213 time_taken: 0.05684471130371094\n",
      "Epoch 3: iteration 638/2501 train_loss: 0.46828120946884155 time_taken: 0.05700230598449707\n",
      "Epoch 3: iteration 639/2501 train_loss: 0.4681569039821625 time_taken: 0.05711030960083008\n",
      "Epoch 3: iteration 640/2501 train_loss: 0.4680230915546417 time_taken: 0.056490182876586914\n",
      "Epoch 3: iteration 641/2501 train_loss: 0.4678723216056824 time_taken: 0.05693340301513672\n",
      "Epoch 3: iteration 642/2501 train_loss: 0.4677024781703949 time_taken: 0.05689191818237305\n",
      "Epoch 3: iteration 643/2501 train_loss: 0.46752968430519104 time_taken: 0.05642843246459961\n",
      "Epoch 3: iteration 644/2501 train_loss: 0.46733832359313965 time_taken: 0.05743217468261719\n",
      "Epoch 3: iteration 645/2501 train_loss: 0.4671628475189209 time_taken: 0.05643463134765625\n",
      "Epoch 3: iteration 646/2501 train_loss: 0.46700116991996765 time_taken: 0.07825660705566406\n",
      "Epoch 3: iteration 647/2501 train_loss: 0.46685028076171875 time_taken: 0.05616188049316406\n",
      "Epoch 3: iteration 648/2501 train_loss: 0.46671801805496216 time_taken: 0.056268930435180664\n",
      "Epoch 3: iteration 649/2501 train_loss: 0.4666181802749634 time_taken: 0.056485891342163086\n",
      "Epoch 3: iteration 650/2501 train_loss: 0.46653062105178833 time_taken: 0.05614161491394043\n",
      "Epoch 3: iteration 651/2501 train_loss: 0.46649324893951416 time_taken: 0.05653643608093262\n",
      "Epoch 3: iteration 652/2501 train_loss: 0.466459184885025 time_taken: 0.05635833740234375\n",
      "Epoch 3: iteration 653/2501 train_loss: 0.46642908453941345 time_taken: 0.056487083435058594\n",
      "Epoch 3: iteration 654/2501 train_loss: 0.466396689414978 time_taken: 0.05684781074523926\n",
      "Epoch 3: iteration 655/2501 train_loss: 0.4663819968700409 time_taken: 0.056913137435913086\n",
      "Epoch 3: iteration 656/2501 train_loss: 0.4663618206977844 time_taken: 0.05695843696594238\n",
      "Epoch 3: iteration 657/2501 train_loss: 0.46635279059410095 time_taken: 0.05724644660949707\n",
      "Epoch 3: iteration 658/2501 train_loss: 0.46634870767593384 time_taken: 0.057332515716552734\n",
      "Epoch 3: iteration 659/2501 train_loss: 0.4663459062576294 time_taken: 0.05779552459716797\n",
      "Epoch 3: iteration 660/2501 train_loss: 0.46636131405830383 time_taken: 0.05691409111022949\n",
      "Epoch 3: iteration 661/2501 train_loss: 0.4663749635219574 time_taken: 0.05689549446105957\n",
      "Epoch 3: iteration 662/2501 train_loss: 0.46640029549598694 time_taken: 0.05665326118469238\n",
      "Epoch 3: iteration 663/2501 train_loss: 0.4664328694343567 time_taken: 0.05756878852844238\n",
      "Epoch 3: iteration 664/2501 train_loss: 0.4664643108844757 time_taken: 0.05732417106628418\n",
      "Epoch 3: iteration 665/2501 train_loss: 0.46651387214660645 time_taken: 0.05681419372558594\n",
      "Epoch 3: iteration 666/2501 train_loss: 0.4665619730949402 time_taken: 0.05797457695007324\n",
      "Epoch 3: iteration 667/2501 train_loss: 0.46660923957824707 time_taken: 0.05692028999328613\n",
      "Epoch 3: iteration 668/2501 train_loss: 0.46665340662002563 time_taken: 0.05745673179626465\n",
      "Epoch 3: iteration 669/2501 train_loss: 0.4666866958141327 time_taken: 0.056947946548461914\n",
      "Epoch 3: iteration 670/2501 train_loss: 0.4667584002017975 time_taken: 0.057128190994262695\n",
      "Epoch 3: iteration 671/2501 train_loss: 0.46684595942497253 time_taken: 0.05711174011230469\n",
      "Epoch 3: iteration 672/2501 train_loss: 0.4671369791030884 time_taken: 0.05653095245361328\n",
      "Epoch 3: iteration 673/2501 train_loss: 0.46752041578292847 time_taken: 0.0566256046295166\n",
      "Epoch 3: iteration 674/2501 train_loss: 0.467592716217041 time_taken: 0.057060956954956055\n",
      "Epoch 3: iteration 675/2501 train_loss: 0.46774816513061523 time_taken: 0.0567476749420166\n",
      "Epoch 3: iteration 676/2501 train_loss: 0.4679279327392578 time_taken: 0.056548118591308594\n",
      "Epoch 3: iteration 677/2501 train_loss: 0.4680503010749817 time_taken: 0.05615663528442383\n",
      "Epoch 3: iteration 678/2501 train_loss: 0.4681299030780792 time_taken: 0.056389808654785156\n",
      "Epoch 3: iteration 679/2501 train_loss: 0.46820423007011414 time_taken: 0.056540727615356445\n",
      "Epoch 3: iteration 680/2501 train_loss: 0.468254953622818 time_taken: 0.05674433708190918\n",
      "Epoch 3: iteration 681/2501 train_loss: 0.46829894185066223 time_taken: 0.056496381759643555\n",
      "Epoch 3: iteration 682/2501 train_loss: 0.4683312773704529 time_taken: 0.056821346282958984\n",
      "Epoch 3: iteration 683/2501 train_loss: 0.4683437645435333 time_taken: 0.0565485954284668\n",
      "Epoch 3: iteration 684/2501 train_loss: 0.46836110949516296 time_taken: 0.05626702308654785\n",
      "Epoch 3: iteration 685/2501 train_loss: 0.46835464239120483 time_taken: 0.056455135345458984\n",
      "Epoch 3: iteration 686/2501 train_loss: 0.4683254659175873 time_taken: 0.05617380142211914\n",
      "Epoch 3: iteration 687/2501 train_loss: 0.4683007001876831 time_taken: 0.05710172653198242\n",
      "Epoch 3: iteration 688/2501 train_loss: 0.468285471200943 time_taken: 0.05698800086975098\n",
      "Epoch 3: iteration 689/2501 train_loss: 0.4682287573814392 time_taken: 0.05704092979431152\n",
      "Epoch 3: iteration 690/2501 train_loss: 0.4681626260280609 time_taken: 0.056890249252319336\n",
      "Epoch 3: iteration 691/2501 train_loss: 0.46808576583862305 time_taken: 0.056848764419555664\n",
      "Epoch 3: iteration 692/2501 train_loss: 0.4680350124835968 time_taken: 0.05686473846435547\n",
      "Epoch 3: iteration 693/2501 train_loss: 0.4680148661136627 time_taken: 0.056604623794555664\n",
      "Epoch 3: iteration 694/2501 train_loss: 0.46799543499946594 time_taken: 0.057385921478271484\n",
      "Epoch 3: iteration 695/2501 train_loss: 0.46797066926956177 time_taken: 0.05670428276062012\n",
      "Epoch 3: iteration 696/2501 train_loss: 0.4679492712020874 time_taken: 0.05636143684387207\n",
      "Epoch 3: iteration 697/2501 train_loss: 0.4679110646247864 time_taken: 0.05748558044433594\n",
      "Epoch 3: iteration 698/2501 train_loss: 0.4678919315338135 time_taken: 0.056912899017333984\n",
      "Epoch 3: iteration 699/2501 train_loss: 0.46787792444229126 time_taken: 0.056847333908081055\n",
      "Epoch 3: iteration 700/2501 train_loss: 0.46790552139282227 time_taken: 0.05802321434020996\n",
      "Epoch 3: iteration 701/2501 train_loss: 0.46794044971466064 time_taken: 0.05711770057678223\n",
      "Epoch 3: iteration 702/2501 train_loss: 0.4679679274559021 time_taken: 0.05601382255554199\n",
      "Epoch 3: iteration 703/2501 train_loss: 0.46798789501190186 time_taken: 0.05675864219665527\n",
      "Epoch 3: iteration 704/2501 train_loss: 0.46804171800613403 time_taken: 0.056685447692871094\n",
      "Epoch 3: iteration 705/2501 train_loss: 0.4681068956851959 time_taken: 0.05692577362060547\n",
      "Epoch 3: iteration 706/2501 train_loss: 0.46816641092300415 time_taken: 0.056596994400024414\n",
      "Epoch 3: iteration 707/2501 train_loss: 0.4682275950908661 time_taken: 0.056337594985961914\n",
      "Epoch 3: iteration 708/2501 train_loss: 0.46830636262893677 time_taken: 0.05722236633300781\n",
      "Epoch 3: iteration 709/2501 train_loss: 0.46841374039649963 time_taken: 0.05683636665344238\n",
      "Epoch 3: iteration 710/2501 train_loss: 0.46851640939712524 time_taken: 0.056946516036987305\n",
      "Epoch 3: iteration 711/2501 train_loss: 0.46861445903778076 time_taken: 0.05737566947937012\n",
      "Epoch 3: iteration 712/2501 train_loss: 0.4687058627605438 time_taken: 0.05637001991271973\n",
      "Epoch 3: iteration 713/2501 train_loss: 0.4687938094139099 time_taken: 0.056569814682006836\n",
      "Epoch 3: iteration 714/2501 train_loss: 0.4688622057437897 time_taken: 0.05668973922729492\n",
      "Epoch 3: iteration 715/2501 train_loss: 0.46892160177230835 time_taken: 0.05723118782043457\n",
      "Epoch 3: iteration 716/2501 train_loss: 0.46899375319480896 time_taken: 0.05652260780334473\n",
      "Epoch 3: iteration 717/2501 train_loss: 0.46903711557388306 time_taken: 0.05681872367858887\n",
      "Epoch 3: iteration 718/2501 train_loss: 0.4690858721733093 time_taken: 0.057032108306884766\n",
      "Epoch 3: iteration 719/2501 train_loss: 0.46911633014678955 time_taken: 0.0568697452545166\n",
      "Epoch 3: iteration 720/2501 train_loss: 0.46915099024772644 time_taken: 0.05666375160217285\n",
      "Epoch 3: iteration 721/2501 train_loss: 0.4692338705062866 time_taken: 0.05683135986328125\n",
      "Epoch 3: iteration 722/2501 train_loss: 0.4693465530872345 time_taken: 0.056585073471069336\n",
      "Epoch 3: iteration 723/2501 train_loss: 0.4694259762763977 time_taken: 0.05681467056274414\n",
      "Epoch 3: iteration 724/2501 train_loss: 0.46948444843292236 time_taken: 0.05712461471557617\n",
      "Epoch 3: iteration 725/2501 train_loss: 0.46955522894859314 time_taken: 0.05682706832885742\n",
      "Epoch 3: iteration 726/2501 train_loss: 0.4696032404899597 time_taken: 0.0570673942565918\n",
      "Epoch 3: iteration 727/2501 train_loss: 0.46963170170783997 time_taken: 0.05672121047973633\n",
      "Epoch 3: iteration 728/2501 train_loss: 0.46964511275291443 time_taken: 0.0566561222076416\n",
      "Epoch 3: iteration 729/2501 train_loss: 0.46963322162628174 time_taken: 0.05631446838378906\n",
      "Epoch 3: iteration 730/2501 train_loss: 0.46961769461631775 time_taken: 0.057222843170166016\n",
      "Epoch 3: iteration 731/2501 train_loss: 0.46958860754966736 time_taken: 0.05665755271911621\n",
      "Epoch 3: iteration 732/2501 train_loss: 0.4695283770561218 time_taken: 0.05725550651550293\n",
      "Epoch 3: iteration 733/2501 train_loss: 0.46947601437568665 time_taken: 0.0563662052154541\n",
      "Epoch 3: iteration 734/2501 train_loss: 0.4694019556045532 time_taken: 0.05854082107543945\n",
      "Epoch 3: iteration 735/2501 train_loss: 0.4693375825881958 time_taken: 0.0569920539855957\n",
      "Epoch 3: iteration 736/2501 train_loss: 0.4692569971084595 time_taken: 0.05684399604797363\n",
      "Epoch 3: iteration 737/2501 train_loss: 0.46919727325439453 time_taken: 0.056899309158325195\n",
      "Epoch 3: iteration 738/2501 train_loss: 0.46914437413215637 time_taken: 0.05710458755493164\n",
      "Epoch 3: iteration 739/2501 train_loss: 0.4691033959388733 time_taken: 0.05662083625793457\n",
      "Epoch 3: iteration 740/2501 train_loss: 0.46905121207237244 time_taken: 0.05647611618041992\n",
      "Epoch 3: iteration 741/2501 train_loss: 0.46902456879615784 time_taken: 0.05718374252319336\n",
      "Epoch 3: iteration 742/2501 train_loss: 0.4689875543117523 time_taken: 0.056624650955200195\n",
      "Epoch 3: iteration 743/2501 train_loss: 0.46893635392189026 time_taken: 0.05637240409851074\n",
      "Epoch 3: iteration 744/2501 train_loss: 0.4688841998577118 time_taken: 0.05636286735534668\n",
      "Epoch 3: iteration 745/2501 train_loss: 0.4688367247581482 time_taken: 0.05622577667236328\n",
      "Epoch 3: iteration 746/2501 train_loss: 0.468797892332077 time_taken: 0.056436777114868164\n",
      "Epoch 3: iteration 747/2501 train_loss: 0.4687270224094391 time_taken: 0.05657696723937988\n",
      "Epoch 3: iteration 748/2501 train_loss: 0.468681663274765 time_taken: 0.05624580383300781\n",
      "Epoch 3: iteration 749/2501 train_loss: 0.468641996383667 time_taken: 0.05611252784729004\n",
      "Epoch 3: iteration 750/2501 train_loss: 0.4685788154602051 time_taken: 0.06395125389099121\n",
      "Epoch 3: iteration 751/2501 train_loss: 0.46854111552238464 time_taken: 0.05620455741882324\n",
      "Epoch 3: iteration 752/2501 train_loss: 0.46847331523895264 time_taken: 0.05631065368652344\n",
      "Epoch 3: iteration 753/2501 train_loss: 0.4683998227119446 time_taken: 0.056525230407714844\n",
      "Epoch 3: iteration 754/2501 train_loss: 0.46833866834640503 time_taken: 0.056661367416381836\n",
      "Epoch 3: iteration 755/2501 train_loss: 0.46826446056365967 time_taken: 0.0561068058013916\n",
      "Epoch 3: iteration 756/2501 train_loss: 0.4681817889213562 time_taken: 0.05670499801635742\n",
      "Epoch 3: iteration 757/2501 train_loss: 0.4680997133255005 time_taken: 0.05689430236816406\n",
      "Epoch 3: iteration 758/2501 train_loss: 0.46800076961517334 time_taken: 0.05718636512756348\n",
      "Epoch 3: iteration 759/2501 train_loss: 0.46794456243515015 time_taken: 0.05626487731933594\n",
      "Epoch 3: iteration 760/2501 train_loss: 0.4678742587566376 time_taken: 0.056383371353149414\n",
      "Epoch 3: iteration 761/2501 train_loss: 0.4678194224834442 time_taken: 0.05709362030029297\n",
      "Epoch 3: iteration 762/2501 train_loss: 0.4677641987800598 time_taken: 0.057158708572387695\n",
      "Epoch 3: iteration 763/2501 train_loss: 0.4677179157733917 time_taken: 0.05687737464904785\n",
      "Epoch 3: iteration 764/2501 train_loss: 0.46770429611206055 time_taken: 0.05681610107421875\n",
      "Epoch 3: iteration 765/2501 train_loss: 0.4676673710346222 time_taken: 0.056654930114746094\n",
      "Epoch 3: iteration 766/2501 train_loss: 0.4676465392112732 time_taken: 0.05702853202819824\n",
      "Epoch 3: iteration 767/2501 train_loss: 0.46765902638435364 time_taken: 0.056738853454589844\n",
      "Epoch 3: iteration 768/2501 train_loss: 0.46768271923065186 time_taken: 0.05700087547302246\n",
      "Epoch 3: iteration 769/2501 train_loss: 0.46769821643829346 time_taken: 0.056975364685058594\n",
      "Epoch 3: iteration 770/2501 train_loss: 0.4676980674266815 time_taken: 0.057264089584350586\n",
      "Epoch 3: iteration 771/2501 train_loss: 0.46770599484443665 time_taken: 0.0573885440826416\n",
      "Epoch 3: iteration 772/2501 train_loss: 0.467733234167099 time_taken: 0.05701756477355957\n",
      "Epoch 3: iteration 773/2501 train_loss: 0.4677336513996124 time_taken: 0.056456565856933594\n",
      "Epoch 3: iteration 774/2501 train_loss: 0.46778300404548645 time_taken: 0.057066917419433594\n",
      "Epoch 3: iteration 775/2501 train_loss: 0.4677945077419281 time_taken: 0.05686545372009277\n",
      "Epoch 3: iteration 776/2501 train_loss: 0.46783581376075745 time_taken: 0.05721855163574219\n",
      "Epoch 3: iteration 777/2501 train_loss: 0.4678778648376465 time_taken: 0.057538747787475586\n",
      "Epoch 3: iteration 778/2501 train_loss: 0.46790555119514465 time_taken: 0.05671048164367676\n",
      "Epoch 3: iteration 779/2501 train_loss: 0.46792662143707275 time_taken: 0.057230234146118164\n",
      "Epoch 3: iteration 780/2501 train_loss: 0.4679241180419922 time_taken: 0.05653691291809082\n",
      "Epoch 3: iteration 781/2501 train_loss: 0.4679373502731323 time_taken: 0.056595563888549805\n",
      "Epoch 3: iteration 782/2501 train_loss: 0.4679368734359741 time_taken: 0.05632615089416504\n",
      "Epoch 3: iteration 783/2501 train_loss: 0.4679332375526428 time_taken: 0.05663704872131348\n",
      "Epoch 3: iteration 784/2501 train_loss: 0.4679126441478729 time_taken: 0.05658268928527832\n",
      "Epoch 3: iteration 785/2501 train_loss: 0.4678855538368225 time_taken: 0.057236433029174805\n",
      "Epoch 3: iteration 786/2501 train_loss: 0.4678376615047455 time_taken: 0.05620384216308594\n",
      "Epoch 3: iteration 787/2501 train_loss: 0.46780771017074585 time_taken: 0.057111501693725586\n",
      "Epoch 3: iteration 788/2501 train_loss: 0.4677678346633911 time_taken: 0.05682778358459473\n",
      "Epoch 3: iteration 789/2501 train_loss: 0.46773022413253784 time_taken: 0.05697894096374512\n",
      "Epoch 3: iteration 790/2501 train_loss: 0.46769341826438904 time_taken: 0.05683469772338867\n",
      "Epoch 3: iteration 791/2501 train_loss: 0.4676874279975891 time_taken: 0.05675768852233887\n",
      "Epoch 3: iteration 792/2501 train_loss: 0.46769434213638306 time_taken: 0.05712580680847168\n",
      "Epoch 3: iteration 793/2501 train_loss: 0.46769702434539795 time_taken: 0.05644512176513672\n",
      "Epoch 3: iteration 794/2501 train_loss: 0.467724084854126 time_taken: 0.056527137756347656\n",
      "Epoch 3: iteration 795/2501 train_loss: 0.46774059534072876 time_taken: 0.056249380111694336\n",
      "Epoch 3: iteration 796/2501 train_loss: 0.46775031089782715 time_taken: 0.056746721267700195\n",
      "Epoch 3: iteration 797/2501 train_loss: 0.4677516520023346 time_taken: 0.05671095848083496\n",
      "Epoch 3: iteration 798/2501 train_loss: 0.46776705980300903 time_taken: 0.056935787200927734\n",
      "Epoch 3: iteration 799/2501 train_loss: 0.46775326132774353 time_taken: 0.05627322196960449\n",
      "Epoch 3: iteration 800/2501 train_loss: 0.467769593000412 time_taken: 0.05771780014038086\n",
      "Epoch 3: iteration 801/2501 train_loss: 0.4677730202674866 time_taken: 0.05773806571960449\n",
      "Epoch 3: iteration 802/2501 train_loss: 0.4677862823009491 time_taken: 0.056577444076538086\n",
      "Epoch 3: iteration 803/2501 train_loss: 0.4677744507789612 time_taken: 0.05663418769836426\n",
      "Epoch 3: iteration 804/2501 train_loss: 0.46776852011680603 time_taken: 0.056966543197631836\n",
      "Epoch 3: iteration 805/2501 train_loss: 0.46775582432746887 time_taken: 0.05676603317260742\n",
      "Epoch 3: iteration 806/2501 train_loss: 0.4677578806877136 time_taken: 0.05696988105773926\n",
      "Epoch 3: iteration 807/2501 train_loss: 0.4677952826023102 time_taken: 0.05707979202270508\n",
      "Epoch 3: iteration 808/2501 train_loss: 0.46783190965652466 time_taken: 0.05649614334106445\n",
      "Epoch 3: iteration 809/2501 train_loss: 0.4678678512573242 time_taken: 0.057382822036743164\n",
      "Epoch 3: iteration 810/2501 train_loss: 0.4678845703601837 time_taken: 0.0569610595703125\n",
      "Epoch 3: iteration 811/2501 train_loss: 0.4679125249385834 time_taken: 0.08383464813232422\n",
      "Epoch 3: iteration 812/2501 train_loss: 0.46794119477272034 time_taken: 0.05772733688354492\n",
      "Epoch 3: iteration 813/2501 train_loss: 0.4679561257362366 time_taken: 0.05701875686645508\n",
      "Epoch 3: iteration 814/2501 train_loss: 0.46797236800193787 time_taken: 0.05638551712036133\n",
      "Epoch 3: iteration 815/2501 train_loss: 0.4680033326148987 time_taken: 0.05734562873840332\n",
      "Epoch 3: iteration 816/2501 train_loss: 0.46802717447280884 time_taken: 0.0569920539855957\n",
      "Epoch 3: iteration 817/2501 train_loss: 0.46804752945899963 time_taken: 0.056296586990356445\n",
      "Epoch 3: iteration 818/2501 train_loss: 0.46808093786239624 time_taken: 0.0573577880859375\n",
      "Epoch 3: iteration 819/2501 train_loss: 0.46814587712287903 time_taken: 0.056754350662231445\n",
      "Epoch 3: iteration 820/2501 train_loss: 0.4682369530200958 time_taken: 0.056902170181274414\n",
      "Epoch 3: iteration 821/2501 train_loss: 0.4682766795158386 time_taken: 0.05721139907836914\n",
      "Epoch 3: iteration 822/2501 train_loss: 0.4683248698711395 time_taken: 0.05679821968078613\n",
      "Epoch 3: iteration 823/2501 train_loss: 0.46837326884269714 time_taken: 0.05709576606750488\n",
      "Epoch 3: iteration 824/2501 train_loss: 0.4684050977230072 time_taken: 0.05751323699951172\n",
      "Epoch 3: iteration 825/2501 train_loss: 0.46843594312667847 time_taken: 0.056784629821777344\n",
      "Epoch 3: iteration 826/2501 train_loss: 0.4684542119503021 time_taken: 0.05634951591491699\n",
      "Epoch 3: iteration 827/2501 train_loss: 0.4684961438179016 time_taken: 0.05705714225769043\n",
      "Epoch 3: iteration 828/2501 train_loss: 0.4685339331626892 time_taken: 0.0566103458404541\n",
      "Epoch 3: iteration 829/2501 train_loss: 0.46856915950775146 time_taken: 0.056939125061035156\n",
      "Epoch 3: iteration 830/2501 train_loss: 0.46860313415527344 time_taken: 0.05635666847229004\n",
      "Epoch 3: iteration 831/2501 train_loss: 0.4686235785484314 time_taken: 0.056987762451171875\n",
      "Epoch 3: iteration 832/2501 train_loss: 0.46866369247436523 time_taken: 0.05709528923034668\n",
      "Epoch 3: iteration 833/2501 train_loss: 0.46868783235549927 time_taken: 0.05708122253417969\n",
      "Epoch 3: iteration 834/2501 train_loss: 0.4687003195285797 time_taken: 0.05694842338562012\n",
      "Epoch 3: iteration 835/2501 train_loss: 0.46872809529304504 time_taken: 0.05646109580993652\n",
      "Epoch 3: iteration 836/2501 train_loss: 0.46871882677078247 time_taken: 0.05836653709411621\n",
      "Epoch 3: iteration 837/2501 train_loss: 0.4687500298023224 time_taken: 0.05648159980773926\n",
      "Epoch 3: iteration 838/2501 train_loss: 0.4687724709510803 time_taken: 0.05793166160583496\n",
      "Epoch 3: iteration 839/2501 train_loss: 0.46879705786705017 time_taken: 0.056939125061035156\n",
      "Epoch 3: iteration 840/2501 train_loss: 0.46881356835365295 time_taken: 0.0567781925201416\n",
      "Epoch 3: iteration 841/2501 train_loss: 0.4688241481781006 time_taken: 0.05652308464050293\n",
      "Epoch 3: iteration 842/2501 train_loss: 0.46885162591934204 time_taken: 0.05673670768737793\n",
      "Epoch 3: iteration 843/2501 train_loss: 0.468862384557724 time_taken: 0.056742191314697266\n",
      "Epoch 3: iteration 844/2501 train_loss: 0.46887892484664917 time_taken: 0.05641627311706543\n",
      "Epoch 3: iteration 845/2501 train_loss: 0.46890947222709656 time_taken: 0.05676460266113281\n",
      "Epoch 3: iteration 846/2501 train_loss: 0.4689215123653412 time_taken: 0.05667686462402344\n",
      "Epoch 3: iteration 847/2501 train_loss: 0.4689440131187439 time_taken: 0.057263851165771484\n",
      "Epoch 3: iteration 848/2501 train_loss: 0.46897268295288086 time_taken: 0.05666351318359375\n",
      "Epoch 3: iteration 849/2501 train_loss: 0.4689870774745941 time_taken: 0.05632138252258301\n",
      "Epoch 3: iteration 850/2501 train_loss: 0.4690023958683014 time_taken: 0.056802988052368164\n",
      "Epoch 3: iteration 851/2501 train_loss: 0.4690289795398712 time_taken: 0.05697154998779297\n",
      "Epoch 3: iteration 852/2501 train_loss: 0.46905261278152466 time_taken: 0.05682635307312012\n",
      "Epoch 3: iteration 853/2501 train_loss: 0.4690632224082947 time_taken: 0.05690622329711914\n",
      "Epoch 3: iteration 854/2501 train_loss: 0.469091534614563 time_taken: 0.05687069892883301\n",
      "Epoch 3: iteration 855/2501 train_loss: 0.46911609172821045 time_taken: 0.056293487548828125\n",
      "Epoch 3: iteration 856/2501 train_loss: 0.46916520595550537 time_taken: 0.05695366859436035\n",
      "Epoch 3: iteration 857/2501 train_loss: 0.46921494603157043 time_taken: 0.05645942687988281\n",
      "Epoch 3: iteration 858/2501 train_loss: 0.4692533314228058 time_taken: 0.05688285827636719\n",
      "Epoch 3: iteration 859/2501 train_loss: 0.46932047605514526 time_taken: 0.056905269622802734\n",
      "Epoch 3: iteration 860/2501 train_loss: 0.46939924359321594 time_taken: 0.05667257308959961\n",
      "Epoch 3: iteration 861/2501 train_loss: 0.4694814682006836 time_taken: 0.05692887306213379\n",
      "Epoch 3: iteration 862/2501 train_loss: 0.469564288854599 time_taken: 0.05671882629394531\n",
      "Epoch 3: iteration 863/2501 train_loss: 0.4696331322193146 time_taken: 0.056420087814331055\n",
      "Epoch 3: iteration 864/2501 train_loss: 0.46969032287597656 time_taken: 0.06000471115112305\n",
      "Epoch 3: iteration 865/2501 train_loss: 0.46976253390312195 time_taken: 0.05659604072570801\n",
      "Epoch 3: iteration 866/2501 train_loss: 0.4698197841644287 time_taken: 0.056595563888549805\n",
      "Epoch 3: iteration 867/2501 train_loss: 0.46990302205085754 time_taken: 0.05687403678894043\n",
      "Epoch 3: iteration 868/2501 train_loss: 0.46998944878578186 time_taken: 0.05631375312805176\n",
      "Epoch 3: iteration 869/2501 train_loss: 0.47006556391716003 time_taken: 0.05703902244567871\n",
      "Epoch 3: iteration 870/2501 train_loss: 0.4701383113861084 time_taken: 0.05646967887878418\n",
      "Epoch 3: iteration 871/2501 train_loss: 0.4702044725418091 time_taken: 0.05716681480407715\n",
      "Epoch 3: iteration 872/2501 train_loss: 0.4702809453010559 time_taken: 0.05687999725341797\n",
      "Epoch 3: iteration 873/2501 train_loss: 0.47034579515457153 time_taken: 0.05684018135070801\n",
      "Epoch 3: iteration 874/2501 train_loss: 0.470424085855484 time_taken: 0.0676717758178711\n",
      "Epoch 3: iteration 875/2501 train_loss: 0.47048473358154297 time_taken: 0.05629467964172363\n",
      "Epoch 3: iteration 876/2501 train_loss: 0.4705342948436737 time_taken: 0.08767414093017578\n",
      "Epoch 3: iteration 877/2501 train_loss: 0.4706018269062042 time_taken: 0.07897615432739258\n",
      "Epoch 3: iteration 878/2501 train_loss: 0.4706548750400543 time_taken: 0.05652737617492676\n",
      "Epoch 3: iteration 879/2501 train_loss: 0.4706815779209137 time_taken: 0.05685544013977051\n",
      "Epoch 3: iteration 880/2501 train_loss: 0.4707454442977905 time_taken: 0.05648541450500488\n",
      "Epoch 3: iteration 881/2501 train_loss: 0.47078803181648254 time_taken: 0.0564875602722168\n",
      "Epoch 3: iteration 882/2501 train_loss: 0.47083738446235657 time_taken: 0.05680537223815918\n",
      "Epoch 3: iteration 883/2501 train_loss: 0.47088178992271423 time_taken: 0.056897640228271484\n",
      "Epoch 3: iteration 884/2501 train_loss: 0.47095170617103577 time_taken: 0.05670881271362305\n",
      "Epoch 3: iteration 885/2501 train_loss: 0.4709908962249756 time_taken: 0.05658388137817383\n",
      "Epoch 3: iteration 886/2501 train_loss: 0.4710390269756317 time_taken: 0.05699300765991211\n",
      "Epoch 3: iteration 887/2501 train_loss: 0.4710788130760193 time_taken: 0.057061195373535156\n",
      "Epoch 3: iteration 888/2501 train_loss: 0.4711383283138275 time_taken: 0.058094024658203125\n",
      "Epoch 3: iteration 889/2501 train_loss: 0.47120317816734314 time_taken: 0.05637073516845703\n",
      "Epoch 3: iteration 890/2501 train_loss: 0.4712698757648468 time_taken: 0.05687570571899414\n",
      "Epoch 3: iteration 891/2501 train_loss: 0.4713308811187744 time_taken: 0.05718731880187988\n",
      "Epoch 3: iteration 892/2501 train_loss: 0.4714076817035675 time_taken: 0.05656909942626953\n",
      "Epoch 3: iteration 893/2501 train_loss: 0.47146135568618774 time_taken: 0.0565493106842041\n",
      "Epoch 3: iteration 894/2501 train_loss: 0.4715195298194885 time_taken: 0.05681586265563965\n",
      "Epoch 3: iteration 895/2501 train_loss: 0.4715569019317627 time_taken: 0.05682682991027832\n",
      "Epoch 3: iteration 896/2501 train_loss: 0.471591591835022 time_taken: 0.056296348571777344\n",
      "Epoch 3: iteration 897/2501 train_loss: 0.4716181755065918 time_taken: 0.05652189254760742\n",
      "Epoch 3: iteration 898/2501 train_loss: 0.47163745760917664 time_taken: 0.0565643310546875\n",
      "Epoch 3: iteration 899/2501 train_loss: 0.47164398431777954 time_taken: 0.05625438690185547\n",
      "Epoch 3: iteration 900/2501 train_loss: 0.471665620803833 time_taken: 0.05627107620239258\n",
      "Epoch 3: iteration 901/2501 train_loss: 0.47168976068496704 time_taken: 0.05721306800842285\n",
      "Epoch 3: iteration 902/2501 train_loss: 0.47170647978782654 time_taken: 0.05697298049926758\n",
      "Epoch 3: iteration 903/2501 train_loss: 0.47173309326171875 time_taken: 0.05651998519897461\n",
      "Epoch 3: iteration 904/2501 train_loss: 0.47175249457359314 time_taken: 0.05640578269958496\n",
      "Epoch 3: iteration 905/2501 train_loss: 0.47178348898887634 time_taken: 0.05694317817687988\n",
      "Epoch 3: iteration 906/2501 train_loss: 0.47177985310554504 time_taken: 0.05649709701538086\n",
      "Epoch 3: iteration 907/2501 train_loss: 0.4717652201652527 time_taken: 0.056502342224121094\n",
      "Epoch 3: iteration 908/2501 train_loss: 0.47178083658218384 time_taken: 0.05700373649597168\n",
      "Epoch 3: iteration 909/2501 train_loss: 0.4717959463596344 time_taken: 0.056432247161865234\n",
      "Epoch 3: iteration 910/2501 train_loss: 0.4718262851238251 time_taken: 0.05662250518798828\n",
      "Epoch 3: iteration 911/2501 train_loss: 0.4718642234802246 time_taken: 0.05620098114013672\n",
      "Epoch 3: iteration 912/2501 train_loss: 0.4719044268131256 time_taken: 0.05662822723388672\n",
      "Epoch 3: iteration 913/2501 train_loss: 0.47196757793426514 time_taken: 0.05757951736450195\n",
      "Epoch 3: iteration 914/2501 train_loss: 0.47203126549720764 time_taken: 0.056328773498535156\n",
      "Epoch 3: iteration 915/2501 train_loss: 0.47208166122436523 time_taken: 0.05702972412109375\n",
      "Epoch 3: iteration 916/2501 train_loss: 0.47215232253074646 time_taken: 0.05651140213012695\n",
      "Epoch 3: iteration 917/2501 train_loss: 0.4722321927547455 time_taken: 0.05727672576904297\n",
      "Epoch 3: iteration 918/2501 train_loss: 0.47230634093284607 time_taken: 0.05660581588745117\n",
      "Epoch 3: iteration 919/2501 train_loss: 0.4723738431930542 time_taken: 0.05708026885986328\n",
      "Epoch 3: iteration 920/2501 train_loss: 0.4724282920360565 time_taken: 0.057099342346191406\n",
      "Epoch 3: iteration 921/2501 train_loss: 0.47244733572006226 time_taken: 0.0570683479309082\n",
      "Epoch 3: iteration 922/2501 train_loss: 0.4724667966365814 time_taken: 0.05666851997375488\n",
      "Epoch 3: iteration 923/2501 train_loss: 0.47247517108917236 time_taken: 0.05681109428405762\n",
      "Epoch 3: iteration 924/2501 train_loss: 0.47247377038002014 time_taken: 0.05645942687988281\n",
      "Epoch 3: iteration 925/2501 train_loss: 0.47244974970817566 time_taken: 0.05702066421508789\n",
      "Epoch 3: iteration 926/2501 train_loss: 0.4724402129650116 time_taken: 0.057335853576660156\n",
      "Epoch 3: iteration 927/2501 train_loss: 0.47240906953811646 time_taken: 0.05667877197265625\n",
      "Epoch 3: iteration 928/2501 train_loss: 0.47236359119415283 time_taken: 0.056870460510253906\n",
      "Epoch 3: iteration 929/2501 train_loss: 0.47231653332710266 time_taken: 0.057009220123291016\n",
      "Epoch 3: iteration 930/2501 train_loss: 0.4722607731819153 time_taken: 0.05799245834350586\n",
      "Epoch 3: iteration 931/2501 train_loss: 0.47220805287361145 time_taken: 0.056909799575805664\n",
      "Epoch 3: iteration 932/2501 train_loss: 0.4721604585647583 time_taken: 0.05734658241271973\n",
      "Epoch 3: iteration 933/2501 train_loss: 0.4720972180366516 time_taken: 0.056951284408569336\n",
      "Epoch 3: iteration 934/2501 train_loss: 0.4720461666584015 time_taken: 0.057364463806152344\n",
      "Epoch 3: iteration 935/2501 train_loss: 0.471998929977417 time_taken: 0.05837416648864746\n",
      "Epoch 3: iteration 936/2501 train_loss: 0.47193726897239685 time_taken: 0.05725717544555664\n",
      "Epoch 3: iteration 937/2501 train_loss: 0.4718916714191437 time_taken: 0.05724596977233887\n",
      "Epoch 3: iteration 938/2501 train_loss: 0.4718674421310425 time_taken: 0.05747032165527344\n",
      "Epoch 3: iteration 939/2501 train_loss: 0.47184672951698303 time_taken: 0.056974172592163086\n",
      "Epoch 3: iteration 940/2501 train_loss: 0.4718373119831085 time_taken: 0.057254791259765625\n",
      "Epoch 3: iteration 941/2501 train_loss: 0.47180429100990295 time_taken: 0.11057376861572266\n",
      "Epoch 3: iteration 942/2501 train_loss: 0.4717714488506317 time_taken: 0.08140063285827637\n",
      "Epoch 3: iteration 943/2501 train_loss: 0.4717360734939575 time_taken: 0.05643606185913086\n",
      "Epoch 3: iteration 944/2501 train_loss: 0.4716945290565491 time_taken: 0.05614948272705078\n",
      "Epoch 3: iteration 945/2501 train_loss: 0.47163915634155273 time_taken: 0.056336402893066406\n",
      "Epoch 3: iteration 946/2501 train_loss: 0.47159677743911743 time_taken: 0.05609321594238281\n",
      "Epoch 3: iteration 947/2501 train_loss: 0.47157928347587585 time_taken: 0.05654597282409668\n",
      "Epoch 3: iteration 948/2501 train_loss: 0.4715658128261566 time_taken: 0.0566709041595459\n",
      "Epoch 3: iteration 949/2501 train_loss: 0.4715502858161926 time_taken: 0.05673360824584961\n",
      "Epoch 3: iteration 950/2501 train_loss: 0.47153252363204956 time_taken: 0.05646944046020508\n",
      "Epoch 3: iteration 951/2501 train_loss: 0.4715307950973511 time_taken: 0.056706905364990234\n",
      "Epoch 3: iteration 952/2501 train_loss: 0.4715130925178528 time_taken: 0.05638718605041504\n",
      "Epoch 3: iteration 953/2501 train_loss: 0.47150918841362 time_taken: 0.05691790580749512\n",
      "Epoch 3: iteration 954/2501 train_loss: 0.47150304913520813 time_taken: 0.056745290756225586\n",
      "Epoch 3: iteration 955/2501 train_loss: 0.4715162515640259 time_taken: 0.056182146072387695\n",
      "Epoch 3: iteration 956/2501 train_loss: 0.47150924801826477 time_taken: 0.05645155906677246\n",
      "Epoch 3: iteration 957/2501 train_loss: 0.4715220034122467 time_taken: 0.05670785903930664\n",
      "Epoch 3: iteration 958/2501 train_loss: 0.47150611877441406 time_taken: 0.05618429183959961\n",
      "Epoch 3: iteration 959/2501 train_loss: 0.4714948832988739 time_taken: 0.05606651306152344\n",
      "Epoch 3: iteration 960/2501 train_loss: 0.4714732766151428 time_taken: 0.0563967227935791\n",
      "Epoch 3: iteration 961/2501 train_loss: 0.47146353125572205 time_taken: 0.05750632286071777\n",
      "Epoch 3: iteration 962/2501 train_loss: 0.47145622968673706 time_taken: 0.056640625\n",
      "Epoch 3: iteration 963/2501 train_loss: 0.4714680016040802 time_taken: 0.057405948638916016\n",
      "Epoch 3: iteration 964/2501 train_loss: 0.4714822471141815 time_taken: 0.056880950927734375\n",
      "Epoch 3: iteration 965/2501 train_loss: 0.4714909791946411 time_taken: 0.056876182556152344\n",
      "Epoch 3: iteration 966/2501 train_loss: 0.4715183973312378 time_taken: 0.056693077087402344\n",
      "Epoch 3: iteration 967/2501 train_loss: 0.4715502858161926 time_taken: 0.056624650955200195\n",
      "Epoch 3: iteration 968/2501 train_loss: 0.4715936481952667 time_taken: 0.056598663330078125\n",
      "Epoch 3: iteration 969/2501 train_loss: 0.4716506004333496 time_taken: 0.05691218376159668\n",
      "Epoch 3: iteration 970/2501 train_loss: 0.471684068441391 time_taken: 0.05897402763366699\n",
      "Epoch 3: iteration 971/2501 train_loss: 0.4717266857624054 time_taken: 0.05672717094421387\n",
      "Epoch 3: iteration 972/2501 train_loss: 0.4717671871185303 time_taken: 0.05635786056518555\n",
      "Epoch 3: iteration 973/2501 train_loss: 0.4717995226383209 time_taken: 0.057054758071899414\n",
      "Epoch 3: iteration 974/2501 train_loss: 0.47183486819267273 time_taken: 0.05718064308166504\n",
      "Epoch 3: iteration 975/2501 train_loss: 0.47184422612190247 time_taken: 0.05722999572753906\n",
      "Epoch 3: iteration 976/2501 train_loss: 0.47186458110809326 time_taken: 0.05688738822937012\n",
      "Epoch 3: iteration 977/2501 train_loss: 0.47187110781669617 time_taken: 0.05711102485656738\n",
      "Epoch 3: iteration 978/2501 train_loss: 0.47187161445617676 time_taken: 0.056589603424072266\n",
      "Epoch 3: iteration 979/2501 train_loss: 0.4718712866306305 time_taken: 0.05722665786743164\n",
      "Epoch 3: iteration 980/2501 train_loss: 0.47186702489852905 time_taken: 0.05635809898376465\n",
      "Epoch 3: iteration 981/2501 train_loss: 0.47186657786369324 time_taken: 0.056833505630493164\n",
      "Epoch 3: iteration 982/2501 train_loss: 0.47186070680618286 time_taken: 0.05683445930480957\n",
      "Epoch 3: iteration 983/2501 train_loss: 0.4718531668186188 time_taken: 0.05665135383605957\n",
      "Epoch 3: iteration 984/2501 train_loss: 0.47183215618133545 time_taken: 0.057320356369018555\n",
      "Epoch 3: iteration 985/2501 train_loss: 0.47183024883270264 time_taken: 0.057694196701049805\n",
      "Epoch 3: iteration 986/2501 train_loss: 0.4718210995197296 time_taken: 0.05697441101074219\n",
      "Epoch 3: iteration 987/2501 train_loss: 0.4718269407749176 time_taken: 0.0569913387298584\n",
      "Epoch 3: iteration 988/2501 train_loss: 0.47182077169418335 time_taken: 0.05667304992675781\n",
      "Epoch 3: iteration 989/2501 train_loss: 0.47182193398475647 time_taken: 0.056772470474243164\n",
      "Epoch 3: iteration 990/2501 train_loss: 0.47181493043899536 time_taken: 0.05646109580993652\n",
      "Epoch 3: iteration 991/2501 train_loss: 0.4718293249607086 time_taken: 0.05685162544250488\n",
      "Epoch 3: iteration 992/2501 train_loss: 0.47184282541275024 time_taken: 0.0567471981048584\n",
      "Epoch 3: iteration 993/2501 train_loss: 0.471860408782959 time_taken: 0.05651998519897461\n",
      "Epoch 3: iteration 994/2501 train_loss: 0.4718575179576874 time_taken: 0.05668330192565918\n",
      "Epoch 3: iteration 995/2501 train_loss: 0.47187623381614685 time_taken: 0.05649971961975098\n",
      "Epoch 3: iteration 996/2501 train_loss: 0.47187376022338867 time_taken: 0.05635380744934082\n",
      "Epoch 3: iteration 997/2501 train_loss: 0.47185641527175903 time_taken: 0.05675816535949707\n",
      "Epoch 3: iteration 998/2501 train_loss: 0.4718376696109772 time_taken: 0.05628252029418945\n",
      "Epoch 3: iteration 999/2501 train_loss: 0.47181203961372375 time_taken: 0.05740094184875488\n",
      "Epoch 3: iteration 1000/2501 train_loss: 0.4717867374420166 time_taken: 0.056905269622802734\n",
      "Epoch 3: iteration 1001/2501 train_loss: 0.47171682119369507 time_taken: 0.0565190315246582\n",
      "Epoch 3: iteration 1002/2501 train_loss: 0.471648246049881 time_taken: 0.058173179626464844\n",
      "Epoch 3: iteration 1003/2501 train_loss: 0.47158941626548767 time_taken: 0.0571897029876709\n",
      "Epoch 3: iteration 1004/2501 train_loss: 0.4715249240398407 time_taken: 0.05665254592895508\n",
      "Epoch 3: iteration 1005/2501 train_loss: 0.4714530110359192 time_taken: 0.05685615539550781\n",
      "Epoch 3: iteration 1006/2501 train_loss: 0.4713659882545471 time_taken: 0.05661606788635254\n",
      "Epoch 3: iteration 1007/2501 train_loss: 0.47127658128738403 time_taken: 0.05649757385253906\n",
      "Epoch 3: iteration 1008/2501 train_loss: 0.4711805284023285 time_taken: 0.05642414093017578\n",
      "Epoch 3: iteration 1009/2501 train_loss: 0.47108203172683716 time_taken: 0.056789398193359375\n",
      "Epoch 3: iteration 1010/2501 train_loss: 0.47096890211105347 time_taken: 0.05774736404418945\n",
      "Epoch 3: iteration 1011/2501 train_loss: 0.4708564281463623 time_taken: 0.056813955307006836\n",
      "Epoch 3: iteration 1012/2501 train_loss: 0.47074031829833984 time_taken: 0.057161808013916016\n",
      "Epoch 3: iteration 1013/2501 train_loss: 0.4706245958805084 time_taken: 0.057108402252197266\n",
      "Epoch 3: iteration 1014/2501 train_loss: 0.47050100564956665 time_taken: 0.05678415298461914\n",
      "Epoch 3: iteration 1015/2501 train_loss: 0.47038155794143677 time_taken: 0.05839037895202637\n",
      "Epoch 3: iteration 1016/2501 train_loss: 0.4702846109867096 time_taken: 0.0568087100982666\n",
      "Epoch 3: iteration 1017/2501 train_loss: 0.470211923122406 time_taken: 0.05697894096374512\n",
      "Epoch 3: iteration 1018/2501 train_loss: 0.4701381027698517 time_taken: 0.05747270584106445\n",
      "Epoch 3: iteration 1019/2501 train_loss: 0.47008016705513 time_taken: 0.05763125419616699\n",
      "Epoch 3: iteration 1020/2501 train_loss: 0.47004514932632446 time_taken: 0.05844378471374512\n",
      "Epoch 3: iteration 1021/2501 train_loss: 0.47000497579574585 time_taken: 0.056282758712768555\n",
      "Epoch 3: iteration 1022/2501 train_loss: 0.46999824047088623 time_taken: 0.05680346488952637\n",
      "Epoch 3: iteration 1023/2501 train_loss: 0.4699707627296448 time_taken: 0.05721616744995117\n",
      "Epoch 3: iteration 1024/2501 train_loss: 0.4699750244617462 time_taken: 0.05649518966674805\n",
      "Epoch 3: iteration 1025/2501 train_loss: 0.46997979283332825 time_taken: 0.057320594787597656\n",
      "Epoch 3: iteration 1026/2501 train_loss: 0.4699769914150238 time_taken: 0.05635666847229004\n",
      "Epoch 3: iteration 1027/2501 train_loss: 0.46997976303100586 time_taken: 0.09825396537780762\n",
      "Epoch 3: iteration 1028/2501 train_loss: 0.4699651002883911 time_taken: 0.05655097961425781\n",
      "Epoch 3: iteration 1029/2501 train_loss: 0.46994107961654663 time_taken: 0.056427001953125\n",
      "Epoch 3: iteration 1030/2501 train_loss: 0.469908744096756 time_taken: 0.057349205017089844\n",
      "Epoch 3: iteration 1031/2501 train_loss: 0.4698583781719208 time_taken: 0.056595563888549805\n",
      "Epoch 3: iteration 1032/2501 train_loss: 0.46981993317604065 time_taken: 0.05674600601196289\n",
      "Epoch 3: iteration 1033/2501 train_loss: 0.4697748124599457 time_taken: 0.0581817626953125\n",
      "Epoch 3: iteration 1034/2501 train_loss: 0.46971723437309265 time_taken: 0.05764508247375488\n",
      "Epoch 3: iteration 1035/2501 train_loss: 0.4696618914604187 time_taken: 0.057419776916503906\n",
      "Epoch 3: iteration 1036/2501 train_loss: 0.46959421038627625 time_taken: 0.05643820762634277\n",
      "Epoch 3: iteration 1037/2501 train_loss: 0.4695364534854889 time_taken: 0.05664205551147461\n",
      "Epoch 3: iteration 1038/2501 train_loss: 0.4694679081439972 time_taken: 0.05650591850280762\n",
      "Epoch 3: iteration 1039/2501 train_loss: 0.4694070816040039 time_taken: 0.05936384201049805\n",
      "Epoch 3: iteration 1040/2501 train_loss: 0.46932467818260193 time_taken: 0.05640387535095215\n",
      "Epoch 3: iteration 1041/2501 train_loss: 0.4692402482032776 time_taken: 0.05672287940979004\n",
      "Epoch 3: iteration 1042/2501 train_loss: 0.46917667984962463 time_taken: 0.05643057823181152\n",
      "Epoch 3: iteration 1043/2501 train_loss: 0.46910881996154785 time_taken: 0.05747652053833008\n",
      "Epoch 3: iteration 1044/2501 train_loss: 0.4690510034561157 time_taken: 0.058120012283325195\n",
      "Epoch 3: iteration 1045/2501 train_loss: 0.46898746490478516 time_taken: 0.05706453323364258\n",
      "Epoch 3: iteration 1046/2501 train_loss: 0.46893760561943054 time_taken: 0.057273149490356445\n",
      "Epoch 3: iteration 1047/2501 train_loss: 0.46888992190361023 time_taken: 0.05686545372009277\n",
      "Epoch 3: iteration 1048/2501 train_loss: 0.4688422977924347 time_taken: 0.06169390678405762\n",
      "Epoch 3: iteration 1049/2501 train_loss: 0.46880584955215454 time_taken: 0.05678105354309082\n",
      "Epoch 3: iteration 1050/2501 train_loss: 0.46877381205558777 time_taken: 0.0570073127746582\n",
      "Epoch 3: iteration 1051/2501 train_loss: 0.46874257922172546 time_taken: 0.05658674240112305\n",
      "Epoch 3: iteration 1052/2501 train_loss: 0.46872177720069885 time_taken: 0.056429147720336914\n",
      "Epoch 3: iteration 1053/2501 train_loss: 0.4687182307243347 time_taken: 0.05645942687988281\n",
      "Epoch 3: iteration 1054/2501 train_loss: 0.4687209129333496 time_taken: 0.05630755424499512\n",
      "Epoch 3: iteration 1055/2501 train_loss: 0.4687117040157318 time_taken: 0.05693626403808594\n",
      "Epoch 3: iteration 1056/2501 train_loss: 0.46871793270111084 time_taken: 0.057557106018066406\n",
      "Epoch 3: iteration 1057/2501 train_loss: 0.4687264561653137 time_taken: 0.056331634521484375\n",
      "Epoch 3: iteration 1058/2501 train_loss: 0.4687348008155823 time_taken: 0.056800127029418945\n",
      "Epoch 3: iteration 1059/2501 train_loss: 0.46875494718551636 time_taken: 0.056095123291015625\n",
      "Epoch 3: iteration 1060/2501 train_loss: 0.468766450881958 time_taken: 0.05662989616394043\n",
      "Epoch 3: iteration 1061/2501 train_loss: 0.46877622604370117 time_taken: 0.05636906623840332\n",
      "Epoch 3: iteration 1062/2501 train_loss: 0.4687832295894623 time_taken: 0.05675625801086426\n",
      "Epoch 3: iteration 1063/2501 train_loss: 0.4688038229942322 time_taken: 0.05647397041320801\n",
      "Epoch 3: iteration 1064/2501 train_loss: 0.4688282012939453 time_taken: 0.05624961853027344\n",
      "Epoch 3: iteration 1065/2501 train_loss: 0.46883904933929443 time_taken: 0.056208133697509766\n",
      "Epoch 3: iteration 1066/2501 train_loss: 0.46886348724365234 time_taken: 0.05671811103820801\n",
      "Epoch 3: iteration 1067/2501 train_loss: 0.46889397501945496 time_taken: 0.056688547134399414\n",
      "Epoch 3: iteration 1068/2501 train_loss: 0.46891337633132935 time_taken: 0.05631232261657715\n",
      "Epoch 3: iteration 1069/2501 train_loss: 0.46894529461860657 time_taken: 0.05697059631347656\n",
      "Epoch 3: iteration 1070/2501 train_loss: 0.4689805507659912 time_taken: 0.05685234069824219\n",
      "Epoch 3: iteration 1071/2501 train_loss: 0.46898430585861206 time_taken: 0.05661296844482422\n",
      "Epoch 3: iteration 1072/2501 train_loss: 0.46899861097335815 time_taken: 0.05625557899475098\n",
      "Epoch 3: iteration 1073/2501 train_loss: 0.469010591506958 time_taken: 0.05618691444396973\n",
      "Epoch 3: iteration 1074/2501 train_loss: 0.4690186679363251 time_taken: 0.05615568161010742\n",
      "Epoch 3: iteration 1075/2501 train_loss: 0.469023197889328 time_taken: 0.05752849578857422\n",
      "Epoch 3: iteration 1076/2501 train_loss: 0.46904456615448 time_taken: 0.05669236183166504\n",
      "Epoch 3: iteration 1077/2501 train_loss: 0.4690476059913635 time_taken: 0.056014299392700195\n",
      "Epoch 3: iteration 1078/2501 train_loss: 0.4690638482570648 time_taken: 0.056658029556274414\n",
      "Epoch 3: iteration 1079/2501 train_loss: 0.46907418966293335 time_taken: 0.056044578552246094\n",
      "Epoch 3: iteration 1080/2501 train_loss: 0.46909618377685547 time_taken: 0.05636239051818848\n",
      "Epoch 3: iteration 1081/2501 train_loss: 0.4691208600997925 time_taken: 0.056619882583618164\n",
      "Epoch 3: iteration 1082/2501 train_loss: 0.4691387712955475 time_taken: 0.05620694160461426\n",
      "Epoch 3: iteration 1083/2501 train_loss: 0.46916788816452026 time_taken: 0.056185007095336914\n",
      "Epoch 3: iteration 1084/2501 train_loss: 0.4692133963108063 time_taken: 0.05618739128112793\n",
      "Epoch 3: iteration 1085/2501 train_loss: 0.46926379203796387 time_taken: 0.05708622932434082\n",
      "Epoch 3: iteration 1086/2501 train_loss: 0.4693106710910797 time_taken: 0.056693315505981445\n",
      "Epoch 3: iteration 1087/2501 train_loss: 0.4693703353404999 time_taken: 0.056681156158447266\n",
      "Epoch 3: iteration 1088/2501 train_loss: 0.46943745017051697 time_taken: 0.06251645088195801\n",
      "Epoch 3: iteration 1089/2501 train_loss: 0.4694755971431732 time_taken: 0.05632305145263672\n",
      "Epoch 3: iteration 1090/2501 train_loss: 0.46951010823249817 time_taken: 0.057344675064086914\n",
      "Epoch 3: iteration 1091/2501 train_loss: 0.46956032514572144 time_taken: 0.05633854866027832\n",
      "Epoch 3: iteration 1092/2501 train_loss: 0.4695966839790344 time_taken: 0.05677366256713867\n",
      "Epoch 3: iteration 1093/2501 train_loss: 0.4696379601955414 time_taken: 0.05614161491394043\n",
      "Epoch 3: iteration 1094/2501 train_loss: 0.4696759581565857 time_taken: 0.05627751350402832\n",
      "Epoch 3: iteration 1095/2501 train_loss: 0.4697040021419525 time_taken: 0.05629301071166992\n",
      "Epoch 3: iteration 1096/2501 train_loss: 0.469739705324173 time_taken: 0.056311845779418945\n",
      "Epoch 3: iteration 1097/2501 train_loss: 0.46976375579833984 time_taken: 0.05756187438964844\n",
      "Epoch 3: iteration 1098/2501 train_loss: 0.46978819370269775 time_taken: 0.05642819404602051\n",
      "Epoch 3: iteration 1099/2501 train_loss: 0.46983394026756287 time_taken: 0.057051897048950195\n",
      "Epoch 3: iteration 1100/2501 train_loss: 0.46986159682273865 time_taken: 0.0566403865814209\n",
      "Epoch 3: iteration 1101/2501 train_loss: 0.46990320086479187 time_taken: 0.056624412536621094\n",
      "Epoch 3: iteration 1102/2501 train_loss: 0.46993717551231384 time_taken: 0.05743002891540527\n",
      "Epoch 3: iteration 1103/2501 train_loss: 0.469968318939209 time_taken: 0.05737662315368652\n",
      "Epoch 3: iteration 1104/2501 train_loss: 0.4699929654598236 time_taken: 0.0571904182434082\n",
      "Epoch 3: iteration 1105/2501 train_loss: 0.47002577781677246 time_taken: 0.05664801597595215\n",
      "Epoch 3: iteration 1106/2501 train_loss: 0.47004976868629456 time_taken: 0.056636810302734375\n",
      "Epoch 3: iteration 1107/2501 train_loss: 0.4700506925582886 time_taken: 0.06233072280883789\n",
      "Epoch 3: iteration 1108/2501 train_loss: 0.47006773948669434 time_taken: 0.05632615089416504\n",
      "Epoch 3: iteration 1109/2501 train_loss: 0.4700886905193329 time_taken: 0.056224822998046875\n",
      "Epoch 3: iteration 1110/2501 train_loss: 0.4701201915740967 time_taken: 0.05940890312194824\n",
      "Epoch 3: iteration 1111/2501 train_loss: 0.47015562653541565 time_taken: 0.05661630630493164\n",
      "Epoch 3: iteration 1112/2501 train_loss: 0.47015661001205444 time_taken: 0.056913137435913086\n",
      "Epoch 3: iteration 1113/2501 train_loss: 0.4701705873012543 time_taken: 0.056136131286621094\n",
      "Epoch 3: iteration 1114/2501 train_loss: 0.47018808126449585 time_taken: 0.05613136291503906\n",
      "Epoch 3: iteration 1115/2501 train_loss: 0.47019049525260925 time_taken: 0.056558847427368164\n",
      "Epoch 3: iteration 1116/2501 train_loss: 0.4701904058456421 time_taken: 0.056198835372924805\n",
      "Epoch 3: iteration 1117/2501 train_loss: 0.4701912999153137 time_taken: 0.05642104148864746\n",
      "Epoch 3: iteration 1118/2501 train_loss: 0.47018691897392273 time_taken: 0.057074785232543945\n",
      "Epoch 3: iteration 1119/2501 train_loss: 0.4701903164386749 time_taken: 0.05643463134765625\n",
      "Epoch 3: iteration 1120/2501 train_loss: 0.4701724946498871 time_taken: 0.05746889114379883\n",
      "Epoch 3: iteration 1121/2501 train_loss: 0.4701535999774933 time_taken: 0.056464433670043945\n",
      "Epoch 3: iteration 1122/2501 train_loss: 0.4701397716999054 time_taken: 0.057350873947143555\n",
      "Epoch 3: iteration 1123/2501 train_loss: 0.4701414704322815 time_taken: 0.056153297424316406\n",
      "Epoch 3: iteration 1124/2501 train_loss: 0.4701271653175354 time_taken: 0.05622410774230957\n",
      "Epoch 3: iteration 1125/2501 train_loss: 0.47013038396835327 time_taken: 0.06474137306213379\n",
      "Epoch 3: iteration 1126/2501 train_loss: 0.47012683749198914 time_taken: 0.056868791580200195\n",
      "Epoch 3: iteration 1127/2501 train_loss: 0.4701308608055115 time_taken: 0.056497812271118164\n",
      "Epoch 3: iteration 1128/2501 train_loss: 0.47013866901397705 time_taken: 0.05593705177307129\n",
      "Epoch 3: iteration 1129/2501 train_loss: 0.4701484739780426 time_taken: 0.0568547248840332\n",
      "Epoch 3: iteration 1130/2501 train_loss: 0.4701715111732483 time_taken: 0.055983781814575195\n",
      "Epoch 3: iteration 1131/2501 train_loss: 0.4701915383338928 time_taken: 0.05655932426452637\n",
      "Epoch 3: iteration 1132/2501 train_loss: 0.4702169895172119 time_taken: 0.05636191368103027\n",
      "Epoch 3: iteration 1133/2501 train_loss: 0.47024235129356384 time_taken: 0.05612492561340332\n",
      "Epoch 3: iteration 1134/2501 train_loss: 0.47026437520980835 time_taken: 0.056693315505981445\n",
      "Epoch 3: iteration 1135/2501 train_loss: 0.47030431032180786 time_taken: 0.0566256046295166\n",
      "Epoch 3: iteration 1136/2501 train_loss: 0.4703556001186371 time_taken: 0.056935787200927734\n",
      "Epoch 3: iteration 1137/2501 train_loss: 0.4703981578350067 time_taken: 0.056383371353149414\n",
      "Epoch 3: iteration 1138/2501 train_loss: 0.47040417790412903 time_taken: 0.0565798282623291\n",
      "Epoch 3: iteration 1139/2501 train_loss: 0.4704105257987976 time_taken: 0.05607342720031738\n",
      "Epoch 3: iteration 1140/2501 train_loss: 0.4704192876815796 time_taken: 0.05671334266662598\n",
      "Epoch 3: iteration 1141/2501 train_loss: 0.47041019797325134 time_taken: 0.056775569915771484\n",
      "Epoch 3: iteration 1142/2501 train_loss: 0.4704071879386902 time_taken: 0.056299686431884766\n",
      "Epoch 3: iteration 1143/2501 train_loss: 0.4703889787197113 time_taken: 0.05642843246459961\n",
      "Epoch 3: iteration 1144/2501 train_loss: 0.47035902738571167 time_taken: 0.056242942810058594\n",
      "Epoch 3: iteration 1145/2501 train_loss: 0.4703196585178375 time_taken: 0.05642437934875488\n",
      "Epoch 3: iteration 1146/2501 train_loss: 0.47027432918548584 time_taken: 0.056061744689941406\n",
      "Epoch 3: iteration 1147/2501 train_loss: 0.47021791338920593 time_taken: 0.05634260177612305\n",
      "Epoch 3: iteration 1148/2501 train_loss: 0.47015050053596497 time_taken: 0.059735774993896484\n",
      "Epoch 3: iteration 1149/2501 train_loss: 0.4700799882411957 time_taken: 0.06122994422912598\n",
      "Epoch 3: iteration 1150/2501 train_loss: 0.4700086712837219 time_taken: 0.058180809020996094\n",
      "Epoch 3: iteration 1151/2501 train_loss: 0.46992984414100647 time_taken: 0.05654263496398926\n",
      "Epoch 3: iteration 1152/2501 train_loss: 0.46983587741851807 time_taken: 0.05753612518310547\n",
      "Epoch 3: iteration 1153/2501 train_loss: 0.4697529673576355 time_taken: 0.05658435821533203\n",
      "Epoch 3: iteration 1154/2501 train_loss: 0.46967124938964844 time_taken: 0.05680966377258301\n",
      "Epoch 3: iteration 1155/2501 train_loss: 0.46958547830581665 time_taken: 0.05670285224914551\n",
      "Epoch 3: iteration 1156/2501 train_loss: 0.46952176094055176 time_taken: 0.05661273002624512\n",
      "Epoch 3: iteration 1157/2501 train_loss: 0.4694690406322479 time_taken: 0.05693197250366211\n",
      "Epoch 3: iteration 1158/2501 train_loss: 0.469425767660141 time_taken: 0.05643892288208008\n",
      "Epoch 3: iteration 1159/2501 train_loss: 0.46939554810523987 time_taken: 0.05681252479553223\n",
      "Epoch 3: iteration 1160/2501 train_loss: 0.4693959951400757 time_taken: 0.05626511573791504\n",
      "Epoch 3: iteration 1161/2501 train_loss: 0.4693717956542969 time_taken: 0.05662417411804199\n",
      "Epoch 3: iteration 1162/2501 train_loss: 0.4693545699119568 time_taken: 0.05747365951538086\n",
      "Epoch 3: iteration 1163/2501 train_loss: 0.46933218836784363 time_taken: 0.05676531791687012\n",
      "Epoch 3: iteration 1164/2501 train_loss: 0.4693240523338318 time_taken: 0.056581735610961914\n",
      "Epoch 3: iteration 1165/2501 train_loss: 0.4693002700805664 time_taken: 0.05808615684509277\n",
      "Epoch 3: iteration 1166/2501 train_loss: 0.4692857265472412 time_taken: 0.056884050369262695\n",
      "Epoch 3: iteration 1167/2501 train_loss: 0.4692550599575043 time_taken: 0.056954145431518555\n",
      "Epoch 3: iteration 1168/2501 train_loss: 0.4692435562610626 time_taken: 0.057091474533081055\n",
      "Epoch 3: iteration 1169/2501 train_loss: 0.46924757957458496 time_taken: 0.056771278381347656\n",
      "Epoch 3: iteration 1170/2501 train_loss: 0.46925896406173706 time_taken: 0.0562436580657959\n",
      "Epoch 3: iteration 1171/2501 train_loss: 0.4692747890949249 time_taken: 0.056589603424072266\n",
      "Epoch 3: iteration 1172/2501 train_loss: 0.46927469968795776 time_taken: 0.05635976791381836\n",
      "Epoch 3: iteration 1173/2501 train_loss: 0.4692830443382263 time_taken: 0.056947946548461914\n",
      "Epoch 3: iteration 1174/2501 train_loss: 0.4693104326725006 time_taken: 0.05655956268310547\n",
      "Epoch 3: iteration 1175/2501 train_loss: 0.46933481097221375 time_taken: 0.057118892669677734\n",
      "Epoch 3: iteration 1176/2501 train_loss: 0.46935978531837463 time_taken: 0.05675792694091797\n",
      "Epoch 3: iteration 1177/2501 train_loss: 0.46939143538475037 time_taken: 0.05675387382507324\n",
      "Epoch 3: iteration 1178/2501 train_loss: 0.4694260060787201 time_taken: 0.057023048400878906\n",
      "Epoch 3: iteration 1179/2501 train_loss: 0.4694330394268036 time_taken: 0.056261301040649414\n",
      "Epoch 3: iteration 1180/2501 train_loss: 0.4694420099258423 time_taken: 0.05607271194458008\n",
      "Epoch 3: iteration 1181/2501 train_loss: 0.4694545269012451 time_taken: 0.056105613708496094\n",
      "Epoch 3: iteration 1182/2501 train_loss: 0.4694680869579315 time_taken: 0.0563204288482666\n",
      "Epoch 3: iteration 1183/2501 train_loss: 0.46947789192199707 time_taken: 0.05649256706237793\n",
      "Epoch 3: iteration 1184/2501 train_loss: 0.46947264671325684 time_taken: 0.05649304389953613\n",
      "Epoch 3: iteration 1185/2501 train_loss: 0.46949610114097595 time_taken: 0.05659222602844238\n",
      "Epoch 3: iteration 1186/2501 train_loss: 0.46950289607048035 time_taken: 0.05661654472351074\n",
      "Epoch 3: iteration 1187/2501 train_loss: 0.46953293681144714 time_taken: 0.056612253189086914\n",
      "Epoch 3: iteration 1188/2501 train_loss: 0.469552606344223 time_taken: 0.05660295486450195\n",
      "Epoch 3: iteration 1189/2501 train_loss: 0.4695729613304138 time_taken: 0.056551456451416016\n",
      "Epoch 3: iteration 1190/2501 train_loss: 0.4695928990840912 time_taken: 0.05619549751281738\n",
      "Epoch 3: iteration 1191/2501 train_loss: 0.4696114659309387 time_taken: 0.056081533432006836\n",
      "Epoch 3: iteration 1192/2501 train_loss: 0.469612181186676 time_taken: 0.05606245994567871\n",
      "Epoch 3: iteration 1193/2501 train_loss: 0.469598650932312 time_taken: 0.05636143684387207\n",
      "Epoch 3: iteration 1194/2501 train_loss: 0.469577431678772 time_taken: 0.056145429611206055\n",
      "Epoch 3: iteration 1195/2501 train_loss: 0.4695609509944916 time_taken: 0.05581927299499512\n",
      "Epoch 3: iteration 1196/2501 train_loss: 0.4695180058479309 time_taken: 0.056449174880981445\n",
      "Epoch 3: iteration 1197/2501 train_loss: 0.4694751799106598 time_taken: 0.05684947967529297\n",
      "Epoch 3: iteration 1198/2501 train_loss: 0.46945738792419434 time_taken: 0.05733776092529297\n",
      "Epoch 3: iteration 1199/2501 train_loss: 0.4694412648677826 time_taken: 0.056476593017578125\n",
      "Epoch 3: iteration 1200/2501 train_loss: 0.4694104492664337 time_taken: 0.057730674743652344\n",
      "Epoch 3: iteration 1201/2501 train_loss: 0.46939095854759216 time_taken: 0.056809425354003906\n",
      "Epoch 3: iteration 1202/2501 train_loss: 0.4693668484687805 time_taken: 0.057250022888183594\n",
      "Epoch 3: iteration 1203/2501 train_loss: 0.4693477153778076 time_taken: 0.0566864013671875\n",
      "Epoch 3: iteration 1204/2501 train_loss: 0.469321608543396 time_taken: 0.056897878646850586\n",
      "Epoch 3: iteration 1205/2501 train_loss: 0.46932223439216614 time_taken: 0.05709981918334961\n",
      "Epoch 3: iteration 1206/2501 train_loss: 0.4693189859390259 time_taken: 0.05626964569091797\n",
      "Epoch 3: iteration 1207/2501 train_loss: 0.4693310856819153 time_taken: 0.0559687614440918\n",
      "Epoch 3: iteration 1208/2501 train_loss: 0.4693344533443451 time_taken: 0.0559849739074707\n",
      "Epoch 3: iteration 1209/2501 train_loss: 0.4693513810634613 time_taken: 0.0561833381652832\n",
      "Epoch 3: iteration 1210/2501 train_loss: 0.46937108039855957 time_taken: 0.056388139724731445\n",
      "Epoch 3: iteration 1211/2501 train_loss: 0.4693886935710907 time_taken: 0.05689096450805664\n",
      "Epoch 3: iteration 1212/2501 train_loss: 0.4694201350212097 time_taken: 0.056303977966308594\n",
      "Epoch 3: iteration 1213/2501 train_loss: 0.4694421589374542 time_taken: 0.056207895278930664\n",
      "Epoch 3: iteration 1214/2501 train_loss: 0.46946588158607483 time_taken: 0.057091474533081055\n",
      "Epoch 3: iteration 1215/2501 train_loss: 0.4694996774196625 time_taken: 0.0570220947265625\n",
      "Epoch 3: iteration 1216/2501 train_loss: 0.4695446193218231 time_taken: 0.056836843490600586\n",
      "Epoch 3: iteration 1217/2501 train_loss: 0.46959197521209717 time_taken: 0.05744051933288574\n",
      "Epoch 3: iteration 1218/2501 train_loss: 0.4696524739265442 time_taken: 0.05675077438354492\n",
      "Epoch 3: iteration 1219/2501 train_loss: 0.4697003960609436 time_taken: 0.056125640869140625\n",
      "Epoch 3: iteration 1220/2501 train_loss: 0.469738245010376 time_taken: 0.056291818618774414\n",
      "Epoch 3: iteration 1221/2501 train_loss: 0.46976226568222046 time_taken: 0.05676078796386719\n",
      "Epoch 3: iteration 1222/2501 train_loss: 0.46978092193603516 time_taken: 0.06517267227172852\n",
      "Epoch 3: iteration 1223/2501 train_loss: 0.4697984755039215 time_taken: 0.05666613578796387\n",
      "Epoch 3: iteration 1224/2501 train_loss: 0.4698198735713959 time_taken: 0.0567774772644043\n",
      "Epoch 3: iteration 1225/2501 train_loss: 0.46983957290649414 time_taken: 0.06281304359436035\n",
      "Epoch 3: iteration 1226/2501 train_loss: 0.46988075971603394 time_taken: 0.05669665336608887\n",
      "Epoch 3: iteration 1227/2501 train_loss: 0.4699271619319916 time_taken: 0.05639052391052246\n",
      "Epoch 3: iteration 1228/2501 train_loss: 0.4699658453464508 time_taken: 0.06162714958190918\n",
      "Epoch 3: iteration 1229/2501 train_loss: 0.4700217545032501 time_taken: 0.05710959434509277\n",
      "Epoch 3: iteration 1230/2501 train_loss: 0.47006604075431824 time_taken: 0.0597081184387207\n",
      "Epoch 3: iteration 1231/2501 train_loss: 0.47009268403053284 time_taken: 0.05695223808288574\n",
      "Epoch 3: iteration 1232/2501 train_loss: 0.4701322615146637 time_taken: 0.05662345886230469\n",
      "Epoch 3: iteration 1233/2501 train_loss: 0.4701685607433319 time_taken: 0.05675768852233887\n",
      "Epoch 3: iteration 1234/2501 train_loss: 0.4702121615409851 time_taken: 0.05692338943481445\n",
      "Epoch 3: iteration 1235/2501 train_loss: 0.4702630937099457 time_taken: 0.05641818046569824\n",
      "Epoch 3: iteration 1236/2501 train_loss: 0.47031456232070923 time_taken: 0.05691099166870117\n",
      "Epoch 3: iteration 1237/2501 train_loss: 0.470364511013031 time_taken: 0.056499481201171875\n",
      "Epoch 3: iteration 1238/2501 train_loss: 0.47041282057762146 time_taken: 0.05676579475402832\n",
      "Epoch 3: iteration 1239/2501 train_loss: 0.47044456005096436 time_taken: 0.05759286880493164\n",
      "Epoch 3: iteration 1240/2501 train_loss: 0.47046753764152527 time_taken: 0.05666971206665039\n",
      "Epoch 3: iteration 1241/2501 train_loss: 0.4704952538013458 time_taken: 0.05687856674194336\n",
      "Epoch 3: iteration 1242/2501 train_loss: 0.47051745653152466 time_taken: 0.056900739669799805\n",
      "Epoch 3: iteration 1243/2501 train_loss: 0.4705217778682709 time_taken: 0.057126760482788086\n",
      "Epoch 3: iteration 1244/2501 train_loss: 0.4705381989479065 time_taken: 0.056662797927856445\n",
      "Epoch 3: iteration 1245/2501 train_loss: 0.47056445479393005 time_taken: 0.05661296844482422\n",
      "Epoch 3: iteration 1246/2501 train_loss: 0.47056064009666443 time_taken: 0.05675530433654785\n",
      "Epoch 3: iteration 1247/2501 train_loss: 0.47057420015335083 time_taken: 0.056867122650146484\n",
      "Epoch 3: iteration 1248/2501 train_loss: 0.47060200572013855 time_taken: 0.056803226470947266\n",
      "Epoch 3: iteration 1249/2501 train_loss: 0.4706355333328247 time_taken: 0.05714917182922363\n",
      "Epoch 3: iteration 1250/2501 train_loss: 0.47067388892173767 time_taken: 0.056899309158325195\n",
      "Epoch 3: iteration 1251/2501 train_loss: 0.4707097113132477 time_taken: 0.05673360824584961\n",
      "Epoch 3: iteration 1252/2501 train_loss: 0.4707314372062683 time_taken: 0.05718350410461426\n",
      "Epoch 3: iteration 1253/2501 train_loss: 0.4707760214805603 time_taken: 0.06269335746765137\n",
      "Epoch 3: iteration 1254/2501 train_loss: 0.47081440687179565 time_taken: 0.0644674301147461\n",
      "Epoch 3: iteration 1255/2501 train_loss: 0.4708409905433655 time_taken: 0.06039071083068848\n",
      "Epoch 3: iteration 1256/2501 train_loss: 0.47083622217178345 time_taken: 0.05656099319458008\n",
      "Epoch 3: iteration 1257/2501 train_loss: 0.470858097076416 time_taken: 0.05701279640197754\n",
      "Epoch 3: iteration 1258/2501 train_loss: 0.47086015343666077 time_taken: 0.056592702865600586\n",
      "Epoch 3: iteration 1259/2501 train_loss: 0.47084710001945496 time_taken: 0.056807518005371094\n",
      "Epoch 3: iteration 1260/2501 train_loss: 0.47083184123039246 time_taken: 0.05720973014831543\n",
      "Epoch 3: iteration 1261/2501 train_loss: 0.4708091914653778 time_taken: 0.056774139404296875\n",
      "Epoch 3: iteration 1262/2501 train_loss: 0.47077077627182007 time_taken: 0.05739712715148926\n",
      "Epoch 3: iteration 1263/2501 train_loss: 0.47072771191596985 time_taken: 0.05695772171020508\n",
      "Epoch 3: iteration 1264/2501 train_loss: 0.4706774950027466 time_taken: 0.05650925636291504\n",
      "Epoch 3: iteration 1265/2501 train_loss: 0.47062647342681885 time_taken: 0.056993722915649414\n",
      "Epoch 3: iteration 1266/2501 train_loss: 0.4705597758293152 time_taken: 0.056862592697143555\n",
      "Epoch 3: iteration 1267/2501 train_loss: 0.470497727394104 time_taken: 0.05680489540100098\n",
      "Epoch 3: iteration 1268/2501 train_loss: 0.47043389081954956 time_taken: 0.05621743202209473\n",
      "Epoch 3: iteration 1269/2501 train_loss: 0.4703528583049774 time_taken: 0.05699968338012695\n",
      "Epoch 3: iteration 1270/2501 train_loss: 0.4702959656715393 time_taken: 0.056409358978271484\n",
      "Epoch 3: iteration 1271/2501 train_loss: 0.4702408015727997 time_taken: 0.0570526123046875\n",
      "Epoch 3: iteration 1272/2501 train_loss: 0.47018909454345703 time_taken: 0.05668902397155762\n",
      "Epoch 3: iteration 1273/2501 train_loss: 0.47015294432640076 time_taken: 0.05769991874694824\n",
      "Epoch 3: iteration 1274/2501 train_loss: 0.4701264202594757 time_taken: 0.05642271041870117\n",
      "Epoch 3: iteration 1275/2501 train_loss: 0.47010353207588196 time_taken: 0.05632829666137695\n",
      "Epoch 3: iteration 1276/2501 train_loss: 0.4700929522514343 time_taken: 0.056398630142211914\n",
      "Epoch 3: iteration 1277/2501 train_loss: 0.4700886309146881 time_taken: 0.056299686431884766\n",
      "Epoch 3: iteration 1278/2501 train_loss: 0.47008660435676575 time_taken: 0.05630946159362793\n",
      "Epoch 3: iteration 1279/2501 train_loss: 0.4700818657875061 time_taken: 0.05659008026123047\n",
      "Epoch 3: iteration 1280/2501 train_loss: 0.47007229924201965 time_taken: 0.05718040466308594\n",
      "Epoch 3: iteration 1281/2501 train_loss: 0.47007355093955994 time_taken: 0.06141924858093262\n",
      "Epoch 3: iteration 1282/2501 train_loss: 0.47005558013916016 time_taken: 0.056999921798706055\n",
      "Epoch 3: iteration 1283/2501 train_loss: 0.4700343906879425 time_taken: 0.05729842185974121\n",
      "Epoch 3: iteration 1284/2501 train_loss: 0.4700029194355011 time_taken: 0.05667376518249512\n",
      "Epoch 3: iteration 1285/2501 train_loss: 0.4699763059616089 time_taken: 0.07126927375793457\n",
      "Epoch 3: iteration 1286/2501 train_loss: 0.4699523150920868 time_taken: 0.05621218681335449\n",
      "Epoch 3: iteration 1287/2501 train_loss: 0.46992188692092896 time_taken: 0.05666542053222656\n",
      "Epoch 3: iteration 1288/2501 train_loss: 0.46988722681999207 time_taken: 0.05682229995727539\n",
      "Epoch 3: iteration 1289/2501 train_loss: 0.4698500633239746 time_taken: 0.05672860145568848\n",
      "Epoch 3: iteration 1290/2501 train_loss: 0.46981966495513916 time_taken: 0.05679178237915039\n",
      "Epoch 3: iteration 1291/2501 train_loss: 0.46978136897087097 time_taken: 0.05633211135864258\n",
      "Epoch 3: iteration 1292/2501 train_loss: 0.46975815296173096 time_taken: 0.05642223358154297\n",
      "Epoch 3: iteration 1293/2501 train_loss: 0.4697287380695343 time_taken: 0.05622267723083496\n",
      "Epoch 3: iteration 1294/2501 train_loss: 0.46970832347869873 time_taken: 0.05697274208068848\n",
      "Epoch 3: iteration 1295/2501 train_loss: 0.4696934223175049 time_taken: 0.05684185028076172\n",
      "Epoch 3: iteration 1296/2501 train_loss: 0.4696853458881378 time_taken: 0.05613207817077637\n",
      "Epoch 3: iteration 1297/2501 train_loss: 0.4696919918060303 time_taken: 0.05614185333251953\n",
      "Epoch 3: iteration 1298/2501 train_loss: 0.4696958661079407 time_taken: 0.05766749382019043\n",
      "Epoch 3: iteration 1299/2501 train_loss: 0.46970224380493164 time_taken: 0.05628514289855957\n",
      "Epoch 3: iteration 1300/2501 train_loss: 0.4697137176990509 time_taken: 0.05604743957519531\n",
      "Epoch 3: iteration 1301/2501 train_loss: 0.46973490715026855 time_taken: 0.05610394477844238\n",
      "Epoch 3: iteration 1302/2501 train_loss: 0.469750314950943 time_taken: 0.05714750289916992\n",
      "Epoch 3: iteration 1303/2501 train_loss: 0.46976011991500854 time_taken: 0.056659698486328125\n",
      "Epoch 3: iteration 1304/2501 train_loss: 0.46976181864738464 time_taken: 0.05604100227355957\n",
      "Epoch 3: iteration 1305/2501 train_loss: 0.4697569012641907 time_taken: 0.056535959243774414\n",
      "Epoch 3: iteration 1306/2501 train_loss: 0.4697619676589966 time_taken: 0.0568537712097168\n",
      "Epoch 3: iteration 1307/2501 train_loss: 0.46976175904273987 time_taken: 0.057184696197509766\n",
      "Epoch 3: iteration 1308/2501 train_loss: 0.4697665572166443 time_taken: 0.05687379837036133\n",
      "Epoch 3: iteration 1309/2501 train_loss: 0.4697800874710083 time_taken: 0.05632162094116211\n",
      "Epoch 3: iteration 1310/2501 train_loss: 0.46980398893356323 time_taken: 0.05690598487854004\n",
      "Epoch 3: iteration 1311/2501 train_loss: 0.4698120355606079 time_taken: 0.07104635238647461\n",
      "Epoch 3: iteration 1312/2501 train_loss: 0.46983101963996887 time_taken: 0.0742805004119873\n",
      "Epoch 3: iteration 1313/2501 train_loss: 0.4698573052883148 time_taken: 0.131181001663208\n",
      "Epoch 3: iteration 1314/2501 train_loss: 0.46988117694854736 time_taken: 0.05678415298461914\n",
      "Epoch 3: iteration 1315/2501 train_loss: 0.4699123203754425 time_taken: 0.05656909942626953\n",
      "Epoch 3: iteration 1316/2501 train_loss: 0.46992847323417664 time_taken: 0.05769181251525879\n",
      "Epoch 3: iteration 1317/2501 train_loss: 0.4699349105358124 time_taken: 0.0570676326751709\n",
      "Epoch 3: iteration 1318/2501 train_loss: 0.46994954347610474 time_taken: 0.056975603103637695\n",
      "Epoch 3: iteration 1319/2501 train_loss: 0.46996012330055237 time_taken: 0.056757450103759766\n",
      "Epoch 3: iteration 1320/2501 train_loss: 0.4699494540691376 time_taken: 0.05728602409362793\n",
      "Epoch 3: iteration 1321/2501 train_loss: 0.46994563937187195 time_taken: 0.056879281997680664\n",
      "Epoch 3: iteration 1322/2501 train_loss: 0.46995091438293457 time_taken: 0.05730867385864258\n",
      "Epoch 3: iteration 1323/2501 train_loss: 0.4699860215187073 time_taken: 0.05673503875732422\n",
      "Epoch 3: iteration 1324/2501 train_loss: 0.4701492488384247 time_taken: 0.05675530433654785\n",
      "Epoch 3: iteration 1325/2501 train_loss: 0.4704204499721527 time_taken: 0.0570826530456543\n",
      "Epoch 3: iteration 1326/2501 train_loss: 0.47049981355667114 time_taken: 0.05654263496398926\n",
      "Epoch 3: iteration 1327/2501 train_loss: 0.4706136882305145 time_taken: 0.056429147720336914\n",
      "Epoch 3: iteration 1328/2501 train_loss: 0.4705866575241089 time_taken: 0.05706787109375\n",
      "Epoch 3: iteration 1329/2501 train_loss: 0.4706682860851288 time_taken: 0.05718827247619629\n",
      "Epoch 3: iteration 1330/2501 train_loss: 0.47065773606300354 time_taken: 0.05701136589050293\n",
      "Epoch 3: iteration 1331/2501 train_loss: 0.47065889835357666 time_taken: 0.05762624740600586\n",
      "Epoch 3: iteration 1332/2501 train_loss: 0.4706922769546509 time_taken: 0.057149648666381836\n",
      "Epoch 3: iteration 1333/2501 train_loss: 0.4707064628601074 time_taken: 0.056406259536743164\n",
      "Epoch 3: iteration 1334/2501 train_loss: 0.4707147777080536 time_taken: 0.056719064712524414\n",
      "Epoch 3: iteration 1335/2501 train_loss: 0.4707321226596832 time_taken: 0.05611538887023926\n",
      "Epoch 3: iteration 1336/2501 train_loss: 0.4707408845424652 time_taken: 0.056992292404174805\n",
      "Epoch 3: iteration 1337/2501 train_loss: 0.4707525372505188 time_taken: 0.05666089057922363\n",
      "Epoch 3: iteration 1338/2501 train_loss: 0.4707600474357605 time_taken: 0.05665922164916992\n",
      "Epoch 3: iteration 1339/2501 train_loss: 0.4707604646682739 time_taken: 0.05666923522949219\n",
      "Epoch 3: iteration 1340/2501 train_loss: 0.4707683026790619 time_taken: 0.05623960494995117\n",
      "Epoch 3: iteration 1341/2501 train_loss: 0.4708023965358734 time_taken: 0.056751251220703125\n",
      "Epoch 3: iteration 1342/2501 train_loss: 0.4708351790904999 time_taken: 0.05663466453552246\n",
      "Epoch 3: iteration 1343/2501 train_loss: 0.47085338830947876 time_taken: 0.0567929744720459\n",
      "Epoch 3: iteration 1344/2501 train_loss: 0.4708805978298187 time_taken: 0.05636405944824219\n",
      "Epoch 3: iteration 1345/2501 train_loss: 0.47090578079223633 time_taken: 0.05646848678588867\n",
      "Epoch 3: iteration 1346/2501 train_loss: 0.47094741463661194 time_taken: 0.056265830993652344\n",
      "Epoch 3: iteration 1347/2501 train_loss: 0.4709862470626831 time_taken: 0.056955575942993164\n",
      "Epoch 3: iteration 1348/2501 train_loss: 0.4710088074207306 time_taken: 0.056650638580322266\n",
      "Epoch 3: iteration 1349/2501 train_loss: 0.4710389971733093 time_taken: 0.05620455741882324\n",
      "Epoch 3: iteration 1350/2501 train_loss: 0.4710691571235657 time_taken: 0.05612802505493164\n",
      "Epoch 3: iteration 1351/2501 train_loss: 0.47109416127204895 time_taken: 0.057033538818359375\n",
      "Epoch 3: iteration 1352/2501 train_loss: 0.4711132347583771 time_taken: 0.058118581771850586\n",
      "Epoch 3: iteration 1353/2501 train_loss: 0.47115686535835266 time_taken: 0.05616188049316406\n",
      "Epoch 3: iteration 1354/2501 train_loss: 0.47120213508605957 time_taken: 0.056756019592285156\n",
      "Epoch 3: iteration 1355/2501 train_loss: 0.47123727202415466 time_taken: 0.056978464126586914\n",
      "Epoch 3: iteration 1356/2501 train_loss: 0.4712803363800049 time_taken: 0.056466102600097656\n",
      "Epoch 3: iteration 1357/2501 train_loss: 0.4713306128978729 time_taken: 0.05660867691040039\n",
      "Epoch 3: iteration 1358/2501 train_loss: 0.4713723659515381 time_taken: 0.056226253509521484\n",
      "Epoch 3: iteration 1359/2501 train_loss: 0.47140777111053467 time_taken: 0.057396888732910156\n",
      "Epoch 3: iteration 1360/2501 train_loss: 0.4714406132698059 time_taken: 0.056352853775024414\n",
      "Epoch 3: iteration 1361/2501 train_loss: 0.4714876115322113 time_taken: 0.056658267974853516\n",
      "Epoch 3: iteration 1362/2501 train_loss: 0.47152891755104065 time_taken: 0.05663156509399414\n",
      "Epoch 3: iteration 1363/2501 train_loss: 0.4715689420700073 time_taken: 0.05649423599243164\n",
      "Epoch 3: iteration 1364/2501 train_loss: 0.47160714864730835 time_taken: 0.057221174240112305\n",
      "Epoch 3: iteration 1365/2501 train_loss: 0.4716433584690094 time_taken: 0.0562746524810791\n",
      "Epoch 3: iteration 1366/2501 train_loss: 0.4716949164867401 time_taken: 0.056751251220703125\n",
      "Epoch 3: iteration 1367/2501 train_loss: 0.47173482179641724 time_taken: 0.057306528091430664\n",
      "Epoch 3: iteration 1368/2501 train_loss: 0.47176510095596313 time_taken: 0.05745506286621094\n",
      "Epoch 3: iteration 1369/2501 train_loss: 0.4718155264854431 time_taken: 0.05662894248962402\n",
      "Epoch 3: iteration 1370/2501 train_loss: 0.4718559682369232 time_taken: 0.056232452392578125\n",
      "Epoch 3: iteration 1371/2501 train_loss: 0.47190308570861816 time_taken: 0.056731462478637695\n",
      "Epoch 3: iteration 1372/2501 train_loss: 0.4719479978084564 time_taken: 0.05625319480895996\n",
      "Epoch 3: iteration 1373/2501 train_loss: 0.4719938039779663 time_taken: 0.05760645866394043\n",
      "Epoch 3: iteration 1374/2501 train_loss: 0.47205162048339844 time_taken: 0.057091712951660156\n",
      "Epoch 3: iteration 1375/2501 train_loss: 0.4721125662326813 time_taken: 0.05638527870178223\n",
      "Epoch 3: iteration 1376/2501 train_loss: 0.472165048122406 time_taken: 0.05669760704040527\n",
      "Epoch 3: iteration 1377/2501 train_loss: 0.4722318947315216 time_taken: 0.05635523796081543\n",
      "Epoch 3: iteration 1378/2501 train_loss: 0.47229889035224915 time_taken: 0.05666041374206543\n",
      "Epoch 3: iteration 1379/2501 train_loss: 0.4723873436450958 time_taken: 0.056337833404541016\n",
      "Epoch 3: iteration 1380/2501 train_loss: 0.4724501669406891 time_taken: 0.05654788017272949\n",
      "Epoch 3: iteration 1381/2501 train_loss: 0.47250860929489136 time_taken: 0.0573582649230957\n",
      "Epoch 3: iteration 1382/2501 train_loss: 0.47256866097450256 time_taken: 0.05694293975830078\n",
      "Epoch 3: iteration 1383/2501 train_loss: 0.47262874245643616 time_taken: 0.05688905715942383\n",
      "Epoch 3: iteration 1384/2501 train_loss: 0.472692608833313 time_taken: 0.0565645694732666\n",
      "Epoch 3: iteration 1385/2501 train_loss: 0.47274523973464966 time_taken: 0.05704331398010254\n",
      "Epoch 3: iteration 1386/2501 train_loss: 0.4727948307991028 time_taken: 0.06160449981689453\n",
      "Epoch 3: iteration 1387/2501 train_loss: 0.47284045815467834 time_taken: 0.056519508361816406\n",
      "Epoch 3: iteration 1388/2501 train_loss: 0.4728863835334778 time_taken: 0.05665993690490723\n",
      "Epoch 3: iteration 1389/2501 train_loss: 0.4729253649711609 time_taken: 0.05645608901977539\n",
      "Epoch 3: iteration 1390/2501 train_loss: 0.4729670286178589 time_taken: 0.056664466857910156\n",
      "Epoch 3: iteration 1391/2501 train_loss: 0.47298523783683777 time_taken: 0.05668163299560547\n",
      "Epoch 3: iteration 1392/2501 train_loss: 0.4730077385902405 time_taken: 0.05656147003173828\n",
      "Epoch 3: iteration 1393/2501 train_loss: 0.47302529215812683 time_taken: 0.057037353515625\n",
      "Epoch 3: iteration 1394/2501 train_loss: 0.4730322062969208 time_taken: 0.05656313896179199\n",
      "Epoch 3: iteration 1395/2501 train_loss: 0.47303372621536255 time_taken: 0.05658268928527832\n",
      "Epoch 3: iteration 1396/2501 train_loss: 0.47302865982055664 time_taken: 0.06377935409545898\n",
      "Epoch 3: iteration 1397/2501 train_loss: 0.4730204939842224 time_taken: 0.05631065368652344\n",
      "Epoch 3: iteration 1398/2501 train_loss: 0.47303739190101624 time_taken: 0.05755424499511719\n",
      "Epoch 3: iteration 1399/2501 train_loss: 0.47305458784103394 time_taken: 0.05709195137023926\n",
      "Epoch 3: iteration 1400/2501 train_loss: 0.4730583131313324 time_taken: 0.056456804275512695\n",
      "Epoch 3: iteration 1401/2501 train_loss: 0.4730589985847473 time_taken: 0.05646014213562012\n",
      "Epoch 3: iteration 1402/2501 train_loss: 0.4730678200721741 time_taken: 0.05626845359802246\n",
      "Epoch 3: iteration 1403/2501 train_loss: 0.47307342290878296 time_taken: 0.05633044242858887\n",
      "Epoch 3: iteration 1404/2501 train_loss: 0.47308656573295593 time_taken: 0.05642199516296387\n",
      "Epoch 3: iteration 1405/2501 train_loss: 0.47310447692871094 time_taken: 0.05644106864929199\n",
      "Epoch 3: iteration 1406/2501 train_loss: 0.47311165928840637 time_taken: 0.056531667709350586\n",
      "Epoch 3: iteration 1407/2501 train_loss: 0.4731196165084839 time_taken: 0.05636024475097656\n",
      "Epoch 3: iteration 1408/2501 train_loss: 0.47312015295028687 time_taken: 0.05738067626953125\n",
      "Epoch 3: iteration 1409/2501 train_loss: 0.47312530875205994 time_taken: 0.05643582344055176\n",
      "Epoch 3: iteration 1410/2501 train_loss: 0.4731183648109436 time_taken: 0.06555652618408203\n",
      "Epoch 3: iteration 1411/2501 train_loss: 0.47311457991600037 time_taken: 0.05652928352355957\n",
      "Epoch 3: iteration 1412/2501 train_loss: 0.47311243414878845 time_taken: 0.05631828308105469\n",
      "Epoch 3: iteration 1413/2501 train_loss: 0.4730961322784424 time_taken: 0.05642509460449219\n",
      "Epoch 3: iteration 1414/2501 train_loss: 0.47306346893310547 time_taken: 0.05671334266662598\n",
      "Epoch 3: iteration 1415/2501 train_loss: 0.47305378317832947 time_taken: 0.05647087097167969\n",
      "Epoch 3: iteration 1416/2501 train_loss: 0.47305652499198914 time_taken: 0.05638623237609863\n",
      "Epoch 3: iteration 1417/2501 train_loss: 0.4730525612831116 time_taken: 0.05684161186218262\n",
      "Epoch 3: iteration 1418/2501 train_loss: 0.473043292760849 time_taken: 0.05619668960571289\n",
      "Epoch 3: iteration 1419/2501 train_loss: 0.47303810715675354 time_taken: 0.056375741958618164\n",
      "Epoch 3: iteration 1420/2501 train_loss: 0.4730431139469147 time_taken: 0.0569615364074707\n",
      "Epoch 3: iteration 1421/2501 train_loss: 0.47306016087532043 time_taken: 0.056882381439208984\n",
      "Epoch 3: iteration 1422/2501 train_loss: 0.4730745851993561 time_taken: 0.05688786506652832\n",
      "Epoch 3: iteration 1423/2501 train_loss: 0.47308632731437683 time_taken: 0.05667710304260254\n",
      "Epoch 3: iteration 1424/2501 train_loss: 0.4731096625328064 time_taken: 0.057068824768066406\n",
      "Epoch 3: iteration 1425/2501 train_loss: 0.47313225269317627 time_taken: 0.05634260177612305\n",
      "Epoch 3: iteration 1426/2501 train_loss: 0.47314661741256714 time_taken: 0.0564424991607666\n",
      "Epoch 3: iteration 1427/2501 train_loss: 0.47315514087677 time_taken: 0.05689263343811035\n",
      "Epoch 3: iteration 1428/2501 train_loss: 0.47315990924835205 time_taken: 0.05885457992553711\n",
      "Epoch 3: iteration 1429/2501 train_loss: 0.47316455841064453 time_taken: 0.061365604400634766\n",
      "Epoch 3: iteration 1430/2501 train_loss: 0.47316810488700867 time_taken: 0.05620408058166504\n",
      "Epoch 3: iteration 1431/2501 train_loss: 0.4731723666191101 time_taken: 0.056603193283081055\n",
      "Epoch 3: iteration 1432/2501 train_loss: 0.47316011786460876 time_taken: 0.0564119815826416\n",
      "Epoch 3: iteration 1433/2501 train_loss: 0.47315165400505066 time_taken: 0.05623149871826172\n",
      "Epoch 3: iteration 1434/2501 train_loss: 0.4731570780277252 time_taken: 0.056282997131347656\n",
      "Epoch 3: iteration 1435/2501 train_loss: 0.47317564487457275 time_taken: 0.056825876235961914\n",
      "Epoch 3: iteration 1436/2501 train_loss: 0.4731951057910919 time_taken: 0.05734872817993164\n",
      "Epoch 3: iteration 1437/2501 train_loss: 0.4732217490673065 time_taken: 0.07742047309875488\n",
      "Epoch 3: iteration 1438/2501 train_loss: 0.47325295209884644 time_taken: 0.05671095848083496\n",
      "Epoch 3: iteration 1439/2501 train_loss: 0.47327062487602234 time_taken: 0.059739112854003906\n",
      "Epoch 3: iteration 1440/2501 train_loss: 0.4733061194419861 time_taken: 0.05768275260925293\n",
      "Epoch 3: iteration 1441/2501 train_loss: 0.47333958745002747 time_taken: 0.05656003952026367\n",
      "Epoch 3: iteration 1442/2501 train_loss: 0.4733610153198242 time_taken: 0.05643439292907715\n",
      "Epoch 3: iteration 1443/2501 train_loss: 0.4733917713165283 time_taken: 0.05636119842529297\n",
      "Epoch 3: iteration 1444/2501 train_loss: 0.47342821955680847 time_taken: 0.05643343925476074\n",
      "Epoch 3: iteration 1445/2501 train_loss: 0.4734576940536499 time_taken: 0.056571006774902344\n",
      "Epoch 3: iteration 1446/2501 train_loss: 0.4734818935394287 time_taken: 0.05656170845031738\n",
      "Epoch 3: iteration 1447/2501 train_loss: 0.4735110402107239 time_taken: 0.056919097900390625\n",
      "Epoch 3: iteration 1448/2501 train_loss: 0.4735310971736908 time_taken: 0.05658149719238281\n",
      "Epoch 3: iteration 1449/2501 train_loss: 0.47356241941452026 time_taken: 0.05750679969787598\n",
      "Epoch 3: iteration 1450/2501 train_loss: 0.4735841751098633 time_taken: 0.056662797927856445\n",
      "Epoch 3: iteration 1451/2501 train_loss: 0.47359976172447205 time_taken: 0.05644512176513672\n",
      "Epoch 3: iteration 1452/2501 train_loss: 0.47362837195396423 time_taken: 0.05701899528503418\n",
      "Epoch 3: iteration 1453/2501 train_loss: 0.4736669063568115 time_taken: 0.05691361427307129\n",
      "Epoch 3: iteration 1454/2501 train_loss: 0.47371381521224976 time_taken: 0.0569002628326416\n",
      "Epoch 3: iteration 1455/2501 train_loss: 0.47375911474227905 time_taken: 0.05652213096618652\n",
      "Epoch 3: iteration 1456/2501 train_loss: 0.47380518913269043 time_taken: 0.057608604431152344\n",
      "Epoch 3: iteration 1457/2501 train_loss: 0.4738529324531555 time_taken: 0.05674266815185547\n",
      "Epoch 3: iteration 1458/2501 train_loss: 0.4739098846912384 time_taken: 0.056787967681884766\n",
      "Epoch 3: iteration 1459/2501 train_loss: 0.4739677906036377 time_taken: 0.05685591697692871\n",
      "Epoch 3: iteration 1460/2501 train_loss: 0.47402334213256836 time_taken: 0.057639360427856445\n",
      "Epoch 3: iteration 1461/2501 train_loss: 0.47407612204551697 time_taken: 0.057480812072753906\n",
      "Epoch 3: iteration 1462/2501 train_loss: 0.4741159677505493 time_taken: 0.05732154846191406\n",
      "Epoch 3: iteration 1463/2501 train_loss: 0.4741723835468292 time_taken: 0.05728650093078613\n",
      "Epoch 3: iteration 1464/2501 train_loss: 0.47421324253082275 time_taken: 0.0570368766784668\n",
      "Epoch 3: iteration 1465/2501 train_loss: 0.47424986958503723 time_taken: 0.05719184875488281\n",
      "Epoch 3: iteration 1466/2501 train_loss: 0.4742974042892456 time_taken: 0.057114362716674805\n",
      "Epoch 3: iteration 1467/2501 train_loss: 0.4743378758430481 time_taken: 0.05630946159362793\n",
      "Epoch 3: iteration 1468/2501 train_loss: 0.4743914008140564 time_taken: 0.057431697845458984\n",
      "Epoch 3: iteration 1469/2501 train_loss: 0.47442659735679626 time_taken: 0.05655503273010254\n",
      "Epoch 3: iteration 1470/2501 train_loss: 0.4744606614112854 time_taken: 0.05624723434448242\n",
      "Epoch 3: iteration 1471/2501 train_loss: 0.47450879216194153 time_taken: 0.05735969543457031\n",
      "Epoch 3: iteration 1472/2501 train_loss: 0.47456496953964233 time_taken: 0.057953834533691406\n",
      "Epoch 3: iteration 1473/2501 train_loss: 0.4746135175228119 time_taken: 0.05757260322570801\n",
      "Epoch 3: iteration 1474/2501 train_loss: 0.47466209530830383 time_taken: 0.056722164154052734\n",
      "Epoch 3: iteration 1475/2501 train_loss: 0.47472912073135376 time_taken: 0.05662178993225098\n",
      "Epoch 3: iteration 1476/2501 train_loss: 0.4747922420501709 time_taken: 0.05625796318054199\n",
      "Epoch 3: iteration 1477/2501 train_loss: 0.4748530089855194 time_taken: 0.056767940521240234\n",
      "Epoch 3: iteration 1478/2501 train_loss: 0.47491157054901123 time_taken: 0.05665230751037598\n",
      "Epoch 3: iteration 1479/2501 train_loss: 0.4749918282032013 time_taken: 0.05668139457702637\n",
      "Epoch 3: iteration 1480/2501 train_loss: 0.4750722348690033 time_taken: 0.057167768478393555\n",
      "Epoch 3: iteration 1481/2501 train_loss: 0.47513294219970703 time_taken: 0.05619001388549805\n",
      "Epoch 3: iteration 1482/2501 train_loss: 0.47517305612564087 time_taken: 0.056420326232910156\n",
      "Epoch 3: iteration 1483/2501 train_loss: 0.4752170145511627 time_taken: 0.056232452392578125\n",
      "Epoch 3: iteration 1484/2501 train_loss: 0.4752395749092102 time_taken: 0.056282758712768555\n",
      "Epoch 3: iteration 1485/2501 train_loss: 0.4752640426158905 time_taken: 0.05601024627685547\n",
      "Epoch 3: iteration 1486/2501 train_loss: 0.4752805233001709 time_taken: 0.05610823631286621\n",
      "Epoch 3: iteration 1487/2501 train_loss: 0.47529518604278564 time_taken: 0.05661201477050781\n",
      "Epoch 3: iteration 1488/2501 train_loss: 0.4752880036830902 time_taken: 0.05632209777832031\n",
      "Epoch 3: iteration 1489/2501 train_loss: 0.47528621554374695 time_taken: 0.05623173713684082\n",
      "Epoch 3: iteration 1490/2501 train_loss: 0.4752703309059143 time_taken: 0.05636930465698242\n",
      "Epoch 3: iteration 1491/2501 train_loss: 0.4752632975578308 time_taken: 0.05613207817077637\n",
      "Epoch 3: iteration 1492/2501 train_loss: 0.4752455949783325 time_taken: 0.05622386932373047\n",
      "Epoch 3: iteration 1493/2501 train_loss: 0.47523438930511475 time_taken: 0.05633735656738281\n",
      "Epoch 3: iteration 1494/2501 train_loss: 0.47521108388900757 time_taken: 0.05645632743835449\n",
      "Epoch 3: iteration 1495/2501 train_loss: 0.4751936197280884 time_taken: 0.0564882755279541\n",
      "Epoch 3: iteration 1496/2501 train_loss: 0.47518712282180786 time_taken: 0.05639982223510742\n",
      "Epoch 3: iteration 1497/2501 train_loss: 0.4751954972743988 time_taken: 0.056249380111694336\n",
      "Epoch 3: iteration 1498/2501 train_loss: 0.47521018981933594 time_taken: 0.056125640869140625\n",
      "Epoch 3: iteration 1499/2501 train_loss: 0.47521668672561646 time_taken: 0.05651450157165527\n",
      "Epoch 3: iteration 1500/2501 train_loss: 0.4752211570739746 time_taken: 0.05633211135864258\n",
      "Epoch 3: iteration 1501/2501 train_loss: 0.4752180278301239 time_taken: 0.05640435218811035\n",
      "Epoch 3: iteration 1502/2501 train_loss: 0.47521570324897766 time_taken: 0.05678367614746094\n",
      "Epoch 3: iteration 1503/2501 train_loss: 0.4752148985862732 time_taken: 0.0561525821685791\n",
      "Epoch 3: iteration 1504/2501 train_loss: 0.47522199153900146 time_taken: 0.05652046203613281\n",
      "Epoch 3: iteration 1505/2501 train_loss: 0.47522297501564026 time_taken: 0.056052207946777344\n",
      "Epoch 3: iteration 1506/2501 train_loss: 0.47524014115333557 time_taken: 0.056746482849121094\n",
      "Epoch 3: iteration 1507/2501 train_loss: 0.47525671124458313 time_taken: 0.05653715133666992\n",
      "Epoch 3: iteration 1508/2501 train_loss: 0.4752691090106964 time_taken: 0.05628061294555664\n",
      "Epoch 3: iteration 1509/2501 train_loss: 0.4752761423587799 time_taken: 0.056475162506103516\n",
      "Epoch 3: iteration 1510/2501 train_loss: 0.4752841889858246 time_taken: 0.056391239166259766\n",
      "Epoch 3: iteration 1511/2501 train_loss: 0.47529396414756775 time_taken: 0.056598663330078125\n",
      "Epoch 3: iteration 1512/2501 train_loss: 0.4753185212612152 time_taken: 0.056143999099731445\n",
      "Epoch 3: iteration 1513/2501 train_loss: 0.4753323495388031 time_taken: 0.05689549446105957\n",
      "Epoch 3: iteration 1514/2501 train_loss: 0.475363552570343 time_taken: 0.05618691444396973\n",
      "Epoch 3: iteration 1515/2501 train_loss: 0.47538959980010986 time_taken: 0.05629587173461914\n",
      "Epoch 3: iteration 1516/2501 train_loss: 0.4754088222980499 time_taken: 0.056264400482177734\n",
      "Epoch 3: iteration 1517/2501 train_loss: 0.47544142603874207 time_taken: 0.05626487731933594\n",
      "Epoch 3: iteration 1518/2501 train_loss: 0.47547647356987 time_taken: 0.05624699592590332\n",
      "Epoch 3: iteration 1519/2501 train_loss: 0.4755037724971771 time_taken: 0.05710411071777344\n",
      "Epoch 3: iteration 1520/2501 train_loss: 0.4755481481552124 time_taken: 0.05630826950073242\n",
      "Epoch 3: iteration 1521/2501 train_loss: 0.4755823016166687 time_taken: 0.0566866397857666\n",
      "Epoch 3: iteration 1522/2501 train_loss: 0.475614458322525 time_taken: 0.05641674995422363\n",
      "Epoch 3: iteration 1523/2501 train_loss: 0.4756346046924591 time_taken: 0.05767989158630371\n",
      "Epoch 3: iteration 1524/2501 train_loss: 0.4756685793399811 time_taken: 0.057952165603637695\n",
      "Epoch 3: iteration 1525/2501 train_loss: 0.4756809175014496 time_taken: 0.056643009185791016\n",
      "Epoch 3: iteration 1526/2501 train_loss: 0.4756922125816345 time_taken: 0.05661725997924805\n",
      "Epoch 3: iteration 1527/2501 train_loss: 0.47569623589515686 time_taken: 0.0567164421081543\n",
      "Epoch 3: iteration 1528/2501 train_loss: 0.4757033884525299 time_taken: 0.05681157112121582\n",
      "Epoch 3: iteration 1529/2501 train_loss: 0.47569090127944946 time_taken: 0.05691361427307129\n",
      "Epoch 3: iteration 1530/2501 train_loss: 0.47568365931510925 time_taken: 0.05743408203125\n",
      "Epoch 3: iteration 1531/2501 train_loss: 0.4756653904914856 time_taken: 0.056668758392333984\n",
      "Epoch 3: iteration 1532/2501 train_loss: 0.4756527543067932 time_taken: 0.056499481201171875\n",
      "Epoch 3: iteration 1533/2501 train_loss: 0.4756444990634918 time_taken: 0.05687880516052246\n",
      "Epoch 3: iteration 1534/2501 train_loss: 0.4756479561328888 time_taken: 0.0567934513092041\n",
      "Epoch 3: iteration 1535/2501 train_loss: 0.47564712166786194 time_taken: 0.08140230178833008\n",
      "Epoch 3: iteration 1536/2501 train_loss: 0.4756462574005127 time_taken: 0.07153773307800293\n",
      "Epoch 3: iteration 1537/2501 train_loss: 0.47564855217933655 time_taken: 0.0712885856628418\n",
      "Epoch 3: iteration 1538/2501 train_loss: 0.4756520092487335 time_taken: 0.05629992485046387\n",
      "Epoch 3: iteration 1539/2501 train_loss: 0.4756631851196289 time_taken: 0.056665658950805664\n",
      "Epoch 3: iteration 1540/2501 train_loss: 0.4756634831428528 time_taken: 0.056296586990356445\n",
      "Epoch 3: iteration 1541/2501 train_loss: 0.47566142678260803 time_taken: 0.056395530700683594\n",
      "Epoch 3: iteration 1542/2501 train_loss: 0.47566694021224976 time_taken: 0.05641055107116699\n",
      "Epoch 3: iteration 1543/2501 train_loss: 0.47566789388656616 time_taken: 0.0568544864654541\n",
      "Epoch 3: iteration 1544/2501 train_loss: 0.47567182779312134 time_taken: 0.05694580078125\n",
      "Epoch 3: iteration 1545/2501 train_loss: 0.47566932439804077 time_taken: 0.057000160217285156\n",
      "Epoch 3: iteration 1546/2501 train_loss: 0.4756704568862915 time_taken: 0.05672907829284668\n",
      "Epoch 3: iteration 1547/2501 train_loss: 0.47567039728164673 time_taken: 0.056595563888549805\n",
      "Epoch 3: iteration 1548/2501 train_loss: 0.4756805896759033 time_taken: 0.05669689178466797\n",
      "Epoch 3: iteration 1549/2501 train_loss: 0.47568777203559875 time_taken: 0.057065486907958984\n",
      "Epoch 3: iteration 1550/2501 train_loss: 0.47569552063941956 time_taken: 0.05729484558105469\n",
      "Epoch 3: iteration 1551/2501 train_loss: 0.4757010042667389 time_taken: 0.05678248405456543\n",
      "Epoch 3: iteration 1552/2501 train_loss: 0.4757007360458374 time_taken: 0.05790352821350098\n",
      "Epoch 3: iteration 1553/2501 train_loss: 0.4757104814052582 time_taken: 0.05632448196411133\n",
      "Epoch 3: iteration 1554/2501 train_loss: 0.47571271657943726 time_taken: 0.05808830261230469\n",
      "Epoch 3: iteration 1555/2501 train_loss: 0.4757263660430908 time_taken: 0.057088375091552734\n",
      "Epoch 3: iteration 1556/2501 train_loss: 0.47573015093803406 time_taken: 0.056733131408691406\n",
      "Epoch 3: iteration 1557/2501 train_loss: 0.4757521152496338 time_taken: 0.0567164421081543\n",
      "Epoch 3: iteration 1558/2501 train_loss: 0.47575679421424866 time_taken: 0.05858659744262695\n",
      "Epoch 3: iteration 1559/2501 train_loss: 0.47574442625045776 time_taken: 0.05671882629394531\n",
      "Epoch 3: iteration 1560/2501 train_loss: 0.47573310136795044 time_taken: 0.05643105506896973\n",
      "Epoch 3: iteration 1561/2501 train_loss: 0.4757290780544281 time_taken: 0.05648064613342285\n",
      "Epoch 3: iteration 1562/2501 train_loss: 0.4757150411605835 time_taken: 0.05646109580993652\n",
      "Epoch 3: iteration 1563/2501 train_loss: 0.4756914973258972 time_taken: 0.05686593055725098\n",
      "Epoch 3: iteration 1564/2501 train_loss: 0.47566312551498413 time_taken: 0.05656290054321289\n",
      "Epoch 3: iteration 1565/2501 train_loss: 0.475631445646286 time_taken: 0.05699586868286133\n",
      "Epoch 3: iteration 1566/2501 train_loss: 0.47559845447540283 time_taken: 0.05694580078125\n",
      "Epoch 3: iteration 1567/2501 train_loss: 0.47556060552597046 time_taken: 0.05604720115661621\n",
      "Epoch 3: iteration 1568/2501 train_loss: 0.47553136944770813 time_taken: 0.055933237075805664\n",
      "Epoch 3: iteration 1569/2501 train_loss: 0.4755094349384308 time_taken: 0.056223154067993164\n",
      "Epoch 3: iteration 1570/2501 train_loss: 0.4754866063594818 time_taken: 0.05684995651245117\n",
      "Epoch 3: iteration 1571/2501 train_loss: 0.4754662811756134 time_taken: 0.05596804618835449\n",
      "Epoch 3: iteration 1572/2501 train_loss: 0.47545498609542847 time_taken: 0.05617403984069824\n",
      "Epoch 3: iteration 1573/2501 train_loss: 0.47545313835144043 time_taken: 0.05730557441711426\n",
      "Epoch 3: iteration 1574/2501 train_loss: 0.4754389524459839 time_taken: 0.05666232109069824\n",
      "Epoch 3: iteration 1575/2501 train_loss: 0.475436806678772 time_taken: 0.056496381759643555\n",
      "Epoch 3: iteration 1576/2501 train_loss: 0.4754320979118347 time_taken: 0.057959556579589844\n",
      "Epoch 3: iteration 1577/2501 train_loss: 0.4754255712032318 time_taken: 0.056578874588012695\n",
      "Epoch 3: iteration 1578/2501 train_loss: 0.47542282938957214 time_taken: 0.05627942085266113\n",
      "Epoch 3: iteration 1579/2501 train_loss: 0.47543075680732727 time_taken: 0.05682802200317383\n",
      "Epoch 3: iteration 1580/2501 train_loss: 0.47542065382003784 time_taken: 0.05737471580505371\n",
      "Epoch 3: iteration 1581/2501 train_loss: 0.47541186213493347 time_taken: 0.056673526763916016\n",
      "Epoch 3: iteration 1582/2501 train_loss: 0.4754125475883484 time_taken: 0.05659055709838867\n",
      "Epoch 3: iteration 1583/2501 train_loss: 0.47540992498397827 time_taken: 0.05665302276611328\n",
      "Epoch 3: iteration 1584/2501 train_loss: 0.4754060208797455 time_taken: 0.05700850486755371\n",
      "Epoch 3: iteration 1585/2501 train_loss: 0.4754103422164917 time_taken: 0.05686688423156738\n",
      "Epoch 3: iteration 1586/2501 train_loss: 0.47541290521621704 time_taken: 0.056288957595825195\n",
      "Epoch 3: iteration 1587/2501 train_loss: 0.4754203259944916 time_taken: 0.05637645721435547\n",
      "Epoch 3: iteration 1588/2501 train_loss: 0.47543779015541077 time_taken: 0.056448936462402344\n",
      "Epoch 3: iteration 1589/2501 train_loss: 0.4754517078399658 time_taken: 0.06764698028564453\n",
      "Epoch 3: iteration 1590/2501 train_loss: 0.4754735827445984 time_taken: 0.05667233467102051\n",
      "Epoch 3: iteration 1591/2501 train_loss: 0.4754873812198639 time_taken: 0.056717634201049805\n",
      "Epoch 3: iteration 1592/2501 train_loss: 0.4755105674266815 time_taken: 0.05684828758239746\n",
      "Epoch 3: iteration 1593/2501 train_loss: 0.47552651166915894 time_taken: 0.05664992332458496\n",
      "Epoch 3: iteration 1594/2501 train_loss: 0.47554078698158264 time_taken: 0.05723214149475098\n",
      "Epoch 3: iteration 1595/2501 train_loss: 0.4755738079547882 time_taken: 0.057584524154663086\n",
      "Epoch 3: iteration 1596/2501 train_loss: 0.4756024479866028 time_taken: 0.05653262138366699\n",
      "Epoch 3: iteration 1597/2501 train_loss: 0.47562989592552185 time_taken: 0.0569000244140625\n",
      "Epoch 3: iteration 1598/2501 train_loss: 0.4756622016429901 time_taken: 0.08013629913330078\n",
      "Epoch 3: iteration 1599/2501 train_loss: 0.47568827867507935 time_taken: 0.06488776206970215\n",
      "Epoch 3: iteration 1600/2501 train_loss: 0.4757128953933716 time_taken: 0.056334495544433594\n",
      "Epoch 3: iteration 1601/2501 train_loss: 0.47573646903038025 time_taken: 0.05638742446899414\n",
      "Epoch 3: iteration 1602/2501 train_loss: 0.4757576584815979 time_taken: 0.056850433349609375\n",
      "Epoch 3: iteration 1603/2501 train_loss: 0.4757801294326782 time_taken: 0.056528568267822266\n",
      "Epoch 3: iteration 1604/2501 train_loss: 0.47579893469810486 time_taken: 0.05694890022277832\n",
      "Epoch 3: iteration 1605/2501 train_loss: 0.47581353783607483 time_taken: 0.05630755424499512\n",
      "Epoch 3: iteration 1606/2501 train_loss: 0.4758443534374237 time_taken: 0.05672931671142578\n",
      "Epoch 3: iteration 1607/2501 train_loss: 0.4758543074131012 time_taken: 0.05648922920227051\n",
      "Epoch 3: iteration 1608/2501 train_loss: 0.47587281465530396 time_taken: 0.05625438690185547\n",
      "Epoch 3: iteration 1609/2501 train_loss: 0.4758918583393097 time_taken: 0.05646014213562012\n",
      "Epoch 3: iteration 1610/2501 train_loss: 0.4759068787097931 time_taken: 0.05652499198913574\n",
      "Epoch 3: iteration 1611/2501 train_loss: 0.47591692209243774 time_taken: 0.056398630142211914\n",
      "Epoch 3: iteration 1612/2501 train_loss: 0.4759417176246643 time_taken: 0.05757427215576172\n",
      "Epoch 3: iteration 1613/2501 train_loss: 0.4759718179702759 time_taken: 0.05680418014526367\n",
      "Epoch 3: iteration 1614/2501 train_loss: 0.47600439190864563 time_taken: 0.057591915130615234\n",
      "Epoch 3: iteration 1615/2501 train_loss: 0.4760279059410095 time_taken: 0.05758070945739746\n",
      "Epoch 3: iteration 1616/2501 train_loss: 0.4760429263114929 time_taken: 0.05663585662841797\n",
      "Epoch 3: iteration 1617/2501 train_loss: 0.47606518864631653 time_taken: 0.05676722526550293\n",
      "Epoch 3: iteration 1618/2501 train_loss: 0.4760834276676178 time_taken: 0.05689191818237305\n",
      "Epoch 3: iteration 1619/2501 train_loss: 0.47610044479370117 time_taken: 0.05665993690490723\n",
      "Epoch 3: iteration 1620/2501 train_loss: 0.4761190712451935 time_taken: 0.056674957275390625\n",
      "Epoch 3: iteration 1621/2501 train_loss: 0.4761352837085724 time_taken: 0.05637025833129883\n",
      "Epoch 3: iteration 1622/2501 train_loss: 0.4761617183685303 time_taken: 0.057903289794921875\n",
      "Epoch 3: iteration 1623/2501 train_loss: 0.47616854310035706 time_taken: 0.05700373649597168\n",
      "Epoch 3: iteration 1624/2501 train_loss: 0.47617146372795105 time_taken: 0.05630922317504883\n",
      "Epoch 3: iteration 1625/2501 train_loss: 0.4761699438095093 time_taken: 0.05641531944274902\n",
      "Epoch 3: iteration 1626/2501 train_loss: 0.4761597514152527 time_taken: 0.05717611312866211\n",
      "Epoch 3: iteration 1627/2501 train_loss: 0.47615060210227966 time_taken: 0.05728912353515625\n",
      "Epoch 3: iteration 1628/2501 train_loss: 0.4761336147785187 time_taken: 0.05702519416809082\n",
      "Epoch 3: iteration 1629/2501 train_loss: 0.47612065076828003 time_taken: 0.05660700798034668\n",
      "Epoch 3: iteration 1630/2501 train_loss: 0.4761102497577667 time_taken: 0.05703020095825195\n",
      "Epoch 3: iteration 1631/2501 train_loss: 0.47608834505081177 time_taken: 0.05676627159118652\n",
      "Epoch 3: iteration 1632/2501 train_loss: 0.47606486082077026 time_taken: 0.0566256046295166\n",
      "Epoch 3: iteration 1633/2501 train_loss: 0.47605156898498535 time_taken: 0.057416677474975586\n",
      "Epoch 3: iteration 1634/2501 train_loss: 0.4760548770427704 time_taken: 0.05686354637145996\n",
      "Epoch 3: iteration 1635/2501 train_loss: 0.47606533765792847 time_taken: 0.05667877197265625\n",
      "Epoch 3: iteration 1636/2501 train_loss: 0.4760788381099701 time_taken: 0.05694746971130371\n",
      "Epoch 3: iteration 1637/2501 train_loss: 0.4760983884334564 time_taken: 0.05681800842285156\n",
      "Epoch 3: iteration 1638/2501 train_loss: 0.4761248528957367 time_taken: 0.057303428649902344\n",
      "Epoch 3: iteration 1639/2501 train_loss: 0.47615325450897217 time_taken: 0.056978464126586914\n",
      "Epoch 3: iteration 1640/2501 train_loss: 0.47617438435554504 time_taken: 0.056645870208740234\n",
      "Epoch 3: iteration 1641/2501 train_loss: 0.47620832920074463 time_taken: 0.05641674995422363\n",
      "Epoch 3: iteration 1642/2501 train_loss: 0.4762212634086609 time_taken: 0.05736088752746582\n",
      "Epoch 3: iteration 1643/2501 train_loss: 0.4762439727783203 time_taken: 0.057030677795410156\n",
      "Epoch 3: iteration 1644/2501 train_loss: 0.4762570261955261 time_taken: 0.05685234069824219\n",
      "Epoch 3: iteration 1645/2501 train_loss: 0.476264625787735 time_taken: 0.05643033981323242\n",
      "Epoch 3: iteration 1646/2501 train_loss: 0.47626733779907227 time_taken: 0.056807518005371094\n",
      "Epoch 3: iteration 1647/2501 train_loss: 0.4762685000896454 time_taken: 0.05652618408203125\n",
      "Epoch 3: iteration 1648/2501 train_loss: 0.47626009583473206 time_taken: 0.05655312538146973\n",
      "Epoch 3: iteration 1649/2501 train_loss: 0.47625255584716797 time_taken: 0.05839180946350098\n",
      "Epoch 3: iteration 1650/2501 train_loss: 0.47623640298843384 time_taken: 0.05717325210571289\n",
      "Epoch 3: iteration 1651/2501 train_loss: 0.4762316942214966 time_taken: 0.05658245086669922\n",
      "Epoch 3: iteration 1652/2501 train_loss: 0.4762117862701416 time_taken: 0.05661177635192871\n",
      "Epoch 3: iteration 1653/2501 train_loss: 0.4761902093887329 time_taken: 0.0570225715637207\n",
      "Epoch 3: iteration 1654/2501 train_loss: 0.4761611521244049 time_taken: 0.05718278884887695\n",
      "Epoch 3: iteration 1655/2501 train_loss: 0.4761373996734619 time_taken: 0.057203054428100586\n",
      "Epoch 3: iteration 1656/2501 train_loss: 0.4761168658733368 time_taken: 0.05685925483703613\n",
      "Epoch 3: iteration 1657/2501 train_loss: 0.47610461711883545 time_taken: 0.05693984031677246\n",
      "Epoch 3: iteration 1658/2501 train_loss: 0.4760938286781311 time_taken: 0.0573124885559082\n",
      "Epoch 3: iteration 1659/2501 train_loss: 0.47609010338783264 time_taken: 0.05670571327209473\n",
      "Epoch 3: iteration 1660/2501 train_loss: 0.47609075903892517 time_taken: 0.05689668655395508\n",
      "Epoch 3: iteration 1661/2501 train_loss: 0.4760969281196594 time_taken: 0.0562129020690918\n",
      "Epoch 3: iteration 1662/2501 train_loss: 0.4761040508747101 time_taken: 0.18034720420837402\n",
      "Epoch 3: iteration 1663/2501 train_loss: 0.4761112928390503 time_taken: 0.05660867691040039\n",
      "Epoch 3: iteration 1664/2501 train_loss: 0.4761142432689667 time_taken: 0.056423187255859375\n",
      "Epoch 3: iteration 1665/2501 train_loss: 0.4761234223842621 time_taken: 0.05670499801635742\n",
      "Epoch 3: iteration 1666/2501 train_loss: 0.4761340916156769 time_taken: 0.05668449401855469\n",
      "Epoch 3: iteration 1667/2501 train_loss: 0.4761425256729126 time_taken: 0.05661320686340332\n",
      "Epoch 3: iteration 1668/2501 train_loss: 0.4761520028114319 time_taken: 0.057138919830322266\n",
      "Epoch 3: iteration 1669/2501 train_loss: 0.47618019580841064 time_taken: 0.05650973320007324\n",
      "Epoch 3: iteration 1670/2501 train_loss: 0.4762127995491028 time_taken: 0.05718541145324707\n",
      "Epoch 3: iteration 1671/2501 train_loss: 0.4762551486492157 time_taken: 0.05680251121520996\n",
      "Epoch 3: iteration 1672/2501 train_loss: 0.4762999415397644 time_taken: 0.060086727142333984\n",
      "Epoch 3: iteration 1673/2501 train_loss: 0.47633984684944153 time_taken: 0.05695748329162598\n",
      "Epoch 3: iteration 1674/2501 train_loss: 0.4763748347759247 time_taken: 0.056926727294921875\n",
      "Epoch 3: iteration 1675/2501 train_loss: 0.4764031767845154 time_taken: 0.05640149116516113\n",
      "Epoch 3: iteration 1676/2501 train_loss: 0.47644591331481934 time_taken: 0.05677604675292969\n",
      "Epoch 3: iteration 1677/2501 train_loss: 0.47648051381111145 time_taken: 0.05717062950134277\n",
      "Epoch 3: iteration 1678/2501 train_loss: 0.47650954127311707 time_taken: 0.05739331245422363\n",
      "Epoch 3: iteration 1679/2501 train_loss: 0.476535826921463 time_taken: 0.05669665336608887\n",
      "Epoch 3: iteration 1680/2501 train_loss: 0.4765717089176178 time_taken: 0.056917667388916016\n",
      "Epoch 3: iteration 1681/2501 train_loss: 0.4765913188457489 time_taken: 0.056459665298461914\n",
      "Epoch 3: iteration 1682/2501 train_loss: 0.47661757469177246 time_taken: 0.05730581283569336\n",
      "Epoch 3: iteration 1683/2501 train_loss: 0.4766470789909363 time_taken: 0.05645179748535156\n",
      "Epoch 3: iteration 1684/2501 train_loss: 0.47667643427848816 time_taken: 0.05751156806945801\n",
      "Epoch 3: iteration 1685/2501 train_loss: 0.476695716381073 time_taken: 0.05686688423156738\n",
      "Epoch 3: iteration 1686/2501 train_loss: 0.4767257571220398 time_taken: 0.05689573287963867\n",
      "Epoch 3: iteration 1687/2501 train_loss: 0.4767538607120514 time_taken: 0.056532859802246094\n",
      "Epoch 3: iteration 1688/2501 train_loss: 0.4767798185348511 time_taken: 0.05674934387207031\n",
      "Epoch 3: iteration 1689/2501 train_loss: 0.4768068194389343 time_taken: 0.0571131706237793\n",
      "Epoch 3: iteration 1690/2501 train_loss: 0.4768413305282593 time_taken: 0.05631542205810547\n",
      "Epoch 3: iteration 1691/2501 train_loss: 0.4768577516078949 time_taken: 0.05654311180114746\n",
      "Epoch 3: iteration 1692/2501 train_loss: 0.47689157724380493 time_taken: 0.05718255043029785\n",
      "Epoch 3: iteration 1693/2501 train_loss: 0.4769112467765808 time_taken: 0.056949615478515625\n",
      "Epoch 3: iteration 1694/2501 train_loss: 0.4769439101219177 time_taken: 0.0569605827331543\n",
      "Epoch 3: iteration 1695/2501 train_loss: 0.4769682288169861 time_taken: 0.056828975677490234\n",
      "Epoch 3: iteration 1696/2501 train_loss: 0.4769975543022156 time_taken: 0.056299448013305664\n",
      "Epoch 3: iteration 1697/2501 train_loss: 0.477033793926239 time_taken: 0.05646944046020508\n",
      "Epoch 3: iteration 1698/2501 train_loss: 0.4770691394805908 time_taken: 0.05656242370605469\n",
      "Epoch 3: iteration 1699/2501 train_loss: 0.4771096408367157 time_taken: 0.05612611770629883\n",
      "Epoch 3: iteration 1700/2501 train_loss: 0.47715458273887634 time_taken: 0.05650925636291504\n",
      "Epoch 3: iteration 1701/2501 train_loss: 0.477195680141449 time_taken: 0.05714273452758789\n",
      "Epoch 3: iteration 1702/2501 train_loss: 0.4772251546382904 time_taken: 0.05680680274963379\n",
      "Epoch 3: iteration 1703/2501 train_loss: 0.477260559797287 time_taken: 0.057375192642211914\n",
      "Epoch 3: iteration 1704/2501 train_loss: 0.4772934317588806 time_taken: 0.0574493408203125\n",
      "Epoch 3: iteration 1705/2501 train_loss: 0.47732385993003845 time_taken: 0.05767822265625\n",
      "Epoch 3: iteration 1706/2501 train_loss: 0.47735804319381714 time_taken: 0.056601762771606445\n",
      "Epoch 3: iteration 1707/2501 train_loss: 0.47739335894584656 time_taken: 0.056192636489868164\n",
      "Epoch 3: iteration 1708/2501 train_loss: 0.47742030024528503 time_taken: 0.05754518508911133\n",
      "Epoch 3: iteration 1709/2501 train_loss: 0.4774613678455353 time_taken: 0.05687427520751953\n",
      "Epoch 3: iteration 1710/2501 train_loss: 0.477499395608902 time_taken: 0.05642366409301758\n",
      "Epoch 3: iteration 1711/2501 train_loss: 0.4775318205356598 time_taken: 0.05726456642150879\n",
      "Epoch 3: iteration 1712/2501 train_loss: 0.47756603360176086 time_taken: 0.05696535110473633\n",
      "Epoch 3: iteration 1713/2501 train_loss: 0.47761020064353943 time_taken: 0.05667829513549805\n",
      "Epoch 3: iteration 1714/2501 train_loss: 0.4776422083377838 time_taken: 0.056513071060180664\n",
      "Epoch 3: iteration 1715/2501 train_loss: 0.4776804447174072 time_taken: 0.05827832221984863\n",
      "Epoch 3: iteration 1716/2501 train_loss: 0.47773241996765137 time_taken: 0.0569610595703125\n",
      "Epoch 3: iteration 1717/2501 train_loss: 0.4777703285217285 time_taken: 0.057323455810546875\n",
      "Epoch 3: iteration 1718/2501 train_loss: 0.4778137505054474 time_taken: 0.05688357353210449\n",
      "Epoch 3: iteration 1719/2501 train_loss: 0.4778529405593872 time_taken: 0.056826114654541016\n",
      "Epoch 3: iteration 1720/2501 train_loss: 0.47789308428764343 time_taken: 0.057697296142578125\n",
      "Epoch 3: iteration 1721/2501 train_loss: 0.4779266119003296 time_taken: 0.05646061897277832\n",
      "Epoch 3: iteration 1722/2501 train_loss: 0.47795459628105164 time_taken: 0.056603193283081055\n",
      "Epoch 3: iteration 1723/2501 train_loss: 0.47799980640411377 time_taken: 0.0569155216217041\n",
      "Epoch 3: iteration 1724/2501 train_loss: 0.47804608941078186 time_taken: 0.05699038505554199\n",
      "Epoch 3: iteration 1725/2501 train_loss: 0.47808483242988586 time_taken: 0.056444406509399414\n",
      "Epoch 3: iteration 1726/2501 train_loss: 0.4781227707862854 time_taken: 0.056838035583496094\n",
      "Epoch 3: iteration 1727/2501 train_loss: 0.47816556692123413 time_taken: 0.05641674995422363\n",
      "Epoch 3: iteration 1728/2501 train_loss: 0.4782162010669708 time_taken: 0.05670356750488281\n",
      "Epoch 3: iteration 1729/2501 train_loss: 0.47826164960861206 time_taken: 0.05655241012573242\n",
      "Epoch 3: iteration 1730/2501 train_loss: 0.47830191254615784 time_taken: 0.056295156478881836\n",
      "Epoch 3: iteration 1731/2501 train_loss: 0.47834455966949463 time_taken: 0.056771278381347656\n",
      "Epoch 3: iteration 1732/2501 train_loss: 0.4783877730369568 time_taken: 0.05722856521606445\n",
      "Epoch 3: iteration 1733/2501 train_loss: 0.47842976450920105 time_taken: 0.05641961097717285\n",
      "Epoch 3: iteration 1734/2501 train_loss: 0.47846996784210205 time_taken: 0.05799221992492676\n",
      "Epoch 3: iteration 1735/2501 train_loss: 0.4785209894180298 time_taken: 0.056992530822753906\n",
      "Epoch 3: iteration 1736/2501 train_loss: 0.4785764813423157 time_taken: 0.057874202728271484\n",
      "Epoch 3: iteration 1737/2501 train_loss: 0.47863057255744934 time_taken: 0.05650448799133301\n",
      "Epoch 3: iteration 1738/2501 train_loss: 0.47868645191192627 time_taken: 0.05734515190124512\n",
      "Epoch 3: iteration 1739/2501 train_loss: 0.4787362515926361 time_taken: 0.056938886642456055\n",
      "Epoch 3: iteration 1740/2501 train_loss: 0.4787956178188324 time_taken: 0.05691671371459961\n",
      "Epoch 3: iteration 1741/2501 train_loss: 0.4788411557674408 time_taken: 0.05639195442199707\n",
      "Epoch 3: iteration 1742/2501 train_loss: 0.4788920283317566 time_taken: 0.05632281303405762\n",
      "Epoch 3: iteration 1743/2501 train_loss: 0.4789358377456665 time_taken: 0.0564424991607666\n",
      "Epoch 3: iteration 1744/2501 train_loss: 0.47899049520492554 time_taken: 0.05633878707885742\n",
      "Epoch 3: iteration 1745/2501 train_loss: 0.47904518246650696 time_taken: 0.056809425354003906\n",
      "Epoch 3: iteration 1746/2501 train_loss: 0.4790975749492645 time_taken: 0.05656027793884277\n",
      "Epoch 3: iteration 1747/2501 train_loss: 0.4791567325592041 time_taken: 0.056822776794433594\n",
      "Epoch 3: iteration 1748/2501 train_loss: 0.4792029559612274 time_taken: 0.05707716941833496\n",
      "Epoch 3: iteration 1749/2501 train_loss: 0.47924816608428955 time_taken: 0.05659890174865723\n",
      "Epoch 3: iteration 1750/2501 train_loss: 0.4792930483818054 time_taken: 0.05640602111816406\n",
      "Epoch 3: iteration 1751/2501 train_loss: 0.4793311357498169 time_taken: 0.05682063102722168\n",
      "Epoch 3: iteration 1752/2501 train_loss: 0.4793631434440613 time_taken: 0.05660581588745117\n",
      "Epoch 3: iteration 1753/2501 train_loss: 0.4794031083583832 time_taken: 0.056539297103881836\n",
      "Epoch 3: iteration 1754/2501 train_loss: 0.47943300008773804 time_taken: 0.0568394660949707\n",
      "Epoch 3: iteration 1755/2501 train_loss: 0.4794723391532898 time_taken: 0.05736136436462402\n",
      "Epoch 3: iteration 1756/2501 train_loss: 0.479493647813797 time_taken: 0.05725574493408203\n",
      "Epoch 3: iteration 1757/2501 train_loss: 0.47951027750968933 time_taken: 0.05678439140319824\n",
      "Epoch 3: iteration 1758/2501 train_loss: 0.4795272946357727 time_taken: 0.05668926239013672\n",
      "Epoch 3: iteration 1759/2501 train_loss: 0.4795357882976532 time_taken: 0.05615711212158203\n",
      "Epoch 3: iteration 1760/2501 train_loss: 0.4795285165309906 time_taken: 0.056915998458862305\n",
      "Epoch 3: iteration 1761/2501 train_loss: 0.4795288145542145 time_taken: 0.056618452072143555\n",
      "Epoch 3: iteration 1762/2501 train_loss: 0.4795278012752533 time_taken: 0.056581974029541016\n",
      "Epoch 3: iteration 1763/2501 train_loss: 0.47951197624206543 time_taken: 0.05634474754333496\n",
      "Epoch 3: iteration 1764/2501 train_loss: 0.479491263628006 time_taken: 0.05680036544799805\n",
      "Epoch 3: iteration 1765/2501 train_loss: 0.47946470975875854 time_taken: 0.05657172203063965\n",
      "Epoch 3: iteration 1766/2501 train_loss: 0.47944584488868713 time_taken: 0.05649423599243164\n",
      "Epoch 3: iteration 1767/2501 train_loss: 0.479436457157135 time_taken: 0.056447744369506836\n",
      "Epoch 3: iteration 1768/2501 train_loss: 0.4794294238090515 time_taken: 0.05665993690490723\n",
      "Epoch 3: iteration 1769/2501 train_loss: 0.4794239103794098 time_taken: 0.05682063102722168\n",
      "Epoch 3: iteration 1770/2501 train_loss: 0.4794096350669861 time_taken: 0.05698537826538086\n",
      "Epoch 3: iteration 1771/2501 train_loss: 0.4793991148471832 time_taken: 0.0571596622467041\n",
      "Epoch 3: iteration 1772/2501 train_loss: 0.47940343618392944 time_taken: 0.05666637420654297\n",
      "Epoch 3: iteration 1773/2501 train_loss: 0.4794074594974518 time_taken: 0.056763410568237305\n",
      "Epoch 3: iteration 1774/2501 train_loss: 0.4794020354747772 time_taken: 0.05683708190917969\n",
      "Epoch 3: iteration 1775/2501 train_loss: 0.479397714138031 time_taken: 0.05664324760437012\n",
      "Epoch 3: iteration 1776/2501 train_loss: 0.4794006645679474 time_taken: 0.056362152099609375\n",
      "Epoch 3: iteration 1777/2501 train_loss: 0.47940653562545776 time_taken: 0.05647158622741699\n",
      "Epoch 3: iteration 1778/2501 train_loss: 0.47941726446151733 time_taken: 0.056355953216552734\n",
      "Epoch 3: iteration 1779/2501 train_loss: 0.47942230105400085 time_taken: 0.05635976791381836\n",
      "Epoch 3: iteration 1780/2501 train_loss: 0.4794321358203888 time_taken: 0.05767369270324707\n",
      "Epoch 3: iteration 1781/2501 train_loss: 0.4794430136680603 time_taken: 0.0571742057800293\n",
      "Epoch 3: iteration 1782/2501 train_loss: 0.47944375872612 time_taken: 0.05658745765686035\n",
      "Epoch 3: iteration 1783/2501 train_loss: 0.47945016622543335 time_taken: 0.05652451515197754\n",
      "Epoch 3: iteration 1784/2501 train_loss: 0.47945868968963623 time_taken: 0.0562746524810791\n",
      "Epoch 3: iteration 1785/2501 train_loss: 0.479475736618042 time_taken: 0.056765079498291016\n",
      "Epoch 3: iteration 1786/2501 train_loss: 0.4794906973838806 time_taken: 0.05686211585998535\n",
      "Epoch 3: iteration 1787/2501 train_loss: 0.4795093536376953 time_taken: 0.057485103607177734\n",
      "Epoch 3: iteration 1788/2501 train_loss: 0.479525625705719 time_taken: 0.056786537170410156\n",
      "Epoch 3: iteration 1789/2501 train_loss: 0.47954118251800537 time_taken: 0.0571751594543457\n",
      "Epoch 3: iteration 1790/2501 train_loss: 0.47955673933029175 time_taken: 0.05693531036376953\n",
      "Epoch 3: iteration 1791/2501 train_loss: 0.4795651435852051 time_taken: 0.05675220489501953\n",
      "Epoch 3: iteration 1792/2501 train_loss: 0.4795895218849182 time_taken: 0.05674409866333008\n",
      "Epoch 3: iteration 1793/2501 train_loss: 0.47960495948791504 time_taken: 0.05743050575256348\n",
      "Epoch 3: iteration 1794/2501 train_loss: 0.4796158969402313 time_taken: 0.05652570724487305\n",
      "Epoch 3: iteration 1795/2501 train_loss: 0.4796202778816223 time_taken: 0.056632041931152344\n",
      "Epoch 3: iteration 1796/2501 train_loss: 0.4796288013458252 time_taken: 0.05765533447265625\n",
      "Epoch 3: iteration 1797/2501 train_loss: 0.4796437621116638 time_taken: 0.057256460189819336\n",
      "Epoch 3: iteration 1798/2501 train_loss: 0.47965332865715027 time_taken: 0.05737614631652832\n",
      "Epoch 3: iteration 1799/2501 train_loss: 0.4796692132949829 time_taken: 0.0568385124206543\n",
      "Epoch 3: iteration 1800/2501 train_loss: 0.47968512773513794 time_taken: 0.05662059783935547\n",
      "Epoch 3: iteration 1801/2501 train_loss: 0.4797072410583496 time_taken: 0.05702567100524902\n",
      "Epoch 3: iteration 1802/2501 train_loss: 0.4797298312187195 time_taken: 0.057281494140625\n",
      "Epoch 3: iteration 1803/2501 train_loss: 0.4797503650188446 time_taken: 0.056916236877441406\n",
      "Epoch 3: iteration 1804/2501 train_loss: 0.4797694683074951 time_taken: 0.05741071701049805\n",
      "Epoch 3: iteration 1805/2501 train_loss: 0.47979387640953064 time_taken: 0.05669403076171875\n",
      "Epoch 3: iteration 1806/2501 train_loss: 0.47982266545295715 time_taken: 0.05712294578552246\n",
      "Epoch 3: iteration 1807/2501 train_loss: 0.4798445701599121 time_taken: 0.056962013244628906\n",
      "Epoch 3: iteration 1808/2501 train_loss: 0.4798654019832611 time_taken: 0.05727744102478027\n",
      "Epoch 3: iteration 1809/2501 train_loss: 0.4798898696899414 time_taken: 0.05665016174316406\n",
      "Epoch 3: iteration 1810/2501 train_loss: 0.47990304231643677 time_taken: 0.05734086036682129\n",
      "Epoch 3: iteration 1811/2501 train_loss: 0.4799266755580902 time_taken: 0.056351661682128906\n",
      "Epoch 3: iteration 1812/2501 train_loss: 0.47994306683540344 time_taken: 0.05760049819946289\n",
      "Epoch 3: iteration 1813/2501 train_loss: 0.47996434569358826 time_taken: 0.05685758590698242\n",
      "Epoch 3: iteration 1814/2501 train_loss: 0.4799758493900299 time_taken: 0.05677032470703125\n",
      "Epoch 3: iteration 1815/2501 train_loss: 0.47998476028442383 time_taken: 0.056644439697265625\n",
      "Epoch 3: iteration 1816/2501 train_loss: 0.4800013303756714 time_taken: 0.05744576454162598\n",
      "Epoch 3: iteration 1817/2501 train_loss: 0.48001766204833984 time_taken: 0.05695939064025879\n",
      "Epoch 3: iteration 1818/2501 train_loss: 0.48002976179122925 time_taken: 0.05723404884338379\n",
      "Epoch 3: iteration 1819/2501 train_loss: 0.48003846406936646 time_taken: 0.05712103843688965\n",
      "Epoch 3: iteration 1820/2501 train_loss: 0.48004966974258423 time_taken: 0.0571293830871582\n",
      "Epoch 3: iteration 1821/2501 train_loss: 0.4800693392753601 time_taken: 0.056824684143066406\n",
      "Epoch 3: iteration 1822/2501 train_loss: 0.48007428646087646 time_taken: 0.05644416809082031\n",
      "Epoch 3: iteration 1823/2501 train_loss: 0.4800761640071869 time_taken: 0.056574106216430664\n",
      "Epoch 3: iteration 1824/2501 train_loss: 0.48008206486701965 time_taken: 0.0575261116027832\n",
      "Epoch 3: iteration 1825/2501 train_loss: 0.48010143637657166 time_taken: 0.0567476749420166\n",
      "Epoch 3: iteration 1826/2501 train_loss: 0.4801289439201355 time_taken: 0.056897640228271484\n",
      "Epoch 3: iteration 1827/2501 train_loss: 0.48015666007995605 time_taken: 0.057509422302246094\n",
      "Epoch 3: iteration 1828/2501 train_loss: 0.4801894724369049 time_taken: 0.057029008865356445\n",
      "Epoch 3: iteration 1829/2501 train_loss: 0.48022058606147766 time_taken: 0.056517839431762695\n",
      "Epoch 3: iteration 1830/2501 train_loss: 0.4802587032318115 time_taken: 0.056497812271118164\n",
      "Epoch 3: iteration 1831/2501 train_loss: 0.48029252886772156 time_taken: 0.05708193778991699\n",
      "Epoch 3: iteration 1832/2501 train_loss: 0.48034074902534485 time_taken: 0.0563812255859375\n",
      "Epoch 3: iteration 1833/2501 train_loss: 0.4803870618343353 time_taken: 0.056607961654663086\n",
      "Epoch 3: iteration 1834/2501 train_loss: 0.4804328382015228 time_taken: 0.05708146095275879\n",
      "Epoch 3: iteration 1835/2501 train_loss: 0.4804755449295044 time_taken: 0.05618762969970703\n",
      "Epoch 3: iteration 1836/2501 train_loss: 0.4805208146572113 time_taken: 0.05678057670593262\n",
      "Epoch 3: iteration 1837/2501 train_loss: 0.4805537164211273 time_taken: 0.05671977996826172\n",
      "Epoch 3: iteration 1838/2501 train_loss: 0.48058581352233887 time_taken: 0.05617356300354004\n",
      "Epoch 3: iteration 1839/2501 train_loss: 0.4806230664253235 time_taken: 0.056362152099609375\n",
      "Epoch 3: iteration 1840/2501 train_loss: 0.48065638542175293 time_taken: 0.05677199363708496\n",
      "Epoch 3: iteration 1841/2501 train_loss: 0.48068833351135254 time_taken: 0.057298898696899414\n",
      "Epoch 3: iteration 1842/2501 train_loss: 0.4807247817516327 time_taken: 0.05634760856628418\n",
      "Epoch 3: iteration 1843/2501 train_loss: 0.48076045513153076 time_taken: 0.05632209777832031\n",
      "Epoch 3: iteration 1844/2501 train_loss: 0.48078957200050354 time_taken: 0.05654168128967285\n",
      "Epoch 3: iteration 1845/2501 train_loss: 0.48080602288246155 time_taken: 0.05629086494445801\n",
      "Epoch 3: iteration 1846/2501 train_loss: 0.4808269739151001 time_taken: 0.05669236183166504\n",
      "Epoch 3: iteration 1847/2501 train_loss: 0.48083609342575073 time_taken: 0.05610513687133789\n",
      "Epoch 3: iteration 1848/2501 train_loss: 0.48084911704063416 time_taken: 0.05662345886230469\n",
      "Epoch 3: iteration 1849/2501 train_loss: 0.4808582067489624 time_taken: 0.05751848220825195\n",
      "Epoch 3: iteration 1850/2501 train_loss: 0.4808571934700012 time_taken: 0.05587053298950195\n",
      "Epoch 3: iteration 1851/2501 train_loss: 0.48085451126098633 time_taken: 0.05607867240905762\n",
      "Epoch 3: iteration 1852/2501 train_loss: 0.4808562695980072 time_taken: 0.0561375617980957\n",
      "Epoch 3: iteration 1853/2501 train_loss: 0.4808499217033386 time_taken: 0.05621814727783203\n",
      "Epoch 3: iteration 1854/2501 train_loss: 0.4808361232280731 time_taken: 0.05628824234008789\n",
      "Epoch 3: iteration 1855/2501 train_loss: 0.48081567883491516 time_taken: 0.05646777153015137\n",
      "Epoch 3: iteration 1856/2501 train_loss: 0.4807990789413452 time_taken: 0.056470394134521484\n",
      "Epoch 3: iteration 1857/2501 train_loss: 0.48077380657196045 time_taken: 0.05687904357910156\n",
      "Epoch 3: iteration 1858/2501 train_loss: 0.48075246810913086 time_taken: 0.06471896171569824\n",
      "Epoch 3: iteration 1859/2501 train_loss: 0.480732798576355 time_taken: 0.05604696273803711\n",
      "Epoch 3: iteration 1860/2501 train_loss: 0.480709046125412 time_taken: 0.05637931823730469\n",
      "Epoch 3: iteration 1861/2501 train_loss: 0.48068666458129883 time_taken: 0.056311607360839844\n",
      "Epoch 3: iteration 1862/2501 train_loss: 0.480659544467926 time_taken: 0.05626034736633301\n",
      "Epoch 3: iteration 1863/2501 train_loss: 0.48062369227409363 time_taken: 0.05631709098815918\n",
      "Epoch 3: iteration 1864/2501 train_loss: 0.48059868812561035 time_taken: 0.05711817741394043\n",
      "Epoch 3: iteration 1865/2501 train_loss: 0.48057201504707336 time_taken: 0.05614638328552246\n",
      "Epoch 3: iteration 1866/2501 train_loss: 0.48055166006088257 time_taken: 0.05644345283508301\n",
      "Epoch 3: iteration 1867/2501 train_loss: 0.48054614663124084 time_taken: 0.05614924430847168\n",
      "Epoch 3: iteration 1868/2501 train_loss: 0.48055094480514526 time_taken: 0.05593681335449219\n",
      "Epoch 3: iteration 1869/2501 train_loss: 0.4805450141429901 time_taken: 0.056845664978027344\n",
      "Epoch 3: iteration 1870/2501 train_loss: 0.4805476665496826 time_taken: 0.05642056465148926\n",
      "Epoch 3: iteration 1871/2501 train_loss: 0.48054081201553345 time_taken: 0.0565640926361084\n",
      "Epoch 3: iteration 1872/2501 train_loss: 0.4805542528629303 time_taken: 0.056159257888793945\n",
      "Epoch 3: iteration 1873/2501 train_loss: 0.48056620359420776 time_taken: 0.0570523738861084\n",
      "Epoch 3: iteration 1874/2501 train_loss: 0.48057496547698975 time_taken: 0.05672049522399902\n",
      "Epoch 3: iteration 1875/2501 train_loss: 0.48058250546455383 time_taken: 0.05672192573547363\n",
      "Epoch 3: iteration 1876/2501 train_loss: 0.4805971086025238 time_taken: 0.05679059028625488\n",
      "Epoch 3: iteration 1877/2501 train_loss: 0.48060986399650574 time_taken: 0.056192874908447266\n",
      "Epoch 3: iteration 1878/2501 train_loss: 0.4806183874607086 time_taken: 0.05651044845581055\n",
      "Epoch 3: iteration 1879/2501 train_loss: 0.48062944412231445 time_taken: 0.05649089813232422\n",
      "Epoch 3: iteration 1880/2501 train_loss: 0.4806378483772278 time_taken: 0.05646467208862305\n",
      "Epoch 3: iteration 1881/2501 train_loss: 0.48064368963241577 time_taken: 0.05647611618041992\n",
      "Epoch 3: iteration 1882/2501 train_loss: 0.48064252734184265 time_taken: 0.0620579719543457\n",
      "Epoch 3: iteration 1883/2501 train_loss: 0.48065388202667236 time_taken: 0.05644488334655762\n",
      "Epoch 3: iteration 1884/2501 train_loss: 0.4806571900844574 time_taken: 0.11436176300048828\n",
      "Epoch 3: iteration 1885/2501 train_loss: 0.48066550493240356 time_taken: 0.056036949157714844\n",
      "Epoch 3: iteration 1886/2501 train_loss: 0.4806734323501587 time_taken: 0.05612778663635254\n",
      "Epoch 3: iteration 1887/2501 train_loss: 0.4806816875934601 time_taken: 0.05737161636352539\n",
      "Epoch 3: iteration 1888/2501 train_loss: 0.48069560527801514 time_taken: 0.05750584602355957\n",
      "Epoch 3: iteration 1889/2501 train_loss: 0.48070037364959717 time_taken: 0.05661749839782715\n",
      "Epoch 3: iteration 1890/2501 train_loss: 0.48071375489234924 time_taken: 0.056935787200927734\n",
      "Epoch 3: iteration 1891/2501 train_loss: 0.48073509335517883 time_taken: 0.05662202835083008\n",
      "Epoch 3: iteration 1892/2501 train_loss: 0.48075225949287415 time_taken: 0.0565640926361084\n",
      "Epoch 3: iteration 1893/2501 train_loss: 0.48078039288520813 time_taken: 0.05694270133972168\n",
      "Epoch 3: iteration 1894/2501 train_loss: 0.48082244396209717 time_taken: 0.05706214904785156\n",
      "Epoch 3: iteration 1895/2501 train_loss: 0.48086169362068176 time_taken: 0.056498050689697266\n",
      "Epoch 3: iteration 1896/2501 train_loss: 0.4809090793132782 time_taken: 0.056786537170410156\n",
      "Epoch 3: iteration 1897/2501 train_loss: 0.48096221685409546 time_taken: 0.05621814727783203\n",
      "Epoch 3: iteration 1898/2501 train_loss: 0.481000155210495 time_taken: 0.0562596321105957\n",
      "Epoch 3: iteration 1899/2501 train_loss: 0.4810461401939392 time_taken: 0.05668210983276367\n",
      "Epoch 3: iteration 1900/2501 train_loss: 0.4810892343521118 time_taken: 0.05616188049316406\n",
      "Epoch 3: iteration 1901/2501 train_loss: 0.48112595081329346 time_taken: 0.05652952194213867\n",
      "Epoch 3: iteration 1902/2501 train_loss: 0.4811493158340454 time_taken: 0.056852102279663086\n",
      "Epoch 3: iteration 1903/2501 train_loss: 0.48117563128471375 time_taken: 0.05666518211364746\n",
      "Epoch 3: iteration 1904/2501 train_loss: 0.4812081754207611 time_taken: 0.0576167106628418\n",
      "Epoch 3: iteration 1905/2501 train_loss: 0.4812280833721161 time_taken: 0.05695295333862305\n",
      "Epoch 3: iteration 1906/2501 train_loss: 0.48126885294914246 time_taken: 0.056745290756225586\n",
      "Epoch 3: iteration 1907/2501 train_loss: 0.481298565864563 time_taken: 0.05670285224914551\n",
      "Epoch 3: iteration 1908/2501 train_loss: 0.48133572936058044 time_taken: 0.05694913864135742\n",
      "Epoch 3: iteration 1909/2501 train_loss: 0.48136577010154724 time_taken: 0.05619096755981445\n",
      "Epoch 3: iteration 1910/2501 train_loss: 0.4813985526561737 time_taken: 0.05683279037475586\n",
      "Epoch 3: iteration 1911/2501 train_loss: 0.4814119040966034 time_taken: 0.07978034019470215\n",
      "Epoch 3: iteration 1912/2501 train_loss: 0.4814359247684479 time_taken: 0.0790565013885498\n",
      "Epoch 3: iteration 1913/2501 train_loss: 0.4814600646495819 time_taken: 0.056532859802246094\n",
      "Epoch 3: iteration 1914/2501 train_loss: 0.48148736357688904 time_taken: 0.06377792358398438\n",
      "Epoch 3: iteration 1915/2501 train_loss: 0.48150691390037537 time_taken: 0.05633831024169922\n",
      "Epoch 3: iteration 1916/2501 train_loss: 0.4815327823162079 time_taken: 0.05716586112976074\n",
      "Epoch 3: iteration 1917/2501 train_loss: 0.48155951499938965 time_taken: 0.05631375312805176\n",
      "Epoch 3: iteration 1918/2501 train_loss: 0.48157355189323425 time_taken: 0.05628538131713867\n",
      "Epoch 3: iteration 1919/2501 train_loss: 0.4816012382507324 time_taken: 0.05622100830078125\n",
      "Epoch 3: iteration 1920/2501 train_loss: 0.4816269278526306 time_taken: 0.05601215362548828\n",
      "Epoch 3: iteration 1921/2501 train_loss: 0.48165521025657654 time_taken: 0.056296348571777344\n",
      "Epoch 3: iteration 1922/2501 train_loss: 0.4816834032535553 time_taken: 0.056299686431884766\n",
      "Epoch 3: iteration 1923/2501 train_loss: 0.4817160964012146 time_taken: 0.05648398399353027\n",
      "Epoch 3: iteration 1924/2501 train_loss: 0.4817548394203186 time_taken: 0.056215524673461914\n",
      "Epoch 3: iteration 1925/2501 train_loss: 0.4817948341369629 time_taken: 0.0567777156829834\n",
      "Epoch 3: iteration 1926/2501 train_loss: 0.4818393588066101 time_taken: 0.05623054504394531\n",
      "Epoch 3: iteration 1927/2501 train_loss: 0.4818843603134155 time_taken: 0.05650782585144043\n",
      "Epoch 3: iteration 1928/2501 train_loss: 0.48192381858825684 time_taken: 0.056432485580444336\n",
      "Epoch 3: iteration 1929/2501 train_loss: 0.481975793838501 time_taken: 0.05645179748535156\n",
      "Epoch 3: iteration 1930/2501 train_loss: 0.48203879594802856 time_taken: 0.05648541450500488\n",
      "Epoch 3: iteration 1931/2501 train_loss: 0.48208561539649963 time_taken: 0.05687355995178223\n",
      "Epoch 3: iteration 1932/2501 train_loss: 0.48214611411094666 time_taken: 0.05646514892578125\n",
      "Epoch 3: iteration 1933/2501 train_loss: 0.4822048246860504 time_taken: 0.05672860145568848\n",
      "Epoch 3: iteration 1934/2501 train_loss: 0.48224082589149475 time_taken: 0.05701565742492676\n",
      "Epoch 3: iteration 1935/2501 train_loss: 0.48228269815444946 time_taken: 0.05651378631591797\n",
      "Epoch 3: iteration 1936/2501 train_loss: 0.4823252856731415 time_taken: 0.05676698684692383\n",
      "Epoch 3: iteration 1937/2501 train_loss: 0.48236897587776184 time_taken: 0.05663108825683594\n",
      "Epoch 3: iteration 1938/2501 train_loss: 0.48240625858306885 time_taken: 0.056375741958618164\n",
      "Epoch 3: iteration 1939/2501 train_loss: 0.48243626952171326 time_taken: 0.056778669357299805\n",
      "Epoch 3: iteration 1940/2501 train_loss: 0.4824669361114502 time_taken: 0.05681896209716797\n",
      "Epoch 3: iteration 1941/2501 train_loss: 0.48248758912086487 time_taken: 0.0564422607421875\n",
      "Epoch 3: iteration 1942/2501 train_loss: 0.48250454664230347 time_taken: 0.056490182876586914\n",
      "Epoch 3: iteration 1943/2501 train_loss: 0.4825151562690735 time_taken: 0.05692315101623535\n",
      "Epoch 3: iteration 1944/2501 train_loss: 0.48251408338546753 time_taken: 0.057508230209350586\n",
      "Epoch 3: iteration 1945/2501 train_loss: 0.4825100302696228 time_taken: 0.06297087669372559\n",
      "Epoch 3: iteration 1946/2501 train_loss: 0.4825027883052826 time_taken: 0.056410789489746094\n",
      "Epoch 3: iteration 1947/2501 train_loss: 0.48248472809791565 time_taken: 0.056038618087768555\n",
      "Epoch 3: iteration 1948/2501 train_loss: 0.48246142268180847 time_taken: 0.0562748908996582\n",
      "Epoch 3: iteration 1949/2501 train_loss: 0.48245033621788025 time_taken: 0.056119680404663086\n",
      "Epoch 3: iteration 1950/2501 train_loss: 0.482451468706131 time_taken: 0.060769081115722656\n",
      "Epoch 3: iteration 1951/2501 train_loss: 0.48245275020599365 time_taken: 0.05589580535888672\n",
      "Epoch 3: iteration 1952/2501 train_loss: 0.4824669361114502 time_taken: 0.05592489242553711\n",
      "Epoch 3: iteration 1953/2501 train_loss: 0.4824862480163574 time_taken: 0.056026458740234375\n",
      "Epoch 3: iteration 1954/2501 train_loss: 0.4825003743171692 time_taken: 0.05632352828979492\n",
      "Epoch 3: iteration 1955/2501 train_loss: 0.48250699043273926 time_taken: 0.056177377700805664\n",
      "Epoch 3: iteration 1956/2501 train_loss: 0.48252248764038086 time_taken: 0.05585980415344238\n",
      "Epoch 3: iteration 1957/2501 train_loss: 0.4825337529182434 time_taken: 0.055971384048461914\n",
      "Epoch 3: iteration 1958/2501 train_loss: 0.48254501819610596 time_taken: 0.0598299503326416\n",
      "Epoch 3: iteration 1959/2501 train_loss: 0.48255327343940735 time_taken: 0.055997371673583984\n",
      "Epoch 3: iteration 1960/2501 train_loss: 0.48255079984664917 time_taken: 0.056009769439697266\n",
      "Epoch 3: iteration 1961/2501 train_loss: 0.4825490713119507 time_taken: 0.05649089813232422\n",
      "Epoch 3: iteration 1962/2501 train_loss: 0.4825439453125 time_taken: 0.056260108947753906\n",
      "Epoch 3: iteration 1963/2501 train_loss: 0.4825325310230255 time_taken: 0.056687355041503906\n",
      "Epoch 3: iteration 1964/2501 train_loss: 0.48250794410705566 time_taken: 0.056092023849487305\n",
      "Epoch 3: iteration 1965/2501 train_loss: 0.48249176144599915 time_taken: 0.056092262268066406\n",
      "Epoch 3: iteration 1966/2501 train_loss: 0.4824768900871277 time_taken: 0.06103062629699707\n",
      "Epoch 3: iteration 1967/2501 train_loss: 0.4824438989162445 time_taken: 0.05657529830932617\n",
      "Epoch 3: iteration 1968/2501 train_loss: 0.4824119210243225 time_taken: 0.05778145790100098\n",
      "Epoch 3: iteration 1969/2501 train_loss: 0.4823807179927826 time_taken: 0.05758166313171387\n",
      "Epoch 3: iteration 1970/2501 train_loss: 0.4823439419269562 time_taken: 0.056609392166137695\n",
      "Epoch 3: iteration 1971/2501 train_loss: 0.4823154807090759 time_taken: 0.05703377723693848\n",
      "Epoch 3: iteration 1972/2501 train_loss: 0.48229923844337463 time_taken: 0.05678677558898926\n",
      "Epoch 3: iteration 1973/2501 train_loss: 0.4822767972946167 time_taken: 0.057137250900268555\n",
      "Epoch 3: iteration 1974/2501 train_loss: 0.48226889967918396 time_taken: 0.056210994720458984\n",
      "Epoch 3: iteration 1975/2501 train_loss: 0.48226407170295715 time_taken: 0.05646395683288574\n",
      "Epoch 3: iteration 1976/2501 train_loss: 0.48224711418151855 time_taken: 0.05606961250305176\n",
      "Epoch 3: iteration 1977/2501 train_loss: 0.4822336435317993 time_taken: 0.056052207946777344\n",
      "Epoch 3: iteration 1978/2501 train_loss: 0.48221373558044434 time_taken: 0.05649161338806152\n",
      "Epoch 3: iteration 1979/2501 train_loss: 0.48219484090805054 time_taken: 0.05639457702636719\n",
      "Epoch 3: iteration 1980/2501 train_loss: 0.4821690320968628 time_taken: 0.05627846717834473\n",
      "Epoch 3: iteration 1981/2501 train_loss: 0.48213672637939453 time_taken: 0.056398868560791016\n",
      "Epoch 3: iteration 1982/2501 train_loss: 0.4821160137653351 time_taken: 0.056763648986816406\n",
      "Epoch 3: iteration 1983/2501 train_loss: 0.4820939004421234 time_taken: 0.05735898017883301\n",
      "Epoch 3: iteration 1984/2501 train_loss: 0.48207587003707886 time_taken: 0.05680680274963379\n",
      "Epoch 3: iteration 1985/2501 train_loss: 0.48205357789993286 time_taken: 0.056371212005615234\n",
      "Epoch 3: iteration 1986/2501 train_loss: 0.4820384681224823 time_taken: 0.05652880668640137\n",
      "Epoch 3: iteration 1987/2501 train_loss: 0.4820343255996704 time_taken: 0.05654740333557129\n",
      "Epoch 3: iteration 1988/2501 train_loss: 0.48201650381088257 time_taken: 0.056630849838256836\n",
      "Epoch 3: iteration 1989/2501 train_loss: 0.48200660943984985 time_taken: 0.056767940521240234\n",
      "Epoch 3: iteration 1990/2501 train_loss: 0.4819941222667694 time_taken: 0.056372880935668945\n",
      "Epoch 3: iteration 1991/2501 train_loss: 0.48197972774505615 time_taken: 0.05700564384460449\n",
      "Epoch 3: iteration 1992/2501 train_loss: 0.4819728136062622 time_taken: 0.056505441665649414\n",
      "Epoch 3: iteration 1993/2501 train_loss: 0.4819728434085846 time_taken: 0.05671429634094238\n",
      "Epoch 3: iteration 1994/2501 train_loss: 0.48197343945503235 time_taken: 0.056545257568359375\n",
      "Epoch 3: iteration 1995/2501 train_loss: 0.4819895625114441 time_taken: 0.05676746368408203\n",
      "Epoch 3: iteration 1996/2501 train_loss: 0.4820074737071991 time_taken: 0.056153059005737305\n",
      "Epoch 3: iteration 1997/2501 train_loss: 0.48202192783355713 time_taken: 0.05614447593688965\n",
      "Epoch 3: iteration 1998/2501 train_loss: 0.4820290207862854 time_taken: 0.05756330490112305\n",
      "Epoch 3: iteration 1999/2501 train_loss: 0.4820472300052643 time_taken: 0.057274580001831055\n",
      "Epoch 3: iteration 2000/2501 train_loss: 0.48205944895744324 time_taken: 0.05648970603942871\n",
      "Epoch 3: iteration 2001/2501 train_loss: 0.4820796251296997 time_taken: 0.05995607376098633\n",
      "Epoch 3: iteration 2002/2501 train_loss: 0.48209089040756226 time_taken: 0.0566561222076416\n",
      "Epoch 3: iteration 2003/2501 train_loss: 0.4821128249168396 time_taken: 0.05620431900024414\n",
      "Epoch 3: iteration 2004/2501 train_loss: 0.4821165204048157 time_taken: 0.05625462532043457\n",
      "Epoch 3: iteration 2005/2501 train_loss: 0.482130229473114 time_taken: 0.056200504302978516\n",
      "Epoch 3: iteration 2006/2501 train_loss: 0.4821532368659973 time_taken: 0.05616641044616699\n",
      "Epoch 3: iteration 2007/2501 train_loss: 0.48218050599098206 time_taken: 0.056456565856933594\n",
      "Epoch 3: iteration 2008/2501 train_loss: 0.48219674825668335 time_taken: 0.05747509002685547\n",
      "Epoch 3: iteration 2009/2501 train_loss: 0.48222020268440247 time_taken: 0.05619025230407715\n",
      "Epoch 3: iteration 2010/2501 train_loss: 0.48224663734436035 time_taken: 0.05663156509399414\n",
      "Epoch 3: iteration 2011/2501 train_loss: 0.4822697043418884 time_taken: 0.05640745162963867\n",
      "Epoch 3: iteration 2012/2501 train_loss: 0.4822848439216614 time_taken: 0.056859731674194336\n",
      "Epoch 3: iteration 2013/2501 train_loss: 0.48230719566345215 time_taken: 0.05675315856933594\n",
      "Epoch 3: iteration 2014/2501 train_loss: 0.48233097791671753 time_taken: 0.05659031867980957\n",
      "Epoch 3: iteration 2015/2501 train_loss: 0.48235106468200684 time_taken: 0.05610179901123047\n",
      "Epoch 3: iteration 2016/2501 train_loss: 0.4823761284351349 time_taken: 0.056268930435180664\n",
      "Epoch 3: iteration 2017/2501 train_loss: 0.4824022054672241 time_taken: 0.05678248405456543\n",
      "Epoch 3: iteration 2018/2501 train_loss: 0.4824419617652893 time_taken: 0.056810855865478516\n",
      "Epoch 3: iteration 2019/2501 train_loss: 0.4824782609939575 time_taken: 0.05680584907531738\n",
      "Epoch 3: iteration 2020/2501 train_loss: 0.4825146198272705 time_taken: 0.056668996810913086\n",
      "Epoch 3: iteration 2021/2501 train_loss: 0.48256176710128784 time_taken: 0.05695009231567383\n",
      "Epoch 3: iteration 2022/2501 train_loss: 0.4825946092605591 time_taken: 0.056705474853515625\n",
      "Epoch 3: iteration 2023/2501 train_loss: 0.48262539505958557 time_taken: 0.05653023719787598\n",
      "Epoch 3: iteration 2024/2501 train_loss: 0.4826565980911255 time_taken: 0.05655407905578613\n",
      "Epoch 3: iteration 2025/2501 train_loss: 0.48268353939056396 time_taken: 0.05630064010620117\n",
      "Epoch 3: iteration 2026/2501 train_loss: 0.4827265739440918 time_taken: 0.056507110595703125\n",
      "Epoch 3: iteration 2027/2501 train_loss: 0.4827636480331421 time_taken: 0.061478614807128906\n",
      "Epoch 3: iteration 2028/2501 train_loss: 0.4827895760536194 time_taken: 0.07225370407104492\n",
      "Epoch 3: iteration 2029/2501 train_loss: 0.48281553387641907 time_taken: 0.05714249610900879\n",
      "Epoch 3: iteration 2030/2501 train_loss: 0.4828447103500366 time_taken: 0.05641293525695801\n",
      "Epoch 3: iteration 2031/2501 train_loss: 0.4828766882419586 time_taken: 0.056508541107177734\n",
      "Epoch 3: iteration 2032/2501 train_loss: 0.4828983545303345 time_taken: 0.056413888931274414\n",
      "Epoch 3: iteration 2033/2501 train_loss: 0.48293349146842957 time_taken: 0.05653953552246094\n",
      "Epoch 3: iteration 2034/2501 train_loss: 0.48296067118644714 time_taken: 0.06187725067138672\n",
      "Epoch 3: iteration 2035/2501 train_loss: 0.4829895794391632 time_taken: 0.0565640926361084\n",
      "Epoch 3: iteration 2036/2501 train_loss: 0.4830039441585541 time_taken: 0.05662417411804199\n",
      "Epoch 3: iteration 2037/2501 train_loss: 0.48302993178367615 time_taken: 0.05656003952026367\n",
      "Epoch 3: iteration 2038/2501 train_loss: 0.48305365443229675 time_taken: 0.057349205017089844\n",
      "Epoch 3: iteration 2039/2501 train_loss: 0.4830789566040039 time_taken: 0.05637717247009277\n",
      "Epoch 3: iteration 2040/2501 train_loss: 0.4831145107746124 time_taken: 0.05717778205871582\n",
      "Epoch 3: iteration 2041/2501 train_loss: 0.48314720392227173 time_taken: 0.05677604675292969\n",
      "Epoch 3: iteration 2042/2501 train_loss: 0.4831794202327728 time_taken: 0.0570378303527832\n",
      "Epoch 3: iteration 2043/2501 train_loss: 0.48320212960243225 time_taken: 0.06124091148376465\n",
      "Epoch 3: iteration 2044/2501 train_loss: 0.48323190212249756 time_taken: 0.0569005012512207\n",
      "Epoch 3: iteration 2045/2501 train_loss: 0.48325106501579285 time_taken: 0.05734539031982422\n",
      "Epoch 3: iteration 2046/2501 train_loss: 0.48327478766441345 time_taken: 0.05664205551147461\n",
      "Epoch 3: iteration 2047/2501 train_loss: 0.4832876920700073 time_taken: 0.05647754669189453\n",
      "Epoch 3: iteration 2048/2501 train_loss: 0.4833070933818817 time_taken: 0.056442975997924805\n",
      "Epoch 3: iteration 2049/2501 train_loss: 0.48333215713500977 time_taken: 0.05632901191711426\n",
      "Epoch 3: iteration 2050/2501 train_loss: 0.4833570122718811 time_taken: 0.057794809341430664\n",
      "Epoch 3: iteration 2051/2501 train_loss: 0.48337849974632263 time_taken: 0.057141780853271484\n",
      "Epoch 3: iteration 2052/2501 train_loss: 0.4833957850933075 time_taken: 0.056694984436035156\n",
      "Epoch 3: iteration 2053/2501 train_loss: 0.48341643810272217 time_taken: 0.05704164505004883\n",
      "Epoch 3: iteration 2054/2501 train_loss: 0.4834422469139099 time_taken: 0.05698275566101074\n",
      "Epoch 3: iteration 2055/2501 train_loss: 0.483462929725647 time_taken: 0.05738091468811035\n",
      "Epoch 3: iteration 2056/2501 train_loss: 0.4834895431995392 time_taken: 0.05695319175720215\n",
      "Epoch 3: iteration 2057/2501 train_loss: 0.4835132658481598 time_taken: 0.05657362937927246\n",
      "Epoch 3: iteration 2058/2501 train_loss: 0.48353123664855957 time_taken: 0.0565030574798584\n",
      "Epoch 3: iteration 2059/2501 train_loss: 0.4835464656352997 time_taken: 0.056554555892944336\n",
      "Epoch 3: iteration 2060/2501 train_loss: 0.48356667160987854 time_taken: 0.05637073516845703\n",
      "Epoch 3: iteration 2061/2501 train_loss: 0.48358991742134094 time_taken: 0.05692601203918457\n",
      "Epoch 3: iteration 2062/2501 train_loss: 0.4836145043373108 time_taken: 0.056973934173583984\n",
      "Epoch 3: iteration 2063/2501 train_loss: 0.48363858461380005 time_taken: 0.05791354179382324\n",
      "Epoch 3: iteration 2064/2501 train_loss: 0.483663409948349 time_taken: 0.057790279388427734\n",
      "Epoch 3: iteration 2065/2501 train_loss: 0.48368749022483826 time_taken: 0.05693173408508301\n",
      "Epoch 3: iteration 2066/2501 train_loss: 0.483712762594223 time_taken: 0.05790829658508301\n",
      "Epoch 3: iteration 2067/2501 train_loss: 0.4837268590927124 time_taken: 0.056976318359375\n",
      "Epoch 3: iteration 2068/2501 train_loss: 0.48373886942863464 time_taken: 0.05690193176269531\n",
      "Epoch 3: iteration 2069/2501 train_loss: 0.4837475121021271 time_taken: 0.05652284622192383\n",
      "Epoch 3: iteration 2070/2501 train_loss: 0.4837522506713867 time_taken: 0.05787777900695801\n",
      "Epoch 3: iteration 2071/2501 train_loss: 0.4837506413459778 time_taken: 0.05665326118469238\n",
      "Epoch 3: iteration 2072/2501 train_loss: 0.4837551414966583 time_taken: 0.0564115047454834\n",
      "Epoch 3: iteration 2073/2501 train_loss: 0.48375779390335083 time_taken: 0.057828426361083984\n",
      "Epoch 3: iteration 2074/2501 train_loss: 0.4837508201599121 time_taken: 0.056797027587890625\n",
      "Epoch 3: iteration 2075/2501 train_loss: 0.48374268412590027 time_taken: 0.056609392166137695\n",
      "Epoch 3: iteration 2076/2501 train_loss: 0.48372942209243774 time_taken: 0.05663132667541504\n",
      "Epoch 3: iteration 2077/2501 train_loss: 0.4837213158607483 time_taken: 0.056891679763793945\n",
      "Epoch 3: iteration 2078/2501 train_loss: 0.4837225079536438 time_taken: 0.05691885948181152\n",
      "Epoch 3: iteration 2079/2501 train_loss: 0.483721524477005 time_taken: 0.05661416053771973\n",
      "Epoch 3: iteration 2080/2501 train_loss: 0.48372286558151245 time_taken: 0.05701279640197754\n",
      "Epoch 3: iteration 2081/2501 train_loss: 0.48373159766197205 time_taken: 0.05686497688293457\n",
      "Epoch 3: iteration 2082/2501 train_loss: 0.4837413430213928 time_taken: 0.057021141052246094\n",
      "Epoch 3: iteration 2083/2501 train_loss: 0.4837559163570404 time_taken: 0.05666208267211914\n",
      "Epoch 3: iteration 2084/2501 train_loss: 0.48376503586769104 time_taken: 0.057277679443359375\n",
      "Epoch 3: iteration 2085/2501 train_loss: 0.48376473784446716 time_taken: 0.057895660400390625\n",
      "Epoch 3: iteration 2086/2501 train_loss: 0.48375698924064636 time_taken: 0.05668926239013672\n",
      "Epoch 3: iteration 2087/2501 train_loss: 0.48375290632247925 time_taken: 0.05633234977722168\n",
      "Epoch 3: iteration 2088/2501 train_loss: 0.48374292254447937 time_taken: 0.0686333179473877\n",
      "Epoch 3: iteration 2089/2501 train_loss: 0.48372504115104675 time_taken: 0.05624794960021973\n",
      "Epoch 3: iteration 2090/2501 train_loss: 0.4837125837802887 time_taken: 0.05613255500793457\n",
      "Epoch 3: iteration 2091/2501 train_loss: 0.48368966579437256 time_taken: 0.05637168884277344\n",
      "Epoch 3: iteration 2092/2501 train_loss: 0.4836737811565399 time_taken: 0.05693650245666504\n",
      "Epoch 3: iteration 2093/2501 train_loss: 0.4836477041244507 time_taken: 0.05633687973022461\n",
      "Epoch 3: iteration 2094/2501 train_loss: 0.48361700773239136 time_taken: 0.056368112564086914\n",
      "Epoch 3: iteration 2095/2501 train_loss: 0.48358771204948425 time_taken: 0.05658364295959473\n",
      "Epoch 3: iteration 2096/2501 train_loss: 0.48355528712272644 time_taken: 0.056421756744384766\n",
      "Epoch 3: iteration 2097/2501 train_loss: 0.4835262596607208 time_taken: 0.05622124671936035\n",
      "Epoch 3: iteration 2098/2501 train_loss: 0.48348745703697205 time_taken: 0.056444644927978516\n",
      "Epoch 3: iteration 2099/2501 train_loss: 0.48344704508781433 time_taken: 0.056005001068115234\n",
      "Epoch 3: iteration 2100/2501 train_loss: 0.48341843485832214 time_taken: 0.05617713928222656\n",
      "Epoch 3: iteration 2101/2501 train_loss: 0.4833877682685852 time_taken: 0.05643510818481445\n",
      "Epoch 3: iteration 2102/2501 train_loss: 0.48336556553840637 time_taken: 0.05637478828430176\n",
      "Epoch 3: iteration 2103/2501 train_loss: 0.48334068059921265 time_taken: 0.05585169792175293\n",
      "Epoch 3: iteration 2104/2501 train_loss: 0.48331719636917114 time_taken: 0.05666613578796387\n",
      "Epoch 3: iteration 2105/2501 train_loss: 0.48328983783721924 time_taken: 0.056238412857055664\n",
      "Epoch 3: iteration 2106/2501 train_loss: 0.48326197266578674 time_taken: 0.05626249313354492\n",
      "Epoch 3: iteration 2107/2501 train_loss: 0.483238160610199 time_taken: 0.05649828910827637\n",
      "Epoch 3: iteration 2108/2501 train_loss: 0.4832099974155426 time_taken: 0.05639147758483887\n",
      "Epoch 3: iteration 2109/2501 train_loss: 0.4831863045692444 time_taken: 0.05660605430603027\n",
      "Epoch 3: iteration 2110/2501 train_loss: 0.4831557273864746 time_taken: 0.05629897117614746\n",
      "Epoch 3: iteration 2111/2501 train_loss: 0.48314011096954346 time_taken: 0.05674934387207031\n",
      "Epoch 3: iteration 2112/2501 train_loss: 0.48313042521476746 time_taken: 0.0568692684173584\n",
      "Epoch 3: iteration 2113/2501 train_loss: 0.4831164479255676 time_taken: 0.056134939193725586\n",
      "Epoch 3: iteration 2114/2501 train_loss: 0.4831097424030304 time_taken: 0.0567626953125\n",
      "Epoch 3: iteration 2115/2501 train_loss: 0.4831002652645111 time_taken: 0.05698680877685547\n",
      "Epoch 3: iteration 2116/2501 train_loss: 0.4830887019634247 time_taken: 0.056494712829589844\n",
      "Epoch 3: iteration 2117/2501 train_loss: 0.48308268189430237 time_taken: 0.05778026580810547\n",
      "Epoch 3: iteration 2118/2501 train_loss: 0.483072429895401 time_taken: 0.05668497085571289\n",
      "Epoch 3: iteration 2119/2501 train_loss: 0.4830562472343445 time_taken: 0.056894779205322266\n",
      "Epoch 3: iteration 2120/2501 train_loss: 0.48305201530456543 time_taken: 0.056333065032958984\n",
      "Epoch 3: iteration 2121/2501 train_loss: 0.48304781317710876 time_taken: 0.05663728713989258\n",
      "Epoch 3: iteration 2122/2501 train_loss: 0.4830383360385895 time_taken: 0.056101322174072266\n",
      "Epoch 3: iteration 2123/2501 train_loss: 0.4830326735973358 time_taken: 0.056131601333618164\n",
      "Epoch 3: iteration 2124/2501 train_loss: 0.48303452134132385 time_taken: 0.05705595016479492\n",
      "Epoch 3: iteration 2125/2501 train_loss: 0.483029305934906 time_taken: 0.05659604072570801\n",
      "Epoch 3: iteration 2126/2501 train_loss: 0.483029305934906 time_taken: 0.056548118591308594\n",
      "Epoch 3: iteration 2127/2501 train_loss: 0.48303017020225525 time_taken: 0.057974815368652344\n",
      "Epoch 3: iteration 2128/2501 train_loss: 0.48304346203804016 time_taken: 0.056618452072143555\n",
      "Epoch 3: iteration 2129/2501 train_loss: 0.4830501079559326 time_taken: 0.056618690490722656\n",
      "Epoch 3: iteration 2130/2501 train_loss: 0.4830660820007324 time_taken: 0.05640459060668945\n",
      "Epoch 3: iteration 2131/2501 train_loss: 0.4830816388130188 time_taken: 0.05687117576599121\n",
      "Epoch 3: iteration 2132/2501 train_loss: 0.4830949008464813 time_taken: 0.05729818344116211\n",
      "Epoch 3: iteration 2133/2501 train_loss: 0.483104407787323 time_taken: 0.05647540092468262\n",
      "Epoch 3: iteration 2134/2501 train_loss: 0.48312026262283325 time_taken: 0.056877851486206055\n",
      "Epoch 3: iteration 2135/2501 train_loss: 0.48313748836517334 time_taken: 0.05686330795288086\n",
      "Epoch 3: iteration 2136/2501 train_loss: 0.4831426441669464 time_taken: 0.05639171600341797\n",
      "Epoch 3: iteration 2137/2501 train_loss: 0.4831407070159912 time_taken: 0.05713319778442383\n",
      "Epoch 3: iteration 2138/2501 train_loss: 0.4831506907939911 time_taken: 0.057173728942871094\n",
      "Epoch 3: iteration 2139/2501 train_loss: 0.4831486642360687 time_taken: 0.057482004165649414\n",
      "Epoch 3: iteration 2140/2501 train_loss: 0.4831502437591553 time_taken: 0.05742931365966797\n",
      "Epoch 3: iteration 2141/2501 train_loss: 0.4831540584564209 time_taken: 0.0568087100982666\n",
      "Epoch 3: iteration 2142/2501 train_loss: 0.48315536975860596 time_taken: 0.05732083320617676\n",
      "Epoch 3: iteration 2143/2501 train_loss: 0.48315730690956116 time_taken: 0.05701327323913574\n",
      "Epoch 3: iteration 2144/2501 train_loss: 0.48315149545669556 time_taken: 0.056632280349731445\n",
      "Epoch 3: iteration 2145/2501 train_loss: 0.483151912689209 time_taken: 0.05720162391662598\n",
      "Epoch 3: iteration 2146/2501 train_loss: 0.48316362500190735 time_taken: 0.0572969913482666\n",
      "Epoch 3: iteration 2147/2501 train_loss: 0.48316502571105957 time_taken: 0.05681443214416504\n",
      "Epoch 3: iteration 2148/2501 train_loss: 0.4831674098968506 time_taken: 0.056836605072021484\n",
      "Epoch 3: iteration 2149/2501 train_loss: 0.4831662178039551 time_taken: 0.05650162696838379\n",
      "Epoch 3: iteration 2150/2501 train_loss: 0.4831603169441223 time_taken: 0.056653738021850586\n",
      "Epoch 3: iteration 2151/2501 train_loss: 0.4831596314907074 time_taken: 0.05753970146179199\n",
      "Epoch 3: iteration 2152/2501 train_loss: 0.4831524193286896 time_taken: 0.05637001991271973\n",
      "Epoch 3: iteration 2153/2501 train_loss: 0.48314380645751953 time_taken: 0.05688738822937012\n",
      "Epoch 3: iteration 2154/2501 train_loss: 0.4831315875053406 time_taken: 0.05762505531311035\n",
      "Epoch 3: iteration 2155/2501 train_loss: 0.4831134080886841 time_taken: 0.05718803405761719\n",
      "Epoch 3: iteration 2156/2501 train_loss: 0.48309946060180664 time_taken: 0.05684947967529297\n",
      "Epoch 3: iteration 2157/2501 train_loss: 0.4830820560455322 time_taken: 0.0572047233581543\n",
      "Epoch 3: iteration 2158/2501 train_loss: 0.48307526111602783 time_taken: 0.05685281753540039\n",
      "Epoch 3: iteration 2159/2501 train_loss: 0.48306483030319214 time_taken: 0.056787967681884766\n",
      "Epoch 3: iteration 2160/2501 train_loss: 0.4830597937107086 time_taken: 0.056687116622924805\n",
      "Epoch 3: iteration 2161/2501 train_loss: 0.48306745290756226 time_taken: 0.05707859992980957\n",
      "Epoch 3: iteration 2162/2501 train_loss: 0.4830745458602905 time_taken: 0.05662083625793457\n",
      "Epoch 3: iteration 2163/2501 train_loss: 0.4830833375453949 time_taken: 0.05749201774597168\n",
      "Epoch 3: iteration 2164/2501 train_loss: 0.48308905959129333 time_taken: 0.05740070343017578\n",
      "Epoch 3: iteration 2165/2501 train_loss: 0.48309969902038574 time_taken: 0.06149888038635254\n",
      "Epoch 3: iteration 2166/2501 train_loss: 0.48311182856559753 time_taken: 0.05687546730041504\n",
      "Epoch 3: iteration 2167/2501 train_loss: 0.4831145405769348 time_taken: 0.05698060989379883\n",
      "Epoch 3: iteration 2168/2501 train_loss: 0.48311957716941833 time_taken: 0.05604720115661621\n",
      "Epoch 3: iteration 2169/2501 train_loss: 0.483125776052475 time_taken: 0.056229591369628906\n",
      "Epoch 3: iteration 2170/2501 train_loss: 0.48313021659851074 time_taken: 0.05697154998779297\n",
      "Epoch 3: iteration 2171/2501 train_loss: 0.4831303656101227 time_taken: 0.05693483352661133\n",
      "Epoch 3: iteration 2172/2501 train_loss: 0.48312851786613464 time_taken: 0.056319236755371094\n",
      "Epoch 3: iteration 2173/2501 train_loss: 0.4831186532974243 time_taken: 0.057050466537475586\n",
      "Epoch 3: iteration 2174/2501 train_loss: 0.4831094443798065 time_taken: 0.05678224563598633\n",
      "Epoch 3: iteration 2175/2501 train_loss: 0.48309192061424255 time_taken: 0.05623435974121094\n",
      "Epoch 3: iteration 2176/2501 train_loss: 0.48308151960372925 time_taken: 0.05744290351867676\n",
      "Epoch 3: iteration 2177/2501 train_loss: 0.4830615818500519 time_taken: 0.05674600601196289\n",
      "Epoch 3: iteration 2178/2501 train_loss: 0.4830397963523865 time_taken: 0.05637812614440918\n",
      "Epoch 3: iteration 2179/2501 train_loss: 0.48302459716796875 time_taken: 0.056638240814208984\n",
      "Epoch 3: iteration 2180/2501 train_loss: 0.48301318287849426 time_taken: 0.056029558181762695\n",
      "Epoch 3: iteration 2181/2501 train_loss: 0.48304811120033264 time_taken: 0.056154727935791016\n",
      "Epoch 3: iteration 2182/2501 train_loss: 0.48314014077186584 time_taken: 0.05685114860534668\n",
      "Epoch 3: iteration 2183/2501 train_loss: 0.4831216633319855 time_taken: 0.05690932273864746\n",
      "Epoch 3: iteration 2184/2501 train_loss: 0.48316559195518494 time_taken: 0.056920766830444336\n",
      "Epoch 3: iteration 2185/2501 train_loss: 0.4831651449203491 time_taken: 0.05652976036071777\n",
      "Epoch 3: iteration 2186/2501 train_loss: 0.4831758439540863 time_taken: 0.05676865577697754\n",
      "Epoch 3: iteration 2187/2501 train_loss: 0.48320817947387695 time_taken: 0.05672168731689453\n",
      "Epoch 3: iteration 2188/2501 train_loss: 0.4832250773906708 time_taken: 0.05713510513305664\n",
      "Epoch 3: iteration 2189/2501 train_loss: 0.4832342863082886 time_taken: 0.05665850639343262\n",
      "Epoch 3: iteration 2190/2501 train_loss: 0.4832530915737152 time_taken: 0.05680441856384277\n",
      "Epoch 3: iteration 2191/2501 train_loss: 0.48325881361961365 time_taken: 0.056867361068725586\n",
      "Epoch 3: iteration 2192/2501 train_loss: 0.4832538366317749 time_taken: 0.05716562271118164\n",
      "Epoch 3: iteration 2193/2501 train_loss: 0.4832567870616913 time_taken: 0.05676984786987305\n",
      "Epoch 3: iteration 2194/2501 train_loss: 0.48325619101524353 time_taken: 0.05677342414855957\n",
      "Epoch 3: iteration 2195/2501 train_loss: 0.48324501514434814 time_taken: 0.056604623794555664\n",
      "Epoch 3: iteration 2196/2501 train_loss: 0.48323196172714233 time_taken: 0.05698394775390625\n",
      "Epoch 3: iteration 2197/2501 train_loss: 0.48321232199668884 time_taken: 0.05685734748840332\n",
      "Epoch 3: iteration 2198/2501 train_loss: 0.48318731784820557 time_taken: 0.0565495491027832\n",
      "Epoch 3: iteration 2199/2501 train_loss: 0.4831640124320984 time_taken: 0.0563962459564209\n",
      "Epoch 3: iteration 2200/2501 train_loss: 0.4831312298774719 time_taken: 0.05682682991027832\n",
      "Epoch 3: iteration 2201/2501 train_loss: 0.4830940365791321 time_taken: 0.05659914016723633\n",
      "Epoch 3: iteration 2202/2501 train_loss: 0.48306235671043396 time_taken: 0.0570676326751709\n",
      "Epoch 3: iteration 2203/2501 train_loss: 0.48302918672561646 time_taken: 0.05651402473449707\n",
      "Epoch 3: iteration 2204/2501 train_loss: 0.48299193382263184 time_taken: 0.05655193328857422\n",
      "Epoch 3: iteration 2205/2501 train_loss: 0.4829491078853607 time_taken: 0.05655026435852051\n",
      "Epoch 3: iteration 2206/2501 train_loss: 0.4829176664352417 time_taken: 0.05700564384460449\n",
      "Epoch 3: iteration 2207/2501 train_loss: 0.48288482427597046 time_taken: 0.05607795715332031\n",
      "Epoch 3: iteration 2208/2501 train_loss: 0.4828576445579529 time_taken: 0.056676387786865234\n",
      "Epoch 3: iteration 2209/2501 train_loss: 0.4828309416770935 time_taken: 0.05655550956726074\n",
      "Epoch 3: iteration 2210/2501 train_loss: 0.4828091263771057 time_taken: 0.056509971618652344\n",
      "Epoch 3: iteration 2211/2501 train_loss: 0.48279592394828796 time_taken: 0.05720782279968262\n",
      "Epoch 3: iteration 2212/2501 train_loss: 0.48278626799583435 time_taken: 0.05655050277709961\n",
      "Epoch 3: iteration 2213/2501 train_loss: 0.4827842712402344 time_taken: 0.056433916091918945\n",
      "Epoch 3: iteration 2214/2501 train_loss: 0.4827892482280731 time_taken: 0.05620551109313965\n",
      "Epoch 3: iteration 2215/2501 train_loss: 0.4827967882156372 time_taken: 0.05699634552001953\n",
      "Epoch 3: iteration 2216/2501 train_loss: 0.48280543088912964 time_taken: 0.05732846260070801\n",
      "Epoch 3: iteration 2217/2501 train_loss: 0.4828170835971832 time_taken: 0.05614876747131348\n",
      "Epoch 3: iteration 2218/2501 train_loss: 0.48283594846725464 time_taken: 0.06099891662597656\n",
      "Epoch 3: iteration 2219/2501 train_loss: 0.482852965593338 time_taken: 0.05626630783081055\n",
      "Epoch 3: iteration 2220/2501 train_loss: 0.4828599691390991 time_taken: 0.057383060455322266\n",
      "Epoch 3: iteration 2221/2501 train_loss: 0.4828703701496124 time_taken: 0.060884952545166016\n",
      "Epoch 3: iteration 2222/2501 train_loss: 0.4828794598579407 time_taken: 0.05601859092712402\n",
      "Epoch 3: iteration 2223/2501 train_loss: 0.4828960597515106 time_taken: 0.05606698989868164\n",
      "Epoch 3: iteration 2224/2501 train_loss: 0.4829156994819641 time_taken: 0.05622673034667969\n",
      "Epoch 3: iteration 2225/2501 train_loss: 0.4829263985157013 time_taken: 0.0563054084777832\n",
      "Epoch 3: iteration 2226/2501 train_loss: 0.4829387664794922 time_taken: 0.05664801597595215\n",
      "Epoch 3: iteration 2227/2501 train_loss: 0.482954204082489 time_taken: 0.056321144104003906\n",
      "Epoch 3: iteration 2228/2501 train_loss: 0.48297011852264404 time_taken: 0.056180477142333984\n",
      "Epoch 3: iteration 2229/2501 train_loss: 0.4829844832420349 time_taken: 0.05638575553894043\n",
      "Epoch 3: iteration 2230/2501 train_loss: 0.4829961061477661 time_taken: 0.05681180953979492\n",
      "Epoch 3: iteration 2231/2501 train_loss: 0.4830206334590912 time_taken: 0.05679774284362793\n",
      "Epoch 3: iteration 2232/2501 train_loss: 0.48303964734077454 time_taken: 0.05708026885986328\n",
      "Epoch 3: iteration 2233/2501 train_loss: 0.4830688238143921 time_taken: 0.057806968688964844\n",
      "Epoch 3: iteration 2234/2501 train_loss: 0.48308852314949036 time_taken: 0.0568690299987793\n",
      "Epoch 3: iteration 2235/2501 train_loss: 0.4831191301345825 time_taken: 0.05817747116088867\n",
      "Epoch 3: iteration 2236/2501 train_loss: 0.4831543564796448 time_taken: 0.05703258514404297\n",
      "Epoch 3: iteration 2237/2501 train_loss: 0.4831891655921936 time_taken: 0.05668449401855469\n",
      "Epoch 3: iteration 2238/2501 train_loss: 0.48321864008903503 time_taken: 0.05706501007080078\n",
      "Epoch 3: iteration 2239/2501 train_loss: 0.4832551181316376 time_taken: 0.056847333908081055\n",
      "Epoch 3: iteration 2240/2501 train_loss: 0.48328539729118347 time_taken: 0.05665469169616699\n",
      "Epoch 3: iteration 2241/2501 train_loss: 0.48332053422927856 time_taken: 0.057129621505737305\n",
      "Epoch 3: iteration 2242/2501 train_loss: 0.4833492338657379 time_taken: 0.05701160430908203\n",
      "Epoch 3: iteration 2243/2501 train_loss: 0.4833803176879883 time_taken: 0.05697798728942871\n",
      "Epoch 3: iteration 2244/2501 train_loss: 0.4834054410457611 time_taken: 0.056405067443847656\n",
      "Epoch 3: iteration 2245/2501 train_loss: 0.4834424555301666 time_taken: 0.05617475509643555\n",
      "Epoch 3: iteration 2246/2501 train_loss: 0.48347726464271545 time_taken: 0.0564267635345459\n",
      "Epoch 3: iteration 2247/2501 train_loss: 0.4835119843482971 time_taken: 0.056438446044921875\n",
      "Epoch 3: iteration 2248/2501 train_loss: 0.4835430383682251 time_taken: 0.05706191062927246\n",
      "Epoch 3: iteration 2249/2501 train_loss: 0.48357632756233215 time_taken: 0.05666518211364746\n",
      "Epoch 3: iteration 2250/2501 train_loss: 0.48361241817474365 time_taken: 0.05668020248413086\n",
      "Epoch 3: iteration 2251/2501 train_loss: 0.4836547076702118 time_taken: 0.05751228332519531\n",
      "Epoch 3: iteration 2252/2501 train_loss: 0.4836968779563904 time_taken: 0.05679035186767578\n",
      "Epoch 3: iteration 2253/2501 train_loss: 0.48373356461524963 time_taken: 0.058173179626464844\n",
      "Epoch 3: iteration 2254/2501 train_loss: 0.48375457525253296 time_taken: 0.05696272850036621\n",
      "Epoch 3: iteration 2255/2501 train_loss: 0.4837786555290222 time_taken: 0.05625295639038086\n",
      "Epoch 3: iteration 2256/2501 train_loss: 0.4837954640388489 time_taken: 0.05620145797729492\n",
      "Epoch 3: iteration 2257/2501 train_loss: 0.4838015139102936 time_taken: 0.05627846717834473\n",
      "Epoch 3: iteration 2258/2501 train_loss: 0.48380738496780396 time_taken: 0.05605673789978027\n",
      "Epoch 3: iteration 2259/2501 train_loss: 0.4838078022003174 time_taken: 0.05597686767578125\n",
      "Epoch 3: iteration 2260/2501 train_loss: 0.48380735516548157 time_taken: 0.05745363235473633\n",
      "Epoch 3: iteration 2261/2501 train_loss: 0.4838072955608368 time_taken: 0.05703163146972656\n",
      "Epoch 3: iteration 2262/2501 train_loss: 0.4838070571422577 time_taken: 0.05687713623046875\n",
      "Epoch 3: iteration 2263/2501 train_loss: 0.48379889130592346 time_taken: 0.057799577713012695\n",
      "Epoch 3: iteration 2264/2501 train_loss: 0.4837861657142639 time_taken: 0.05682516098022461\n",
      "Epoch 3: iteration 2265/2501 train_loss: 0.48377659916877747 time_taken: 0.056850433349609375\n",
      "Epoch 3: iteration 2266/2501 train_loss: 0.4837690591812134 time_taken: 0.05683445930480957\n",
      "Epoch 3: iteration 2267/2501 train_loss: 0.48376309871673584 time_taken: 0.05744600296020508\n",
      "Epoch 3: iteration 2268/2501 train_loss: 0.4837587773799896 time_taken: 0.05653786659240723\n",
      "Epoch 3: iteration 2269/2501 train_loss: 0.4837574362754822 time_taken: 0.0560762882232666\n",
      "Epoch 3: iteration 2270/2501 train_loss: 0.4837566316127777 time_taken: 0.057106971740722656\n",
      "Epoch 3: iteration 2271/2501 train_loss: 0.48375535011291504 time_taken: 0.05660748481750488\n",
      "Epoch 3: iteration 2272/2501 train_loss: 0.48375555872917175 time_taken: 0.056600332260131836\n",
      "Epoch 3: iteration 2273/2501 train_loss: 0.48375117778778076 time_taken: 0.0566864013671875\n",
      "Epoch 3: iteration 2274/2501 train_loss: 0.48375239968299866 time_taken: 0.056221723556518555\n",
      "Epoch 3: iteration 2275/2501 train_loss: 0.48375311493873596 time_taken: 0.056604623794555664\n",
      "Epoch 3: iteration 2276/2501 train_loss: 0.48375827074050903 time_taken: 0.05721879005432129\n",
      "Epoch 3: iteration 2277/2501 train_loss: 0.48376211524009705 time_taken: 0.05683636665344238\n",
      "Epoch 3: iteration 2278/2501 train_loss: 0.4837721884250641 time_taken: 0.07087230682373047\n",
      "Epoch 3: iteration 2279/2501 train_loss: 0.4837804436683655 time_taken: 0.05626392364501953\n",
      "Epoch 3: iteration 2280/2501 train_loss: 0.4837951064109802 time_taken: 0.0754389762878418\n",
      "Epoch 3: iteration 2281/2501 train_loss: 0.48380669951438904 time_taken: 0.05641317367553711\n",
      "Epoch 3: iteration 2282/2501 train_loss: 0.48382115364074707 time_taken: 0.05661416053771973\n",
      "Epoch 3: iteration 2283/2501 train_loss: 0.4838353097438812 time_taken: 0.05702042579650879\n",
      "Epoch 3: iteration 2284/2501 train_loss: 0.4838491678237915 time_taken: 0.057084083557128906\n",
      "Epoch 3: iteration 2285/2501 train_loss: 0.4838639795780182 time_taken: 0.05729985237121582\n",
      "Epoch 3: iteration 2286/2501 train_loss: 0.4838840365409851 time_taken: 0.05689668655395508\n",
      "Epoch 3: iteration 2287/2501 train_loss: 0.4839012324810028 time_taken: 0.057367801666259766\n",
      "Epoch 3: iteration 2288/2501 train_loss: 0.4839273691177368 time_taken: 0.05735635757446289\n",
      "Epoch 3: iteration 2289/2501 train_loss: 0.48395654559135437 time_taken: 0.05683469772338867\n",
      "Epoch 3: iteration 2290/2501 train_loss: 0.48398566246032715 time_taken: 0.05743575096130371\n",
      "Epoch 3: iteration 2291/2501 train_loss: 0.48402339220046997 time_taken: 0.05650496482849121\n",
      "Epoch 3: iteration 2292/2501 train_loss: 0.4840605854988098 time_taken: 0.05767059326171875\n",
      "Epoch 3: iteration 2293/2501 train_loss: 0.48409372568130493 time_taken: 0.05698251724243164\n",
      "Epoch 3: iteration 2294/2501 train_loss: 0.48413121700286865 time_taken: 0.057285308837890625\n",
      "Epoch 3: iteration 2295/2501 train_loss: 0.48416003584861755 time_taken: 0.05644488334655762\n",
      "Epoch 3: iteration 2296/2501 train_loss: 0.48421016335487366 time_taken: 0.056867361068725586\n",
      "Epoch 3: iteration 2297/2501 train_loss: 0.48424723744392395 time_taken: 0.057288408279418945\n",
      "Epoch 3: iteration 2298/2501 train_loss: 0.4842865467071533 time_taken: 0.0605466365814209\n",
      "Epoch 3: iteration 2299/2501 train_loss: 0.48431676626205444 time_taken: 0.05632281303405762\n",
      "Epoch 3: iteration 2300/2501 train_loss: 0.4843517541885376 time_taken: 0.05635476112365723\n",
      "Epoch 3: iteration 2301/2501 train_loss: 0.4843827486038208 time_taken: 0.05607342720031738\n",
      "Epoch 3: iteration 2302/2501 train_loss: 0.48441559076309204 time_taken: 0.05694770812988281\n",
      "Epoch 3: iteration 2303/2501 train_loss: 0.48445674777030945 time_taken: 0.05655312538146973\n",
      "Epoch 3: iteration 2304/2501 train_loss: 0.484492689371109 time_taken: 0.05704450607299805\n",
      "Epoch 3: iteration 2305/2501 train_loss: 0.4845274090766907 time_taken: 0.05701804161071777\n",
      "Epoch 3: iteration 2306/2501 train_loss: 0.48456040024757385 time_taken: 0.05725860595703125\n",
      "Epoch 3: iteration 2307/2501 train_loss: 0.48458802700042725 time_taken: 0.05771660804748535\n",
      "Epoch 3: iteration 2308/2501 train_loss: 0.48461538553237915 time_taken: 0.056862831115722656\n",
      "Epoch 3: iteration 2309/2501 train_loss: 0.4846542179584503 time_taken: 0.05740857124328613\n",
      "Epoch 3: iteration 2310/2501 train_loss: 0.48468706011772156 time_taken: 0.058152198791503906\n",
      "Epoch 3: iteration 2311/2501 train_loss: 0.48472630977630615 time_taken: 0.05652499198913574\n",
      "Epoch 3: iteration 2312/2501 train_loss: 0.4847528338432312 time_taken: 0.05695939064025879\n",
      "Epoch 3: iteration 2313/2501 train_loss: 0.484794020652771 time_taken: 0.06849980354309082\n",
      "Epoch 3: iteration 2314/2501 train_loss: 0.48483702540397644 time_taken: 0.05740857124328613\n",
      "Epoch 3: iteration 2315/2501 train_loss: 0.484875351190567 time_taken: 0.05679202079772949\n",
      "Epoch 3: iteration 2316/2501 train_loss: 0.48490774631500244 time_taken: 0.05765938758850098\n",
      "Epoch 3: iteration 2317/2501 train_loss: 0.4849487543106079 time_taken: 0.05657362937927246\n",
      "Epoch 3: iteration 2318/2501 train_loss: 0.4849867820739746 time_taken: 0.05628538131713867\n",
      "Epoch 3: iteration 2319/2501 train_loss: 0.48503008484840393 time_taken: 0.0570683479309082\n",
      "Epoch 3: iteration 2320/2501 train_loss: 0.4850655496120453 time_taken: 0.05763363838195801\n",
      "Epoch 3: iteration 2321/2501 train_loss: 0.4851122498512268 time_taken: 0.057584285736083984\n",
      "Epoch 3: iteration 2322/2501 train_loss: 0.4851418435573578 time_taken: 0.057791709899902344\n",
      "Epoch 3: iteration 2323/2501 train_loss: 0.4851756989955902 time_taken: 0.05735158920288086\n",
      "Epoch 3: iteration 2324/2501 train_loss: 0.4852057099342346 time_taken: 0.05667257308959961\n",
      "Epoch 3: iteration 2325/2501 train_loss: 0.4852302372455597 time_taken: 0.056241750717163086\n",
      "Epoch 3: iteration 2326/2501 train_loss: 0.4852529466152191 time_taken: 0.056372642517089844\n",
      "Epoch 3: iteration 2327/2501 train_loss: 0.4852744936943054 time_taken: 0.05691981315612793\n",
      "Epoch 3: iteration 2328/2501 train_loss: 0.48529988527297974 time_taken: 0.05645298957824707\n",
      "Epoch 3: iteration 2329/2501 train_loss: 0.48532459139823914 time_taken: 0.05712318420410156\n",
      "Epoch 3: iteration 2330/2501 train_loss: 0.4853512942790985 time_taken: 0.05648374557495117\n",
      "Epoch 3: iteration 2331/2501 train_loss: 0.4853653907775879 time_taken: 0.05768918991088867\n",
      "Epoch 3: iteration 2332/2501 train_loss: 0.4853809177875519 time_taken: 0.05721473693847656\n",
      "Epoch 3: iteration 2333/2501 train_loss: 0.4854001998901367 time_taken: 0.05734443664550781\n",
      "Epoch 3: iteration 2334/2501 train_loss: 0.485408753156662 time_taken: 0.05754804611206055\n",
      "Epoch 3: iteration 2335/2501 train_loss: 0.4854220151901245 time_taken: 0.056688785552978516\n",
      "Epoch 3: iteration 2336/2501 train_loss: 0.4854382574558258 time_taken: 0.05719137191772461\n",
      "Epoch 3: iteration 2337/2501 train_loss: 0.48546090722084045 time_taken: 0.056856632232666016\n",
      "Epoch 3: iteration 2338/2501 train_loss: 0.48548203706741333 time_taken: 0.05703997611999512\n",
      "Epoch 3: iteration 2339/2501 train_loss: 0.4854961037635803 time_taken: 0.05709981918334961\n",
      "Epoch 3: iteration 2340/2501 train_loss: 0.48551830649375916 time_taken: 0.05713629722595215\n",
      "Epoch 3: iteration 2341/2501 train_loss: 0.48553764820098877 time_taken: 0.056954145431518555\n",
      "Epoch 3: iteration 2342/2501 train_loss: 0.48555710911750793 time_taken: 0.056429386138916016\n",
      "Epoch 3: iteration 2343/2501 train_loss: 0.48557278513908386 time_taken: 0.056199073791503906\n",
      "Epoch 3: iteration 2344/2501 train_loss: 0.48558467626571655 time_taken: 0.06194710731506348\n",
      "Epoch 3: iteration 2345/2501 train_loss: 0.4855934679508209 time_taken: 0.056717634201049805\n",
      "Epoch 3: iteration 2346/2501 train_loss: 0.4856035113334656 time_taken: 0.0561826229095459\n",
      "Epoch 3: iteration 2347/2501 train_loss: 0.4856134355068207 time_taken: 0.056694984436035156\n",
      "Epoch 3: iteration 2348/2501 train_loss: 0.48562029004096985 time_taken: 0.056794166564941406\n",
      "Epoch 3: iteration 2349/2501 train_loss: 0.485623300075531 time_taken: 0.05643343925476074\n",
      "Epoch 3: iteration 2350/2501 train_loss: 0.48561570048332214 time_taken: 0.057135581970214844\n",
      "Epoch 3: iteration 2351/2501 train_loss: 0.4856146574020386 time_taken: 0.05616426467895508\n",
      "Epoch 3: iteration 2352/2501 train_loss: 0.4855985939502716 time_taken: 0.05664849281311035\n",
      "Epoch 3: iteration 2353/2501 train_loss: 0.48558735847473145 time_taken: 0.05722332000732422\n",
      "Epoch 3: iteration 2354/2501 train_loss: 0.4855795204639435 time_taken: 0.0564267635345459\n",
      "Epoch 3: iteration 2355/2501 train_loss: 0.48555994033813477 time_taken: 0.05741286277770996\n",
      "Epoch 3: iteration 2356/2501 train_loss: 0.4855422079563141 time_taken: 0.05729389190673828\n",
      "Epoch 3: iteration 2357/2501 train_loss: 0.4855211675167084 time_taken: 0.05656290054321289\n",
      "Epoch 3: iteration 2358/2501 train_loss: 0.48549219965934753 time_taken: 0.05653977394104004\n",
      "Epoch 3: iteration 2359/2501 train_loss: 0.48546525835990906 time_taken: 0.057292938232421875\n",
      "Epoch 3: iteration 2360/2501 train_loss: 0.4854392111301422 time_taken: 0.05659365653991699\n",
      "Epoch 3: iteration 2361/2501 train_loss: 0.48540857434272766 time_taken: 0.05712604522705078\n",
      "Epoch 3: iteration 2362/2501 train_loss: 0.4853680431842804 time_taken: 0.05657601356506348\n",
      "Epoch 3: iteration 2363/2501 train_loss: 0.4853360652923584 time_taken: 0.05741071701049805\n",
      "Epoch 3: iteration 2364/2501 train_loss: 0.485309898853302 time_taken: 0.05678248405456543\n",
      "Epoch 3: iteration 2365/2501 train_loss: 0.48528701066970825 time_taken: 0.05677938461303711\n",
      "Epoch 3: iteration 2366/2501 train_loss: 0.4852624535560608 time_taken: 0.05676460266113281\n",
      "Epoch 3: iteration 2367/2501 train_loss: 0.48524099588394165 time_taken: 0.05668997764587402\n",
      "Epoch 3: iteration 2368/2501 train_loss: 0.48521485924720764 time_taken: 0.056806087493896484\n",
      "Epoch 3: iteration 2369/2501 train_loss: 0.48519420623779297 time_taken: 0.05637621879577637\n",
      "Epoch 3: iteration 2370/2501 train_loss: 0.4851663112640381 time_taken: 0.05682635307312012\n",
      "Epoch 3: iteration 2371/2501 train_loss: 0.4851425290107727 time_taken: 0.05669069290161133\n",
      "Epoch 3: iteration 2372/2501 train_loss: 0.48511436581611633 time_taken: 0.05656552314758301\n",
      "Epoch 3: iteration 2373/2501 train_loss: 0.48509472608566284 time_taken: 0.056389808654785156\n",
      "Epoch 3: iteration 2374/2501 train_loss: 0.4850759208202362 time_taken: 0.07184004783630371\n",
      "Epoch 3: iteration 2375/2501 train_loss: 0.48505640029907227 time_taken: 0.07213950157165527\n",
      "Epoch 3: iteration 2376/2501 train_loss: 0.48504143953323364 time_taken: 0.05658102035522461\n",
      "Epoch 3: iteration 2377/2501 train_loss: 0.4850274920463562 time_taken: 0.05729985237121582\n",
      "Epoch 3: iteration 2378/2501 train_loss: 0.48501697182655334 time_taken: 0.05692577362060547\n",
      "Epoch 3: iteration 2379/2501 train_loss: 0.48500970005989075 time_taken: 0.05671048164367676\n",
      "Epoch 3: iteration 2380/2501 train_loss: 0.48500990867614746 time_taken: 0.05641770362854004\n",
      "Epoch 3: iteration 2381/2501 train_loss: 0.48501041531562805 time_taken: 0.05724358558654785\n",
      "Epoch 3: iteration 2382/2501 train_loss: 0.4850120544433594 time_taken: 0.05738496780395508\n",
      "Epoch 3: iteration 2383/2501 train_loss: 0.48501288890838623 time_taken: 0.05661773681640625\n",
      "Epoch 3: iteration 2384/2501 train_loss: 0.48501938581466675 time_taken: 0.0569913387298584\n",
      "Epoch 3: iteration 2385/2501 train_loss: 0.4850195646286011 time_taken: 0.05757331848144531\n",
      "Epoch 3: iteration 2386/2501 train_loss: 0.4850160479545593 time_taken: 0.05719494819641113\n",
      "Epoch 3: iteration 2387/2501 train_loss: 0.48501336574554443 time_taken: 0.05751538276672363\n",
      "Epoch 3: iteration 2388/2501 train_loss: 0.48500773310661316 time_taken: 0.05666160583496094\n",
      "Epoch 3: iteration 2389/2501 train_loss: 0.48499515652656555 time_taken: 0.056398868560791016\n",
      "Epoch 3: iteration 2390/2501 train_loss: 0.4849826991558075 time_taken: 0.05693244934082031\n",
      "Epoch 3: iteration 2391/2501 train_loss: 0.4849703907966614 time_taken: 0.0569148063659668\n",
      "Epoch 3: iteration 2392/2501 train_loss: 0.48495903611183167 time_taken: 0.05709266662597656\n",
      "Epoch 3: iteration 2393/2501 train_loss: 0.48494747281074524 time_taken: 0.059004783630371094\n",
      "Epoch 3: iteration 2394/2501 train_loss: 0.4849473237991333 time_taken: 0.056943416595458984\n",
      "Epoch 3: iteration 2395/2501 train_loss: 0.4849470853805542 time_taken: 0.05663156509399414\n",
      "Epoch 3: iteration 2396/2501 train_loss: 0.4849478602409363 time_taken: 0.05744600296020508\n",
      "Epoch 3: iteration 2397/2501 train_loss: 0.4849454462528229 time_taken: 0.05663895606994629\n",
      "Epoch 3: iteration 2398/2501 train_loss: 0.48494356870651245 time_taken: 0.05732321739196777\n",
      "Epoch 3: iteration 2399/2501 train_loss: 0.4849506616592407 time_taken: 0.0574338436126709\n",
      "Epoch 3: iteration 2400/2501 train_loss: 0.48495185375213623 time_taken: 0.05711030960083008\n",
      "Epoch 3: iteration 2401/2501 train_loss: 0.4849536418914795 time_taken: 0.056630611419677734\n",
      "Epoch 3: iteration 2402/2501 train_loss: 0.4849510192871094 time_taken: 0.05723929405212402\n",
      "Epoch 3: iteration 2403/2501 train_loss: 0.484946608543396 time_taken: 0.05714726448059082\n",
      "Epoch 3: iteration 2404/2501 train_loss: 0.48494526743888855 time_taken: 0.05683636665344238\n",
      "Epoch 3: iteration 2405/2501 train_loss: 0.48494353890419006 time_taken: 0.0565946102142334\n",
      "Epoch 3: iteration 2406/2501 train_loss: 0.484940767288208 time_taken: 0.05736088752746582\n",
      "Epoch 3: iteration 2407/2501 train_loss: 0.48493561148643494 time_taken: 0.05628776550292969\n",
      "Epoch 3: iteration 2408/2501 train_loss: 0.48492977023124695 time_taken: 0.05630016326904297\n",
      "Epoch 3: iteration 2409/2501 train_loss: 0.4849245548248291 time_taken: 0.05663609504699707\n",
      "Epoch 3: iteration 2410/2501 train_loss: 0.4849186837673187 time_taken: 0.05668950080871582\n",
      "Epoch 3: iteration 2411/2501 train_loss: 0.4849211871623993 time_taken: 0.05701041221618652\n",
      "Epoch 3: iteration 2412/2501 train_loss: 0.4849250912666321 time_taken: 0.057320594787597656\n",
      "Epoch 3: iteration 2413/2501 train_loss: 0.4849283695220947 time_taken: 0.05706024169921875\n",
      "Epoch 3: iteration 2414/2501 train_loss: 0.4849357008934021 time_taken: 0.057091474533081055\n",
      "Epoch 3: iteration 2415/2501 train_loss: 0.4849434196949005 time_taken: 0.05685710906982422\n",
      "Epoch 3: iteration 2416/2501 train_loss: 0.4849507510662079 time_taken: 0.057001590728759766\n",
      "Epoch 3: iteration 2417/2501 train_loss: 0.4849700629711151 time_taken: 0.0569605827331543\n",
      "Epoch 3: iteration 2418/2501 train_loss: 0.48498642444610596 time_taken: 0.05666184425354004\n",
      "Epoch 3: iteration 2419/2501 train_loss: 0.4849962592124939 time_taken: 0.056496620178222656\n",
      "Epoch 3: iteration 2420/2501 train_loss: 0.4850059747695923 time_taken: 0.05664420127868652\n",
      "Epoch 3: iteration 2421/2501 train_loss: 0.48501116037368774 time_taken: 0.056642770767211914\n",
      "Epoch 3: iteration 2422/2501 train_loss: 0.48501765727996826 time_taken: 0.0562746524810791\n",
      "Epoch 3: iteration 2423/2501 train_loss: 0.4850313365459442 time_taken: 0.05615949630737305\n",
      "Epoch 3: iteration 2424/2501 train_loss: 0.4850447475910187 time_taken: 0.05618786811828613\n",
      "Epoch 3: iteration 2425/2501 train_loss: 0.48505890369415283 time_taken: 0.05610036849975586\n",
      "Epoch 3: iteration 2426/2501 train_loss: 0.4850725531578064 time_taken: 0.056496381759643555\n",
      "Epoch 3: iteration 2427/2501 train_loss: 0.48508965969085693 time_taken: 0.056276559829711914\n",
      "Epoch 3: iteration 2428/2501 train_loss: 0.4851112365722656 time_taken: 0.05734372138977051\n",
      "Epoch 3: iteration 2429/2501 train_loss: 0.48512983322143555 time_taken: 0.05748581886291504\n",
      "Epoch 3: iteration 2430/2501 train_loss: 0.48515617847442627 time_taken: 0.05629086494445801\n",
      "Epoch 3: iteration 2431/2501 train_loss: 0.4851830005645752 time_taken: 0.06100130081176758\n",
      "Epoch 3: iteration 2432/2501 train_loss: 0.48520681262016296 time_taken: 0.05660653114318848\n",
      "Epoch 3: iteration 2433/2501 train_loss: 0.4852333962917328 time_taken: 0.05666041374206543\n",
      "Epoch 3: iteration 2434/2501 train_loss: 0.48526081442832947 time_taken: 0.05632805824279785\n",
      "Epoch 3: iteration 2435/2501 train_loss: 0.48529139161109924 time_taken: 0.05658221244812012\n",
      "Epoch 3: iteration 2436/2501 train_loss: 0.4853143095970154 time_taken: 0.056487083435058594\n",
      "Epoch 3: iteration 2437/2501 train_loss: 0.48533740639686584 time_taken: 0.05650186538696289\n",
      "Epoch 3: iteration 2438/2501 train_loss: 0.48536357283592224 time_taken: 0.05646228790283203\n",
      "Epoch 3: iteration 2439/2501 train_loss: 0.48539069294929504 time_taken: 0.05618715286254883\n",
      "Epoch 3: iteration 2440/2501 train_loss: 0.4854218661785126 time_taken: 0.05721163749694824\n",
      "Epoch 3: iteration 2441/2501 train_loss: 0.485464870929718 time_taken: 0.057353973388671875\n",
      "Epoch 3: iteration 2442/2501 train_loss: 0.48549193143844604 time_taken: 0.05696582794189453\n",
      "Epoch 3: iteration 2443/2501 train_loss: 0.4855205714702606 time_taken: 0.05688357353210449\n",
      "Epoch 3: iteration 2444/2501 train_loss: 0.485553115606308 time_taken: 0.05658864974975586\n",
      "Epoch 3: iteration 2445/2501 train_loss: 0.4855906665325165 time_taken: 0.056279897689819336\n",
      "Epoch 3: iteration 2446/2501 train_loss: 0.48562145233154297 time_taken: 0.05727243423461914\n",
      "Epoch 3: iteration 2447/2501 train_loss: 0.48564890027046204 time_taken: 0.056640625\n",
      "Epoch 3: iteration 2448/2501 train_loss: 0.4856710135936737 time_taken: 0.05690431594848633\n",
      "Epoch 3: iteration 2449/2501 train_loss: 0.4856918752193451 time_taken: 0.05644345283508301\n",
      "Epoch 3: iteration 2450/2501 train_loss: 0.4857035279273987 time_taken: 0.05636191368103027\n",
      "Epoch 3: iteration 2451/2501 train_loss: 0.4857213497161865 time_taken: 0.05688905715942383\n",
      "Epoch 3: iteration 2452/2501 train_loss: 0.48572662472724915 time_taken: 0.05701184272766113\n",
      "Epoch 3: iteration 2453/2501 train_loss: 0.4857272803783417 time_taken: 0.05700802803039551\n",
      "Epoch 3: iteration 2454/2501 train_loss: 0.48573070764541626 time_taken: 0.05663609504699707\n",
      "Epoch 3: iteration 2455/2501 train_loss: 0.4857233762741089 time_taken: 0.05730700492858887\n",
      "Epoch 3: iteration 2456/2501 train_loss: 0.4857238829135895 time_taken: 0.0568544864654541\n",
      "Epoch 3: iteration 2457/2501 train_loss: 0.48572075366973877 time_taken: 0.0569300651550293\n",
      "Epoch 3: iteration 2458/2501 train_loss: 0.4857141971588135 time_taken: 0.05669260025024414\n",
      "Epoch 3: iteration 2459/2501 train_loss: 0.48570170998573303 time_taken: 0.05718088150024414\n",
      "Epoch 3: iteration 2460/2501 train_loss: 0.4856896996498108 time_taken: 0.05727529525756836\n",
      "Epoch 3: iteration 2461/2501 train_loss: 0.4856764078140259 time_taken: 0.05674123764038086\n",
      "Epoch 3: iteration 2462/2501 train_loss: 0.48567134141921997 time_taken: 0.0566716194152832\n",
      "Epoch 3: iteration 2463/2501 train_loss: 0.4856812655925751 time_taken: 0.056777000427246094\n",
      "Epoch 3: iteration 2464/2501 train_loss: 0.4856870770454407 time_taken: 0.05695676803588867\n",
      "Epoch 3: iteration 2465/2501 train_loss: 0.4856956899166107 time_taken: 0.05672430992126465\n",
      "Epoch 3: iteration 2466/2501 train_loss: 0.48571649193763733 time_taken: 0.05731320381164551\n",
      "Epoch 3: iteration 2467/2501 train_loss: 0.4857376515865326 time_taken: 0.056426286697387695\n",
      "Epoch 3: iteration 2468/2501 train_loss: 0.48575103282928467 time_taken: 0.05744504928588867\n",
      "Epoch 3: iteration 2469/2501 train_loss: 0.4857630431652069 time_taken: 0.05793023109436035\n",
      "Epoch 3: iteration 2470/2501 train_loss: 0.48576608300209045 time_taken: 0.057131052017211914\n",
      "Epoch 3: iteration 2471/2501 train_loss: 0.4857734739780426 time_taken: 0.05727696418762207\n",
      "Epoch 3: iteration 2472/2501 train_loss: 0.48578718304634094 time_taken: 0.05674433708190918\n",
      "Epoch 3: iteration 2473/2501 train_loss: 0.4857962727546692 time_taken: 0.0570526123046875\n",
      "Epoch 3: iteration 2474/2501 train_loss: 0.4858008325099945 time_taken: 0.05649280548095703\n",
      "Epoch 3: iteration 2475/2501 train_loss: 0.48580217361450195 time_taken: 0.056014299392700195\n",
      "Epoch 3: iteration 2476/2501 train_loss: 0.48582032322883606 time_taken: 0.05621814727783203\n",
      "Epoch 3: iteration 2477/2501 train_loss: 0.4858457148075104 time_taken: 0.05682730674743652\n",
      "Epoch 3: iteration 2478/2501 train_loss: 0.48586708307266235 time_taken: 0.056467294692993164\n",
      "Epoch 3: iteration 2479/2501 train_loss: 0.48588788509368896 time_taken: 0.05695056915283203\n",
      "Epoch 3: iteration 2480/2501 train_loss: 0.48591870069503784 time_taken: 0.05644631385803223\n",
      "Epoch 3: iteration 2481/2501 train_loss: 0.48595374822616577 time_taken: 0.056580305099487305\n",
      "Epoch 3: iteration 2482/2501 train_loss: 0.4859955906867981 time_taken: 0.056720733642578125\n",
      "Epoch 3: iteration 2483/2501 train_loss: 0.4860207438468933 time_taken: 0.057131052017211914\n",
      "Epoch 3: iteration 2484/2501 train_loss: 0.48606762290000916 time_taken: 0.05675935745239258\n",
      "Epoch 3: iteration 2485/2501 train_loss: 0.4861172139644623 time_taken: 0.056534767150878906\n",
      "Epoch 3: iteration 2486/2501 train_loss: 0.48619839549064636 time_taken: 0.05708050727844238\n",
      "Epoch 3: iteration 2487/2501 train_loss: 0.48628470301628113 time_taken: 0.056136369705200195\n",
      "Epoch 3: iteration 2488/2501 train_loss: 0.48634955286979675 time_taken: 0.05609536170959473\n",
      "Epoch 3: iteration 2489/2501 train_loss: 0.4864102900028229 time_taken: 0.05646777153015137\n",
      "Epoch 3: iteration 2490/2501 train_loss: 0.4864656925201416 time_taken: 0.05606889724731445\n",
      "Epoch 3: iteration 2491/2501 train_loss: 0.48651832342147827 time_taken: 0.05619978904724121\n",
      "Epoch 3: iteration 2492/2501 train_loss: 0.4865567088127136 time_taken: 0.05765652656555176\n",
      "Epoch 3: iteration 2493/2501 train_loss: 0.4865962862968445 time_taken: 0.056203603744506836\n",
      "Epoch 3: iteration 2494/2501 train_loss: 0.48662737011909485 time_taken: 0.05651569366455078\n",
      "Epoch 3: iteration 2495/2501 train_loss: 0.4866606891155243 time_taken: 0.05637383460998535\n",
      "Epoch 3: iteration 2496/2501 train_loss: 0.48669061064720154 time_taken: 0.05632519721984863\n",
      "Epoch 3: iteration 2497/2501 train_loss: 0.48671627044677734 time_taken: 0.056047677993774414\n",
      "Epoch 3: iteration 2498/2501 train_loss: 0.4867379069328308 time_taken: 0.05591893196105957\n",
      "Epoch 3: iteration 2499/2501 train_loss: 0.4867555797100067 time_taken: 0.055942535400390625\n",
      "Epoch 3: iteration 2500/2501 train_loss: 0.4867779314517975 time_taken: 0.05498528480529785\n",
      "Finished epoch 3 took 448.1595709323883\n",
      "Starting epoch 4/5\n",
      "Epoch 4: iteration 0/2501 train_loss: 0.591090738773346 time_taken: 0.057260751724243164\n",
      "Epoch 4: iteration 1/2501 train_loss: 0.5767751336097717 time_taken: 0.056652069091796875\n",
      "Epoch 4: iteration 2/2501 train_loss: 0.5636792182922363 time_taken: 0.05712628364562988\n",
      "Epoch 4: iteration 3/2501 train_loss: 0.5643668174743652 time_taken: 0.06478190422058105\n",
      "Epoch 4: iteration 4/2501 train_loss: 0.5593173503875732 time_taken: 0.0563969612121582\n",
      "Epoch 4: iteration 5/2501 train_loss: 0.5534815788269043 time_taken: 0.05670332908630371\n",
      "Epoch 4: iteration 6/2501 train_loss: 0.5521029233932495 time_taken: 0.05649971961975098\n",
      "Epoch 4: iteration 7/2501 train_loss: 0.5454778075218201 time_taken: 0.05708026885986328\n",
      "Epoch 4: iteration 8/2501 train_loss: 0.5401265621185303 time_taken: 0.05711627006530762\n",
      "Epoch 4: iteration 9/2501 train_loss: 0.5363035202026367 time_taken: 0.05738496780395508\n",
      "Epoch 4: iteration 10/2501 train_loss: 0.5331587195396423 time_taken: 0.05684494972229004\n",
      "Epoch 4: iteration 11/2501 train_loss: 0.5308597683906555 time_taken: 0.05780506134033203\n",
      "Epoch 4: iteration 12/2501 train_loss: 0.5289869904518127 time_taken: 0.05643320083618164\n",
      "Epoch 4: iteration 13/2501 train_loss: 0.5271016955375671 time_taken: 0.05738663673400879\n",
      "Epoch 4: iteration 14/2501 train_loss: 0.5261268615722656 time_taken: 0.05786585807800293\n",
      "Epoch 4: iteration 15/2501 train_loss: 0.5243926048278809 time_taken: 0.05695486068725586\n",
      "Epoch 4: iteration 16/2501 train_loss: 0.5231187343597412 time_taken: 0.05760359764099121\n",
      "Epoch 4: iteration 17/2501 train_loss: 0.5227526426315308 time_taken: 0.057022809982299805\n",
      "Epoch 4: iteration 18/2501 train_loss: 0.5231096148490906 time_taken: 0.05695843696594238\n",
      "Epoch 4: iteration 19/2501 train_loss: 0.5232328176498413 time_taken: 0.058710336685180664\n",
      "Epoch 4: iteration 20/2501 train_loss: 0.5232918858528137 time_taken: 0.05740809440612793\n",
      "Epoch 4: iteration 21/2501 train_loss: 0.5220600962638855 time_taken: 0.05715823173522949\n",
      "Epoch 4: iteration 22/2501 train_loss: 0.5217328667640686 time_taken: 0.05684995651245117\n",
      "Epoch 4: iteration 23/2501 train_loss: 0.5214326977729797 time_taken: 0.05652022361755371\n",
      "Epoch 4: iteration 24/2501 train_loss: 0.5202586650848389 time_taken: 0.05688977241516113\n",
      "Epoch 4: iteration 25/2501 train_loss: 0.5189418196678162 time_taken: 0.05650496482849121\n",
      "Epoch 4: iteration 26/2501 train_loss: 0.5174418091773987 time_taken: 0.05712294578552246\n",
      "Epoch 4: iteration 27/2501 train_loss: 0.5165767073631287 time_taken: 0.05663037300109863\n",
      "Epoch 4: iteration 28/2501 train_loss: 0.5161322951316833 time_taken: 0.05674934387207031\n",
      "Epoch 4: iteration 29/2501 train_loss: 0.5157493948936462 time_taken: 0.056798696517944336\n",
      "Epoch 4: iteration 30/2501 train_loss: 0.5151359438896179 time_taken: 0.056264400482177734\n",
      "Epoch 4: iteration 31/2501 train_loss: 0.5145416259765625 time_taken: 0.05738377571105957\n",
      "Epoch 4: iteration 32/2501 train_loss: 0.5142350792884827 time_taken: 0.05754876136779785\n",
      "Epoch 4: iteration 33/2501 train_loss: 0.514064371585846 time_taken: 0.057164669036865234\n",
      "Epoch 4: iteration 34/2501 train_loss: 0.5148503184318542 time_taken: 0.05684971809387207\n",
      "Epoch 4: iteration 35/2501 train_loss: 0.5152486562728882 time_taken: 0.05679965019226074\n",
      "Epoch 4: iteration 36/2501 train_loss: 0.5150243043899536 time_taken: 0.05759787559509277\n",
      "Epoch 4: iteration 37/2501 train_loss: 0.5153221487998962 time_taken: 0.05692410469055176\n",
      "Epoch 4: iteration 38/2501 train_loss: 0.5153414607048035 time_taken: 0.056577444076538086\n",
      "Epoch 4: iteration 39/2501 train_loss: 0.5152572989463806 time_taken: 0.05648398399353027\n",
      "Epoch 4: iteration 40/2501 train_loss: 0.5156292915344238 time_taken: 0.05677938461303711\n",
      "Epoch 4: iteration 41/2501 train_loss: 0.515667736530304 time_taken: 0.05753898620605469\n",
      "Epoch 4: iteration 42/2501 train_loss: 0.5158923864364624 time_taken: 0.05725216865539551\n",
      "Epoch 4: iteration 43/2501 train_loss: 0.5159380435943604 time_taken: 0.05659914016723633\n",
      "Epoch 4: iteration 44/2501 train_loss: 0.5162239074707031 time_taken: 0.05695819854736328\n",
      "Epoch 4: iteration 45/2501 train_loss: 0.5165100693702698 time_taken: 0.05697751045227051\n",
      "Epoch 4: iteration 46/2501 train_loss: 0.5166260004043579 time_taken: 0.05744147300720215\n",
      "Epoch 4: iteration 47/2501 train_loss: 0.5168166160583496 time_taken: 0.05746006965637207\n",
      "Epoch 4: iteration 48/2501 train_loss: 0.5167562365531921 time_taken: 0.057051897048950195\n",
      "Epoch 4: iteration 49/2501 train_loss: 0.5164265036582947 time_taken: 0.05630207061767578\n",
      "Epoch 4: iteration 50/2501 train_loss: 0.5161092877388 time_taken: 0.05678820610046387\n",
      "Epoch 4: iteration 51/2501 train_loss: 0.5155717134475708 time_taken: 0.0573427677154541\n",
      "Epoch 4: iteration 52/2501 train_loss: 0.5145834684371948 time_taken: 0.05701899528503418\n",
      "Epoch 4: iteration 53/2501 train_loss: 0.5139985680580139 time_taken: 0.05627012252807617\n",
      "Epoch 4: iteration 54/2501 train_loss: 0.5131164789199829 time_taken: 0.05687236785888672\n",
      "Epoch 4: iteration 55/2501 train_loss: 0.5121799111366272 time_taken: 0.05667710304260254\n",
      "Epoch 4: iteration 56/2501 train_loss: 0.5111040472984314 time_taken: 0.056566476821899414\n",
      "Epoch 4: iteration 57/2501 train_loss: 0.5102453827857971 time_taken: 0.05623221397399902\n",
      "Epoch 4: iteration 58/2501 train_loss: 0.5094221234321594 time_taken: 0.05707097053527832\n",
      "Epoch 4: iteration 59/2501 train_loss: 0.508553147315979 time_taken: 0.05739760398864746\n",
      "Epoch 4: iteration 60/2501 train_loss: 0.5082547068595886 time_taken: 0.057234764099121094\n",
      "Epoch 4: iteration 61/2501 train_loss: 0.5077048540115356 time_taken: 0.05735349655151367\n",
      "Epoch 4: iteration 62/2501 train_loss: 0.5070717334747314 time_taken: 0.057264089584350586\n",
      "Epoch 4: iteration 63/2501 train_loss: 0.5063015818595886 time_taken: 0.05684208869934082\n",
      "Epoch 4: iteration 64/2501 train_loss: 0.5058512091636658 time_taken: 0.057216644287109375\n",
      "Epoch 4: iteration 65/2501 train_loss: 0.5051084756851196 time_taken: 0.056586503982543945\n",
      "Epoch 4: iteration 66/2501 train_loss: 0.5042294859886169 time_taken: 0.056981801986694336\n",
      "Epoch 4: iteration 67/2501 train_loss: 0.5033581852912903 time_taken: 0.05644083023071289\n",
      "Epoch 4: iteration 68/2501 train_loss: 0.5022522211074829 time_taken: 0.056674957275390625\n",
      "Epoch 4: iteration 69/2501 train_loss: 0.5012820363044739 time_taken: 0.05708646774291992\n",
      "Epoch 4: iteration 70/2501 train_loss: 0.5001500248908997 time_taken: 0.05727052688598633\n",
      "Epoch 4: iteration 71/2501 train_loss: 0.4990777373313904 time_taken: 0.05704545974731445\n",
      "Epoch 4: iteration 72/2501 train_loss: 0.49794700741767883 time_taken: 0.056586265563964844\n",
      "Epoch 4: iteration 73/2501 train_loss: 0.4965992867946625 time_taken: 0.05675101280212402\n",
      "Epoch 4: iteration 74/2501 train_loss: 0.49532943964004517 time_taken: 0.07140684127807617\n",
      "Epoch 4: iteration 75/2501 train_loss: 0.4941137731075287 time_taken: 0.056598663330078125\n",
      "Epoch 4: iteration 76/2501 train_loss: 0.49300938844680786 time_taken: 0.056284427642822266\n",
      "Epoch 4: iteration 77/2501 train_loss: 0.49174538254737854 time_taken: 0.056795358657836914\n",
      "Epoch 4: iteration 78/2501 train_loss: 0.49033233523368835 time_taken: 0.0563807487487793\n",
      "Epoch 4: iteration 79/2501 train_loss: 0.4889467656612396 time_taken: 0.0563657283782959\n",
      "Epoch 4: iteration 80/2501 train_loss: 0.487428218126297 time_taken: 0.05664825439453125\n",
      "Epoch 4: iteration 81/2501 train_loss: 0.4862368404865265 time_taken: 0.056131601333618164\n",
      "Epoch 4: iteration 82/2501 train_loss: 0.4850936830043793 time_taken: 0.056276559829711914\n",
      "Epoch 4: iteration 83/2501 train_loss: 0.4838913083076477 time_taken: 0.05753898620605469\n",
      "Epoch 4: iteration 84/2501 train_loss: 0.4829060137271881 time_taken: 0.05674242973327637\n",
      "Epoch 4: iteration 85/2501 train_loss: 0.48217570781707764 time_taken: 0.05682706832885742\n",
      "Epoch 4: iteration 86/2501 train_loss: 0.48137757182121277 time_taken: 0.0564427375793457\n",
      "Epoch 4: iteration 87/2501 train_loss: 0.4807799458503723 time_taken: 0.05729317665100098\n",
      "Epoch 4: iteration 88/2501 train_loss: 0.48025187849998474 time_taken: 0.05675029754638672\n",
      "Epoch 4: iteration 89/2501 train_loss: 0.47973203659057617 time_taken: 0.057329416275024414\n",
      "Epoch 4: iteration 90/2501 train_loss: 0.4790540039539337 time_taken: 0.057543039321899414\n",
      "Epoch 4: iteration 91/2501 train_loss: 0.47862887382507324 time_taken: 0.05675005912780762\n",
      "Epoch 4: iteration 92/2501 train_loss: 0.4782949388027191 time_taken: 0.05715823173522949\n",
      "Epoch 4: iteration 93/2501 train_loss: 0.47795405983924866 time_taken: 0.05691695213317871\n",
      "Epoch 4: iteration 94/2501 train_loss: 0.47759920358657837 time_taken: 0.057404518127441406\n",
      "Epoch 4: iteration 95/2501 train_loss: 0.47737184166908264 time_taken: 0.05702614784240723\n",
      "Epoch 4: iteration 96/2501 train_loss: 0.477054625749588 time_taken: 0.05680513381958008\n",
      "Epoch 4: iteration 97/2501 train_loss: 0.47656214237213135 time_taken: 0.05770087242126465\n",
      "Epoch 4: iteration 98/2501 train_loss: 0.47595369815826416 time_taken: 0.057470083236694336\n",
      "Epoch 4: iteration 99/2501 train_loss: 0.47559234499931335 time_taken: 0.05708146095275879\n",
      "Epoch 4: iteration 100/2501 train_loss: 0.47528159618377686 time_taken: 0.05727410316467285\n",
      "Epoch 4: iteration 101/2501 train_loss: 0.4748958647251129 time_taken: 0.05751347541809082\n",
      "Epoch 4: iteration 102/2501 train_loss: 0.4745405614376068 time_taken: 0.0569610595703125\n",
      "Epoch 4: iteration 103/2501 train_loss: 0.4742785692214966 time_taken: 0.056992530822753906\n",
      "Epoch 4: iteration 104/2501 train_loss: 0.47412794828414917 time_taken: 0.05676126480102539\n",
      "Epoch 4: iteration 105/2501 train_loss: 0.47399017214775085 time_taken: 0.05740237236022949\n",
      "Epoch 4: iteration 106/2501 train_loss: 0.47380194067955017 time_taken: 0.05703473091125488\n",
      "Epoch 4: iteration 107/2501 train_loss: 0.47393229603767395 time_taken: 0.05724596977233887\n",
      "Epoch 4: iteration 108/2501 train_loss: 0.4739442467689514 time_taken: 0.05678749084472656\n",
      "Epoch 4: iteration 109/2501 train_loss: 0.4739688038825989 time_taken: 0.056633710861206055\n",
      "Epoch 4: iteration 110/2501 train_loss: 0.47393882274627686 time_taken: 0.05673623085021973\n",
      "Epoch 4: iteration 111/2501 train_loss: 0.47407928109169006 time_taken: 0.05741238594055176\n",
      "Epoch 4: iteration 112/2501 train_loss: 0.474117636680603 time_taken: 0.057433128356933594\n",
      "Epoch 4: iteration 113/2501 train_loss: 0.4742736518383026 time_taken: 0.05696606636047363\n",
      "Epoch 4: iteration 114/2501 train_loss: 0.47452598810195923 time_taken: 0.05684828758239746\n",
      "Epoch 4: iteration 115/2501 train_loss: 0.47463110089302063 time_taken: 0.05676007270812988\n",
      "Epoch 4: iteration 116/2501 train_loss: 0.47471433877944946 time_taken: 0.05681753158569336\n",
      "Epoch 4: iteration 117/2501 train_loss: 0.4745808243751526 time_taken: 0.05722522735595703\n",
      "Epoch 4: iteration 118/2501 train_loss: 0.4745572507381439 time_taken: 0.05687069892883301\n",
      "Epoch 4: iteration 119/2501 train_loss: 0.474610835313797 time_taken: 0.05675959587097168\n",
      "Epoch 4: iteration 120/2501 train_loss: 0.47470566630363464 time_taken: 0.057859182357788086\n",
      "Epoch 4: iteration 121/2501 train_loss: 0.4748281240463257 time_taken: 0.05675530433654785\n",
      "Epoch 4: iteration 122/2501 train_loss: 0.47488123178482056 time_taken: 0.056359291076660156\n",
      "Epoch 4: iteration 123/2501 train_loss: 0.47502052783966064 time_taken: 0.05654191970825195\n",
      "Epoch 4: iteration 124/2501 train_loss: 0.47511643171310425 time_taken: 0.056508541107177734\n",
      "Epoch 4: iteration 125/2501 train_loss: 0.4751245081424713 time_taken: 0.05732393264770508\n",
      "Epoch 4: iteration 126/2501 train_loss: 0.4751894772052765 time_taken: 0.056922197341918945\n",
      "Epoch 4: iteration 127/2501 train_loss: 0.47519731521606445 time_taken: 0.056859493255615234\n",
      "Epoch 4: iteration 128/2501 train_loss: 0.47529828548431396 time_taken: 0.0584409236907959\n",
      "Epoch 4: iteration 129/2501 train_loss: 0.47544318437576294 time_taken: 0.05699563026428223\n",
      "Epoch 4: iteration 130/2501 train_loss: 0.47560641169548035 time_taken: 0.05708193778991699\n",
      "Epoch 4: iteration 131/2501 train_loss: 0.4758235514163971 time_taken: 0.05803275108337402\n",
      "Epoch 4: iteration 132/2501 train_loss: 0.4759174883365631 time_taken: 0.056611061096191406\n",
      "Epoch 4: iteration 133/2501 train_loss: 0.4760747253894806 time_taken: 0.0571901798248291\n",
      "Epoch 4: iteration 134/2501 train_loss: 0.47618621587753296 time_taken: 0.05710911750793457\n",
      "Epoch 4: iteration 135/2501 train_loss: 0.4763358533382416 time_taken: 0.05675864219665527\n",
      "Epoch 4: iteration 136/2501 train_loss: 0.4764113128185272 time_taken: 0.05749034881591797\n",
      "Epoch 4: iteration 137/2501 train_loss: 0.4763188064098358 time_taken: 0.05680036544799805\n",
      "Epoch 4: iteration 138/2501 train_loss: 0.4762133061885834 time_taken: 0.056270599365234375\n",
      "Epoch 4: iteration 139/2501 train_loss: 0.4762784242630005 time_taken: 0.057105302810668945\n",
      "Epoch 4: iteration 140/2501 train_loss: 0.47628241777420044 time_taken: 0.0565333366394043\n",
      "Epoch 4: iteration 141/2501 train_loss: 0.47629058361053467 time_taken: 0.0569462776184082\n",
      "Epoch 4: iteration 142/2501 train_loss: 0.4762779772281647 time_taken: 0.05695700645446777\n",
      "Epoch 4: iteration 143/2501 train_loss: 0.4762536585330963 time_taken: 0.05738973617553711\n",
      "Epoch 4: iteration 144/2501 train_loss: 0.47617870569229126 time_taken: 0.05691027641296387\n",
      "Epoch 4: iteration 145/2501 train_loss: 0.4761275053024292 time_taken: 0.05707526206970215\n",
      "Epoch 4: iteration 146/2501 train_loss: 0.47605153918266296 time_taken: 0.05646085739135742\n",
      "Epoch 4: iteration 147/2501 train_loss: 0.47613680362701416 time_taken: 0.057152748107910156\n",
      "Epoch 4: iteration 148/2501 train_loss: 0.4761289656162262 time_taken: 0.05698204040527344\n",
      "Epoch 4: iteration 149/2501 train_loss: 0.4761616587638855 time_taken: 0.05732417106628418\n",
      "Epoch 4: iteration 150/2501 train_loss: 0.4761742651462555 time_taken: 0.05698585510253906\n",
      "Epoch 4: iteration 151/2501 train_loss: 0.47615423798561096 time_taken: 0.05769038200378418\n",
      "Epoch 4: iteration 152/2501 train_loss: 0.47611650824546814 time_taken: 0.05748796463012695\n",
      "Epoch 4: iteration 153/2501 train_loss: 0.4760153591632843 time_taken: 0.056941986083984375\n",
      "Epoch 4: iteration 154/2501 train_loss: 0.4759562909603119 time_taken: 0.056607961654663086\n",
      "Epoch 4: iteration 155/2501 train_loss: 0.4759140908718109 time_taken: 0.056604862213134766\n",
      "Epoch 4: iteration 156/2501 train_loss: 0.4757919907569885 time_taken: 0.05662679672241211\n",
      "Epoch 4: iteration 157/2501 train_loss: 0.4756770133972168 time_taken: 0.05660676956176758\n",
      "Epoch 4: iteration 158/2501 train_loss: 0.4755327105522156 time_taken: 0.05667448043823242\n",
      "Epoch 4: iteration 159/2501 train_loss: 0.4753493666648865 time_taken: 0.05727648735046387\n",
      "Epoch 4: iteration 160/2501 train_loss: 0.4750874638557434 time_taken: 0.06112241744995117\n",
      "Epoch 4: iteration 161/2501 train_loss: 0.47491538524627686 time_taken: 0.05708765983581543\n",
      "Epoch 4: iteration 162/2501 train_loss: 0.4748721420764923 time_taken: 0.05758333206176758\n",
      "Epoch 4: iteration 163/2501 train_loss: 0.474869042634964 time_taken: 0.05651521682739258\n",
      "Epoch 4: iteration 164/2501 train_loss: 0.47476550936698914 time_taken: 0.05724048614501953\n",
      "Epoch 4: iteration 165/2501 train_loss: 0.4747891128063202 time_taken: 0.05687689781188965\n",
      "Epoch 4: iteration 166/2501 train_loss: 0.4747209846973419 time_taken: 0.05692863464355469\n",
      "Epoch 4: iteration 167/2501 train_loss: 0.47475534677505493 time_taken: 0.056746721267700195\n",
      "Epoch 4: iteration 168/2501 train_loss: 0.4746907651424408 time_taken: 0.05630326271057129\n",
      "Epoch 4: iteration 169/2501 train_loss: 0.47468459606170654 time_taken: 0.055959463119506836\n",
      "Epoch 4: iteration 170/2501 train_loss: 0.4747495651245117 time_taken: 0.05679035186767578\n",
      "Epoch 4: iteration 171/2501 train_loss: 0.47484925389289856 time_taken: 0.05697011947631836\n",
      "Epoch 4: iteration 172/2501 train_loss: 0.4748806357383728 time_taken: 0.05642247200012207\n",
      "Epoch 4: iteration 173/2501 train_loss: 0.47492432594299316 time_taken: 0.05721092224121094\n",
      "Epoch 4: iteration 174/2501 train_loss: 0.4748765230178833 time_taken: 0.05697822570800781\n",
      "Epoch 4: iteration 175/2501 train_loss: 0.4750288128852844 time_taken: 0.057080745697021484\n",
      "Epoch 4: iteration 176/2501 train_loss: 0.4750663936138153 time_taken: 0.05682492256164551\n",
      "Epoch 4: iteration 177/2501 train_loss: 0.47496822476387024 time_taken: 0.05679154396057129\n",
      "Epoch 4: iteration 178/2501 train_loss: 0.47494301199913025 time_taken: 0.05681037902832031\n",
      "Epoch 4: iteration 179/2501 train_loss: 0.47473806142807007 time_taken: 0.05655550956726074\n",
      "Epoch 4: iteration 180/2501 train_loss: 0.4746309220790863 time_taken: 0.056574344635009766\n",
      "Epoch 4: iteration 181/2501 train_loss: 0.4745763838291168 time_taken: 0.056639909744262695\n",
      "Epoch 4: iteration 182/2501 train_loss: 0.474609375 time_taken: 0.05654191970825195\n",
      "Epoch 4: iteration 183/2501 train_loss: 0.47463926672935486 time_taken: 0.056565284729003906\n",
      "Epoch 4: iteration 184/2501 train_loss: 0.47470512986183167 time_taken: 0.0568232536315918\n",
      "Epoch 4: iteration 185/2501 train_loss: 0.4747265577316284 time_taken: 0.05660843849182129\n",
      "Epoch 4: iteration 186/2501 train_loss: 0.4747592806816101 time_taken: 0.056081295013427734\n",
      "Epoch 4: iteration 187/2501 train_loss: 0.47485920786857605 time_taken: 0.05678439140319824\n",
      "Epoch 4: iteration 188/2501 train_loss: 0.4748094379901886 time_taken: 0.057607173919677734\n",
      "Epoch 4: iteration 189/2501 train_loss: 0.4747718870639801 time_taken: 0.05889534950256348\n",
      "Epoch 4: iteration 190/2501 train_loss: 0.47468504309654236 time_taken: 0.05741286277770996\n",
      "Epoch 4: iteration 191/2501 train_loss: 0.47463539242744446 time_taken: 0.05711865425109863\n",
      "Epoch 4: iteration 192/2501 train_loss: 0.47451967000961304 time_taken: 0.057190656661987305\n",
      "Epoch 4: iteration 193/2501 train_loss: 0.4744032919406891 time_taken: 0.05599570274353027\n",
      "Epoch 4: iteration 194/2501 train_loss: 0.47434383630752563 time_taken: 0.05661129951477051\n",
      "Epoch 4: iteration 195/2501 train_loss: 0.47435393929481506 time_taken: 0.05800509452819824\n",
      "Epoch 4: iteration 196/2501 train_loss: 0.47431373596191406 time_taken: 0.06128382682800293\n",
      "Epoch 4: iteration 197/2501 train_loss: 0.47433337569236755 time_taken: 0.05614352226257324\n",
      "Epoch 4: iteration 198/2501 train_loss: 0.47440779209136963 time_taken: 0.07835197448730469\n",
      "Epoch 4: iteration 199/2501 train_loss: 0.474608451128006 time_taken: 0.05895400047302246\n",
      "Epoch 4: iteration 200/2501 train_loss: 0.4747300446033478 time_taken: 0.05584907531738281\n",
      "Epoch 4: iteration 201/2501 train_loss: 0.47492343187332153 time_taken: 0.0565798282623291\n",
      "Epoch 4: iteration 202/2501 train_loss: 0.4751400947570801 time_taken: 0.056500911712646484\n",
      "Epoch 4: iteration 203/2501 train_loss: 0.475349098443985 time_taken: 0.05708932876586914\n",
      "Epoch 4: iteration 204/2501 train_loss: 0.4755781292915344 time_taken: 0.056093692779541016\n",
      "Epoch 4: iteration 205/2501 train_loss: 0.4757280945777893 time_taken: 0.056746482849121094\n",
      "Epoch 4: iteration 206/2501 train_loss: 0.47596418857574463 time_taken: 0.05610227584838867\n",
      "Epoch 4: iteration 207/2501 train_loss: 0.47615668177604675 time_taken: 0.056710004806518555\n",
      "Epoch 4: iteration 208/2501 train_loss: 0.47640863060951233 time_taken: 0.05670809745788574\n",
      "Epoch 4: iteration 209/2501 train_loss: 0.47656452655792236 time_taken: 0.05669903755187988\n",
      "Epoch 4: iteration 210/2501 train_loss: 0.47671714425086975 time_taken: 0.05711627006530762\n",
      "Epoch 4: iteration 211/2501 train_loss: 0.47678884863853455 time_taken: 0.05679059028625488\n",
      "Epoch 4: iteration 212/2501 train_loss: 0.4769156873226166 time_taken: 0.05657219886779785\n",
      "Epoch 4: iteration 213/2501 train_loss: 0.4769941568374634 time_taken: 0.05720806121826172\n",
      "Epoch 4: iteration 214/2501 train_loss: 0.4771478772163391 time_taken: 0.05701398849487305\n",
      "Epoch 4: iteration 215/2501 train_loss: 0.4772692024707794 time_taken: 0.060265541076660156\n",
      "Epoch 4: iteration 216/2501 train_loss: 0.4773477017879486 time_taken: 0.05610489845275879\n",
      "Epoch 4: iteration 217/2501 train_loss: 0.4775567352771759 time_taken: 0.05656599998474121\n",
      "Epoch 4: iteration 218/2501 train_loss: 0.47772353887557983 time_taken: 0.05706954002380371\n",
      "Epoch 4: iteration 219/2501 train_loss: 0.4779202938079834 time_taken: 0.056710004806518555\n",
      "Epoch 4: iteration 220/2501 train_loss: 0.47821325063705444 time_taken: 0.05666327476501465\n",
      "Epoch 4: iteration 221/2501 train_loss: 0.47851741313934326 time_taken: 0.056532859802246094\n",
      "Epoch 4: iteration 222/2501 train_loss: 0.47883421182632446 time_taken: 0.05775141716003418\n",
      "Epoch 4: iteration 223/2501 train_loss: 0.4791072905063629 time_taken: 0.05707907676696777\n",
      "Epoch 4: iteration 224/2501 train_loss: 0.47945329546928406 time_taken: 0.05683016777038574\n",
      "Epoch 4: iteration 225/2501 train_loss: 0.4797954261302948 time_taken: 0.056439876556396484\n",
      "Epoch 4: iteration 226/2501 train_loss: 0.48022207617759705 time_taken: 0.05675506591796875\n",
      "Epoch 4: iteration 227/2501 train_loss: 0.48054859042167664 time_taken: 0.05669212341308594\n",
      "Epoch 4: iteration 228/2501 train_loss: 0.480788916349411 time_taken: 0.0572359561920166\n",
      "Epoch 4: iteration 229/2501 train_loss: 0.48098090291023254 time_taken: 0.05668926239013672\n",
      "Epoch 4: iteration 230/2501 train_loss: 0.4811319410800934 time_taken: 0.057970285415649414\n",
      "Epoch 4: iteration 231/2501 train_loss: 0.48127618432044983 time_taken: 0.05727338790893555\n",
      "Epoch 4: iteration 232/2501 train_loss: 0.48136991262435913 time_taken: 0.05653691291809082\n",
      "Epoch 4: iteration 233/2501 train_loss: 0.48162588477134705 time_taken: 0.05674028396606445\n",
      "Epoch 4: iteration 234/2501 train_loss: 0.4816844165325165 time_taken: 0.056134700775146484\n",
      "Epoch 4: iteration 235/2501 train_loss: 0.48176077008247375 time_taken: 0.05774235725402832\n",
      "Epoch 4: iteration 236/2501 train_loss: 0.48186689615249634 time_taken: 0.056322336196899414\n",
      "Epoch 4: iteration 237/2501 train_loss: 0.4818889796733856 time_taken: 0.056097984313964844\n",
      "Epoch 4: iteration 238/2501 train_loss: 0.48184627294540405 time_taken: 0.056319475173950195\n",
      "Epoch 4: iteration 239/2501 train_loss: 0.4818148612976074 time_taken: 0.05678391456604004\n",
      "Epoch 4: iteration 240/2501 train_loss: 0.4818258583545685 time_taken: 0.05680418014526367\n",
      "Epoch 4: iteration 241/2501 train_loss: 0.48172229528427124 time_taken: 0.056658029556274414\n",
      "Epoch 4: iteration 242/2501 train_loss: 0.4816611707210541 time_taken: 0.056487083435058594\n",
      "Epoch 4: iteration 243/2501 train_loss: 0.4815610647201538 time_taken: 0.056786298751831055\n",
      "Epoch 4: iteration 244/2501 train_loss: 0.48168855905532837 time_taken: 0.056448936462402344\n",
      "Epoch 4: iteration 245/2501 train_loss: 0.4826759099960327 time_taken: 0.06440138816833496\n",
      "Epoch 4: iteration 246/2501 train_loss: 0.48390018939971924 time_taken: 0.056861162185668945\n",
      "Epoch 4: iteration 247/2501 train_loss: 0.48377344012260437 time_taken: 0.0570526123046875\n",
      "Epoch 4: iteration 248/2501 train_loss: 0.484229177236557 time_taken: 0.05665946006774902\n",
      "Epoch 4: iteration 249/2501 train_loss: 0.4841817021369934 time_taken: 0.05847620964050293\n",
      "Epoch 4: iteration 250/2501 train_loss: 0.4840696156024933 time_taken: 0.05643296241760254\n",
      "Epoch 4: iteration 251/2501 train_loss: 0.48410049080848694 time_taken: 0.056672096252441406\n",
      "Epoch 4: iteration 252/2501 train_loss: 0.48393091559410095 time_taken: 0.057077884674072266\n",
      "Epoch 4: iteration 253/2501 train_loss: 0.4837307333946228 time_taken: 0.05663776397705078\n",
      "Epoch 4: iteration 254/2501 train_loss: 0.4835869073867798 time_taken: 0.0574648380279541\n",
      "Epoch 4: iteration 255/2501 train_loss: 0.48352453112602234 time_taken: 0.05677390098571777\n",
      "Epoch 4: iteration 256/2501 train_loss: 0.48344507813453674 time_taken: 0.05687403678894043\n",
      "Epoch 4: iteration 257/2501 train_loss: 0.48340076208114624 time_taken: 0.05726480484008789\n",
      "Epoch 4: iteration 258/2501 train_loss: 0.4833512008190155 time_taken: 0.05655694007873535\n",
      "Epoch 4: iteration 259/2501 train_loss: 0.48328155279159546 time_taken: 0.056342124938964844\n",
      "Epoch 4: iteration 260/2501 train_loss: 0.48313337564468384 time_taken: 0.05600309371948242\n",
      "Epoch 4: iteration 261/2501 train_loss: 0.48305878043174744 time_taken: 0.057021141052246094\n",
      "Epoch 4: iteration 262/2501 train_loss: 0.4829341173171997 time_taken: 0.057027339935302734\n",
      "Epoch 4: iteration 263/2501 train_loss: 0.4828203618526459 time_taken: 0.05653882026672363\n",
      "Epoch 4: iteration 264/2501 train_loss: 0.48277637362480164 time_taken: 0.05727672576904297\n",
      "Epoch 4: iteration 265/2501 train_loss: 0.48271459341049194 time_taken: 0.0571141242980957\n",
      "Epoch 4: iteration 266/2501 train_loss: 0.4825522303581238 time_taken: 0.056921958923339844\n",
      "Epoch 4: iteration 267/2501 train_loss: 0.48240360617637634 time_taken: 0.05650019645690918\n",
      "Epoch 4: iteration 268/2501 train_loss: 0.48217159509658813 time_taken: 0.0561213493347168\n",
      "Epoch 4: iteration 269/2501 train_loss: 0.4820045232772827 time_taken: 0.05698752403259277\n",
      "Epoch 4: iteration 270/2501 train_loss: 0.4817439615726471 time_taken: 0.05604124069213867\n",
      "Epoch 4: iteration 271/2501 train_loss: 0.481497585773468 time_taken: 0.05778145790100098\n",
      "Epoch 4: iteration 272/2501 train_loss: 0.4812144637107849 time_taken: 0.05702066421508789\n",
      "Epoch 4: iteration 273/2501 train_loss: 0.48091521859169006 time_taken: 0.05629897117614746\n",
      "Epoch 4: iteration 274/2501 train_loss: 0.48068615794181824 time_taken: 0.05696511268615723\n",
      "Epoch 4: iteration 275/2501 train_loss: 0.4804342985153198 time_taken: 0.057068824768066406\n",
      "Epoch 4: iteration 276/2501 train_loss: 0.4802132546901703 time_taken: 0.05603313446044922\n",
      "Epoch 4: iteration 277/2501 train_loss: 0.47993019223213196 time_taken: 0.05757284164428711\n",
      "Epoch 4: iteration 278/2501 train_loss: 0.47969821095466614 time_taken: 0.05689740180969238\n",
      "Epoch 4: iteration 279/2501 train_loss: 0.4794299602508545 time_taken: 0.05650472640991211\n",
      "Epoch 4: iteration 280/2501 train_loss: 0.47922590374946594 time_taken: 0.05616116523742676\n",
      "Epoch 4: iteration 281/2501 train_loss: 0.47905465960502625 time_taken: 0.056114912033081055\n",
      "Epoch 4: iteration 282/2501 train_loss: 0.478863388299942 time_taken: 0.05666184425354004\n",
      "Epoch 4: iteration 283/2501 train_loss: 0.4786643981933594 time_taken: 0.057088375091552734\n",
      "Epoch 4: iteration 284/2501 train_loss: 0.4785475432872772 time_taken: 0.056149959564208984\n",
      "Epoch 4: iteration 285/2501 train_loss: 0.47840994596481323 time_taken: 0.055916547775268555\n",
      "Epoch 4: iteration 286/2501 train_loss: 0.4783041179180145 time_taken: 0.05592536926269531\n",
      "Epoch 4: iteration 287/2501 train_loss: 0.47822248935699463 time_taken: 0.055966854095458984\n",
      "Epoch 4: iteration 288/2501 train_loss: 0.4782138764858246 time_taken: 0.0560154914855957\n",
      "Epoch 4: iteration 289/2501 train_loss: 0.4781414568424225 time_taken: 0.05702567100524902\n",
      "Epoch 4: iteration 290/2501 train_loss: 0.4781842827796936 time_taken: 0.057225704193115234\n",
      "Epoch 4: iteration 291/2501 train_loss: 0.4782449007034302 time_taken: 0.05623292922973633\n",
      "Epoch 4: iteration 292/2501 train_loss: 0.4783506989479065 time_taken: 0.05611681938171387\n",
      "Epoch 4: iteration 293/2501 train_loss: 0.4786139130592346 time_taken: 0.05625462532043457\n",
      "Epoch 4: iteration 294/2501 train_loss: 0.478804349899292 time_taken: 0.08829998970031738\n",
      "Epoch 4: iteration 295/2501 train_loss: 0.4788784384727478 time_taken: 0.05660605430603027\n",
      "Epoch 4: iteration 296/2501 train_loss: 0.47901999950408936 time_taken: 0.05655837059020996\n",
      "Epoch 4: iteration 297/2501 train_loss: 0.47914281487464905 time_taken: 0.0567934513092041\n",
      "Epoch 4: iteration 298/2501 train_loss: 0.4793173372745514 time_taken: 0.05715537071228027\n",
      "Epoch 4: iteration 299/2501 train_loss: 0.47940343618392944 time_taken: 0.05670332908630371\n",
      "Epoch 4: iteration 300/2501 train_loss: 0.4795394241809845 time_taken: 0.05707359313964844\n",
      "Epoch 4: iteration 301/2501 train_loss: 0.47965437173843384 time_taken: 0.05930900573730469\n",
      "Epoch 4: iteration 302/2501 train_loss: 0.47966763377189636 time_taken: 0.05724191665649414\n",
      "Epoch 4: iteration 303/2501 train_loss: 0.4796347916126251 time_taken: 0.056333303451538086\n",
      "Epoch 4: iteration 304/2501 train_loss: 0.47951555252075195 time_taken: 0.05670428276062012\n",
      "Epoch 4: iteration 305/2501 train_loss: 0.47940605878829956 time_taken: 0.057178497314453125\n",
      "Epoch 4: iteration 306/2501 train_loss: 0.4792541563510895 time_taken: 0.05677652359008789\n",
      "Epoch 4: iteration 307/2501 train_loss: 0.4790852963924408 time_taken: 0.05762958526611328\n",
      "Epoch 4: iteration 308/2501 train_loss: 0.47891417145729065 time_taken: 0.057460784912109375\n",
      "Epoch 4: iteration 309/2501 train_loss: 0.4787158966064453 time_taken: 0.056587934494018555\n",
      "Epoch 4: iteration 310/2501 train_loss: 0.4784797132015228 time_taken: 0.05730938911437988\n",
      "Epoch 4: iteration 311/2501 train_loss: 0.47822311520576477 time_taken: 0.057056427001953125\n",
      "Epoch 4: iteration 312/2501 train_loss: 0.4779212772846222 time_taken: 0.0573580265045166\n",
      "Epoch 4: iteration 313/2501 train_loss: 0.47764039039611816 time_taken: 0.057533979415893555\n",
      "Epoch 4: iteration 314/2501 train_loss: 0.47732940316200256 time_taken: 0.05714249610900879\n",
      "Epoch 4: iteration 315/2501 train_loss: 0.47700202465057373 time_taken: 0.057215213775634766\n",
      "Epoch 4: iteration 316/2501 train_loss: 0.4766389727592468 time_taken: 0.05697989463806152\n",
      "Epoch 4: iteration 317/2501 train_loss: 0.4763232171535492 time_taken: 0.057318925857543945\n",
      "Epoch 4: iteration 318/2501 train_loss: 0.47599491477012634 time_taken: 0.05678367614746094\n",
      "Epoch 4: iteration 319/2501 train_loss: 0.47570085525512695 time_taken: 0.056458234786987305\n",
      "Epoch 4: iteration 320/2501 train_loss: 0.47544366121292114 time_taken: 0.056450605392456055\n",
      "Epoch 4: iteration 321/2501 train_loss: 0.47522974014282227 time_taken: 0.05707263946533203\n",
      "Epoch 4: iteration 322/2501 train_loss: 0.4749913215637207 time_taken: 0.05719637870788574\n",
      "Epoch 4: iteration 323/2501 train_loss: 0.4747730791568756 time_taken: 0.05634331703186035\n",
      "Epoch 4: iteration 324/2501 train_loss: 0.4745315909385681 time_taken: 0.05627179145812988\n",
      "Epoch 4: iteration 325/2501 train_loss: 0.4742932915687561 time_taken: 0.055983543395996094\n",
      "Epoch 4: iteration 326/2501 train_loss: 0.47401806712150574 time_taken: 0.055994272232055664\n",
      "Epoch 4: iteration 327/2501 train_loss: 0.47374817728996277 time_taken: 0.05699324607849121\n",
      "Epoch 4: iteration 328/2501 train_loss: 0.4734635651111603 time_taken: 0.05671095848083496\n",
      "Epoch 4: iteration 329/2501 train_loss: 0.47315534949302673 time_taken: 0.05742502212524414\n",
      "Epoch 4: iteration 330/2501 train_loss: 0.4728473722934723 time_taken: 0.05763506889343262\n",
      "Epoch 4: iteration 331/2501 train_loss: 0.47252798080444336 time_taken: 0.05644822120666504\n",
      "Epoch 4: iteration 332/2501 train_loss: 0.4722338616847992 time_taken: 0.056142330169677734\n",
      "Epoch 4: iteration 333/2501 train_loss: 0.4719068706035614 time_taken: 0.056783437728881836\n",
      "Epoch 4: iteration 334/2501 train_loss: 0.4716624319553375 time_taken: 0.05622053146362305\n",
      "Epoch 4: iteration 335/2501 train_loss: 0.47140857577323914 time_taken: 0.05619049072265625\n",
      "Epoch 4: iteration 336/2501 train_loss: 0.4712047576904297 time_taken: 0.05643916130065918\n",
      "Epoch 4: iteration 337/2501 train_loss: 0.4710184633731842 time_taken: 0.05646252632141113\n",
      "Epoch 4: iteration 338/2501 train_loss: 0.4708084464073181 time_taken: 0.06152224540710449\n",
      "Epoch 4: iteration 339/2501 train_loss: 0.4706462621688843 time_taken: 0.055927276611328125\n",
      "Epoch 4: iteration 340/2501 train_loss: 0.47056373953819275 time_taken: 0.061186790466308594\n",
      "Epoch 4: iteration 341/2501 train_loss: 0.4705010652542114 time_taken: 0.05616950988769531\n",
      "Epoch 4: iteration 342/2501 train_loss: 0.47036826610565186 time_taken: 0.05609607696533203\n",
      "Epoch 4: iteration 343/2501 train_loss: 0.47026944160461426 time_taken: 0.05602145195007324\n",
      "Epoch 4: iteration 344/2501 train_loss: 0.470152348279953 time_taken: 0.059239864349365234\n",
      "Epoch 4: iteration 345/2501 train_loss: 0.47005459666252136 time_taken: 0.057224273681640625\n",
      "Epoch 4: iteration 346/2501 train_loss: 0.4699772894382477 time_taken: 0.05580925941467285\n",
      "Epoch 4: iteration 347/2501 train_loss: 0.46989673376083374 time_taken: 0.05907392501831055\n",
      "Epoch 4: iteration 348/2501 train_loss: 0.46980443596839905 time_taken: 0.060304880142211914\n",
      "Epoch 4: iteration 349/2501 train_loss: 0.4697287976741791 time_taken: 0.0558624267578125\n",
      "Epoch 4: iteration 350/2501 train_loss: 0.4696851372718811 time_taken: 0.05578303337097168\n",
      "Epoch 4: iteration 351/2501 train_loss: 0.4696759879589081 time_taken: 0.05591940879821777\n",
      "Epoch 4: iteration 352/2501 train_loss: 0.469664067029953 time_taken: 0.05709123611450195\n",
      "Epoch 4: iteration 353/2501 train_loss: 0.46964073181152344 time_taken: 0.055892229080200195\n",
      "Epoch 4: iteration 354/2501 train_loss: 0.4696314036846161 time_taken: 0.05724692344665527\n",
      "Epoch 4: iteration 355/2501 train_loss: 0.469608873128891 time_taken: 0.05646157264709473\n",
      "Epoch 4: iteration 356/2501 train_loss: 0.46962830424308777 time_taken: 0.06054806709289551\n",
      "Epoch 4: iteration 357/2501 train_loss: 0.4696948826313019 time_taken: 0.056259870529174805\n",
      "Epoch 4: iteration 358/2501 train_loss: 0.4697836935520172 time_taken: 0.05672478675842285\n",
      "Epoch 4: iteration 359/2501 train_loss: 0.46979621052742004 time_taken: 0.07390666007995605\n",
      "Epoch 4: iteration 360/2501 train_loss: 0.4698258936405182 time_taken: 0.05572104454040527\n",
      "Epoch 4: iteration 361/2501 train_loss: 0.46985718607902527 time_taken: 0.05581474304199219\n",
      "Epoch 4: iteration 362/2501 train_loss: 0.46986785531044006 time_taken: 0.05595207214355469\n",
      "Epoch 4: iteration 363/2501 train_loss: 0.46988779306411743 time_taken: 0.05588030815124512\n",
      "Epoch 4: iteration 364/2501 train_loss: 0.4699965715408325 time_taken: 0.05608081817626953\n",
      "Epoch 4: iteration 365/2501 train_loss: 0.4700508713722229 time_taken: 0.05588483810424805\n",
      "Epoch 4: iteration 366/2501 train_loss: 0.4701448976993561 time_taken: 0.05673623085021973\n",
      "Epoch 4: iteration 367/2501 train_loss: 0.4702123999595642 time_taken: 0.06046485900878906\n",
      "Epoch 4: iteration 368/2501 train_loss: 0.47028952836990356 time_taken: 0.05585145950317383\n",
      "Epoch 4: iteration 369/2501 train_loss: 0.47036194801330566 time_taken: 0.05590391159057617\n",
      "Epoch 4: iteration 370/2501 train_loss: 0.4704519808292389 time_taken: 0.05588722229003906\n",
      "Epoch 4: iteration 371/2501 train_loss: 0.4704684317111969 time_taken: 0.058133840560913086\n",
      "Epoch 4: iteration 372/2501 train_loss: 0.4704630672931671 time_taken: 0.057734012603759766\n",
      "Epoch 4: iteration 373/2501 train_loss: 0.4704683721065521 time_taken: 0.05677628517150879\n",
      "Epoch 4: iteration 374/2501 train_loss: 0.47048330307006836 time_taken: 0.05639934539794922\n",
      "Epoch 4: iteration 375/2501 train_loss: 0.47046616673469543 time_taken: 0.056212663650512695\n",
      "Epoch 4: iteration 376/2501 train_loss: 0.47044143080711365 time_taken: 0.056963205337524414\n",
      "Epoch 4: iteration 377/2501 train_loss: 0.47041672468185425 time_taken: 0.056764841079711914\n",
      "Epoch 4: iteration 378/2501 train_loss: 0.47041046619415283 time_taken: 0.05649518966674805\n",
      "Epoch 4: iteration 379/2501 train_loss: 0.4704569876194 time_taken: 0.0570831298828125\n",
      "Epoch 4: iteration 380/2501 train_loss: 0.470431923866272 time_taken: 0.056738853454589844\n",
      "Epoch 4: iteration 381/2501 train_loss: 0.4704150855541229 time_taken: 0.05690813064575195\n",
      "Epoch 4: iteration 382/2501 train_loss: 0.4703671932220459 time_taken: 0.05615496635437012\n",
      "Epoch 4: iteration 383/2501 train_loss: 0.47041213512420654 time_taken: 0.05643606185913086\n",
      "Epoch 4: iteration 384/2501 train_loss: 0.47044476866722107 time_taken: 0.056818246841430664\n",
      "Epoch 4: iteration 385/2501 train_loss: 0.47043025493621826 time_taken: 0.05640244483947754\n",
      "Epoch 4: iteration 386/2501 train_loss: 0.4704793691635132 time_taken: 0.056519269943237305\n",
      "Epoch 4: iteration 387/2501 train_loss: 0.47046056389808655 time_taken: 0.05695772171020508\n",
      "Epoch 4: iteration 388/2501 train_loss: 0.47044694423675537 time_taken: 0.056908607482910156\n",
      "Epoch 4: iteration 389/2501 train_loss: 0.47042912244796753 time_taken: 0.05694317817687988\n",
      "Epoch 4: iteration 390/2501 train_loss: 0.4704451262950897 time_taken: 0.0569765567779541\n",
      "Epoch 4: iteration 391/2501 train_loss: 0.4704761505126953 time_taken: 0.05669140815734863\n",
      "Epoch 4: iteration 392/2501 train_loss: 0.4704776704311371 time_taken: 0.057288408279418945\n",
      "Epoch 4: iteration 393/2501 train_loss: 0.4704294204711914 time_taken: 0.05649304389953613\n",
      "Epoch 4: iteration 394/2501 train_loss: 0.47036194801330566 time_taken: 0.05634665489196777\n",
      "Epoch 4: iteration 395/2501 train_loss: 0.4702676236629486 time_taken: 0.07101607322692871\n",
      "Epoch 4: iteration 396/2501 train_loss: 0.47017234563827515 time_taken: 0.05670905113220215\n",
      "Epoch 4: iteration 397/2501 train_loss: 0.4700978100299835 time_taken: 0.055907487869262695\n",
      "Epoch 4: iteration 398/2501 train_loss: 0.4699786901473999 time_taken: 0.05651569366455078\n",
      "Epoch 4: iteration 399/2501 train_loss: 0.4698427617549896 time_taken: 0.05670976638793945\n",
      "Epoch 4: iteration 400/2501 train_loss: 0.46965137124061584 time_taken: 0.056479454040527344\n",
      "Epoch 4: iteration 401/2501 train_loss: 0.46946513652801514 time_taken: 0.05649280548095703\n",
      "Epoch 4: iteration 402/2501 train_loss: 0.4692564904689789 time_taken: 0.056121110916137695\n",
      "Epoch 4: iteration 403/2501 train_loss: 0.46903368830680847 time_taken: 0.05629611015319824\n",
      "Epoch 4: iteration 404/2501 train_loss: 0.46884772181510925 time_taken: 0.056154489517211914\n",
      "Epoch 4: iteration 405/2501 train_loss: 0.4686964750289917 time_taken: 0.05613541603088379\n",
      "Epoch 4: iteration 406/2501 train_loss: 0.4685402512550354 time_taken: 0.055938720703125\n",
      "Epoch 4: iteration 407/2501 train_loss: 0.4683454632759094 time_taken: 0.05621480941772461\n",
      "Epoch 4: iteration 408/2501 train_loss: 0.4682380259037018 time_taken: 0.05631613731384277\n",
      "Epoch 4: iteration 409/2501 train_loss: 0.468118280172348 time_taken: 0.05609941482543945\n",
      "Epoch 4: iteration 410/2501 train_loss: 0.4680052101612091 time_taken: 0.056070804595947266\n",
      "Epoch 4: iteration 411/2501 train_loss: 0.46791231632232666 time_taken: 0.05618453025817871\n",
      "Epoch 4: iteration 412/2501 train_loss: 0.46783730387687683 time_taken: 0.0560915470123291\n",
      "Epoch 4: iteration 413/2501 train_loss: 0.4677673876285553 time_taken: 0.056001901626586914\n",
      "Epoch 4: iteration 414/2501 train_loss: 0.4676680564880371 time_taken: 0.061068058013916016\n",
      "Epoch 4: iteration 415/2501 train_loss: 0.46754196286201477 time_taken: 0.056418418884277344\n",
      "Epoch 4: iteration 416/2501 train_loss: 0.4674546718597412 time_taken: 0.05603790283203125\n",
      "Epoch 4: iteration 417/2501 train_loss: 0.4673325717449188 time_taken: 0.056002140045166016\n",
      "Epoch 4: iteration 418/2501 train_loss: 0.46726715564727783 time_taken: 0.05608415603637695\n",
      "Epoch 4: iteration 419/2501 train_loss: 0.4671565592288971 time_taken: 0.05594515800476074\n",
      "Epoch 4: iteration 420/2501 train_loss: 0.46704164147377014 time_taken: 0.05939173698425293\n",
      "Epoch 4: iteration 421/2501 train_loss: 0.46693846583366394 time_taken: 0.05693697929382324\n",
      "Epoch 4: iteration 422/2501 train_loss: 0.46686145663261414 time_taken: 0.05638408660888672\n",
      "Epoch 4: iteration 423/2501 train_loss: 0.46676933765411377 time_taken: 0.056388139724731445\n",
      "Epoch 4: iteration 424/2501 train_loss: 0.46666237711906433 time_taken: 0.05613136291503906\n",
      "Epoch 4: iteration 425/2501 train_loss: 0.46657565236091614 time_taken: 0.06021380424499512\n",
      "Epoch 4: iteration 426/2501 train_loss: 0.4664556384086609 time_taken: 0.05627727508544922\n",
      "Epoch 4: iteration 427/2501 train_loss: 0.46635475754737854 time_taken: 0.05669665336608887\n",
      "Epoch 4: iteration 428/2501 train_loss: 0.46630120277404785 time_taken: 0.05681109428405762\n",
      "Epoch 4: iteration 429/2501 train_loss: 0.46625036001205444 time_taken: 0.056267499923706055\n",
      "Epoch 4: iteration 430/2501 train_loss: 0.4662021994590759 time_taken: 0.057015180587768555\n",
      "Epoch 4: iteration 431/2501 train_loss: 0.46617546677589417 time_taken: 0.05621504783630371\n",
      "Epoch 4: iteration 432/2501 train_loss: 0.46620288491249084 time_taken: 0.05613350868225098\n",
      "Epoch 4: iteration 433/2501 train_loss: 0.46625053882598877 time_taken: 0.05672621726989746\n",
      "Epoch 4: iteration 434/2501 train_loss: 0.4662823975086212 time_taken: 0.0565342903137207\n",
      "Epoch 4: iteration 435/2501 train_loss: 0.46634727716445923 time_taken: 0.0571596622467041\n",
      "Epoch 4: iteration 436/2501 train_loss: 0.4664459526538849 time_taken: 0.05660557746887207\n",
      "Epoch 4: iteration 437/2501 train_loss: 0.46654263138771057 time_taken: 0.05628824234008789\n",
      "Epoch 4: iteration 438/2501 train_loss: 0.4666134715080261 time_taken: 0.05603480339050293\n",
      "Epoch 4: iteration 439/2501 train_loss: 0.46670323610305786 time_taken: 0.05676555633544922\n",
      "Epoch 4: iteration 440/2501 train_loss: 0.4668118357658386 time_taken: 0.05641961097717285\n",
      "Epoch 4: iteration 441/2501 train_loss: 0.46689271926879883 time_taken: 0.05589795112609863\n",
      "Epoch 4: iteration 442/2501 train_loss: 0.466953307390213 time_taken: 0.05716848373413086\n",
      "Epoch 4: iteration 443/2501 train_loss: 0.4670505225658417 time_taken: 0.05707955360412598\n",
      "Epoch 4: iteration 444/2501 train_loss: 0.467146635055542 time_taken: 0.05635547637939453\n",
      "Epoch 4: iteration 445/2501 train_loss: 0.4672183096408844 time_taken: 0.06265521049499512\n",
      "Epoch 4: iteration 446/2501 train_loss: 0.4672917425632477 time_taken: 0.05579495429992676\n",
      "Epoch 4: iteration 447/2501 train_loss: 0.4673612117767334 time_taken: 0.05674147605895996\n",
      "Epoch 4: iteration 448/2501 train_loss: 0.4674617052078247 time_taken: 0.056932687759399414\n",
      "Epoch 4: iteration 449/2501 train_loss: 0.4675009846687317 time_taken: 0.056818485260009766\n",
      "Epoch 4: iteration 450/2501 train_loss: 0.46757107973098755 time_taken: 0.057250261306762695\n",
      "Epoch 4: iteration 451/2501 train_loss: 0.467637836933136 time_taken: 0.057332515716552734\n",
      "Epoch 4: iteration 452/2501 train_loss: 0.467714786529541 time_taken: 0.05655932426452637\n",
      "Epoch 4: iteration 453/2501 train_loss: 0.4677738547325134 time_taken: 0.055922508239746094\n",
      "Epoch 4: iteration 454/2501 train_loss: 0.46777451038360596 time_taken: 0.05657649040222168\n",
      "Epoch 4: iteration 455/2501 train_loss: 0.4677557051181793 time_taken: 0.056069374084472656\n",
      "Epoch 4: iteration 456/2501 train_loss: 0.4677324891090393 time_taken: 0.05630779266357422\n",
      "Epoch 4: iteration 457/2501 train_loss: 0.4676591157913208 time_taken: 0.05673694610595703\n",
      "Epoch 4: iteration 458/2501 train_loss: 0.4675896465778351 time_taken: 0.05707573890686035\n",
      "Epoch 4: iteration 459/2501 train_loss: 0.46747758984565735 time_taken: 0.05677390098571777\n",
      "Epoch 4: iteration 460/2501 train_loss: 0.46735021471977234 time_taken: 0.05629420280456543\n",
      "Epoch 4: iteration 461/2501 train_loss: 0.4672049582004547 time_taken: 0.05683112144470215\n",
      "Epoch 4: iteration 462/2501 train_loss: 0.46702781319618225 time_taken: 0.05593729019165039\n",
      "Epoch 4: iteration 463/2501 train_loss: 0.46685388684272766 time_taken: 0.0559239387512207\n",
      "Epoch 4: iteration 464/2501 train_loss: 0.46668383479118347 time_taken: 0.056382179260253906\n",
      "Epoch 4: iteration 465/2501 train_loss: 0.46655967831611633 time_taken: 0.05657219886779785\n",
      "Epoch 4: iteration 466/2501 train_loss: 0.4664350748062134 time_taken: 0.056203603744506836\n",
      "Epoch 4: iteration 467/2501 train_loss: 0.46632567048072815 time_taken: 0.0563054084777832\n",
      "Epoch 4: iteration 468/2501 train_loss: 0.4661861062049866 time_taken: 0.05657219886779785\n",
      "Epoch 4: iteration 469/2501 train_loss: 0.46608418226242065 time_taken: 0.05607199668884277\n",
      "Epoch 4: iteration 470/2501 train_loss: 0.46598321199417114 time_taken: 0.05611705780029297\n",
      "Epoch 4: iteration 471/2501 train_loss: 0.4658772051334381 time_taken: 0.05612516403198242\n",
      "Epoch 4: iteration 472/2501 train_loss: 0.4658002257347107 time_taken: 0.05653786659240723\n",
      "Epoch 4: iteration 473/2501 train_loss: 0.46576380729675293 time_taken: 0.05694270133972168\n",
      "Epoch 4: iteration 474/2501 train_loss: 0.46574667096138 time_taken: 0.05943942070007324\n",
      "Epoch 4: iteration 475/2501 train_loss: 0.465738981962204 time_taken: 0.055890798568725586\n",
      "Epoch 4: iteration 476/2501 train_loss: 0.4657323658466339 time_taken: 0.05677437782287598\n",
      "Epoch 4: iteration 477/2501 train_loss: 0.46574071049690247 time_taken: 0.05664658546447754\n",
      "Epoch 4: iteration 478/2501 train_loss: 0.4657370150089264 time_taken: 0.05721688270568848\n",
      "Epoch 4: iteration 479/2501 train_loss: 0.465760201215744 time_taken: 0.056525468826293945\n",
      "Epoch 4: iteration 480/2501 train_loss: 0.4657871127128601 time_taken: 0.05640888214111328\n",
      "Epoch 4: iteration 481/2501 train_loss: 0.46580368280410767 time_taken: 0.0570828914642334\n",
      "Epoch 4: iteration 482/2501 train_loss: 0.46585455536842346 time_taken: 0.05716753005981445\n",
      "Epoch 4: iteration 483/2501 train_loss: 0.4658906161785126 time_taken: 0.056691646575927734\n",
      "Epoch 4: iteration 484/2501 train_loss: 0.4659499228000641 time_taken: 0.056453704833984375\n",
      "Epoch 4: iteration 485/2501 train_loss: 0.46600696444511414 time_taken: 0.05698347091674805\n",
      "Epoch 4: iteration 486/2501 train_loss: 0.4660702347755432 time_taken: 0.05697059631347656\n",
      "Epoch 4: iteration 487/2501 train_loss: 0.46613699197769165 time_taken: 0.05703854560852051\n",
      "Epoch 4: iteration 488/2501 train_loss: 0.46621084213256836 time_taken: 0.056975364685058594\n",
      "Epoch 4: iteration 489/2501 train_loss: 0.4662638306617737 time_taken: 0.05652809143066406\n",
      "Epoch 4: iteration 490/2501 train_loss: 0.4662667214870453 time_taken: 0.056929826736450195\n",
      "Epoch 4: iteration 491/2501 train_loss: 0.46631503105163574 time_taken: 0.05614113807678223\n",
      "Epoch 4: iteration 492/2501 train_loss: 0.46638771891593933 time_taken: 0.06400227546691895\n",
      "Epoch 4: iteration 493/2501 train_loss: 0.4664752185344696 time_taken: 0.05611276626586914\n",
      "Epoch 4: iteration 494/2501 train_loss: 0.4665224552154541 time_taken: 0.06155204772949219\n",
      "Epoch 4: iteration 495/2501 train_loss: 0.46654757857322693 time_taken: 0.05614447593688965\n",
      "Epoch 4: iteration 496/2501 train_loss: 0.4665701687335968 time_taken: 0.055959224700927734\n",
      "Epoch 4: iteration 497/2501 train_loss: 0.4665883183479309 time_taken: 0.055962324142456055\n",
      "Epoch 4: iteration 498/2501 train_loss: 0.4665626883506775 time_taken: 0.05761599540710449\n",
      "Epoch 4: iteration 499/2501 train_loss: 0.4665314257144928 time_taken: 0.05630922317504883\n",
      "Epoch 4: iteration 500/2501 train_loss: 0.4665042459964752 time_taken: 0.05658435821533203\n",
      "Epoch 4: iteration 501/2501 train_loss: 0.4664651155471802 time_taken: 0.05747556686401367\n",
      "Epoch 4: iteration 502/2501 train_loss: 0.4664575755596161 time_taken: 0.05629587173461914\n",
      "Epoch 4: iteration 503/2501 train_loss: 0.4664310812950134 time_taken: 0.05669832229614258\n",
      "Epoch 4: iteration 504/2501 train_loss: 0.466359406709671 time_taken: 0.05698823928833008\n",
      "Epoch 4: iteration 505/2501 train_loss: 0.4663681983947754 time_taken: 0.05648684501647949\n",
      "Epoch 4: iteration 506/2501 train_loss: 0.46635544300079346 time_taken: 0.05718350410461426\n",
      "Epoch 4: iteration 507/2501 train_loss: 0.4663309156894684 time_taken: 0.05801582336425781\n",
      "Epoch 4: iteration 508/2501 train_loss: 0.4663279354572296 time_taken: 0.05707049369812012\n",
      "Epoch 4: iteration 509/2501 train_loss: 0.46633246541023254 time_taken: 0.05610060691833496\n",
      "Epoch 4: iteration 510/2501 train_loss: 0.4663599729537964 time_taken: 0.056697845458984375\n",
      "Epoch 4: iteration 511/2501 train_loss: 0.466397762298584 time_taken: 0.05652904510498047\n",
      "Epoch 4: iteration 512/2501 train_loss: 0.46643343567848206 time_taken: 0.056112051010131836\n",
      "Epoch 4: iteration 513/2501 train_loss: 0.4664483368396759 time_taken: 0.05635547637939453\n",
      "Epoch 4: iteration 514/2501 train_loss: 0.4664819836616516 time_taken: 0.05665707588195801\n",
      "Epoch 4: iteration 515/2501 train_loss: 0.46654069423675537 time_taken: 0.05670332908630371\n",
      "Epoch 4: iteration 516/2501 train_loss: 0.46658048033714294 time_taken: 0.05654454231262207\n",
      "Epoch 4: iteration 517/2501 train_loss: 0.4666169583797455 time_taken: 0.05619454383850098\n",
      "Epoch 4: iteration 518/2501 train_loss: 0.4666599929332733 time_taken: 0.05682873725891113\n",
      "Epoch 4: iteration 519/2501 train_loss: 0.4666788876056671 time_taken: 0.056235313415527344\n",
      "Epoch 4: iteration 520/2501 train_loss: 0.46673908829689026 time_taken: 0.05607247352600098\n",
      "Epoch 4: iteration 521/2501 train_loss: 0.4668031334877014 time_taken: 0.05640864372253418\n",
      "Epoch 4: iteration 522/2501 train_loss: 0.46685194969177246 time_taken: 0.05729508399963379\n",
      "Epoch 4: iteration 523/2501 train_loss: 0.4668784737586975 time_taken: 0.05605196952819824\n",
      "Epoch 4: iteration 524/2501 train_loss: 0.4668864905834198 time_taken: 0.06654930114746094\n",
      "Epoch 4: iteration 525/2501 train_loss: 0.466925710439682 time_taken: 0.0558624267578125\n",
      "Epoch 4: iteration 526/2501 train_loss: 0.4669305384159088 time_taken: 0.05596113204956055\n",
      "Epoch 4: iteration 527/2501 train_loss: 0.46699440479278564 time_taken: 0.056470394134521484\n",
      "Epoch 4: iteration 528/2501 train_loss: 0.46703922748565674 time_taken: 0.056226491928100586\n",
      "Epoch 4: iteration 529/2501 train_loss: 0.46706223487854004 time_taken: 0.0559232234954834\n",
      "Epoch 4: iteration 530/2501 train_loss: 0.46709856390953064 time_taken: 0.05678725242614746\n",
      "Epoch 4: iteration 531/2501 train_loss: 0.4671298563480377 time_taken: 0.05670809745788574\n",
      "Epoch 4: iteration 532/2501 train_loss: 0.46718117594718933 time_taken: 0.05710101127624512\n",
      "Epoch 4: iteration 533/2501 train_loss: 0.4672237038612366 time_taken: 0.05704903602600098\n",
      "Epoch 4: iteration 534/2501 train_loss: 0.4672377109527588 time_taken: 0.05674386024475098\n",
      "Epoch 4: iteration 535/2501 train_loss: 0.4672521650791168 time_taken: 0.05637836456298828\n",
      "Epoch 4: iteration 536/2501 train_loss: 0.46726563572883606 time_taken: 0.05693674087524414\n",
      "Epoch 4: iteration 537/2501 train_loss: 0.46725958585739136 time_taken: 0.05665421485900879\n",
      "Epoch 4: iteration 538/2501 train_loss: 0.4672362804412842 time_taken: 0.05630683898925781\n",
      "Epoch 4: iteration 539/2501 train_loss: 0.4671756625175476 time_taken: 0.05704975128173828\n",
      "Epoch 4: iteration 540/2501 train_loss: 0.4671007990837097 time_taken: 0.056783437728881836\n",
      "Epoch 4: iteration 541/2501 train_loss: 0.46708887815475464 time_taken: 0.05650639533996582\n",
      "Epoch 4: iteration 542/2501 train_loss: 0.4670717716217041 time_taken: 0.056223392486572266\n",
      "Epoch 4: iteration 543/2501 train_loss: 0.4670562148094177 time_taken: 0.05619525909423828\n",
      "Epoch 4: iteration 544/2501 train_loss: 0.4670577347278595 time_taken: 0.0560460090637207\n",
      "Epoch 4: iteration 545/2501 train_loss: 0.4670501947402954 time_taken: 0.05628252029418945\n",
      "Epoch 4: iteration 546/2501 train_loss: 0.46704643964767456 time_taken: 0.056856632232666016\n",
      "Epoch 4: iteration 547/2501 train_loss: 0.46704205870628357 time_taken: 0.05585670471191406\n",
      "Epoch 4: iteration 548/2501 train_loss: 0.46707281470298767 time_taken: 0.056066274642944336\n",
      "Epoch 4: iteration 549/2501 train_loss: 0.4670655429363251 time_taken: 0.05653500556945801\n",
      "Epoch 4: iteration 550/2501 train_loss: 0.4670538008213043 time_taken: 0.05647897720336914\n",
      "Epoch 4: iteration 551/2501 train_loss: 0.46706512570381165 time_taken: 0.05646204948425293\n",
      "Epoch 4: iteration 552/2501 train_loss: 0.4670287072658539 time_taken: 0.056520700454711914\n",
      "Epoch 4: iteration 553/2501 train_loss: 0.4670090675354004 time_taken: 0.05686163902282715\n",
      "Epoch 4: iteration 554/2501 train_loss: 0.4669809639453888 time_taken: 0.05661916732788086\n",
      "Epoch 4: iteration 555/2501 train_loss: 0.4669530391693115 time_taken: 0.061774253845214844\n",
      "Epoch 4: iteration 556/2501 train_loss: 0.46695372462272644 time_taken: 0.05612754821777344\n",
      "Epoch 4: iteration 557/2501 train_loss: 0.46692556142807007 time_taken: 0.056069374084472656\n",
      "Epoch 4: iteration 558/2501 train_loss: 0.4668610095977783 time_taken: 0.056490421295166016\n",
      "Epoch 4: iteration 559/2501 train_loss: 0.46680667996406555 time_taken: 0.05627107620239258\n",
      "Epoch 4: iteration 560/2501 train_loss: 0.4667251706123352 time_taken: 0.056717872619628906\n",
      "Epoch 4: iteration 561/2501 train_loss: 0.4666213095188141 time_taken: 0.05658721923828125\n",
      "Epoch 4: iteration 562/2501 train_loss: 0.46652042865753174 time_taken: 0.056848764419555664\n",
      "Epoch 4: iteration 563/2501 train_loss: 0.4664243757724762 time_taken: 0.056883811950683594\n",
      "Epoch 4: iteration 564/2501 train_loss: 0.4663064777851105 time_taken: 0.05647897720336914\n",
      "Epoch 4: iteration 565/2501 train_loss: 0.4661797285079956 time_taken: 0.05695390701293945\n",
      "Epoch 4: iteration 566/2501 train_loss: 0.4660775363445282 time_taken: 0.05682373046875\n",
      "Epoch 4: iteration 567/2501 train_loss: 0.46596840023994446 time_taken: 0.056731462478637695\n",
      "Epoch 4: iteration 568/2501 train_loss: 0.4658733606338501 time_taken: 0.057024240493774414\n",
      "Epoch 4: iteration 569/2501 train_loss: 0.4657990634441376 time_taken: 0.056095123291015625\n",
      "Epoch 4: iteration 570/2501 train_loss: 0.465763121843338 time_taken: 0.05690121650695801\n",
      "Epoch 4: iteration 571/2501 train_loss: 0.46573394536972046 time_taken: 0.057416439056396484\n",
      "Epoch 4: iteration 572/2501 train_loss: 0.46570488810539246 time_taken: 0.0564885139465332\n",
      "Epoch 4: iteration 573/2501 train_loss: 0.4656887352466583 time_taken: 0.056362152099609375\n",
      "Epoch 4: iteration 574/2501 train_loss: 0.4656643271446228 time_taken: 0.05653834342956543\n",
      "Epoch 4: iteration 575/2501 train_loss: 0.46565166115760803 time_taken: 0.05657386779785156\n",
      "Epoch 4: iteration 576/2501 train_loss: 0.465606153011322 time_taken: 0.05656886100769043\n",
      "Epoch 4: iteration 577/2501 train_loss: 0.46558719873428345 time_taken: 0.05643486976623535\n",
      "Epoch 4: iteration 578/2501 train_loss: 0.4655340611934662 time_taken: 0.056711673736572266\n",
      "Epoch 4: iteration 579/2501 train_loss: 0.46548062562942505 time_taken: 0.06224417686462402\n",
      "Epoch 4: iteration 580/2501 train_loss: 0.4654066264629364 time_taken: 0.05658292770385742\n",
      "Epoch 4: iteration 581/2501 train_loss: 0.4653280973434448 time_taken: 0.05746722221374512\n",
      "Epoch 4: iteration 582/2501 train_loss: 0.4652697443962097 time_taken: 0.05622744560241699\n",
      "Epoch 4: iteration 583/2501 train_loss: 0.4651728570461273 time_taken: 0.05708503723144531\n",
      "Epoch 4: iteration 584/2501 train_loss: 0.46509304642677307 time_taken: 0.05779862403869629\n",
      "Epoch 4: iteration 585/2501 train_loss: 0.4649870693683624 time_taken: 0.056036949157714844\n",
      "Epoch 4: iteration 586/2501 train_loss: 0.4648989737033844 time_taken: 0.056166887283325195\n",
      "Epoch 4: iteration 587/2501 train_loss: 0.4647809565067291 time_taken: 0.05603432655334473\n",
      "Epoch 4: iteration 588/2501 train_loss: 0.4646555781364441 time_taken: 0.056427717208862305\n",
      "Epoch 4: iteration 589/2501 train_loss: 0.46453583240509033 time_taken: 0.05655932426452637\n",
      "Epoch 4: iteration 590/2501 train_loss: 0.4643919765949249 time_taken: 0.05650138854980469\n",
      "Epoch 4: iteration 591/2501 train_loss: 0.46426814794540405 time_taken: 0.055962562561035156\n",
      "Epoch 4: iteration 592/2501 train_loss: 0.46411800384521484 time_taken: 0.05622696876525879\n",
      "Epoch 4: iteration 593/2501 train_loss: 0.46397876739501953 time_taken: 0.05657505989074707\n",
      "Epoch 4: iteration 594/2501 train_loss: 0.4638293981552124 time_taken: 0.05632925033569336\n",
      "Epoch 4: iteration 595/2501 train_loss: 0.46367958188056946 time_taken: 0.0593876838684082\n",
      "Epoch 4: iteration 596/2501 train_loss: 0.4635336995124817 time_taken: 0.05606722831726074\n",
      "Epoch 4: iteration 597/2501 train_loss: 0.46339282393455505 time_taken: 0.055979013442993164\n",
      "Epoch 4: iteration 598/2501 train_loss: 0.4632517993450165 time_taken: 0.05663943290710449\n",
      "Epoch 4: iteration 599/2501 train_loss: 0.46309584379196167 time_taken: 0.05661487579345703\n",
      "Epoch 4: iteration 600/2501 train_loss: 0.4629840552806854 time_taken: 0.05651378631591797\n",
      "Epoch 4: iteration 601/2501 train_loss: 0.46289291977882385 time_taken: 0.061080217361450195\n",
      "Epoch 4: iteration 602/2501 train_loss: 0.4627968370914459 time_taken: 0.05665946006774902\n",
      "Epoch 4: iteration 603/2501 train_loss: 0.4627426266670227 time_taken: 0.0565493106842041\n",
      "Epoch 4: iteration 604/2501 train_loss: 0.4626788794994354 time_taken: 0.056528329849243164\n",
      "Epoch 4: iteration 605/2501 train_loss: 0.4626193940639496 time_taken: 0.05692338943481445\n",
      "Epoch 4: iteration 606/2501 train_loss: 0.46256494522094727 time_taken: 0.05763864517211914\n",
      "Epoch 4: iteration 607/2501 train_loss: 0.4625149667263031 time_taken: 0.05691409111022949\n",
      "Epoch 4: iteration 608/2501 train_loss: 0.4624793231487274 time_taken: 0.05671954154968262\n",
      "Epoch 4: iteration 609/2501 train_loss: 0.46246498823165894 time_taken: 0.05698800086975098\n",
      "Epoch 4: iteration 610/2501 train_loss: 0.4624197781085968 time_taken: 0.05730128288269043\n",
      "Epoch 4: iteration 611/2501 train_loss: 0.46238693594932556 time_taken: 0.056234121322631836\n",
      "Epoch 4: iteration 612/2501 train_loss: 0.46232134103775024 time_taken: 0.056922197341918945\n",
      "Epoch 4: iteration 613/2501 train_loss: 0.462271124124527 time_taken: 0.056481361389160156\n",
      "Epoch 4: iteration 614/2501 train_loss: 0.4622105658054352 time_taken: 0.05633401870727539\n",
      "Epoch 4: iteration 615/2501 train_loss: 0.4621346592903137 time_taken: 0.05592465400695801\n",
      "Epoch 4: iteration 616/2501 train_loss: 0.4620555341243744 time_taken: 0.059533119201660156\n",
      "Epoch 4: iteration 617/2501 train_loss: 0.46195968985557556 time_taken: 0.05695486068725586\n",
      "Epoch 4: iteration 618/2501 train_loss: 0.4618518054485321 time_taken: 0.0563352108001709\n",
      "Epoch 4: iteration 619/2501 train_loss: 0.46175646781921387 time_taken: 0.056107282638549805\n",
      "Epoch 4: iteration 620/2501 train_loss: 0.4616696238517761 time_taken: 0.08119654655456543\n",
      "Epoch 4: iteration 621/2501 train_loss: 0.46159425377845764 time_taken: 0.09152936935424805\n",
      "Epoch 4: iteration 622/2501 train_loss: 0.46153348684310913 time_taken: 0.0708470344543457\n",
      "Epoch 4: iteration 623/2501 train_loss: 0.4614800810813904 time_taken: 0.055812835693359375\n",
      "Epoch 4: iteration 624/2501 train_loss: 0.46142080426216125 time_taken: 0.060585975646972656\n",
      "Epoch 4: iteration 625/2501 train_loss: 0.4613519608974457 time_taken: 0.05567288398742676\n",
      "Epoch 4: iteration 626/2501 train_loss: 0.46129339933395386 time_taken: 0.05588102340698242\n",
      "Epoch 4: iteration 627/2501 train_loss: 0.46121522784233093 time_taken: 0.05605506896972656\n",
      "Epoch 4: iteration 628/2501 train_loss: 0.4611417055130005 time_taken: 0.05623269081115723\n",
      "Epoch 4: iteration 629/2501 train_loss: 0.46106794476509094 time_taken: 0.06203413009643555\n",
      "Epoch 4: iteration 630/2501 train_loss: 0.46101245284080505 time_taken: 0.05762028694152832\n",
      "Epoch 4: iteration 631/2501 train_loss: 0.4609454572200775 time_taken: 0.05670928955078125\n",
      "Epoch 4: iteration 632/2501 train_loss: 0.4609105587005615 time_taken: 0.056121826171875\n",
      "Epoch 4: iteration 633/2501 train_loss: 0.4608209729194641 time_taken: 0.05947113037109375\n",
      "Epoch 4: iteration 634/2501 train_loss: 0.46073001623153687 time_taken: 0.05620837211608887\n",
      "Epoch 4: iteration 635/2501 train_loss: 0.46062028408050537 time_taken: 0.056929588317871094\n",
      "Epoch 4: iteration 636/2501 train_loss: 0.4605003893375397 time_taken: 0.05695605278015137\n",
      "Epoch 4: iteration 637/2501 train_loss: 0.46036699414253235 time_taken: 0.05641484260559082\n",
      "Epoch 4: iteration 638/2501 train_loss: 0.4602302610874176 time_taken: 0.057219505310058594\n",
      "Epoch 4: iteration 639/2501 train_loss: 0.4600774645805359 time_taken: 0.05687093734741211\n",
      "Epoch 4: iteration 640/2501 train_loss: 0.45991918444633484 time_taken: 0.057451486587524414\n",
      "Epoch 4: iteration 641/2501 train_loss: 0.45973482728004456 time_taken: 0.05701923370361328\n",
      "Epoch 4: iteration 642/2501 train_loss: 0.4595365822315216 time_taken: 0.05747246742248535\n",
      "Epoch 4: iteration 643/2501 train_loss: 0.45933815836906433 time_taken: 0.05699563026428223\n",
      "Epoch 4: iteration 644/2501 train_loss: 0.4591532349586487 time_taken: 0.05721902847290039\n",
      "Epoch 4: iteration 645/2501 train_loss: 0.45894885063171387 time_taken: 0.059386253356933594\n",
      "Epoch 4: iteration 646/2501 train_loss: 0.4587571322917938 time_taken: 0.056966304779052734\n",
      "Epoch 4: iteration 647/2501 train_loss: 0.45857685804367065 time_taken: 0.056380510330200195\n",
      "Epoch 4: iteration 648/2501 train_loss: 0.45841795206069946 time_taken: 0.05670022964477539\n",
      "Epoch 4: iteration 649/2501 train_loss: 0.45830637216567993 time_taken: 0.0569608211517334\n",
      "Epoch 4: iteration 650/2501 train_loss: 0.45821210741996765 time_taken: 0.057434797286987305\n",
      "Epoch 4: iteration 651/2501 train_loss: 0.4581451416015625 time_taken: 0.05691981315612793\n",
      "Epoch 4: iteration 652/2501 train_loss: 0.4580722153186798 time_taken: 0.08986234664916992\n",
      "Epoch 4: iteration 653/2501 train_loss: 0.4580172002315521 time_taken: 0.07474398612976074\n",
      "Epoch 4: iteration 654/2501 train_loss: 0.4579642117023468 time_taken: 0.0566713809967041\n",
      "Epoch 4: iteration 655/2501 train_loss: 0.4579220414161682 time_taken: 0.08648467063903809\n",
      "Epoch 4: iteration 656/2501 train_loss: 0.45788443088531494 time_taken: 0.05620002746582031\n",
      "Epoch 4: iteration 657/2501 train_loss: 0.457831472158432 time_taken: 0.05630850791931152\n",
      "Epoch 4: iteration 658/2501 train_loss: 0.457805871963501 time_taken: 0.057097673416137695\n",
      "Epoch 4: iteration 659/2501 train_loss: 0.4577881395816803 time_taken: 0.056523799896240234\n",
      "Epoch 4: iteration 660/2501 train_loss: 0.45777571201324463 time_taken: 0.0565946102142334\n",
      "Epoch 4: iteration 661/2501 train_loss: 0.4577995240688324 time_taken: 0.05704545974731445\n",
      "Epoch 4: iteration 662/2501 train_loss: 0.45779597759246826 time_taken: 0.0560603141784668\n",
      "Epoch 4: iteration 663/2501 train_loss: 0.4577915370464325 time_taken: 0.05658912658691406\n",
      "Epoch 4: iteration 664/2501 train_loss: 0.45780301094055176 time_taken: 0.056557655334472656\n",
      "Epoch 4: iteration 665/2501 train_loss: 0.4578293263912201 time_taken: 0.05679917335510254\n",
      "Epoch 4: iteration 666/2501 train_loss: 0.45784708857536316 time_taken: 0.05621767044067383\n",
      "Epoch 4: iteration 667/2501 train_loss: 0.457850843667984 time_taken: 0.05616903305053711\n",
      "Epoch 4: iteration 668/2501 train_loss: 0.4579014480113983 time_taken: 0.05656766891479492\n",
      "Epoch 4: iteration 669/2501 train_loss: 0.45792102813720703 time_taken: 0.056659698486328125\n",
      "Epoch 4: iteration 670/2501 train_loss: 0.45796284079551697 time_taken: 0.05687904357910156\n",
      "Epoch 4: iteration 671/2501 train_loss: 0.458030641078949 time_taken: 0.05686044692993164\n",
      "Epoch 4: iteration 672/2501 train_loss: 0.45808860659599304 time_taken: 0.056517601013183594\n",
      "Epoch 4: iteration 673/2501 train_loss: 0.4581500291824341 time_taken: 0.05676078796386719\n",
      "Epoch 4: iteration 674/2501 train_loss: 0.4581763744354248 time_taken: 0.056348323822021484\n",
      "Epoch 4: iteration 675/2501 train_loss: 0.458247572183609 time_taken: 0.05650639533996582\n",
      "Epoch 4: iteration 676/2501 train_loss: 0.4582764804363251 time_taken: 0.05641508102416992\n",
      "Epoch 4: iteration 677/2501 train_loss: 0.4583149254322052 time_taken: 0.05640459060668945\n",
      "Epoch 4: iteration 678/2501 train_loss: 0.4583441913127899 time_taken: 0.05707263946533203\n",
      "Epoch 4: iteration 679/2501 train_loss: 0.45833927392959595 time_taken: 0.05716133117675781\n",
      "Epoch 4: iteration 680/2501 train_loss: 0.45834290981292725 time_taken: 0.056890010833740234\n",
      "Epoch 4: iteration 681/2501 train_loss: 0.45831093192100525 time_taken: 0.05673980712890625\n",
      "Epoch 4: iteration 682/2501 train_loss: 0.45827269554138184 time_taken: 0.057721614837646484\n",
      "Epoch 4: iteration 683/2501 train_loss: 0.4582486152648926 time_taken: 0.05600762367248535\n",
      "Epoch 4: iteration 684/2501 train_loss: 0.4582957327365875 time_taken: 0.05669808387756348\n",
      "Epoch 4: iteration 685/2501 train_loss: 0.45824429392814636 time_taken: 0.057114362716674805\n",
      "Epoch 4: iteration 686/2501 train_loss: 0.4581845998764038 time_taken: 0.056707143783569336\n",
      "Epoch 4: iteration 687/2501 train_loss: 0.4580923020839691 time_taken: 0.05579495429992676\n",
      "Epoch 4: iteration 688/2501 train_loss: 0.4580037295818329 time_taken: 0.05592083930969238\n",
      "Epoch 4: iteration 689/2501 train_loss: 0.4578874111175537 time_taken: 0.05579543113708496\n",
      "Epoch 4: iteration 690/2501 train_loss: 0.4578002393245697 time_taken: 0.05650901794433594\n",
      "Epoch 4: iteration 691/2501 train_loss: 0.4576977789402008 time_taken: 0.05636906623840332\n",
      "Epoch 4: iteration 692/2501 train_loss: 0.45756977796554565 time_taken: 0.05723261833190918\n",
      "Epoch 4: iteration 693/2501 train_loss: 0.4574846625328064 time_taken: 0.05644059181213379\n",
      "Epoch 4: iteration 694/2501 train_loss: 0.4573962390422821 time_taken: 0.05666160583496094\n",
      "Epoch 4: iteration 695/2501 train_loss: 0.45731350779533386 time_taken: 0.05654191970825195\n",
      "Epoch 4: iteration 696/2501 train_loss: 0.45722487568855286 time_taken: 0.0565495491027832\n",
      "Epoch 4: iteration 697/2501 train_loss: 0.4571946859359741 time_taken: 0.05638241767883301\n",
      "Epoch 4: iteration 698/2501 train_loss: 0.45713987946510315 time_taken: 0.05639457702636719\n",
      "Epoch 4: iteration 699/2501 train_loss: 0.4570887088775635 time_taken: 0.05758023262023926\n",
      "Epoch 4: iteration 700/2501 train_loss: 0.4570610821247101 time_taken: 0.056610822677612305\n",
      "Epoch 4: iteration 701/2501 train_loss: 0.45706015825271606 time_taken: 0.05621981620788574\n",
      "Epoch 4: iteration 702/2501 train_loss: 0.45705968141555786 time_taken: 0.05619931221008301\n",
      "Epoch 4: iteration 703/2501 train_loss: 0.45707759261131287 time_taken: 0.05668282508850098\n",
      "Epoch 4: iteration 704/2501 train_loss: 0.45711448788642883 time_taken: 0.05592775344848633\n",
      "Epoch 4: iteration 705/2501 train_loss: 0.4571472704410553 time_taken: 0.056407928466796875\n",
      "Epoch 4: iteration 706/2501 train_loss: 0.4571729302406311 time_taken: 0.05718064308166504\n",
      "Epoch 4: iteration 707/2501 train_loss: 0.45720452070236206 time_taken: 0.0566403865814209\n",
      "Epoch 4: iteration 708/2501 train_loss: 0.45726278424263 time_taken: 0.05611157417297363\n",
      "Epoch 4: iteration 709/2501 train_loss: 0.45732352137565613 time_taken: 0.0562899112701416\n",
      "Epoch 4: iteration 710/2501 train_loss: 0.45737239718437195 time_taken: 0.05609607696533203\n",
      "Epoch 4: iteration 711/2501 train_loss: 0.4574282765388489 time_taken: 0.056908607482910156\n",
      "Epoch 4: iteration 712/2501 train_loss: 0.4575077295303345 time_taken: 0.0569605827331543\n",
      "Epoch 4: iteration 713/2501 train_loss: 0.45753204822540283 time_taken: 0.057089805603027344\n",
      "Epoch 4: iteration 714/2501 train_loss: 0.45756685733795166 time_taken: 0.05685067176818848\n",
      "Epoch 4: iteration 715/2501 train_loss: 0.45759207010269165 time_taken: 0.05744624137878418\n",
      "Epoch 4: iteration 716/2501 train_loss: 0.45763126015663147 time_taken: 0.0570833683013916\n",
      "Epoch 4: iteration 717/2501 train_loss: 0.45765265822410583 time_taken: 0.056910037994384766\n",
      "Epoch 4: iteration 718/2501 train_loss: 0.45765894651412964 time_taken: 0.05698418617248535\n",
      "Epoch 4: iteration 719/2501 train_loss: 0.4576665759086609 time_taken: 0.056986093521118164\n",
      "Epoch 4: iteration 720/2501 train_loss: 0.4576776921749115 time_taken: 0.05622410774230957\n",
      "Epoch 4: iteration 721/2501 train_loss: 0.4576842784881592 time_taken: 0.05617952346801758\n",
      "Epoch 4: iteration 722/2501 train_loss: 0.45772120356559753 time_taken: 0.05659604072570801\n",
      "Epoch 4: iteration 723/2501 train_loss: 0.4577670395374298 time_taken: 0.061487674713134766\n",
      "Epoch 4: iteration 724/2501 train_loss: 0.45782166719436646 time_taken: 0.056029558181762695\n",
      "Epoch 4: iteration 725/2501 train_loss: 0.4578271806240082 time_taken: 0.056008338928222656\n",
      "Epoch 4: iteration 726/2501 train_loss: 0.4578182101249695 time_taken: 0.05617785453796387\n",
      "Epoch 4: iteration 727/2501 train_loss: 0.45779913663864136 time_taken: 0.05595827102661133\n",
      "Epoch 4: iteration 728/2501 train_loss: 0.45778778195381165 time_taken: 0.057359933853149414\n",
      "Epoch 4: iteration 729/2501 train_loss: 0.4577299654483795 time_taken: 0.05703616142272949\n",
      "Epoch 4: iteration 730/2501 train_loss: 0.45766663551330566 time_taken: 0.056569814682006836\n",
      "Epoch 4: iteration 731/2501 train_loss: 0.45758557319641113 time_taken: 0.05654788017272949\n",
      "Epoch 4: iteration 732/2501 train_loss: 0.4574958086013794 time_taken: 0.057947397232055664\n",
      "Epoch 4: iteration 733/2501 train_loss: 0.4573930501937866 time_taken: 0.05651283264160156\n",
      "Epoch 4: iteration 734/2501 train_loss: 0.45729535818099976 time_taken: 0.0567936897277832\n",
      "Epoch 4: iteration 735/2501 train_loss: 0.45716479420661926 time_taken: 0.056554555892944336\n",
      "Epoch 4: iteration 736/2501 train_loss: 0.4570334553718567 time_taken: 0.05649399757385254\n",
      "Epoch 4: iteration 737/2501 train_loss: 0.4569139778614044 time_taken: 0.05659675598144531\n",
      "Epoch 4: iteration 738/2501 train_loss: 0.4567986726760864 time_taken: 0.05642223358154297\n",
      "Epoch 4: iteration 739/2501 train_loss: 0.45671889185905457 time_taken: 0.05621790885925293\n",
      "Epoch 4: iteration 740/2501 train_loss: 0.4566386044025421 time_taken: 0.057415008544921875\n",
      "Epoch 4: iteration 741/2501 train_loss: 0.45656049251556396 time_taken: 0.05643177032470703\n",
      "Epoch 4: iteration 742/2501 train_loss: 0.4564739763736725 time_taken: 0.05583906173706055\n",
      "Epoch 4: iteration 743/2501 train_loss: 0.4563927948474884 time_taken: 0.057358503341674805\n",
      "Epoch 4: iteration 744/2501 train_loss: 0.45630520582199097 time_taken: 0.05759167671203613\n",
      "Epoch 4: iteration 745/2501 train_loss: 0.4562045633792877 time_taken: 0.05742168426513672\n",
      "Epoch 4: iteration 746/2501 train_loss: 0.4561040699481964 time_taken: 0.05648159980773926\n",
      "Epoch 4: iteration 747/2501 train_loss: 0.45603179931640625 time_taken: 0.05645298957824707\n",
      "Epoch 4: iteration 748/2501 train_loss: 0.4559493362903595 time_taken: 0.05606985092163086\n",
      "Epoch 4: iteration 749/2501 train_loss: 0.45586153864860535 time_taken: 0.056989431381225586\n",
      "Epoch 4: iteration 750/2501 train_loss: 0.4557676315307617 time_taken: 0.056854963302612305\n",
      "Epoch 4: iteration 751/2501 train_loss: 0.4556867778301239 time_taken: 0.056482553482055664\n",
      "Epoch 4: iteration 752/2501 train_loss: 0.4555984139442444 time_taken: 0.05640578269958496\n",
      "Epoch 4: iteration 753/2501 train_loss: 0.4554952383041382 time_taken: 0.05692577362060547\n",
      "Epoch 4: iteration 754/2501 train_loss: 0.4553920030593872 time_taken: 0.057688236236572266\n",
      "Epoch 4: iteration 755/2501 train_loss: 0.45526984333992004 time_taken: 0.0564875602722168\n",
      "Epoch 4: iteration 756/2501 train_loss: 0.4551762044429779 time_taken: 0.056934356689453125\n",
      "Epoch 4: iteration 757/2501 train_loss: 0.4550912082195282 time_taken: 0.06512713432312012\n",
      "Epoch 4: iteration 758/2501 train_loss: 0.4550151526927948 time_taken: 0.05681180953979492\n",
      "Epoch 4: iteration 759/2501 train_loss: 0.4549303650856018 time_taken: 0.056584835052490234\n",
      "Epoch 4: iteration 760/2501 train_loss: 0.454844206571579 time_taken: 0.055834054946899414\n",
      "Epoch 4: iteration 761/2501 train_loss: 0.4547770321369171 time_taken: 0.05572700500488281\n",
      "Epoch 4: iteration 762/2501 train_loss: 0.4547046720981598 time_taken: 0.05631852149963379\n",
      "Epoch 4: iteration 763/2501 train_loss: 0.4546372890472412 time_taken: 0.05575108528137207\n",
      "Epoch 4: iteration 764/2501 train_loss: 0.45458391308784485 time_taken: 0.056291818618774414\n",
      "Epoch 4: iteration 765/2501 train_loss: 0.4545571804046631 time_taken: 0.05653047561645508\n",
      "Epoch 4: iteration 766/2501 train_loss: 0.4545145332813263 time_taken: 0.05668830871582031\n",
      "Epoch 4: iteration 767/2501 train_loss: 0.4545089304447174 time_taken: 0.05604839324951172\n",
      "Epoch 4: iteration 768/2501 train_loss: 0.45450153946876526 time_taken: 0.05607199668884277\n",
      "Epoch 4: iteration 769/2501 train_loss: 0.45449963212013245 time_taken: 0.05666208267211914\n",
      "Epoch 4: iteration 770/2501 train_loss: 0.45447877049446106 time_taken: 0.056531429290771484\n",
      "Epoch 4: iteration 771/2501 train_loss: 0.45445969700813293 time_taken: 0.056195974349975586\n",
      "Epoch 4: iteration 772/2501 train_loss: 0.45444872975349426 time_taken: 0.05611085891723633\n",
      "Epoch 4: iteration 773/2501 train_loss: 0.45444825291633606 time_taken: 0.05624103546142578\n",
      "Epoch 4: iteration 774/2501 train_loss: 0.4544469118118286 time_taken: 0.05661916732788086\n",
      "Epoch 4: iteration 775/2501 train_loss: 0.45448461174964905 time_taken: 0.05633711814880371\n",
      "Epoch 4: iteration 776/2501 train_loss: 0.4544813334941864 time_taken: 0.055916786193847656\n",
      "Epoch 4: iteration 777/2501 train_loss: 0.45451465249061584 time_taken: 0.05653548240661621\n",
      "Epoch 4: iteration 778/2501 train_loss: 0.4545144736766815 time_taken: 0.05617856979370117\n",
      "Epoch 4: iteration 779/2501 train_loss: 0.4545019567012787 time_taken: 0.05677437782287598\n",
      "Epoch 4: iteration 780/2501 train_loss: 0.45446497201919556 time_taken: 0.055816650390625\n",
      "Epoch 4: iteration 781/2501 train_loss: 0.4544426500797272 time_taken: 0.05584406852722168\n",
      "Epoch 4: iteration 782/2501 train_loss: 0.45442062616348267 time_taken: 0.05714082717895508\n",
      "Epoch 4: iteration 783/2501 train_loss: 0.4543896019458771 time_taken: 0.056596994400024414\n",
      "Epoch 4: iteration 784/2501 train_loss: 0.4543338119983673 time_taken: 0.05634593963623047\n",
      "Epoch 4: iteration 785/2501 train_loss: 0.4542902112007141 time_taken: 0.05659365653991699\n",
      "Epoch 4: iteration 786/2501 train_loss: 0.45423561334609985 time_taken: 0.05646085739135742\n",
      "Epoch 4: iteration 787/2501 train_loss: 0.4541642665863037 time_taken: 0.056439876556396484\n",
      "Epoch 4: iteration 788/2501 train_loss: 0.4540705382823944 time_taken: 0.0566556453704834\n",
      "Epoch 4: iteration 789/2501 train_loss: 0.45400112867355347 time_taken: 0.057013750076293945\n",
      "Epoch 4: iteration 790/2501 train_loss: 0.45392563939094543 time_taken: 0.056113243103027344\n",
      "Epoch 4: iteration 791/2501 train_loss: 0.4538833200931549 time_taken: 0.05585741996765137\n",
      "Epoch 4: iteration 792/2501 train_loss: 0.45385104417800903 time_taken: 0.05619978904724121\n",
      "Epoch 4: iteration 793/2501 train_loss: 0.4538358151912689 time_taken: 0.05623006820678711\n",
      "Epoch 4: iteration 794/2501 train_loss: 0.4538126587867737 time_taken: 0.05614519119262695\n",
      "Epoch 4: iteration 795/2501 train_loss: 0.45378437638282776 time_taken: 0.05647730827331543\n",
      "Epoch 4: iteration 796/2501 train_loss: 0.45376846194267273 time_taken: 0.05648303031921387\n",
      "Epoch 4: iteration 797/2501 train_loss: 0.4537242650985718 time_taken: 0.05640006065368652\n",
      "Epoch 4: iteration 798/2501 train_loss: 0.45369279384613037 time_taken: 0.05693793296813965\n",
      "Epoch 4: iteration 799/2501 train_loss: 0.45365220308303833 time_taken: 0.056600332260131836\n",
      "Epoch 4: iteration 800/2501 train_loss: 0.4536131024360657 time_taken: 0.055931806564331055\n",
      "Epoch 4: iteration 801/2501 train_loss: 0.4535861909389496 time_taken: 0.056018829345703125\n",
      "Epoch 4: iteration 802/2501 train_loss: 0.4535609185695648 time_taken: 0.055914878845214844\n",
      "Epoch 4: iteration 803/2501 train_loss: 0.4535227417945862 time_taken: 0.05615711212158203\n",
      "Epoch 4: iteration 804/2501 train_loss: 0.4535004496574402 time_taken: 0.056104421615600586\n",
      "Epoch 4: iteration 805/2501 train_loss: 0.45347678661346436 time_taken: 0.056110382080078125\n",
      "Epoch 4: iteration 806/2501 train_loss: 0.45348402857780457 time_taken: 0.056851863861083984\n",
      "Epoch 4: iteration 807/2501 train_loss: 0.4534926116466522 time_taken: 0.05670952796936035\n",
      "Epoch 4: iteration 808/2501 train_loss: 0.45349860191345215 time_taken: 0.05684089660644531\n",
      "Epoch 4: iteration 809/2501 train_loss: 0.45350950956344604 time_taken: 0.05648994445800781\n",
      "Epoch 4: iteration 810/2501 train_loss: 0.4535377323627472 time_taken: 0.05611562728881836\n",
      "Epoch 4: iteration 811/2501 train_loss: 0.45355644822120667 time_taken: 0.0563662052154541\n",
      "Epoch 4: iteration 812/2501 train_loss: 0.45357391238212585 time_taken: 0.056447505950927734\n",
      "Epoch 4: iteration 813/2501 train_loss: 0.45356160402297974 time_taken: 0.05642104148864746\n",
      "Epoch 4: iteration 814/2501 train_loss: 0.4535661041736603 time_taken: 0.056389808654785156\n",
      "Epoch 4: iteration 815/2501 train_loss: 0.45357179641723633 time_taken: 0.05644845962524414\n",
      "Epoch 4: iteration 816/2501 train_loss: 0.4535845220088959 time_taken: 0.05650949478149414\n",
      "Epoch 4: iteration 817/2501 train_loss: 0.4535931646823883 time_taken: 0.056030988693237305\n",
      "Epoch 4: iteration 818/2501 train_loss: 0.4536186158657074 time_taken: 0.06013607978820801\n",
      "Epoch 4: iteration 819/2501 train_loss: 0.45366233587265015 time_taken: 0.05661416053771973\n",
      "Epoch 4: iteration 820/2501 train_loss: 0.45368728041648865 time_taken: 0.0562138557434082\n",
      "Epoch 4: iteration 821/2501 train_loss: 0.4537118375301361 time_taken: 0.05605816841125488\n",
      "Epoch 4: iteration 822/2501 train_loss: 0.4537501335144043 time_taken: 0.055974483489990234\n",
      "Epoch 4: iteration 823/2501 train_loss: 0.45375946164131165 time_taken: 0.056067705154418945\n",
      "Epoch 4: iteration 824/2501 train_loss: 0.45376482605934143 time_taken: 0.056334495544433594\n",
      "Epoch 4: iteration 825/2501 train_loss: 0.45378080010414124 time_taken: 0.056108951568603516\n",
      "Epoch 4: iteration 826/2501 train_loss: 0.4537842571735382 time_taken: 0.055695533752441406\n",
      "Epoch 4: iteration 827/2501 train_loss: 0.4538033902645111 time_taken: 0.055887699127197266\n",
      "Epoch 4: iteration 828/2501 train_loss: 0.4538256824016571 time_taken: 0.05588221549987793\n",
      "Epoch 4: iteration 829/2501 train_loss: 0.45383599400520325 time_taken: 0.05630993843078613\n",
      "Epoch 4: iteration 830/2501 train_loss: 0.4538503587245941 time_taken: 0.055840253829956055\n",
      "Epoch 4: iteration 831/2501 train_loss: 0.4538459777832031 time_taken: 0.05634331703186035\n",
      "Epoch 4: iteration 832/2501 train_loss: 0.4538502097129822 time_taken: 0.05626940727233887\n",
      "Epoch 4: iteration 833/2501 train_loss: 0.453840047121048 time_taken: 0.05626940727233887\n",
      "Epoch 4: iteration 834/2501 train_loss: 0.4538433849811554 time_taken: 0.056294918060302734\n",
      "Epoch 4: iteration 835/2501 train_loss: 0.4538683593273163 time_taken: 0.056511878967285156\n",
      "Epoch 4: iteration 836/2501 train_loss: 0.4538661241531372 time_taken: 0.056565284729003906\n",
      "Epoch 4: iteration 837/2501 train_loss: 0.45387396216392517 time_taken: 0.05682373046875\n",
      "Epoch 4: iteration 838/2501 train_loss: 0.4538846015930176 time_taken: 0.05646109580993652\n",
      "Epoch 4: iteration 839/2501 train_loss: 0.4538719952106476 time_taken: 0.05653071403503418\n",
      "Epoch 4: iteration 840/2501 train_loss: 0.45389461517333984 time_taken: 0.056535959243774414\n",
      "Epoch 4: iteration 841/2501 train_loss: 0.4539051651954651 time_taken: 0.05632662773132324\n",
      "Epoch 4: iteration 842/2501 train_loss: 0.4539071321487427 time_taken: 0.05644488334655762\n",
      "Epoch 4: iteration 843/2501 train_loss: 0.45390570163726807 time_taken: 0.05699014663696289\n",
      "Epoch 4: iteration 844/2501 train_loss: 0.45391541719436646 time_taken: 0.05680131912231445\n",
      "Epoch 4: iteration 845/2501 train_loss: 0.45392492413520813 time_taken: 0.05680680274963379\n",
      "Epoch 4: iteration 846/2501 train_loss: 0.4539167881011963 time_taken: 0.056861162185668945\n",
      "Epoch 4: iteration 847/2501 train_loss: 0.45392048358917236 time_taken: 0.05785036087036133\n",
      "Epoch 4: iteration 848/2501 train_loss: 0.45390525460243225 time_taken: 0.057145118713378906\n",
      "Epoch 4: iteration 849/2501 train_loss: 0.4539092183113098 time_taken: 0.056969642639160156\n",
      "Epoch 4: iteration 850/2501 train_loss: 0.4539002776145935 time_taken: 0.05725216865539551\n",
      "Epoch 4: iteration 851/2501 train_loss: 0.45390570163726807 time_taken: 0.05722618103027344\n",
      "Epoch 4: iteration 852/2501 train_loss: 0.45391345024108887 time_taken: 0.0571441650390625\n",
      "Epoch 4: iteration 853/2501 train_loss: 0.45391377806663513 time_taken: 0.056136369705200195\n",
      "Epoch 4: iteration 854/2501 train_loss: 0.4539262056350708 time_taken: 0.0777277946472168\n",
      "Epoch 4: iteration 855/2501 train_loss: 0.45394352078437805 time_taken: 0.05630850791931152\n",
      "Epoch 4: iteration 856/2501 train_loss: 0.4539574384689331 time_taken: 0.056841135025024414\n",
      "Epoch 4: iteration 857/2501 train_loss: 0.4539908766746521 time_taken: 0.055934906005859375\n",
      "Epoch 4: iteration 858/2501 train_loss: 0.4539952278137207 time_taken: 0.05655622482299805\n",
      "Epoch 4: iteration 859/2501 train_loss: 0.4540446102619171 time_taken: 0.05716419219970703\n",
      "Epoch 4: iteration 860/2501 train_loss: 0.4540994465351105 time_taken: 0.05690312385559082\n",
      "Epoch 4: iteration 861/2501 train_loss: 0.454166442155838 time_taken: 0.05630230903625488\n",
      "Epoch 4: iteration 862/2501 train_loss: 0.4542243778705597 time_taken: 0.057009220123291016\n",
      "Epoch 4: iteration 863/2501 train_loss: 0.45428749918937683 time_taken: 0.05715608596801758\n",
      "Epoch 4: iteration 864/2501 train_loss: 0.45432382822036743 time_taken: 0.056218624114990234\n",
      "Epoch 4: iteration 865/2501 train_loss: 0.45436879992485046 time_taken: 0.05616044998168945\n",
      "Epoch 4: iteration 866/2501 train_loss: 0.4544159173965454 time_taken: 0.05646538734436035\n",
      "Epoch 4: iteration 867/2501 train_loss: 0.45446667075157166 time_taken: 0.056291818618774414\n",
      "Epoch 4: iteration 868/2501 train_loss: 0.4545203745365143 time_taken: 0.057190656661987305\n",
      "Epoch 4: iteration 869/2501 train_loss: 0.45458412170410156 time_taken: 0.05695152282714844\n",
      "Epoch 4: iteration 870/2501 train_loss: 0.4546428918838501 time_taken: 0.0572354793548584\n",
      "Epoch 4: iteration 871/2501 train_loss: 0.4546964764595032 time_taken: 0.05605792999267578\n",
      "Epoch 4: iteration 872/2501 train_loss: 0.45475852489471436 time_taken: 0.05636787414550781\n",
      "Epoch 4: iteration 873/2501 train_loss: 0.45479220151901245 time_taken: 0.05604910850524902\n",
      "Epoch 4: iteration 874/2501 train_loss: 0.4548184871673584 time_taken: 0.05699443817138672\n",
      "Epoch 4: iteration 875/2501 train_loss: 0.4548594057559967 time_taken: 0.05648398399353027\n",
      "Epoch 4: iteration 876/2501 train_loss: 0.45489558577537537 time_taken: 0.05646061897277832\n",
      "Epoch 4: iteration 877/2501 train_loss: 0.45492178201675415 time_taken: 0.057529449462890625\n",
      "Epoch 4: iteration 878/2501 train_loss: 0.4549686014652252 time_taken: 0.05673956871032715\n",
      "Epoch 4: iteration 879/2501 train_loss: 0.45499369502067566 time_taken: 0.0568234920501709\n",
      "Epoch 4: iteration 880/2501 train_loss: 0.4549995958805084 time_taken: 0.05630183219909668\n",
      "Epoch 4: iteration 881/2501 train_loss: 0.45503243803977966 time_taken: 0.056557655334472656\n",
      "Epoch 4: iteration 882/2501 train_loss: 0.45504340529441833 time_taken: 0.05626320838928223\n",
      "Epoch 4: iteration 883/2501 train_loss: 0.4550590217113495 time_taken: 0.056391000747680664\n",
      "Epoch 4: iteration 884/2501 train_loss: 0.45508071780204773 time_taken: 0.05617475509643555\n",
      "Epoch 4: iteration 885/2501 train_loss: 0.4551331400871277 time_taken: 0.05631732940673828\n",
      "Epoch 4: iteration 886/2501 train_loss: 0.4554535150527954 time_taken: 0.05689382553100586\n",
      "Epoch 4: iteration 887/2501 train_loss: 0.45592495799064636 time_taken: 0.05753040313720703\n",
      "Epoch 4: iteration 888/2501 train_loss: 0.45595583319664 time_taken: 0.05745077133178711\n",
      "Epoch 4: iteration 889/2501 train_loss: 0.4561646580696106 time_taken: 0.05686211585998535\n",
      "Epoch 4: iteration 890/2501 train_loss: 0.456287682056427 time_taken: 0.0560910701751709\n",
      "Epoch 4: iteration 891/2501 train_loss: 0.45639267563819885 time_taken: 0.056000471115112305\n",
      "Epoch 4: iteration 892/2501 train_loss: 0.4565223157405853 time_taken: 0.056296348571777344\n",
      "Epoch 4: iteration 893/2501 train_loss: 0.45662105083465576 time_taken: 0.05661177635192871\n",
      "Epoch 4: iteration 894/2501 train_loss: 0.4567154049873352 time_taken: 0.05621600151062012\n",
      "Epoch 4: iteration 895/2501 train_loss: 0.4567956030368805 time_taken: 0.05706214904785156\n",
      "Epoch 4: iteration 896/2501 train_loss: 0.4568534195423126 time_taken: 0.05739474296569824\n",
      "Epoch 4: iteration 897/2501 train_loss: 0.4569140672683716 time_taken: 0.05679607391357422\n",
      "Epoch 4: iteration 898/2501 train_loss: 0.45694291591644287 time_taken: 0.056540489196777344\n",
      "Epoch 4: iteration 899/2501 train_loss: 0.4569563567638397 time_taken: 0.05637049674987793\n",
      "Epoch 4: iteration 900/2501 train_loss: 0.45698103308677673 time_taken: 0.05624580383300781\n",
      "Epoch 4: iteration 901/2501 train_loss: 0.45701250433921814 time_taken: 0.05655241012573242\n",
      "Epoch 4: iteration 902/2501 train_loss: 0.4570392966270447 time_taken: 0.06286120414733887\n",
      "Epoch 4: iteration 903/2501 train_loss: 0.4570431709289551 time_taken: 0.0561368465423584\n",
      "Epoch 4: iteration 904/2501 train_loss: 0.4570586681365967 time_taken: 0.057537078857421875\n",
      "Epoch 4: iteration 905/2501 train_loss: 0.457061767578125 time_taken: 0.0603179931640625\n",
      "Epoch 4: iteration 906/2501 train_loss: 0.457053005695343 time_taken: 0.05672764778137207\n",
      "Epoch 4: iteration 907/2501 train_loss: 0.4570518136024475 time_taken: 0.056730031967163086\n",
      "Epoch 4: iteration 908/2501 train_loss: 0.457061767578125 time_taken: 0.05987071990966797\n",
      "Epoch 4: iteration 909/2501 train_loss: 0.4570755064487457 time_taken: 0.05593466758728027\n",
      "Epoch 4: iteration 910/2501 train_loss: 0.45709294080734253 time_taken: 0.05723834037780762\n",
      "Epoch 4: iteration 911/2501 train_loss: 0.4571157991886139 time_taken: 0.0568084716796875\n",
      "Epoch 4: iteration 912/2501 train_loss: 0.45716655254364014 time_taken: 0.05778384208679199\n",
      "Epoch 4: iteration 913/2501 train_loss: 0.4572131335735321 time_taken: 0.05777573585510254\n",
      "Epoch 4: iteration 914/2501 train_loss: 0.45725151896476746 time_taken: 0.05698990821838379\n",
      "Epoch 4: iteration 915/2501 train_loss: 0.4573062062263489 time_taken: 0.056860923767089844\n",
      "Epoch 4: iteration 916/2501 train_loss: 0.4573553204536438 time_taken: 0.056360483169555664\n",
      "Epoch 4: iteration 917/2501 train_loss: 0.4574131965637207 time_taken: 0.05693531036376953\n",
      "Epoch 4: iteration 918/2501 train_loss: 0.45749029517173767 time_taken: 0.056011199951171875\n",
      "Epoch 4: iteration 919/2501 train_loss: 0.45755454897880554 time_taken: 0.056320905685424805\n",
      "Epoch 4: iteration 920/2501 train_loss: 0.4575922191143036 time_taken: 0.05721330642700195\n",
      "Epoch 4: iteration 921/2501 train_loss: 0.457623153924942 time_taken: 0.05632591247558594\n",
      "Epoch 4: iteration 922/2501 train_loss: 0.45764192938804626 time_taken: 0.05680131912231445\n",
      "Epoch 4: iteration 923/2501 train_loss: 0.45765507221221924 time_taken: 0.05657553672790527\n",
      "Epoch 4: iteration 924/2501 train_loss: 0.4576452672481537 time_taken: 0.05625414848327637\n",
      "Epoch 4: iteration 925/2501 train_loss: 0.45762497186660767 time_taken: 0.05695605278015137\n",
      "Epoch 4: iteration 926/2501 train_loss: 0.45760858058929443 time_taken: 0.056580305099487305\n",
      "Epoch 4: iteration 927/2501 train_loss: 0.4575574994087219 time_taken: 0.05685234069824219\n",
      "Epoch 4: iteration 928/2501 train_loss: 0.45750704407691956 time_taken: 0.05637383460998535\n",
      "Epoch 4: iteration 929/2501 train_loss: 0.4574452340602875 time_taken: 0.05655336380004883\n",
      "Epoch 4: iteration 930/2501 train_loss: 0.45737919211387634 time_taken: 0.055968284606933594\n",
      "Epoch 4: iteration 931/2501 train_loss: 0.45733165740966797 time_taken: 0.05606198310852051\n",
      "Epoch 4: iteration 932/2501 train_loss: 0.4572805166244507 time_taken: 0.056935787200927734\n",
      "Epoch 4: iteration 933/2501 train_loss: 0.45722222328186035 time_taken: 0.056975603103637695\n",
      "Epoch 4: iteration 934/2501 train_loss: 0.4571684002876282 time_taken: 0.05648922920227051\n",
      "Epoch 4: iteration 935/2501 train_loss: 0.457095742225647 time_taken: 0.05640220642089844\n",
      "Epoch 4: iteration 936/2501 train_loss: 0.457052618265152 time_taken: 0.05673527717590332\n",
      "Epoch 4: iteration 937/2501 train_loss: 0.45701518654823303 time_taken: 0.056612253189086914\n",
      "Epoch 4: iteration 938/2501 train_loss: 0.4569739103317261 time_taken: 0.05728793144226074\n",
      "Epoch 4: iteration 939/2501 train_loss: 0.456935852766037 time_taken: 0.05701804161071777\n",
      "Epoch 4: iteration 940/2501 train_loss: 0.45693469047546387 time_taken: 0.056295156478881836\n",
      "Epoch 4: iteration 941/2501 train_loss: 0.4569047689437866 time_taken: 0.05682969093322754\n",
      "Epoch 4: iteration 942/2501 train_loss: 0.4568721652030945 time_taken: 0.05642414093017578\n",
      "Epoch 4: iteration 943/2501 train_loss: 0.45682400465011597 time_taken: 0.05645489692687988\n",
      "Epoch 4: iteration 944/2501 train_loss: 0.45677411556243896 time_taken: 0.05678534507751465\n",
      "Epoch 4: iteration 945/2501 train_loss: 0.4567280113697052 time_taken: 0.056352853775024414\n",
      "Epoch 4: iteration 946/2501 train_loss: 0.4566743075847626 time_taken: 0.05658221244812012\n",
      "Epoch 4: iteration 947/2501 train_loss: 0.4566226601600647 time_taken: 0.05632758140563965\n",
      "Epoch 4: iteration 948/2501 train_loss: 0.4565906226634979 time_taken: 0.05689263343811035\n",
      "Epoch 4: iteration 949/2501 train_loss: 0.4565621018409729 time_taken: 0.05732154846191406\n",
      "Epoch 4: iteration 950/2501 train_loss: 0.45654335618019104 time_taken: 0.056995391845703125\n",
      "Epoch 4: iteration 951/2501 train_loss: 0.4565178155899048 time_taken: 0.05663895606994629\n",
      "Epoch 4: iteration 952/2501 train_loss: 0.4565170109272003 time_taken: 0.05764508247375488\n",
      "Epoch 4: iteration 953/2501 train_loss: 0.4564872980117798 time_taken: 0.05811476707458496\n",
      "Epoch 4: iteration 954/2501 train_loss: 0.45647481083869934 time_taken: 0.05683541297912598\n",
      "Epoch 4: iteration 955/2501 train_loss: 0.45644885301589966 time_taken: 0.056488037109375\n",
      "Epoch 4: iteration 956/2501 train_loss: 0.4564220905303955 time_taken: 0.05672574043273926\n",
      "Epoch 4: iteration 957/2501 train_loss: 0.45639368891716003 time_taken: 0.056691646575927734\n",
      "Epoch 4: iteration 958/2501 train_loss: 0.45636656880378723 time_taken: 0.05667424201965332\n",
      "Epoch 4: iteration 959/2501 train_loss: 0.4563351273536682 time_taken: 0.05655241012573242\n",
      "Epoch 4: iteration 960/2501 train_loss: 0.456288605928421 time_taken: 0.05672335624694824\n",
      "Epoch 4: iteration 961/2501 train_loss: 0.4562799036502838 time_taken: 0.057338714599609375\n",
      "Epoch 4: iteration 962/2501 train_loss: 0.45626261830329895 time_taken: 0.05673527717590332\n",
      "Epoch 4: iteration 963/2501 train_loss: 0.4562531113624573 time_taken: 0.05647420883178711\n",
      "Epoch 4: iteration 964/2501 train_loss: 0.4562453627586365 time_taken: 0.056322336196899414\n",
      "Epoch 4: iteration 965/2501 train_loss: 0.45623090863227844 time_taken: 0.05619454383850098\n",
      "Epoch 4: iteration 966/2501 train_loss: 0.4562341868877411 time_taken: 0.05722761154174805\n",
      "Epoch 4: iteration 967/2501 train_loss: 0.4562477767467499 time_taken: 0.056333303451538086\n",
      "Epoch 4: iteration 968/2501 train_loss: 0.45628270506858826 time_taken: 0.06090188026428223\n",
      "Epoch 4: iteration 969/2501 train_loss: 0.45629894733428955 time_taken: 0.05628180503845215\n",
      "Epoch 4: iteration 970/2501 train_loss: 0.45631879568099976 time_taken: 0.05648493766784668\n",
      "Epoch 4: iteration 971/2501 train_loss: 0.4563254415988922 time_taken: 0.05620598793029785\n",
      "Epoch 4: iteration 972/2501 train_loss: 0.45632293820381165 time_taken: 0.05697202682495117\n",
      "Epoch 4: iteration 973/2501 train_loss: 0.45632699131965637 time_taken: 0.057480812072753906\n",
      "Epoch 4: iteration 974/2501 train_loss: 0.45630764961242676 time_taken: 0.057250261306762695\n",
      "Epoch 4: iteration 975/2501 train_loss: 0.45629364252090454 time_taken: 0.05763506889343262\n",
      "Epoch 4: iteration 976/2501 train_loss: 0.4562665820121765 time_taken: 0.05684304237365723\n",
      "Epoch 4: iteration 977/2501 train_loss: 0.45622915029525757 time_taken: 0.056850433349609375\n",
      "Epoch 4: iteration 978/2501 train_loss: 0.45620957016944885 time_taken: 0.05694150924682617\n",
      "Epoch 4: iteration 979/2501 train_loss: 0.4561823010444641 time_taken: 0.057427406311035156\n",
      "Epoch 4: iteration 980/2501 train_loss: 0.45616042613983154 time_taken: 0.05688071250915527\n",
      "Epoch 4: iteration 981/2501 train_loss: 0.4561315178871155 time_taken: 0.05693793296813965\n",
      "Epoch 4: iteration 982/2501 train_loss: 0.45614999532699585 time_taken: 0.05773353576660156\n",
      "Epoch 4: iteration 983/2501 train_loss: 0.4561680853366852 time_taken: 0.05662393569946289\n",
      "Epoch 4: iteration 984/2501 train_loss: 0.4561535120010376 time_taken: 0.05641317367553711\n",
      "Epoch 4: iteration 985/2501 train_loss: 0.45616042613983154 time_taken: 0.0569765567779541\n",
      "Epoch 4: iteration 986/2501 train_loss: 0.4561893939971924 time_taken: 0.056903839111328125\n",
      "Epoch 4: iteration 987/2501 train_loss: 0.45620203018188477 time_taken: 0.05666017532348633\n",
      "Epoch 4: iteration 988/2501 train_loss: 0.456197589635849 time_taken: 0.0563349723815918\n",
      "Epoch 4: iteration 989/2501 train_loss: 0.4561977684497833 time_taken: 0.056339263916015625\n",
      "Epoch 4: iteration 990/2501 train_loss: 0.45620203018188477 time_taken: 0.05621075630187988\n",
      "Epoch 4: iteration 991/2501 train_loss: 0.45619475841522217 time_taken: 0.05613207817077637\n",
      "Epoch 4: iteration 992/2501 train_loss: 0.4562031924724579 time_taken: 0.05694174766540527\n",
      "Epoch 4: iteration 993/2501 train_loss: 0.4562143385410309 time_taken: 0.05684494972229004\n",
      "Epoch 4: iteration 994/2501 train_loss: 0.4562247395515442 time_taken: 0.056941986083984375\n",
      "Epoch 4: iteration 995/2501 train_loss: 0.45621830224990845 time_taken: 0.05702519416809082\n",
      "Epoch 4: iteration 996/2501 train_loss: 0.45621031522750854 time_taken: 0.05686330795288086\n",
      "Epoch 4: iteration 997/2501 train_loss: 0.4561750590801239 time_taken: 0.0578303337097168\n",
      "Epoch 4: iteration 998/2501 train_loss: 0.4561305046081543 time_taken: 0.05656862258911133\n",
      "Epoch 4: iteration 999/2501 train_loss: 0.4560808837413788 time_taken: 0.05684828758239746\n",
      "Epoch 4: iteration 1000/2501 train_loss: 0.4560156762599945 time_taken: 0.05697822570800781\n",
      "Epoch 4: iteration 1001/2501 train_loss: 0.4559430778026581 time_taken: 0.05717635154724121\n",
      "Epoch 4: iteration 1002/2501 train_loss: 0.45587119460105896 time_taken: 0.05628848075866699\n",
      "Epoch 4: iteration 1003/2501 train_loss: 0.4557954668998718 time_taken: 0.05659675598144531\n",
      "Epoch 4: iteration 1004/2501 train_loss: 0.4557066559791565 time_taken: 0.05572319030761719\n",
      "Epoch 4: iteration 1005/2501 train_loss: 0.45563143491744995 time_taken: 0.055907249450683594\n",
      "Epoch 4: iteration 1006/2501 train_loss: 0.45558270812034607 time_taken: 0.05576157569885254\n",
      "Epoch 4: iteration 1007/2501 train_loss: 0.4555697441101074 time_taken: 0.05640363693237305\n",
      "Epoch 4: iteration 1008/2501 train_loss: 0.4554695785045624 time_taken: 0.056183815002441406\n",
      "Epoch 4: iteration 1009/2501 train_loss: 0.45537978410720825 time_taken: 0.05588078498840332\n",
      "Epoch 4: iteration 1010/2501 train_loss: 0.45528367161750793 time_taken: 0.05743598937988281\n",
      "Epoch 4: iteration 1011/2501 train_loss: 0.45518070459365845 time_taken: 0.05627012252807617\n",
      "Epoch 4: iteration 1012/2501 train_loss: 0.4550715982913971 time_taken: 0.05677938461303711\n",
      "Epoch 4: iteration 1013/2501 train_loss: 0.45495107769966125 time_taken: 0.05643725395202637\n",
      "Epoch 4: iteration 1014/2501 train_loss: 0.45483702421188354 time_taken: 0.056957244873046875\n",
      "Epoch 4: iteration 1015/2501 train_loss: 0.45474183559417725 time_taken: 0.05638694763183594\n",
      "Epoch 4: iteration 1016/2501 train_loss: 0.45463570952415466 time_taken: 0.05644702911376953\n",
      "Epoch 4: iteration 1017/2501 train_loss: 0.45454519987106323 time_taken: 0.05623030662536621\n",
      "Epoch 4: iteration 1018/2501 train_loss: 0.45444899797439575 time_taken: 0.057739973068237305\n",
      "Epoch 4: iteration 1019/2501 train_loss: 0.45439413189888 time_taken: 0.05666995048522949\n",
      "Epoch 4: iteration 1020/2501 train_loss: 0.4543358087539673 time_taken: 0.05616927146911621\n",
      "Epoch 4: iteration 1021/2501 train_loss: 0.45428213477134705 time_taken: 0.05609869956970215\n",
      "Epoch 4: iteration 1022/2501 train_loss: 0.45426636934280396 time_taken: 0.05646657943725586\n",
      "Epoch 4: iteration 1023/2501 train_loss: 0.45425209403038025 time_taken: 0.0569303035736084\n",
      "Epoch 4: iteration 1024/2501 train_loss: 0.4542257785797119 time_taken: 0.05667519569396973\n",
      "Epoch 4: iteration 1025/2501 train_loss: 0.4542238414287567 time_taken: 0.05667924880981445\n",
      "Epoch 4: iteration 1026/2501 train_loss: 0.4542052447795868 time_taken: 0.05657243728637695\n",
      "Epoch 4: iteration 1027/2501 train_loss: 0.4541914165019989 time_taken: 0.05646228790283203\n",
      "Epoch 4: iteration 1028/2501 train_loss: 0.45417317748069763 time_taken: 0.05728721618652344\n",
      "Epoch 4: iteration 1029/2501 train_loss: 0.4541526734828949 time_taken: 0.05669260025024414\n",
      "Epoch 4: iteration 1030/2501 train_loss: 0.4541124403476715 time_taken: 0.0569455623626709\n",
      "Epoch 4: iteration 1031/2501 train_loss: 0.4540633261203766 time_taken: 0.05676412582397461\n",
      "Epoch 4: iteration 1032/2501 train_loss: 0.4539937674999237 time_taken: 0.05667304992675781\n",
      "Epoch 4: iteration 1033/2501 train_loss: 0.45394158363342285 time_taken: 0.056911468505859375\n",
      "Epoch 4: iteration 1034/2501 train_loss: 0.45388028025627136 time_taken: 0.056176185607910156\n",
      "Epoch 4: iteration 1035/2501 train_loss: 0.45381051301956177 time_taken: 0.056756019592285156\n",
      "Epoch 4: iteration 1036/2501 train_loss: 0.45372796058654785 time_taken: 0.05599784851074219\n",
      "Epoch 4: iteration 1037/2501 train_loss: 0.4536522328853607 time_taken: 0.05666160583496094\n",
      "Epoch 4: iteration 1038/2501 train_loss: 0.45357176661491394 time_taken: 0.0560302734375\n",
      "Epoch 4: iteration 1039/2501 train_loss: 0.4534704387187958 time_taken: 0.056867361068725586\n",
      "Epoch 4: iteration 1040/2501 train_loss: 0.45338675379753113 time_taken: 0.056386709213256836\n",
      "Epoch 4: iteration 1041/2501 train_loss: 0.45329394936561584 time_taken: 0.05623149871826172\n",
      "Epoch 4: iteration 1042/2501 train_loss: 0.4532066881656647 time_taken: 0.05694007873535156\n",
      "Epoch 4: iteration 1043/2501 train_loss: 0.4531288146972656 time_taken: 0.05636024475097656\n",
      "Epoch 4: iteration 1044/2501 train_loss: 0.45305079221725464 time_taken: 0.05688762664794922\n",
      "Epoch 4: iteration 1045/2501 train_loss: 0.45297887921333313 time_taken: 0.05699944496154785\n",
      "Epoch 4: iteration 1046/2501 train_loss: 0.4528956413269043 time_taken: 0.05662202835083008\n",
      "Epoch 4: iteration 1047/2501 train_loss: 0.45283815264701843 time_taken: 0.05636167526245117\n",
      "Epoch 4: iteration 1048/2501 train_loss: 0.4527689814567566 time_taken: 0.05621194839477539\n",
      "Epoch 4: iteration 1049/2501 train_loss: 0.45272400975227356 time_taken: 0.05657649040222168\n",
      "Epoch 4: iteration 1050/2501 train_loss: 0.4526787996292114 time_taken: 0.05629158020019531\n",
      "Epoch 4: iteration 1051/2501 train_loss: 0.4526304006576538 time_taken: 0.05598139762878418\n",
      "Epoch 4: iteration 1052/2501 train_loss: 0.4525865614414215 time_taken: 0.05623626708984375\n",
      "Epoch 4: iteration 1053/2501 train_loss: 0.4525669813156128 time_taken: 0.056496381759643555\n",
      "Epoch 4: iteration 1054/2501 train_loss: 0.45255014300346375 time_taken: 0.0766763687133789\n",
      "Epoch 4: iteration 1055/2501 train_loss: 0.4525391757488251 time_taken: 0.07117319107055664\n",
      "Epoch 4: iteration 1056/2501 train_loss: 0.4525391459465027 time_taken: 0.05611228942871094\n",
      "Epoch 4: iteration 1057/2501 train_loss: 0.45253199338912964 time_taken: 0.056555986404418945\n",
      "Epoch 4: iteration 1058/2501 train_loss: 0.452536016702652 time_taken: 0.05616569519042969\n",
      "Epoch 4: iteration 1059/2501 train_loss: 0.45252835750579834 time_taken: 0.05659151077270508\n",
      "Epoch 4: iteration 1060/2501 train_loss: 0.45252564549446106 time_taken: 0.05637097358703613\n",
      "Epoch 4: iteration 1061/2501 train_loss: 0.45253193378448486 time_taken: 0.05658435821533203\n",
      "Epoch 4: iteration 1062/2501 train_loss: 0.45254820585250854 time_taken: 0.05948591232299805\n",
      "Epoch 4: iteration 1063/2501 train_loss: 0.45255088806152344 time_taken: 0.05599641799926758\n",
      "Epoch 4: iteration 1064/2501 train_loss: 0.4525735080242157 time_taken: 0.056149959564208984\n",
      "Epoch 4: iteration 1065/2501 train_loss: 0.4525931775569916 time_taken: 0.05953812599182129\n",
      "Epoch 4: iteration 1066/2501 train_loss: 0.4526280164718628 time_taken: 0.056513071060180664\n",
      "Epoch 4: iteration 1067/2501 train_loss: 0.4526471793651581 time_taken: 0.057663679122924805\n",
      "Epoch 4: iteration 1068/2501 train_loss: 0.4526790976524353 time_taken: 0.05613088607788086\n",
      "Epoch 4: iteration 1069/2501 train_loss: 0.4526994824409485 time_taken: 0.05646944046020508\n",
      "Epoch 4: iteration 1070/2501 train_loss: 0.45271170139312744 time_taken: 0.05624198913574219\n",
      "Epoch 4: iteration 1071/2501 train_loss: 0.45273149013519287 time_taken: 0.05691862106323242\n",
      "Epoch 4: iteration 1072/2501 train_loss: 0.4527478814125061 time_taken: 0.05624055862426758\n",
      "Epoch 4: iteration 1073/2501 train_loss: 0.4527496099472046 time_taken: 0.05627560615539551\n",
      "Epoch 4: iteration 1074/2501 train_loss: 0.45275938510894775 time_taken: 0.05657219886779785\n",
      "Epoch 4: iteration 1075/2501 train_loss: 0.452751487493515 time_taken: 0.056519269943237305\n",
      "Epoch 4: iteration 1076/2501 train_loss: 0.4527527987957001 time_taken: 0.05726122856140137\n",
      "Epoch 4: iteration 1077/2501 train_loss: 0.4527740180492401 time_taken: 0.05658388137817383\n",
      "Epoch 4: iteration 1078/2501 train_loss: 0.4527839422225952 time_taken: 0.05739593505859375\n",
      "Epoch 4: iteration 1079/2501 train_loss: 0.4527832865715027 time_taken: 0.056914329528808594\n",
      "Epoch 4: iteration 1080/2501 train_loss: 0.45278164744377136 time_taken: 0.056635379791259766\n",
      "Epoch 4: iteration 1081/2501 train_loss: 0.45279133319854736 time_taken: 0.06975579261779785\n",
      "Epoch 4: iteration 1082/2501 train_loss: 0.4528122544288635 time_taken: 0.056516170501708984\n",
      "Epoch 4: iteration 1083/2501 train_loss: 0.4528411626815796 time_taken: 0.05680227279663086\n",
      "Epoch 4: iteration 1084/2501 train_loss: 0.45287641882896423 time_taken: 0.06215929985046387\n",
      "Epoch 4: iteration 1085/2501 train_loss: 0.4529113471508026 time_taken: 0.05689740180969238\n",
      "Epoch 4: iteration 1086/2501 train_loss: 0.4529339373111725 time_taken: 0.056543588638305664\n",
      "Epoch 4: iteration 1087/2501 train_loss: 0.4529815912246704 time_taken: 0.05671072006225586\n",
      "Epoch 4: iteration 1088/2501 train_loss: 0.4530150592327118 time_taken: 0.0568995475769043\n",
      "Epoch 4: iteration 1089/2501 train_loss: 0.45304617285728455 time_taken: 0.05731081962585449\n",
      "Epoch 4: iteration 1090/2501 train_loss: 0.4530731737613678 time_taken: 0.05661511421203613\n",
      "Epoch 4: iteration 1091/2501 train_loss: 0.45307567715644836 time_taken: 0.0565338134765625\n",
      "Epoch 4: iteration 1092/2501 train_loss: 0.4531143307685852 time_taken: 0.0566408634185791\n",
      "Epoch 4: iteration 1093/2501 train_loss: 0.45313626527786255 time_taken: 0.05697965621948242\n",
      "Epoch 4: iteration 1094/2501 train_loss: 0.453141987323761 time_taken: 0.05703544616699219\n",
      "Epoch 4: iteration 1095/2501 train_loss: 0.45315223932266235 time_taken: 0.056394338607788086\n",
      "Epoch 4: iteration 1096/2501 train_loss: 0.45316001772880554 time_taken: 0.05644822120666504\n",
      "Epoch 4: iteration 1097/2501 train_loss: 0.45316430926322937 time_taken: 0.05727076530456543\n",
      "Epoch 4: iteration 1098/2501 train_loss: 0.4531593322753906 time_taken: 0.05690956115722656\n",
      "Epoch 4: iteration 1099/2501 train_loss: 0.45316338539123535 time_taken: 0.0565800666809082\n",
      "Epoch 4: iteration 1100/2501 train_loss: 0.4531889855861664 time_taken: 0.056349754333496094\n",
      "Epoch 4: iteration 1101/2501 train_loss: 0.45321139693260193 time_taken: 0.05614519119262695\n",
      "Epoch 4: iteration 1102/2501 train_loss: 0.4532204270362854 time_taken: 0.056983232498168945\n",
      "Epoch 4: iteration 1103/2501 train_loss: 0.45323702692985535 time_taken: 0.05666804313659668\n",
      "Epoch 4: iteration 1104/2501 train_loss: 0.45325061678886414 time_taken: 0.05701947212219238\n",
      "Epoch 4: iteration 1105/2501 train_loss: 0.45326629281044006 time_taken: 0.0614473819732666\n",
      "Epoch 4: iteration 1106/2501 train_loss: 0.45327088236808777 time_taken: 0.05668997764587402\n",
      "Epoch 4: iteration 1107/2501 train_loss: 0.4532674551010132 time_taken: 0.05725884437561035\n",
      "Epoch 4: iteration 1108/2501 train_loss: 0.4532707929611206 time_taken: 0.05678153038024902\n",
      "Epoch 4: iteration 1109/2501 train_loss: 0.453266978263855 time_taken: 0.057065725326538086\n",
      "Epoch 4: iteration 1110/2501 train_loss: 0.45328444242477417 time_taken: 0.05698752403259277\n",
      "Epoch 4: iteration 1111/2501 train_loss: 0.4532853960990906 time_taken: 0.05670785903930664\n",
      "Epoch 4: iteration 1112/2501 train_loss: 0.4532853066921234 time_taken: 0.05696463584899902\n",
      "Epoch 4: iteration 1113/2501 train_loss: 0.4532861113548279 time_taken: 0.05670571327209473\n",
      "Epoch 4: iteration 1114/2501 train_loss: 0.4532729387283325 time_taken: 0.05666542053222656\n",
      "Epoch 4: iteration 1115/2501 train_loss: 0.45324698090553284 time_taken: 0.05704760551452637\n",
      "Epoch 4: iteration 1116/2501 train_loss: 0.4532237946987152 time_taken: 0.057236671447753906\n",
      "Epoch 4: iteration 1117/2501 train_loss: 0.4532112777233124 time_taken: 0.05690598487854004\n",
      "Epoch 4: iteration 1118/2501 train_loss: 0.45318421721458435 time_taken: 0.05674266815185547\n",
      "Epoch 4: iteration 1119/2501 train_loss: 0.45315060019493103 time_taken: 0.061625003814697266\n",
      "Epoch 4: iteration 1120/2501 train_loss: 0.4531058073043823 time_taken: 0.0570523738861084\n",
      "Epoch 4: iteration 1121/2501 train_loss: 0.4530501067638397 time_taken: 0.05764436721801758\n",
      "Epoch 4: iteration 1122/2501 train_loss: 0.4530128538608551 time_taken: 0.056467294692993164\n",
      "Epoch 4: iteration 1123/2501 train_loss: 0.45297133922576904 time_taken: 0.05697202682495117\n",
      "Epoch 4: iteration 1124/2501 train_loss: 0.4529537856578827 time_taken: 0.0565946102142334\n",
      "Epoch 4: iteration 1125/2501 train_loss: 0.4529304802417755 time_taken: 0.05634927749633789\n",
      "Epoch 4: iteration 1126/2501 train_loss: 0.452926903963089 time_taken: 0.05656909942626953\n",
      "Epoch 4: iteration 1127/2501 train_loss: 0.4528951346874237 time_taken: 0.05623579025268555\n",
      "Epoch 4: iteration 1128/2501 train_loss: 0.4529065191745758 time_taken: 0.056267499923706055\n",
      "Epoch 4: iteration 1129/2501 train_loss: 0.4529162049293518 time_taken: 0.05635523796081543\n",
      "Epoch 4: iteration 1130/2501 train_loss: 0.4529285132884979 time_taken: 0.05682063102722168\n",
      "Epoch 4: iteration 1131/2501 train_loss: 0.45294350385665894 time_taken: 0.056963205337524414\n",
      "Epoch 4: iteration 1132/2501 train_loss: 0.4529412090778351 time_taken: 0.0566563606262207\n",
      "Epoch 4: iteration 1133/2501 train_loss: 0.45294755697250366 time_taken: 0.05760455131530762\n",
      "Epoch 4: iteration 1134/2501 train_loss: 0.4529692232608795 time_taken: 0.05606198310852051\n",
      "Epoch 4: iteration 1135/2501 train_loss: 0.4530017077922821 time_taken: 0.0564730167388916\n",
      "Epoch 4: iteration 1136/2501 train_loss: 0.4530094265937805 time_taken: 0.05764365196228027\n",
      "Epoch 4: iteration 1137/2501 train_loss: 0.45303136110305786 time_taken: 0.05617713928222656\n",
      "Epoch 4: iteration 1138/2501 train_loss: 0.45302683115005493 time_taken: 0.05665326118469238\n",
      "Epoch 4: iteration 1139/2501 train_loss: 0.4530125558376312 time_taken: 0.056938886642456055\n",
      "Epoch 4: iteration 1140/2501 train_loss: 0.452973872423172 time_taken: 0.05611419677734375\n",
      "Epoch 4: iteration 1141/2501 train_loss: 0.4529426395893097 time_taken: 0.05671286582946777\n",
      "Epoch 4: iteration 1142/2501 train_loss: 0.45291125774383545 time_taken: 0.05631613731384277\n",
      "Epoch 4: iteration 1143/2501 train_loss: 0.45289313793182373 time_taken: 0.05630779266357422\n",
      "Epoch 4: iteration 1144/2501 train_loss: 0.4528448283672333 time_taken: 0.058001041412353516\n",
      "Epoch 4: iteration 1145/2501 train_loss: 0.4527665674686432 time_taken: 0.05610060691833496\n",
      "Epoch 4: iteration 1146/2501 train_loss: 0.45269152522087097 time_taken: 0.05774068832397461\n",
      "Epoch 4: iteration 1147/2501 train_loss: 0.4526100754737854 time_taken: 0.05607271194458008\n",
      "Epoch 4: iteration 1148/2501 train_loss: 0.4525279700756073 time_taken: 0.057386159896850586\n",
      "Epoch 4: iteration 1149/2501 train_loss: 0.452434241771698 time_taken: 0.06716322898864746\n",
      "Epoch 4: iteration 1150/2501 train_loss: 0.4523305296897888 time_taken: 0.05670738220214844\n",
      "Epoch 4: iteration 1151/2501 train_loss: 0.45222097635269165 time_taken: 0.05652189254760742\n",
      "Epoch 4: iteration 1152/2501 train_loss: 0.4521172046661377 time_taken: 0.05629563331604004\n",
      "Epoch 4: iteration 1153/2501 train_loss: 0.45200395584106445 time_taken: 0.056113481521606445\n",
      "Epoch 4: iteration 1154/2501 train_loss: 0.45188596844673157 time_taken: 0.05589437484741211\n",
      "Epoch 4: iteration 1155/2501 train_loss: 0.45178160071372986 time_taken: 0.05578494071960449\n",
      "Epoch 4: iteration 1156/2501 train_loss: 0.4516884386539459 time_taken: 0.05646371841430664\n",
      "Epoch 4: iteration 1157/2501 train_loss: 0.4516158401966095 time_taken: 0.056038856506347656\n",
      "Epoch 4: iteration 1158/2501 train_loss: 0.45154860615730286 time_taken: 0.05751323699951172\n",
      "Epoch 4: iteration 1159/2501 train_loss: 0.451482892036438 time_taken: 0.057413578033447266\n",
      "Epoch 4: iteration 1160/2501 train_loss: 0.45144331455230713 time_taken: 0.0578913688659668\n",
      "Epoch 4: iteration 1161/2501 train_loss: 0.4514080286026001 time_taken: 0.0572354793548584\n",
      "Epoch 4: iteration 1162/2501 train_loss: 0.4513853192329407 time_taken: 0.05689239501953125\n",
      "Epoch 4: iteration 1163/2501 train_loss: 0.4513542056083679 time_taken: 0.05673098564147949\n",
      "Epoch 4: iteration 1164/2501 train_loss: 0.4513196647167206 time_taken: 0.056710004806518555\n",
      "Epoch 4: iteration 1165/2501 train_loss: 0.45126211643218994 time_taken: 0.05670976638793945\n",
      "Epoch 4: iteration 1166/2501 train_loss: 0.45120927691459656 time_taken: 0.056067466735839844\n",
      "Epoch 4: iteration 1167/2501 train_loss: 0.4511581361293793 time_taken: 0.056586265563964844\n",
      "Epoch 4: iteration 1168/2501 train_loss: 0.45112356543540955 time_taken: 0.06054115295410156\n",
      "Epoch 4: iteration 1169/2501 train_loss: 0.45109477639198303 time_taken: 0.05612063407897949\n",
      "Epoch 4: iteration 1170/2501 train_loss: 0.45108935236930847 time_taken: 0.05657839775085449\n",
      "Epoch 4: iteration 1171/2501 train_loss: 0.45108386874198914 time_taken: 0.05658578872680664\n",
      "Epoch 4: iteration 1172/2501 train_loss: 0.4510814845561981 time_taken: 0.05617713928222656\n",
      "Epoch 4: iteration 1173/2501 train_loss: 0.45107465982437134 time_taken: 0.056516170501708984\n",
      "Epoch 4: iteration 1174/2501 train_loss: 0.45105981826782227 time_taken: 0.057329654693603516\n",
      "Epoch 4: iteration 1175/2501 train_loss: 0.45106807351112366 time_taken: 0.05666017532348633\n",
      "Epoch 4: iteration 1176/2501 train_loss: 0.45109155774116516 time_taken: 0.05686187744140625\n",
      "Epoch 4: iteration 1177/2501 train_loss: 0.4511125981807709 time_taken: 0.05676841735839844\n",
      "Epoch 4: iteration 1178/2501 train_loss: 0.4511290192604065 time_taken: 0.05686211585998535\n",
      "Epoch 4: iteration 1179/2501 train_loss: 0.4511215388774872 time_taken: 0.06109952926635742\n",
      "Epoch 4: iteration 1180/2501 train_loss: 0.4511094391345978 time_taken: 0.056719064712524414\n",
      "Epoch 4: iteration 1181/2501 train_loss: 0.4511072635650635 time_taken: 0.05686020851135254\n",
      "Epoch 4: iteration 1182/2501 train_loss: 0.4511157274246216 time_taken: 0.057891130447387695\n",
      "Epoch 4: iteration 1183/2501 train_loss: 0.4511200189590454 time_taken: 0.056784868240356445\n",
      "Epoch 4: iteration 1184/2501 train_loss: 0.4511163532733917 time_taken: 0.05751538276672363\n",
      "Epoch 4: iteration 1185/2501 train_loss: 0.45111414790153503 time_taken: 0.07140111923217773\n",
      "Epoch 4: iteration 1186/2501 train_loss: 0.4511226713657379 time_taken: 0.056937456130981445\n",
      "Epoch 4: iteration 1187/2501 train_loss: 0.4511301517486572 time_taken: 0.056975603103637695\n",
      "Epoch 4: iteration 1188/2501 train_loss: 0.45114806294441223 time_taken: 0.05667519569396973\n",
      "Epoch 4: iteration 1189/2501 train_loss: 0.45117250084877014 time_taken: 0.05669450759887695\n",
      "Epoch 4: iteration 1190/2501 train_loss: 0.45117270946502686 time_taken: 0.05659747123718262\n",
      "Epoch 4: iteration 1191/2501 train_loss: 0.4511706829071045 time_taken: 0.056566715240478516\n",
      "Epoch 4: iteration 1192/2501 train_loss: 0.4511719346046448 time_taken: 0.05662393569946289\n",
      "Epoch 4: iteration 1193/2501 train_loss: 0.45115795731544495 time_taken: 0.05704474449157715\n",
      "Epoch 4: iteration 1194/2501 train_loss: 0.45112285017967224 time_taken: 0.056948184967041016\n",
      "Epoch 4: iteration 1195/2501 train_loss: 0.4510904848575592 time_taken: 0.0568087100982666\n",
      "Epoch 4: iteration 1196/2501 train_loss: 0.45105189085006714 time_taken: 0.05709123611450195\n",
      "Epoch 4: iteration 1197/2501 train_loss: 0.4510057866573334 time_taken: 0.05674910545349121\n",
      "Epoch 4: iteration 1198/2501 train_loss: 0.4509689211845398 time_taken: 0.057030439376831055\n",
      "Epoch 4: iteration 1199/2501 train_loss: 0.4509333670139313 time_taken: 0.056345462799072266\n",
      "Epoch 4: iteration 1200/2501 train_loss: 0.4509072005748749 time_taken: 0.056630611419677734\n",
      "Epoch 4: iteration 1201/2501 train_loss: 0.4508746266365051 time_taken: 0.05598855018615723\n",
      "Epoch 4: iteration 1202/2501 train_loss: 0.4508490562438965 time_taken: 0.05665779113769531\n",
      "Epoch 4: iteration 1203/2501 train_loss: 0.4508230984210968 time_taken: 0.057150840759277344\n",
      "Epoch 4: iteration 1204/2501 train_loss: 0.45080050826072693 time_taken: 0.05713176727294922\n",
      "Epoch 4: iteration 1205/2501 train_loss: 0.45078566670417786 time_taken: 0.0568695068359375\n",
      "Epoch 4: iteration 1206/2501 train_loss: 0.45078179240226746 time_taken: 0.05682945251464844\n",
      "Epoch 4: iteration 1207/2501 train_loss: 0.45079314708709717 time_taken: 0.05688834190368652\n",
      "Epoch 4: iteration 1208/2501 train_loss: 0.45081037282943726 time_taken: 0.057576894760131836\n",
      "Epoch 4: iteration 1209/2501 train_loss: 0.4508304297924042 time_taken: 0.05638623237609863\n",
      "Epoch 4: iteration 1210/2501 train_loss: 0.45084694027900696 time_taken: 0.05650949478149414\n",
      "Epoch 4: iteration 1211/2501 train_loss: 0.45086196064949036 time_taken: 0.056182146072387695\n",
      "Epoch 4: iteration 1212/2501 train_loss: 0.45087486505508423 time_taken: 0.05669450759887695\n",
      "Epoch 4: iteration 1213/2501 train_loss: 0.45088711380958557 time_taken: 0.056168556213378906\n",
      "Epoch 4: iteration 1214/2501 train_loss: 0.45091909170150757 time_taken: 0.05595207214355469\n",
      "Epoch 4: iteration 1215/2501 train_loss: 0.45094820857048035 time_taken: 0.056833505630493164\n",
      "Epoch 4: iteration 1216/2501 train_loss: 0.45100080966949463 time_taken: 0.05688047409057617\n",
      "Epoch 4: iteration 1217/2501 train_loss: 0.45105767250061035 time_taken: 0.056849002838134766\n",
      "Epoch 4: iteration 1218/2501 train_loss: 0.4511052370071411 time_taken: 0.056670188903808594\n",
      "Epoch 4: iteration 1219/2501 train_loss: 0.45113930106163025 time_taken: 0.05689859390258789\n",
      "Epoch 4: iteration 1220/2501 train_loss: 0.45118191838264465 time_taken: 0.056548357009887695\n",
      "Epoch 4: iteration 1221/2501 train_loss: 0.4512152373790741 time_taken: 0.05671358108520508\n",
      "Epoch 4: iteration 1222/2501 train_loss: 0.45123371481895447 time_taken: 0.05666160583496094\n",
      "Epoch 4: iteration 1223/2501 train_loss: 0.4512369632720947 time_taken: 0.05719590187072754\n",
      "Epoch 4: iteration 1224/2501 train_loss: 0.45126184821128845 time_taken: 0.056612491607666016\n",
      "Epoch 4: iteration 1225/2501 train_loss: 0.4512653052806854 time_taken: 0.056715965270996094\n",
      "Epoch 4: iteration 1226/2501 train_loss: 0.4512825906276703 time_taken: 0.05617094039916992\n",
      "Epoch 4: iteration 1227/2501 train_loss: 0.4513077139854431 time_taken: 0.05676698684692383\n",
      "Epoch 4: iteration 1228/2501 train_loss: 0.45133838057518005 time_taken: 0.0568087100982666\n",
      "Epoch 4: iteration 1229/2501 train_loss: 0.45135200023651123 time_taken: 0.06182408332824707\n",
      "Epoch 4: iteration 1230/2501 train_loss: 0.45138680934906006 time_taken: 0.057462453842163086\n",
      "Epoch 4: iteration 1231/2501 train_loss: 0.4514119625091553 time_taken: 0.05649089813232422\n",
      "Epoch 4: iteration 1232/2501 train_loss: 0.4514455199241638 time_taken: 0.056825876235961914\n",
      "Epoch 4: iteration 1233/2501 train_loss: 0.45147815346717834 time_taken: 0.05689072608947754\n",
      "Epoch 4: iteration 1234/2501 train_loss: 0.45151519775390625 time_taken: 0.056723833084106445\n",
      "Epoch 4: iteration 1235/2501 train_loss: 0.45155295729637146 time_taken: 0.0597531795501709\n",
      "Epoch 4: iteration 1236/2501 train_loss: 0.4515978991985321 time_taken: 0.05602526664733887\n",
      "Epoch 4: iteration 1237/2501 train_loss: 0.45163288712501526 time_taken: 0.05659341812133789\n",
      "Epoch 4: iteration 1238/2501 train_loss: 0.45166221261024475 time_taken: 0.05713152885437012\n",
      "Epoch 4: iteration 1239/2501 train_loss: 0.4516778290271759 time_taken: 0.06121373176574707\n",
      "Epoch 4: iteration 1240/2501 train_loss: 0.4516870081424713 time_taken: 0.05709695816040039\n",
      "Epoch 4: iteration 1241/2501 train_loss: 0.45170316100120544 time_taken: 0.056539058685302734\n",
      "Epoch 4: iteration 1242/2501 train_loss: 0.4517086148262024 time_taken: 0.05636191368103027\n",
      "Epoch 4: iteration 1243/2501 train_loss: 0.45170873403549194 time_taken: 0.05695605278015137\n",
      "Epoch 4: iteration 1244/2501 train_loss: 0.45170751214027405 time_taken: 0.05745077133178711\n",
      "Epoch 4: iteration 1245/2501 train_loss: 0.4517122209072113 time_taken: 0.05652475357055664\n",
      "Epoch 4: iteration 1246/2501 train_loss: 0.4517240822315216 time_taken: 0.05666780471801758\n",
      "Epoch 4: iteration 1247/2501 train_loss: 0.45173561573028564 time_taken: 0.05722641944885254\n",
      "Epoch 4: iteration 1248/2501 train_loss: 0.45175838470458984 time_taken: 0.0563349723815918\n",
      "Epoch 4: iteration 1249/2501 train_loss: 0.4517735242843628 time_taken: 0.05632162094116211\n",
      "Epoch 4: iteration 1250/2501 train_loss: 0.45178109407424927 time_taken: 0.05644702911376953\n",
      "Epoch 4: iteration 1251/2501 train_loss: 0.4518018662929535 time_taken: 0.05694007873535156\n",
      "Epoch 4: iteration 1252/2501 train_loss: 0.4518200159072876 time_taken: 0.05710768699645996\n",
      "Epoch 4: iteration 1253/2501 train_loss: 0.451849102973938 time_taken: 0.05612659454345703\n",
      "Epoch 4: iteration 1254/2501 train_loss: 0.45186635851860046 time_taken: 0.05640435218811035\n",
      "Epoch 4: iteration 1255/2501 train_loss: 0.4518508315086365 time_taken: 0.05686783790588379\n",
      "Epoch 4: iteration 1256/2501 train_loss: 0.4518465995788574 time_taken: 0.0572972297668457\n",
      "Epoch 4: iteration 1257/2501 train_loss: 0.4518424868583679 time_taken: 0.056821584701538086\n",
      "Epoch 4: iteration 1258/2501 train_loss: 0.45183345675468445 time_taken: 0.05670905113220215\n",
      "Epoch 4: iteration 1259/2501 train_loss: 0.45181745290756226 time_taken: 0.057115793228149414\n",
      "Epoch 4: iteration 1260/2501 train_loss: 0.45179837942123413 time_taken: 0.056939125061035156\n",
      "Epoch 4: iteration 1261/2501 train_loss: 0.45177051424980164 time_taken: 0.0566103458404541\n",
      "Epoch 4: iteration 1262/2501 train_loss: 0.4517326354980469 time_taken: 0.057196855545043945\n",
      "Epoch 4: iteration 1263/2501 train_loss: 0.4516803026199341 time_taken: 0.05656933784484863\n",
      "Epoch 4: iteration 1264/2501 train_loss: 0.45162874460220337 time_taken: 0.057138919830322266\n",
      "Epoch 4: iteration 1265/2501 train_loss: 0.45157280564308167 time_taken: 0.05648446083068848\n",
      "Epoch 4: iteration 1266/2501 train_loss: 0.451513409614563 time_taken: 0.056455373764038086\n",
      "Epoch 4: iteration 1267/2501 train_loss: 0.4514484703540802 time_taken: 0.05696535110473633\n",
      "Epoch 4: iteration 1268/2501 train_loss: 0.451386958360672 time_taken: 0.05693340301513672\n",
      "Epoch 4: iteration 1269/2501 train_loss: 0.4513101279735565 time_taken: 0.056208133697509766\n",
      "Epoch 4: iteration 1270/2501 train_loss: 0.4512447714805603 time_taken: 0.056270599365234375\n",
      "Epoch 4: iteration 1271/2501 train_loss: 0.45119619369506836 time_taken: 0.056241512298583984\n",
      "Epoch 4: iteration 1272/2501 train_loss: 0.45112988352775574 time_taken: 0.05593991279602051\n",
      "Epoch 4: iteration 1273/2501 train_loss: 0.4510810077190399 time_taken: 0.07076573371887207\n",
      "Epoch 4: iteration 1274/2501 train_loss: 0.4510471820831299 time_taken: 0.056416988372802734\n",
      "Epoch 4: iteration 1275/2501 train_loss: 0.4510127902030945 time_taken: 0.05697035789489746\n",
      "Epoch 4: iteration 1276/2501 train_loss: 0.45099470019340515 time_taken: 0.06335592269897461\n",
      "Epoch 4: iteration 1277/2501 train_loss: 0.45097553730010986 time_taken: 0.05658078193664551\n",
      "Epoch 4: iteration 1278/2501 train_loss: 0.4509598910808563 time_taken: 0.05675196647644043\n",
      "Epoch 4: iteration 1279/2501 train_loss: 0.45093783736228943 time_taken: 0.05675911903381348\n",
      "Epoch 4: iteration 1280/2501 train_loss: 0.45091068744659424 time_taken: 0.05631685256958008\n",
      "Epoch 4: iteration 1281/2501 train_loss: 0.4508723318576813 time_taken: 0.056409597396850586\n",
      "Epoch 4: iteration 1282/2501 train_loss: 0.4508507549762726 time_taken: 0.0568540096282959\n",
      "Epoch 4: iteration 1283/2501 train_loss: 0.4508102238178253 time_taken: 0.05660271644592285\n",
      "Epoch 4: iteration 1284/2501 train_loss: 0.45077085494995117 time_taken: 0.057640790939331055\n",
      "Epoch 4: iteration 1285/2501 train_loss: 0.4507239758968353 time_taken: 0.05633974075317383\n",
      "Epoch 4: iteration 1286/2501 train_loss: 0.4506765305995941 time_taken: 0.05659365653991699\n",
      "Epoch 4: iteration 1287/2501 train_loss: 0.4506261646747589 time_taken: 0.05666828155517578\n",
      "Epoch 4: iteration 1288/2501 train_loss: 0.4505786597728729 time_taken: 0.05671238899230957\n",
      "Epoch 4: iteration 1289/2501 train_loss: 0.450528085231781 time_taken: 0.05596351623535156\n",
      "Epoch 4: iteration 1290/2501 train_loss: 0.4504818022251129 time_taken: 0.0564885139465332\n",
      "Epoch 4: iteration 1291/2501 train_loss: 0.4504370093345642 time_taken: 0.05625605583190918\n",
      "Epoch 4: iteration 1292/2501 train_loss: 0.45038822293281555 time_taken: 0.05659127235412598\n",
      "Epoch 4: iteration 1293/2501 train_loss: 0.4503500759601593 time_taken: 0.05712127685546875\n",
      "Epoch 4: iteration 1294/2501 train_loss: 0.4503101706504822 time_taken: 0.05721449851989746\n",
      "Epoch 4: iteration 1295/2501 train_loss: 0.45028451085090637 time_taken: 0.05712318420410156\n",
      "Epoch 4: iteration 1296/2501 train_loss: 0.45026203989982605 time_taken: 0.056305885314941406\n",
      "Epoch 4: iteration 1297/2501 train_loss: 0.45024770498275757 time_taken: 0.05640363693237305\n",
      "Epoch 4: iteration 1298/2501 train_loss: 0.450246661901474 time_taken: 0.05641984939575195\n",
      "Epoch 4: iteration 1299/2501 train_loss: 0.4502401053905487 time_taken: 0.05717658996582031\n",
      "Epoch 4: iteration 1300/2501 train_loss: 0.4502478539943695 time_taken: 0.0568697452545166\n",
      "Epoch 4: iteration 1301/2501 train_loss: 0.45025986433029175 time_taken: 0.05714821815490723\n",
      "Epoch 4: iteration 1302/2501 train_loss: 0.45028001070022583 time_taken: 0.05652308464050293\n",
      "Epoch 4: iteration 1303/2501 train_loss: 0.4502929151058197 time_taken: 0.05651688575744629\n",
      "Epoch 4: iteration 1304/2501 train_loss: 0.450291246175766 time_taken: 0.05692601203918457\n",
      "Epoch 4: iteration 1305/2501 train_loss: 0.45029276609420776 time_taken: 0.0563349723815918\n",
      "Epoch 4: iteration 1306/2501 train_loss: 0.4502830505371094 time_taken: 0.05627036094665527\n",
      "Epoch 4: iteration 1307/2501 train_loss: 0.4502905011177063 time_taken: 0.05653119087219238\n",
      "Epoch 4: iteration 1308/2501 train_loss: 0.45029929280281067 time_taken: 0.05610990524291992\n",
      "Epoch 4: iteration 1309/2501 train_loss: 0.45030102133750916 time_taken: 0.05784106254577637\n",
      "Epoch 4: iteration 1310/2501 train_loss: 0.4502951204776764 time_taken: 0.05712723731994629\n",
      "Epoch 4: iteration 1311/2501 train_loss: 0.4503108263015747 time_taken: 0.056923627853393555\n",
      "Epoch 4: iteration 1312/2501 train_loss: 0.45032161474227905 time_taken: 0.05683779716491699\n",
      "Epoch 4: iteration 1313/2501 train_loss: 0.450337678194046 time_taken: 0.05694937705993652\n",
      "Epoch 4: iteration 1314/2501 train_loss: 0.4503440260887146 time_taken: 0.05689287185668945\n",
      "Epoch 4: iteration 1315/2501 train_loss: 0.45036885142326355 time_taken: 0.057340383529663086\n",
      "Epoch 4: iteration 1316/2501 train_loss: 0.4503832757472992 time_taken: 0.056879281997680664\n",
      "Epoch 4: iteration 1317/2501 train_loss: 0.45039382576942444 time_taken: 0.05647778511047363\n",
      "Epoch 4: iteration 1318/2501 train_loss: 0.4503995180130005 time_taken: 0.05649876594543457\n",
      "Epoch 4: iteration 1319/2501 train_loss: 0.4504088759422302 time_taken: 0.05687260627746582\n",
      "Epoch 4: iteration 1320/2501 train_loss: 0.4504036009311676 time_taken: 0.05679941177368164\n",
      "Epoch 4: iteration 1321/2501 train_loss: 0.4504101276397705 time_taken: 0.05674004554748535\n",
      "Epoch 4: iteration 1322/2501 train_loss: 0.45039910078048706 time_taken: 0.05707097053527832\n",
      "Epoch 4: iteration 1323/2501 train_loss: 0.4503919780254364 time_taken: 0.057402610778808594\n",
      "Epoch 4: iteration 1324/2501 train_loss: 0.4503827393054962 time_taken: 0.05654478073120117\n",
      "Epoch 4: iteration 1325/2501 train_loss: 0.4503655731678009 time_taken: 0.057318925857543945\n",
      "Epoch 4: iteration 1326/2501 train_loss: 0.45035287737846375 time_taken: 0.056839704513549805\n",
      "Epoch 4: iteration 1327/2501 train_loss: 0.4503367841243744 time_taken: 0.0565028190612793\n",
      "Epoch 4: iteration 1328/2501 train_loss: 0.45033708214759827 time_taken: 0.05682802200317383\n",
      "Epoch 4: iteration 1329/2501 train_loss: 0.45041149854660034 time_taken: 0.0574953556060791\n",
      "Epoch 4: iteration 1330/2501 train_loss: 0.4505310356616974 time_taken: 0.05672454833984375\n",
      "Epoch 4: iteration 1331/2501 train_loss: 0.4505510628223419 time_taken: 0.05666685104370117\n",
      "Epoch 4: iteration 1332/2501 train_loss: 0.45055198669433594 time_taken: 0.05640864372253418\n",
      "Epoch 4: iteration 1333/2501 train_loss: 0.45056724548339844 time_taken: 0.057427167892456055\n",
      "Epoch 4: iteration 1334/2501 train_loss: 0.4505672752857208 time_taken: 0.0565035343170166\n",
      "Epoch 4: iteration 1335/2501 train_loss: 0.4505658745765686 time_taken: 0.05733227729797363\n",
      "Epoch 4: iteration 1336/2501 train_loss: 0.45059236884117126 time_taken: 0.05626940727233887\n",
      "Epoch 4: iteration 1337/2501 train_loss: 0.45059287548065186 time_taken: 0.05614876747131348\n",
      "Epoch 4: iteration 1338/2501 train_loss: 0.45060351490974426 time_taken: 0.05604386329650879\n",
      "Epoch 4: iteration 1339/2501 train_loss: 0.45061203837394714 time_taken: 0.05629563331604004\n",
      "Epoch 4: iteration 1340/2501 train_loss: 0.4506188631057739 time_taken: 0.05744528770446777\n",
      "Epoch 4: iteration 1341/2501 train_loss: 0.450632244348526 time_taken: 0.05790996551513672\n",
      "Epoch 4: iteration 1342/2501 train_loss: 0.4506461024284363 time_taken: 0.056847572326660156\n",
      "Epoch 4: iteration 1343/2501 train_loss: 0.45065611600875854 time_taken: 0.05710101127624512\n",
      "Epoch 4: iteration 1344/2501 train_loss: 0.4506675601005554 time_taken: 0.05743074417114258\n",
      "Epoch 4: iteration 1345/2501 train_loss: 0.4506838619709015 time_taken: 0.056868553161621094\n",
      "Epoch 4: iteration 1346/2501 train_loss: 0.4507102370262146 time_taken: 0.05689382553100586\n",
      "Epoch 4: iteration 1347/2501 train_loss: 0.4507439434528351 time_taken: 0.05721259117126465\n",
      "Epoch 4: iteration 1348/2501 train_loss: 0.4507659375667572 time_taken: 0.056799888610839844\n",
      "Epoch 4: iteration 1349/2501 train_loss: 0.45079728960990906 time_taken: 0.056944847106933594\n",
      "Epoch 4: iteration 1350/2501 train_loss: 0.4508295953273773 time_taken: 0.05738377571105957\n",
      "Epoch 4: iteration 1351/2501 train_loss: 0.4508514404296875 time_taken: 0.05703258514404297\n",
      "Epoch 4: iteration 1352/2501 train_loss: 0.4508746266365051 time_taken: 0.057068586349487305\n",
      "Epoch 4: iteration 1353/2501 train_loss: 0.4508957266807556 time_taken: 0.05677390098571777\n",
      "Epoch 4: iteration 1354/2501 train_loss: 0.4509264826774597 time_taken: 0.05691957473754883\n",
      "Epoch 4: iteration 1355/2501 train_loss: 0.4509683847427368 time_taken: 0.05756497383117676\n",
      "Epoch 4: iteration 1356/2501 train_loss: 0.4509951174259186 time_taken: 0.05662870407104492\n",
      "Epoch 4: iteration 1357/2501 train_loss: 0.45103615522384644 time_taken: 0.05689406394958496\n",
      "Epoch 4: iteration 1358/2501 train_loss: 0.4510718584060669 time_taken: 0.05682492256164551\n",
      "Epoch 4: iteration 1359/2501 train_loss: 0.45109498500823975 time_taken: 0.05720996856689453\n",
      "Epoch 4: iteration 1360/2501 train_loss: 0.4511275589466095 time_taken: 0.05663013458251953\n",
      "Epoch 4: iteration 1361/2501 train_loss: 0.45115453004837036 time_taken: 0.05708909034729004\n",
      "Epoch 4: iteration 1362/2501 train_loss: 0.4511865973472595 time_taken: 0.056937217712402344\n",
      "Epoch 4: iteration 1363/2501 train_loss: 0.4512106776237488 time_taken: 0.056873321533203125\n",
      "Epoch 4: iteration 1364/2501 train_loss: 0.45123881101608276 time_taken: 0.0569915771484375\n",
      "Epoch 4: iteration 1365/2501 train_loss: 0.4512835443019867 time_taken: 0.058233022689819336\n",
      "Epoch 4: iteration 1366/2501 train_loss: 0.4513223469257355 time_taken: 0.05726361274719238\n",
      "Epoch 4: iteration 1367/2501 train_loss: 0.45136529207229614 time_taken: 0.05739331245422363\n",
      "Epoch 4: iteration 1368/2501 train_loss: 0.4513896107673645 time_taken: 0.056472063064575195\n",
      "Epoch 4: iteration 1369/2501 train_loss: 0.45141464471817017 time_taken: 0.05667543411254883\n",
      "Epoch 4: iteration 1370/2501 train_loss: 0.4514561593532562 time_taken: 0.057500600814819336\n",
      "Epoch 4: iteration 1371/2501 train_loss: 0.4514862895011902 time_taken: 0.05706453323364258\n",
      "Epoch 4: iteration 1372/2501 train_loss: 0.45152291655540466 time_taken: 0.05713510513305664\n",
      "Epoch 4: iteration 1373/2501 train_loss: 0.45156463980674744 time_taken: 0.056713104248046875\n",
      "Epoch 4: iteration 1374/2501 train_loss: 0.4516243040561676 time_taken: 0.05692315101623535\n",
      "Epoch 4: iteration 1375/2501 train_loss: 0.45166999101638794 time_taken: 0.05732321739196777\n",
      "Epoch 4: iteration 1376/2501 train_loss: 0.4517080783843994 time_taken: 0.05642962455749512\n",
      "Epoch 4: iteration 1377/2501 train_loss: 0.4517683684825897 time_taken: 0.056723833084106445\n",
      "Epoch 4: iteration 1378/2501 train_loss: 0.4518314003944397 time_taken: 0.05693626403808594\n",
      "Epoch 4: iteration 1379/2501 train_loss: 0.45191043615341187 time_taken: 0.05752992630004883\n",
      "Epoch 4: iteration 1380/2501 train_loss: 0.45197218656539917 time_taken: 0.05644583702087402\n",
      "Epoch 4: iteration 1381/2501 train_loss: 0.45203039050102234 time_taken: 0.05646538734436035\n",
      "Epoch 4: iteration 1382/2501 train_loss: 0.45209866762161255 time_taken: 0.056603431701660156\n",
      "Epoch 4: iteration 1383/2501 train_loss: 0.4521627724170685 time_taken: 0.05716705322265625\n",
      "Epoch 4: iteration 1384/2501 train_loss: 0.45221272110939026 time_taken: 0.05714297294616699\n",
      "Epoch 4: iteration 1385/2501 train_loss: 0.45226550102233887 time_taken: 0.05690121650695801\n",
      "Epoch 4: iteration 1386/2501 train_loss: 0.4523257315158844 time_taken: 0.05714082717895508\n",
      "Epoch 4: iteration 1387/2501 train_loss: 0.4523577094078064 time_taken: 0.0567774772644043\n",
      "Epoch 4: iteration 1388/2501 train_loss: 0.45239266753196716 time_taken: 0.056900978088378906\n",
      "Epoch 4: iteration 1389/2501 train_loss: 0.4524214267730713 time_taken: 0.05763077735900879\n",
      "Epoch 4: iteration 1390/2501 train_loss: 0.45245325565338135 time_taken: 0.0573573112487793\n",
      "Epoch 4: iteration 1391/2501 train_loss: 0.4524816870689392 time_taken: 0.05769658088684082\n",
      "Epoch 4: iteration 1392/2501 train_loss: 0.452495276927948 time_taken: 0.057128190994262695\n",
      "Epoch 4: iteration 1393/2501 train_loss: 0.45250922441482544 time_taken: 0.057422637939453125\n",
      "Epoch 4: iteration 1394/2501 train_loss: 0.45251429080963135 time_taken: 0.057376861572265625\n",
      "Epoch 4: iteration 1395/2501 train_loss: 0.45251673460006714 time_taken: 0.056984901428222656\n",
      "Epoch 4: iteration 1396/2501 train_loss: 0.4525160491466522 time_taken: 0.05714988708496094\n",
      "Epoch 4: iteration 1397/2501 train_loss: 0.4525085687637329 time_taken: 0.056925058364868164\n",
      "Epoch 4: iteration 1398/2501 train_loss: 0.4525194466114044 time_taken: 0.05680704116821289\n",
      "Epoch 4: iteration 1399/2501 train_loss: 0.4525166153907776 time_taken: 0.056961774826049805\n",
      "Epoch 4: iteration 1400/2501 train_loss: 0.4525166153907776 time_taken: 0.05674123764038086\n",
      "Epoch 4: iteration 1401/2501 train_loss: 0.4525010585784912 time_taken: 0.05658388137817383\n",
      "Epoch 4: iteration 1402/2501 train_loss: 0.45249366760253906 time_taken: 0.05652761459350586\n",
      "Epoch 4: iteration 1403/2501 train_loss: 0.45248469710350037 time_taken: 0.055886268615722656\n",
      "Epoch 4: iteration 1404/2501 train_loss: 0.4524916708469391 time_taken: 0.056037187576293945\n",
      "Epoch 4: iteration 1405/2501 train_loss: 0.4525146782398224 time_taken: 0.05618143081665039\n",
      "Epoch 4: iteration 1406/2501 train_loss: 0.4525185823440552 time_taken: 0.05655312538146973\n",
      "Epoch 4: iteration 1407/2501 train_loss: 0.4525068998336792 time_taken: 0.05637550354003906\n",
      "Epoch 4: iteration 1408/2501 train_loss: 0.4525052011013031 time_taken: 0.057109832763671875\n",
      "Epoch 4: iteration 1409/2501 train_loss: 0.452496200799942 time_taken: 0.05684185028076172\n",
      "Epoch 4: iteration 1410/2501 train_loss: 0.4524700939655304 time_taken: 0.05678510665893555\n",
      "Epoch 4: iteration 1411/2501 train_loss: 0.45244768261909485 time_taken: 0.05634188652038574\n",
      "Epoch 4: iteration 1412/2501 train_loss: 0.4524152874946594 time_taken: 0.05648231506347656\n",
      "Epoch 4: iteration 1413/2501 train_loss: 0.4523903727531433 time_taken: 0.05717325210571289\n",
      "Epoch 4: iteration 1414/2501 train_loss: 0.45235827565193176 time_taken: 0.057102203369140625\n",
      "Epoch 4: iteration 1415/2501 train_loss: 0.4523334503173828 time_taken: 0.05716300010681152\n",
      "Epoch 4: iteration 1416/2501 train_loss: 0.45232176780700684 time_taken: 0.05826091766357422\n",
      "Epoch 4: iteration 1417/2501 train_loss: 0.45230865478515625 time_taken: 0.05684232711791992\n",
      "Epoch 4: iteration 1418/2501 train_loss: 0.45229101181030273 time_taken: 0.05710864067077637\n",
      "Epoch 4: iteration 1419/2501 train_loss: 0.4522855877876282 time_taken: 0.05715346336364746\n",
      "Epoch 4: iteration 1420/2501 train_loss: 0.45228147506713867 time_taken: 0.05692172050476074\n",
      "Epoch 4: iteration 1421/2501 train_loss: 0.45228639245033264 time_taken: 0.05718255043029785\n",
      "Epoch 4: iteration 1422/2501 train_loss: 0.45228537917137146 time_taken: 0.05705523490905762\n",
      "Epoch 4: iteration 1423/2501 train_loss: 0.45228853821754456 time_taken: 0.05807805061340332\n",
      "Epoch 4: iteration 1424/2501 train_loss: 0.45230674743652344 time_taken: 0.05750608444213867\n",
      "Epoch 4: iteration 1425/2501 train_loss: 0.45232269167900085 time_taken: 0.057048797607421875\n",
      "Epoch 4: iteration 1426/2501 train_loss: 0.4523329436779022 time_taken: 0.05719709396362305\n",
      "Epoch 4: iteration 1427/2501 train_loss: 0.45234137773513794 time_taken: 0.05704188346862793\n",
      "Epoch 4: iteration 1428/2501 train_loss: 0.45232900977134705 time_taken: 0.05698251724243164\n",
      "Epoch 4: iteration 1429/2501 train_loss: 0.4523269832134247 time_taken: 0.05781960487365723\n",
      "Epoch 4: iteration 1430/2501 train_loss: 0.4523106813430786 time_taken: 0.05723428726196289\n",
      "Epoch 4: iteration 1431/2501 train_loss: 0.4523095488548279 time_taken: 0.05693817138671875\n",
      "Epoch 4: iteration 1432/2501 train_loss: 0.4522971212863922 time_taken: 0.05678391456604004\n",
      "Epoch 4: iteration 1433/2501 train_loss: 0.4522879123687744 time_taken: 0.05656599998474121\n",
      "Epoch 4: iteration 1434/2501 train_loss: 0.45227694511413574 time_taken: 0.05684304237365723\n",
      "Epoch 4: iteration 1435/2501 train_loss: 0.4522808790206909 time_taken: 0.05636286735534668\n",
      "Epoch 4: iteration 1436/2501 train_loss: 0.45229458808898926 time_taken: 0.05690431594848633\n",
      "Epoch 4: iteration 1437/2501 train_loss: 0.4523058533668518 time_taken: 0.05678439140319824\n",
      "Epoch 4: iteration 1438/2501 train_loss: 0.4523206949234009 time_taken: 0.05787920951843262\n",
      "Epoch 4: iteration 1439/2501 train_loss: 0.45234215259552 time_taken: 0.05768275260925293\n",
      "Epoch 4: iteration 1440/2501 train_loss: 0.45236217975616455 time_taken: 0.05683279037475586\n",
      "Epoch 4: iteration 1441/2501 train_loss: 0.4523894488811493 time_taken: 0.05747056007385254\n",
      "Epoch 4: iteration 1442/2501 train_loss: 0.4523952007293701 time_taken: 0.0572967529296875\n",
      "Epoch 4: iteration 1443/2501 train_loss: 0.4524220824241638 time_taken: 0.05751848220825195\n",
      "Epoch 4: iteration 1444/2501 train_loss: 0.4524543285369873 time_taken: 0.057005882263183594\n",
      "Epoch 4: iteration 1445/2501 train_loss: 0.4524887204170227 time_taken: 0.05655026435852051\n",
      "Epoch 4: iteration 1446/2501 train_loss: 0.4525115191936493 time_taken: 0.05664968490600586\n",
      "Epoch 4: iteration 1447/2501 train_loss: 0.4525374174118042 time_taken: 0.056375980377197266\n",
      "Epoch 4: iteration 1448/2501 train_loss: 0.4525592625141144 time_taken: 0.05636954307556152\n",
      "Epoch 4: iteration 1449/2501 train_loss: 0.4525734484195709 time_taken: 0.05673551559448242\n",
      "Epoch 4: iteration 1450/2501 train_loss: 0.4525814354419708 time_taken: 0.05646061897277832\n",
      "Epoch 4: iteration 1451/2501 train_loss: 0.4526074528694153 time_taken: 0.057549476623535156\n",
      "Epoch 4: iteration 1452/2501 train_loss: 0.45263516902923584 time_taken: 0.056917428970336914\n",
      "Epoch 4: iteration 1453/2501 train_loss: 0.45266783237457275 time_taken: 0.056684017181396484\n",
      "Epoch 4: iteration 1454/2501 train_loss: 0.4526975154876709 time_taken: 0.0563356876373291\n",
      "Epoch 4: iteration 1455/2501 train_loss: 0.4527429938316345 time_taken: 0.056440114974975586\n",
      "Epoch 4: iteration 1456/2501 train_loss: 0.45277926325798035 time_taken: 0.05610847473144531\n",
      "Epoch 4: iteration 1457/2501 train_loss: 0.4528251886367798 time_taken: 0.056580543518066406\n",
      "Epoch 4: iteration 1458/2501 train_loss: 0.4528732895851135 time_taken: 0.0565028190612793\n",
      "Epoch 4: iteration 1459/2501 train_loss: 0.4529159367084503 time_taken: 0.057102203369140625\n",
      "Epoch 4: iteration 1460/2501 train_loss: 0.45295974612236023 time_taken: 0.05630779266357422\n",
      "Epoch 4: iteration 1461/2501 train_loss: 0.45300114154815674 time_taken: 0.05590510368347168\n",
      "Epoch 4: iteration 1462/2501 train_loss: 0.4530370533466339 time_taken: 0.05680060386657715\n",
      "Epoch 4: iteration 1463/2501 train_loss: 0.45306429266929626 time_taken: 0.055670738220214844\n",
      "Epoch 4: iteration 1464/2501 train_loss: 0.4530865550041199 time_taken: 0.06004047393798828\n",
      "Epoch 4: iteration 1465/2501 train_loss: 0.45311710238456726 time_taken: 0.06079578399658203\n",
      "Epoch 4: iteration 1466/2501 train_loss: 0.45315060019493103 time_taken: 0.05638551712036133\n",
      "Epoch 4: iteration 1467/2501 train_loss: 0.45317625999450684 time_taken: 0.05693364143371582\n",
      "Epoch 4: iteration 1468/2501 train_loss: 0.4531990885734558 time_taken: 0.05743408203125\n",
      "Epoch 4: iteration 1469/2501 train_loss: 0.4532206654548645 time_taken: 0.056220293045043945\n",
      "Epoch 4: iteration 1470/2501 train_loss: 0.4532434940338135 time_taken: 0.05623006820678711\n",
      "Epoch 4: iteration 1471/2501 train_loss: 0.45327028632164 time_taken: 0.05752277374267578\n",
      "Epoch 4: iteration 1472/2501 train_loss: 0.45330512523651123 time_taken: 0.0566251277923584\n",
      "Epoch 4: iteration 1473/2501 train_loss: 0.4533440172672272 time_taken: 0.056847572326660156\n",
      "Epoch 4: iteration 1474/2501 train_loss: 0.4533906877040863 time_taken: 0.05694150924682617\n",
      "Epoch 4: iteration 1475/2501 train_loss: 0.4534328579902649 time_taken: 0.05689048767089844\n",
      "Epoch 4: iteration 1476/2501 train_loss: 0.4534761309623718 time_taken: 0.056459903717041016\n",
      "Epoch 4: iteration 1477/2501 train_loss: 0.4535251259803772 time_taken: 0.0575253963470459\n",
      "Epoch 4: iteration 1478/2501 train_loss: 0.4535774290561676 time_taken: 0.05704140663146973\n",
      "Epoch 4: iteration 1479/2501 train_loss: 0.45362961292266846 time_taken: 0.05645632743835449\n",
      "Epoch 4: iteration 1480/2501 train_loss: 0.45367851853370667 time_taken: 0.056801795959472656\n",
      "Epoch 4: iteration 1481/2501 train_loss: 0.45372501015663147 time_taken: 0.05648541450500488\n",
      "Epoch 4: iteration 1482/2501 train_loss: 0.45375901460647583 time_taken: 0.05688309669494629\n",
      "Epoch 4: iteration 1483/2501 train_loss: 0.4537838101387024 time_taken: 0.05931878089904785\n",
      "Epoch 4: iteration 1484/2501 train_loss: 0.4538072347640991 time_taken: 0.0566713809967041\n",
      "Epoch 4: iteration 1485/2501 train_loss: 0.45381420850753784 time_taken: 0.05612325668334961\n",
      "Epoch 4: iteration 1486/2501 train_loss: 0.453828364610672 time_taken: 0.056379079818725586\n",
      "Epoch 4: iteration 1487/2501 train_loss: 0.45382028818130493 time_taken: 0.05630826950073242\n",
      "Epoch 4: iteration 1488/2501 train_loss: 0.45382237434387207 time_taken: 0.057486534118652344\n",
      "Epoch 4: iteration 1489/2501 train_loss: 0.45380130410194397 time_taken: 0.05641484260559082\n",
      "Epoch 4: iteration 1490/2501 train_loss: 0.4537802040576935 time_taken: 0.056943655014038086\n",
      "Epoch 4: iteration 1491/2501 train_loss: 0.45374906063079834 time_taken: 0.056179046630859375\n",
      "Epoch 4: iteration 1492/2501 train_loss: 0.4537202715873718 time_taken: 0.056828975677490234\n",
      "Epoch 4: iteration 1493/2501 train_loss: 0.4536796808242798 time_taken: 0.05591297149658203\n",
      "Epoch 4: iteration 1494/2501 train_loss: 0.4536427855491638 time_taken: 0.05637001991271973\n",
      "Epoch 4: iteration 1495/2501 train_loss: 0.45360711216926575 time_taken: 0.05704903602600098\n",
      "Epoch 4: iteration 1496/2501 train_loss: 0.4535847306251526 time_taken: 0.05647087097167969\n",
      "Epoch 4: iteration 1497/2501 train_loss: 0.45357370376586914 time_taken: 0.056227922439575195\n",
      "Epoch 4: iteration 1498/2501 train_loss: 0.4535674452781677 time_taken: 0.06131243705749512\n",
      "Epoch 4: iteration 1499/2501 train_loss: 0.4535547196865082 time_taken: 0.056466102600097656\n",
      "Epoch 4: iteration 1500/2501 train_loss: 0.45354652404785156 time_taken: 0.05645275115966797\n",
      "Epoch 4: iteration 1501/2501 train_loss: 0.45353570580482483 time_taken: 0.07889246940612793\n",
      "Epoch 4: iteration 1502/2501 train_loss: 0.4535234868526459 time_taken: 0.06633996963500977\n",
      "Epoch 4: iteration 1503/2501 train_loss: 0.4535137712955475 time_taken: 0.05695319175720215\n",
      "Epoch 4: iteration 1504/2501 train_loss: 0.45350906252861023 time_taken: 0.0565495491027832\n",
      "Epoch 4: iteration 1505/2501 train_loss: 0.45349985361099243 time_taken: 0.056798458099365234\n",
      "Epoch 4: iteration 1506/2501 train_loss: 0.45349642634391785 time_taken: 0.056986093521118164\n",
      "Epoch 4: iteration 1507/2501 train_loss: 0.4534837603569031 time_taken: 0.05662846565246582\n",
      "Epoch 4: iteration 1508/2501 train_loss: 0.45347464084625244 time_taken: 0.056751251220703125\n",
      "Epoch 4: iteration 1509/2501 train_loss: 0.4534704089164734 time_taken: 0.056105852127075195\n",
      "Epoch 4: iteration 1510/2501 train_loss: 0.4534595310688019 time_taken: 0.05686235427856445\n",
      "Epoch 4: iteration 1511/2501 train_loss: 0.45344963669776917 time_taken: 0.056694984436035156\n",
      "Epoch 4: iteration 1512/2501 train_loss: 0.453450471162796 time_taken: 0.05684828758239746\n",
      "Epoch 4: iteration 1513/2501 train_loss: 0.4534587264060974 time_taken: 0.056604862213134766\n",
      "Epoch 4: iteration 1514/2501 train_loss: 0.4534790515899658 time_taken: 0.056886911392211914\n",
      "Epoch 4: iteration 1515/2501 train_loss: 0.45349106192588806 time_taken: 0.05645251274108887\n",
      "Epoch 4: iteration 1516/2501 train_loss: 0.4535045027732849 time_taken: 0.05686211585998535\n",
      "Epoch 4: iteration 1517/2501 train_loss: 0.4535146951675415 time_taken: 0.05637526512145996\n",
      "Epoch 4: iteration 1518/2501 train_loss: 0.45353859663009644 time_taken: 0.05605483055114746\n",
      "Epoch 4: iteration 1519/2501 train_loss: 0.453561007976532 time_taken: 0.05646872520446777\n",
      "Epoch 4: iteration 1520/2501 train_loss: 0.45358479022979736 time_taken: 0.05653786659240723\n",
      "Epoch 4: iteration 1521/2501 train_loss: 0.45361220836639404 time_taken: 0.056784868240356445\n",
      "Epoch 4: iteration 1522/2501 train_loss: 0.45362618565559387 time_taken: 0.056615591049194336\n",
      "Epoch 4: iteration 1523/2501 train_loss: 0.4536358416080475 time_taken: 0.05696749687194824\n",
      "Epoch 4: iteration 1524/2501 train_loss: 0.4536440074443817 time_taken: 0.05691361427307129\n",
      "Epoch 4: iteration 1525/2501 train_loss: 0.4536457061767578 time_taken: 0.056499481201171875\n",
      "Epoch 4: iteration 1526/2501 train_loss: 0.4536382555961609 time_taken: 0.057309865951538086\n",
      "Epoch 4: iteration 1527/2501 train_loss: 0.4536382853984833 time_taken: 0.05810356140136719\n",
      "Epoch 4: iteration 1528/2501 train_loss: 0.4536309540271759 time_taken: 0.05648493766784668\n",
      "Epoch 4: iteration 1529/2501 train_loss: 0.45362043380737305 time_taken: 0.05697369575500488\n",
      "Epoch 4: iteration 1530/2501 train_loss: 0.4536030888557434 time_taken: 0.05679512023925781\n",
      "Epoch 4: iteration 1531/2501 train_loss: 0.45357948541641235 time_taken: 0.05678987503051758\n",
      "Epoch 4: iteration 1532/2501 train_loss: 0.45356041193008423 time_taken: 0.056389808654785156\n",
      "Epoch 4: iteration 1533/2501 train_loss: 0.4535670876502991 time_taken: 0.056752920150756836\n",
      "Epoch 4: iteration 1534/2501 train_loss: 0.4535849690437317 time_taken: 0.056310176849365234\n",
      "Epoch 4: iteration 1535/2501 train_loss: 0.4535822868347168 time_taken: 0.056624650955200195\n",
      "Epoch 4: iteration 1536/2501 train_loss: 0.4535808861255646 time_taken: 0.05615878105163574\n",
      "Epoch 4: iteration 1537/2501 train_loss: 0.4535912871360779 time_taken: 0.0561368465423584\n",
      "Epoch 4: iteration 1538/2501 train_loss: 0.4536016285419464 time_taken: 0.056412458419799805\n",
      "Epoch 4: iteration 1539/2501 train_loss: 0.45360279083251953 time_taken: 0.056285858154296875\n",
      "Epoch 4: iteration 1540/2501 train_loss: 0.45359325408935547 time_taken: 0.056443214416503906\n",
      "Epoch 4: iteration 1541/2501 train_loss: 0.45359915494918823 time_taken: 0.056754112243652344\n",
      "Epoch 4: iteration 1542/2501 train_loss: 0.4535878598690033 time_taken: 0.05664992332458496\n",
      "Epoch 4: iteration 1543/2501 train_loss: 0.45357799530029297 time_taken: 0.05671882629394531\n",
      "Epoch 4: iteration 1544/2501 train_loss: 0.4535714387893677 time_taken: 0.05652809143066406\n",
      "Epoch 4: iteration 1545/2501 train_loss: 0.45356041193008423 time_taken: 0.05696916580200195\n",
      "Epoch 4: iteration 1546/2501 train_loss: 0.45354360342025757 time_taken: 0.056783437728881836\n",
      "Epoch 4: iteration 1547/2501 train_loss: 0.45353248715400696 time_taken: 0.05713367462158203\n",
      "Epoch 4: iteration 1548/2501 train_loss: 0.45352739095687866 time_taken: 0.05727267265319824\n",
      "Epoch 4: iteration 1549/2501 train_loss: 0.4535219967365265 time_taken: 0.0569911003112793\n",
      "Epoch 4: iteration 1550/2501 train_loss: 0.45353013277053833 time_taken: 0.057511091232299805\n",
      "Epoch 4: iteration 1551/2501 train_loss: 0.45352569222450256 time_taken: 0.05728745460510254\n",
      "Epoch 4: iteration 1552/2501 train_loss: 0.45352211594581604 time_taken: 0.05695080757141113\n",
      "Epoch 4: iteration 1553/2501 train_loss: 0.4535311162471771 time_taken: 0.05666923522949219\n",
      "Epoch 4: iteration 1554/2501 train_loss: 0.4535324275493622 time_taken: 0.05712890625\n",
      "Epoch 4: iteration 1555/2501 train_loss: 0.4535289704799652 time_taken: 0.056884765625\n",
      "Epoch 4: iteration 1556/2501 train_loss: 0.4535265266895294 time_taken: 0.05626654624938965\n",
      "Epoch 4: iteration 1557/2501 train_loss: 0.4535345435142517 time_taken: 0.056371450424194336\n",
      "Epoch 4: iteration 1558/2501 train_loss: 0.4535340368747711 time_taken: 0.05647420883178711\n",
      "Epoch 4: iteration 1559/2501 train_loss: 0.45351672172546387 time_taken: 0.05714011192321777\n",
      "Epoch 4: iteration 1560/2501 train_loss: 0.4534967243671417 time_taken: 0.05658221244812012\n",
      "Epoch 4: iteration 1561/2501 train_loss: 0.4534759223461151 time_taken: 0.056948184967041016\n",
      "Epoch 4: iteration 1562/2501 train_loss: 0.45344868302345276 time_taken: 0.056169748306274414\n",
      "Epoch 4: iteration 1563/2501 train_loss: 0.45341289043426514 time_taken: 0.05632591247558594\n",
      "Epoch 4: iteration 1564/2501 train_loss: 0.45338207483291626 time_taken: 0.05710959434509277\n",
      "Epoch 4: iteration 1565/2501 train_loss: 0.4533442258834839 time_taken: 0.05645895004272461\n",
      "Epoch 4: iteration 1566/2501 train_loss: 0.45329177379608154 time_taken: 0.05660676956176758\n",
      "Epoch 4: iteration 1567/2501 train_loss: 0.4532480835914612 time_taken: 0.056200265884399414\n",
      "Epoch 4: iteration 1568/2501 train_loss: 0.4531939625740051 time_taken: 0.05639767646789551\n",
      "Epoch 4: iteration 1569/2501 train_loss: 0.4531499445438385 time_taken: 0.056986093521118164\n",
      "Epoch 4: iteration 1570/2501 train_loss: 0.45312124490737915 time_taken: 0.05663752555847168\n",
      "Epoch 4: iteration 1571/2501 train_loss: 0.4530889391899109 time_taken: 0.0565943717956543\n",
      "Epoch 4: iteration 1572/2501 train_loss: 0.4530560374259949 time_taken: 0.05649542808532715\n",
      "Epoch 4: iteration 1573/2501 train_loss: 0.45302724838256836 time_taken: 0.056795358657836914\n",
      "Epoch 4: iteration 1574/2501 train_loss: 0.45300498604774475 time_taken: 0.05730271339416504\n",
      "Epoch 4: iteration 1575/2501 train_loss: 0.45299169421195984 time_taken: 0.05742335319519043\n",
      "Epoch 4: iteration 1576/2501 train_loss: 0.4529978334903717 time_taken: 0.05735063552856445\n",
      "Epoch 4: iteration 1577/2501 train_loss: 0.452983021736145 time_taken: 0.05700039863586426\n",
      "Epoch 4: iteration 1578/2501 train_loss: 0.45296311378479004 time_taken: 0.05748796463012695\n",
      "Epoch 4: iteration 1579/2501 train_loss: 0.45294830203056335 time_taken: 0.056497812271118164\n",
      "Epoch 4: iteration 1580/2501 train_loss: 0.45292460918426514 time_taken: 0.05646109580993652\n",
      "Epoch 4: iteration 1581/2501 train_loss: 0.4528977870941162 time_taken: 0.05730891227722168\n",
      "Epoch 4: iteration 1582/2501 train_loss: 0.45288601517677307 time_taken: 0.05673956871032715\n",
      "Epoch 4: iteration 1583/2501 train_loss: 0.45287370681762695 time_taken: 0.056946516036987305\n",
      "Epoch 4: iteration 1584/2501 train_loss: 0.4528760015964508 time_taken: 0.05674290657043457\n",
      "Epoch 4: iteration 1585/2501 train_loss: 0.4528675377368927 time_taken: 0.056249380111694336\n",
      "Epoch 4: iteration 1586/2501 train_loss: 0.4528597593307495 time_taken: 0.05706334114074707\n",
      "Epoch 4: iteration 1587/2501 train_loss: 0.4528636336326599 time_taken: 0.05645251274108887\n",
      "Epoch 4: iteration 1588/2501 train_loss: 0.4528638422489166 time_taken: 0.056409358978271484\n",
      "Epoch 4: iteration 1589/2501 train_loss: 0.45286497473716736 time_taken: 0.056421518325805664\n",
      "Epoch 4: iteration 1590/2501 train_loss: 0.4528651237487793 time_taken: 0.057657480239868164\n",
      "Epoch 4: iteration 1591/2501 train_loss: 0.452868789434433 time_taken: 0.0565645694732666\n",
      "Epoch 4: iteration 1592/2501 train_loss: 0.45286473631858826 time_taken: 0.05696749687194824\n",
      "Epoch 4: iteration 1593/2501 train_loss: 0.4528655707836151 time_taken: 0.058032989501953125\n",
      "Epoch 4: iteration 1594/2501 train_loss: 0.4528820812702179 time_taken: 0.057251930236816406\n",
      "Epoch 4: iteration 1595/2501 train_loss: 0.45289790630340576 time_taken: 0.056960105895996094\n",
      "Epoch 4: iteration 1596/2501 train_loss: 0.4529050588607788 time_taken: 0.057033538818359375\n",
      "Epoch 4: iteration 1597/2501 train_loss: 0.45292428135871887 time_taken: 0.05758357048034668\n",
      "Epoch 4: iteration 1598/2501 train_loss: 0.45294076204299927 time_taken: 0.057245731353759766\n",
      "Epoch 4: iteration 1599/2501 train_loss: 0.45295220613479614 time_taken: 0.05695629119873047\n",
      "Epoch 4: iteration 1600/2501 train_loss: 0.45295941829681396 time_taken: 0.05664563179016113\n",
      "Epoch 4: iteration 1601/2501 train_loss: 0.45296329259872437 time_taken: 0.056319236755371094\n",
      "Epoch 4: iteration 1602/2501 train_loss: 0.4529634118080139 time_taken: 0.05673956871032715\n",
      "Epoch 4: iteration 1603/2501 train_loss: 0.4529748857021332 time_taken: 0.05670499801635742\n",
      "Epoch 4: iteration 1604/2501 train_loss: 0.4529944956302643 time_taken: 0.05688905715942383\n",
      "Epoch 4: iteration 1605/2501 train_loss: 0.4530102014541626 time_taken: 0.056488990783691406\n",
      "Epoch 4: iteration 1606/2501 train_loss: 0.45301663875579834 time_taken: 0.05651211738586426\n",
      "Epoch 4: iteration 1607/2501 train_loss: 0.45302170515060425 time_taken: 0.05618119239807129\n",
      "Epoch 4: iteration 1608/2501 train_loss: 0.4530229866504669 time_taken: 0.056090354919433594\n",
      "Epoch 4: iteration 1609/2501 train_loss: 0.4530309736728668 time_taken: 0.05622601509094238\n",
      "Epoch 4: iteration 1610/2501 train_loss: 0.4530434012413025 time_taken: 0.0562281608581543\n",
      "Epoch 4: iteration 1611/2501 train_loss: 0.45304685831069946 time_taken: 0.05628490447998047\n",
      "Epoch 4: iteration 1612/2501 train_loss: 0.4530639946460724 time_taken: 0.05621480941772461\n",
      "Epoch 4: iteration 1613/2501 train_loss: 0.45308348536491394 time_taken: 0.05654263496398926\n",
      "Epoch 4: iteration 1614/2501 train_loss: 0.4531024396419525 time_taken: 0.05679440498352051\n",
      "Epoch 4: iteration 1615/2501 train_loss: 0.4531264305114746 time_taken: 0.05656695365905762\n",
      "Epoch 4: iteration 1616/2501 train_loss: 0.45314499735832214 time_taken: 0.05662870407104492\n",
      "Epoch 4: iteration 1617/2501 train_loss: 0.4531640112400055 time_taken: 0.056351661682128906\n",
      "Epoch 4: iteration 1618/2501 train_loss: 0.45316827297210693 time_taken: 0.05695152282714844\n",
      "Epoch 4: iteration 1619/2501 train_loss: 0.45317766070365906 time_taken: 0.05656719207763672\n",
      "Epoch 4: iteration 1620/2501 train_loss: 0.4531887471675873 time_taken: 0.056893110275268555\n",
      "Epoch 4: iteration 1621/2501 train_loss: 0.45320361852645874 time_taken: 0.05671977996826172\n",
      "Epoch 4: iteration 1622/2501 train_loss: 0.4532183110713959 time_taken: 0.056450605392456055\n",
      "Epoch 4: iteration 1623/2501 train_loss: 0.4532296359539032 time_taken: 0.0563812255859375\n",
      "Epoch 4: iteration 1624/2501 train_loss: 0.45322903990745544 time_taken: 0.056441307067871094\n",
      "Epoch 4: iteration 1625/2501 train_loss: 0.45321911573410034 time_taken: 0.056374311447143555\n",
      "Epoch 4: iteration 1626/2501 train_loss: 0.45321226119995117 time_taken: 0.05614113807678223\n",
      "Epoch 4: iteration 1627/2501 train_loss: 0.453193724155426 time_taken: 0.05715036392211914\n",
      "Epoch 4: iteration 1628/2501 train_loss: 0.45317673683166504 time_taken: 0.05716896057128906\n",
      "Epoch 4: iteration 1629/2501 train_loss: 0.45315834879875183 time_taken: 0.05651974678039551\n",
      "Epoch 4: iteration 1630/2501 train_loss: 0.4531342387199402 time_taken: 0.06824755668640137\n",
      "Epoch 4: iteration 1631/2501 train_loss: 0.45311206579208374 time_taken: 0.06734442710876465\n",
      "Epoch 4: iteration 1632/2501 train_loss: 0.4530870318412781 time_taken: 0.056413888931274414\n",
      "Epoch 4: iteration 1633/2501 train_loss: 0.45307210087776184 time_taken: 0.06322836875915527\n",
      "Epoch 4: iteration 1634/2501 train_loss: 0.4530757963657379 time_taken: 0.056258440017700195\n",
      "Epoch 4: iteration 1635/2501 train_loss: 0.4530729651451111 time_taken: 0.056058406829833984\n",
      "Epoch 4: iteration 1636/2501 train_loss: 0.4530782699584961 time_taken: 0.05618000030517578\n",
      "Epoch 4: iteration 1637/2501 train_loss: 0.4530949592590332 time_taken: 0.05655241012573242\n",
      "Epoch 4: iteration 1638/2501 train_loss: 0.4531112313270569 time_taken: 0.05701279640197754\n",
      "Epoch 4: iteration 1639/2501 train_loss: 0.45312678813934326 time_taken: 0.057099103927612305\n",
      "Epoch 4: iteration 1640/2501 train_loss: 0.4531399607658386 time_taken: 0.05643010139465332\n",
      "Epoch 4: iteration 1641/2501 train_loss: 0.4531572163105011 time_taken: 0.05673670768737793\n",
      "Epoch 4: iteration 1642/2501 train_loss: 0.45318442583084106 time_taken: 0.057691335678100586\n",
      "Epoch 4: iteration 1643/2501 train_loss: 0.45319119095802307 time_taken: 0.05689072608947754\n",
      "Epoch 4: iteration 1644/2501 train_loss: 0.45319709181785583 time_taken: 0.05626034736633301\n",
      "Epoch 4: iteration 1645/2501 train_loss: 0.4531867504119873 time_taken: 0.05802559852600098\n",
      "Epoch 4: iteration 1646/2501 train_loss: 0.4531804025173187 time_taken: 0.056856393814086914\n",
      "Epoch 4: iteration 1647/2501 train_loss: 0.4531596601009369 time_taken: 0.0563807487487793\n",
      "Epoch 4: iteration 1648/2501 train_loss: 0.45314154028892517 time_taken: 0.05733513832092285\n",
      "Epoch 4: iteration 1649/2501 train_loss: 0.4531276226043701 time_taken: 0.05712580680847168\n",
      "Epoch 4: iteration 1650/2501 train_loss: 0.4531036615371704 time_taken: 0.05678582191467285\n",
      "Epoch 4: iteration 1651/2501 train_loss: 0.4530753195285797 time_taken: 0.05612993240356445\n",
      "Epoch 4: iteration 1652/2501 train_loss: 0.4530353248119354 time_taken: 0.05703568458557129\n",
      "Epoch 4: iteration 1653/2501 train_loss: 0.4529981315135956 time_taken: 0.05678415298461914\n",
      "Epoch 4: iteration 1654/2501 train_loss: 0.45295870304107666 time_taken: 0.0574648380279541\n",
      "Epoch 4: iteration 1655/2501 train_loss: 0.45291537046432495 time_taken: 0.056830644607543945\n",
      "Epoch 4: iteration 1656/2501 train_loss: 0.45287731289863586 time_taken: 0.05666708946228027\n",
      "Epoch 4: iteration 1657/2501 train_loss: 0.45284849405288696 time_taken: 0.05759787559509277\n",
      "Epoch 4: iteration 1658/2501 train_loss: 0.45282092690467834 time_taken: 0.05650615692138672\n",
      "Epoch 4: iteration 1659/2501 train_loss: 0.4527999758720398 time_taken: 0.05646562576293945\n",
      "Epoch 4: iteration 1660/2501 train_loss: 0.4527839124202728 time_taken: 0.05632948875427246\n",
      "Epoch 4: iteration 1661/2501 train_loss: 0.4527812898159027 time_taken: 0.05633425712585449\n",
      "Epoch 4: iteration 1662/2501 train_loss: 0.45277586579322815 time_taken: 0.05724978446960449\n",
      "Epoch 4: iteration 1663/2501 train_loss: 0.45277056097984314 time_taken: 0.05745410919189453\n",
      "Epoch 4: iteration 1664/2501 train_loss: 0.45276910066604614 time_taken: 0.0564115047454834\n",
      "Epoch 4: iteration 1665/2501 train_loss: 0.45276203751564026 time_taken: 0.05734062194824219\n",
      "Epoch 4: iteration 1666/2501 train_loss: 0.45276084542274475 time_taken: 0.05655860900878906\n",
      "Epoch 4: iteration 1667/2501 train_loss: 0.4527592658996582 time_taken: 0.056183576583862305\n",
      "Epoch 4: iteration 1668/2501 train_loss: 0.452752023935318 time_taken: 0.05647444725036621\n",
      "Epoch 4: iteration 1669/2501 train_loss: 0.4527614116668701 time_taken: 0.05738425254821777\n",
      "Epoch 4: iteration 1670/2501 train_loss: 0.45276767015457153 time_taken: 0.056432247161865234\n",
      "Epoch 4: iteration 1671/2501 train_loss: 0.45278605818748474 time_taken: 0.05640602111816406\n",
      "Epoch 4: iteration 1672/2501 train_loss: 0.45280781388282776 time_taken: 0.05663418769836426\n",
      "Epoch 4: iteration 1673/2501 train_loss: 0.4528212547302246 time_taken: 0.056693077087402344\n",
      "Epoch 4: iteration 1674/2501 train_loss: 0.45284023880958557 time_taken: 0.05641984939575195\n",
      "Epoch 4: iteration 1675/2501 train_loss: 0.45285236835479736 time_taken: 0.05677008628845215\n",
      "Epoch 4: iteration 1676/2501 train_loss: 0.45286402106285095 time_taken: 0.05663442611694336\n",
      "Epoch 4: iteration 1677/2501 train_loss: 0.45286238193511963 time_taken: 0.05681920051574707\n",
      "Epoch 4: iteration 1678/2501 train_loss: 0.45286253094673157 time_taken: 0.05647993087768555\n",
      "Epoch 4: iteration 1679/2501 train_loss: 0.45286521315574646 time_taken: 0.05627298355102539\n",
      "Epoch 4: iteration 1680/2501 train_loss: 0.45286044478416443 time_taken: 0.056499481201171875\n",
      "Epoch 4: iteration 1681/2501 train_loss: 0.4528510272502899 time_taken: 0.0562901496887207\n",
      "Epoch 4: iteration 1682/2501 train_loss: 0.45283743739128113 time_taken: 0.05628252029418945\n",
      "Epoch 4: iteration 1683/2501 train_loss: 0.452822208404541 time_taken: 0.05682969093322754\n",
      "Epoch 4: iteration 1684/2501 train_loss: 0.4528055787086487 time_taken: 0.05674481391906738\n",
      "Epoch 4: iteration 1685/2501 train_loss: 0.4527837038040161 time_taken: 0.05640220642089844\n",
      "Epoch 4: iteration 1686/2501 train_loss: 0.4527531564235687 time_taken: 0.0565338134765625\n",
      "Epoch 4: iteration 1687/2501 train_loss: 0.45274391770362854 time_taken: 0.05660367012023926\n",
      "Epoch 4: iteration 1688/2501 train_loss: 0.4527437686920166 time_taken: 0.05617928504943848\n",
      "Epoch 4: iteration 1689/2501 train_loss: 0.45274198055267334 time_taken: 0.056163787841796875\n",
      "Epoch 4: iteration 1690/2501 train_loss: 0.45273473858833313 time_taken: 0.056761741638183594\n",
      "Epoch 4: iteration 1691/2501 train_loss: 0.4527350664138794 time_taken: 0.05647921562194824\n",
      "Epoch 4: iteration 1692/2501 train_loss: 0.4527365565299988 time_taken: 0.056287288665771484\n",
      "Epoch 4: iteration 1693/2501 train_loss: 0.4527425765991211 time_taken: 0.05669450759887695\n",
      "Epoch 4: iteration 1694/2501 train_loss: 0.4527457654476166 time_taken: 0.05712389945983887\n",
      "Epoch 4: iteration 1695/2501 train_loss: 0.45274844765663147 time_taken: 0.058058738708496094\n",
      "Epoch 4: iteration 1696/2501 train_loss: 0.4527610242366791 time_taken: 0.05650448799133301\n",
      "Epoch 4: iteration 1697/2501 train_loss: 0.4527827203273773 time_taken: 0.05681014060974121\n",
      "Epoch 4: iteration 1698/2501 train_loss: 0.45279988646507263 time_taken: 0.05631566047668457\n",
      "Epoch 4: iteration 1699/2501 train_loss: 0.4528299868106842 time_taken: 0.056519269943237305\n",
      "Epoch 4: iteration 1700/2501 train_loss: 0.45285463333129883 time_taken: 0.056327104568481445\n",
      "Epoch 4: iteration 1701/2501 train_loss: 0.4528835117816925 time_taken: 0.05631208419799805\n",
      "Epoch 4: iteration 1702/2501 train_loss: 0.4529070556163788 time_taken: 0.05613994598388672\n",
      "Epoch 4: iteration 1703/2501 train_loss: 0.45292916893959045 time_taken: 0.056693077087402344\n",
      "Epoch 4: iteration 1704/2501 train_loss: 0.45294541120529175 time_taken: 0.0567021369934082\n",
      "Epoch 4: iteration 1705/2501 train_loss: 0.4529609680175781 time_taken: 0.05706667900085449\n",
      "Epoch 4: iteration 1706/2501 train_loss: 0.45297977328300476 time_taken: 0.05800747871398926\n",
      "Epoch 4: iteration 1707/2501 train_loss: 0.45299091935157776 time_taken: 0.05660533905029297\n",
      "Epoch 4: iteration 1708/2501 train_loss: 0.45300766825675964 time_taken: 0.05659604072570801\n",
      "Epoch 4: iteration 1709/2501 train_loss: 0.4530234634876251 time_taken: 0.057608604431152344\n",
      "Epoch 4: iteration 1710/2501 train_loss: 0.45304906368255615 time_taken: 0.05622458457946777\n",
      "Epoch 4: iteration 1711/2501 train_loss: 0.4530683755874634 time_taken: 0.056914329528808594\n",
      "Epoch 4: iteration 1712/2501 train_loss: 0.4530932903289795 time_taken: 0.05645346641540527\n",
      "Epoch 4: iteration 1713/2501 train_loss: 0.4531153738498688 time_taken: 0.056447744369506836\n",
      "Epoch 4: iteration 1714/2501 train_loss: 0.4531513452529907 time_taken: 0.057351112365722656\n",
      "Epoch 4: iteration 1715/2501 train_loss: 0.4531802833080292 time_taken: 0.05650210380554199\n",
      "Epoch 4: iteration 1716/2501 train_loss: 0.45321905612945557 time_taken: 0.057982444763183594\n",
      "Epoch 4: iteration 1717/2501 train_loss: 0.45326241850852966 time_taken: 0.057003021240234375\n",
      "Epoch 4: iteration 1718/2501 train_loss: 0.4532957375049591 time_taken: 0.05665946006774902\n",
      "Epoch 4: iteration 1719/2501 train_loss: 0.45333096385002136 time_taken: 0.056915998458862305\n",
      "Epoch 4: iteration 1720/2501 train_loss: 0.45336392521858215 time_taken: 0.05685758590698242\n",
      "Epoch 4: iteration 1721/2501 train_loss: 0.45339640974998474 time_taken: 0.05681586265563965\n",
      "Epoch 4: iteration 1722/2501 train_loss: 0.4534216821193695 time_taken: 0.056458473205566406\n",
      "Epoch 4: iteration 1723/2501 train_loss: 0.4534514248371124 time_taken: 0.05615091323852539\n",
      "Epoch 4: iteration 1724/2501 train_loss: 0.4534873068332672 time_taken: 0.05653500556945801\n",
      "Epoch 4: iteration 1725/2501 train_loss: 0.45351672172546387 time_taken: 0.05611824989318848\n",
      "Epoch 4: iteration 1726/2501 train_loss: 0.45354893803596497 time_taken: 0.05826091766357422\n",
      "Epoch 4: iteration 1727/2501 train_loss: 0.4535832703113556 time_taken: 0.056624650955200195\n",
      "Epoch 4: iteration 1728/2501 train_loss: 0.453622043132782 time_taken: 0.05653810501098633\n",
      "Epoch 4: iteration 1729/2501 train_loss: 0.453651487827301 time_taken: 0.05953669548034668\n",
      "Epoch 4: iteration 1730/2501 train_loss: 0.4536806046962738 time_taken: 0.05693960189819336\n",
      "Epoch 4: iteration 1731/2501 train_loss: 0.45371392369270325 time_taken: 0.056414127349853516\n",
      "Epoch 4: iteration 1732/2501 train_loss: 0.4537450671195984 time_taken: 0.06235194206237793\n",
      "Epoch 4: iteration 1733/2501 train_loss: 0.453767865896225 time_taken: 0.056604862213134766\n",
      "Epoch 4: iteration 1734/2501 train_loss: 0.4537946283817291 time_taken: 0.05631828308105469\n",
      "Epoch 4: iteration 1735/2501 train_loss: 0.45382755994796753 time_taken: 0.0570828914642334\n",
      "Epoch 4: iteration 1736/2501 train_loss: 0.45385509729385376 time_taken: 0.0566248893737793\n",
      "Epoch 4: iteration 1737/2501 train_loss: 0.4538934826850891 time_taken: 0.058359622955322266\n",
      "Epoch 4: iteration 1738/2501 train_loss: 0.4539291262626648 time_taken: 0.056784629821777344\n",
      "Epoch 4: iteration 1739/2501 train_loss: 0.4539637565612793 time_taken: 0.05652761459350586\n",
      "Epoch 4: iteration 1740/2501 train_loss: 0.4540104269981384 time_taken: 0.05659675598144531\n",
      "Epoch 4: iteration 1741/2501 train_loss: 0.45406070351600647 time_taken: 0.05663943290710449\n",
      "Epoch 4: iteration 1742/2501 train_loss: 0.4540999233722687 time_taken: 0.05714821815490723\n",
      "Epoch 4: iteration 1743/2501 train_loss: 0.4541493058204651 time_taken: 0.057323455810546875\n",
      "Epoch 4: iteration 1744/2501 train_loss: 0.45420047640800476 time_taken: 0.05639457702636719\n",
      "Epoch 4: iteration 1745/2501 train_loss: 0.45425254106521606 time_taken: 0.05671286582946777\n",
      "Epoch 4: iteration 1746/2501 train_loss: 0.4542957544326782 time_taken: 0.056763410568237305\n",
      "Epoch 4: iteration 1747/2501 train_loss: 0.4543444514274597 time_taken: 0.05645489692687988\n",
      "Epoch 4: iteration 1748/2501 train_loss: 0.45438912510871887 time_taken: 0.05758953094482422\n",
      "Epoch 4: iteration 1749/2501 train_loss: 0.4544300436973572 time_taken: 0.05601620674133301\n",
      "Epoch 4: iteration 1750/2501 train_loss: 0.45446035265922546 time_taken: 0.05624890327453613\n",
      "Epoch 4: iteration 1751/2501 train_loss: 0.4544928967952728 time_taken: 0.05618023872375488\n",
      "Epoch 4: iteration 1752/2501 train_loss: 0.4545171856880188 time_taken: 0.05605816841125488\n",
      "Epoch 4: iteration 1753/2501 train_loss: 0.4545333683490753 time_taken: 0.05604410171508789\n",
      "Epoch 4: iteration 1754/2501 train_loss: 0.4545425772666931 time_taken: 0.05596303939819336\n",
      "Epoch 4: iteration 1755/2501 train_loss: 0.454549640417099 time_taken: 0.05617332458496094\n",
      "Epoch 4: iteration 1756/2501 train_loss: 0.4545551538467407 time_taken: 0.05710172653198242\n",
      "Epoch 4: iteration 1757/2501 train_loss: 0.4545474648475647 time_taken: 0.056554317474365234\n",
      "Epoch 4: iteration 1758/2501 train_loss: 0.45454564690589905 time_taken: 0.0564577579498291\n",
      "Epoch 4: iteration 1759/2501 train_loss: 0.45453333854675293 time_taken: 0.05679798126220703\n",
      "Epoch 4: iteration 1760/2501 train_loss: 0.4545222818851471 time_taken: 0.05645585060119629\n",
      "Epoch 4: iteration 1761/2501 train_loss: 0.4544951021671295 time_taken: 0.05675792694091797\n",
      "Epoch 4: iteration 1762/2501 train_loss: 0.4544767737388611 time_taken: 0.056543588638305664\n",
      "Epoch 4: iteration 1763/2501 train_loss: 0.4544471204280853 time_taken: 0.056524038314819336\n",
      "Epoch 4: iteration 1764/2501 train_loss: 0.4544242024421692 time_taken: 0.05700564384460449\n",
      "Epoch 4: iteration 1765/2501 train_loss: 0.45440608263015747 time_taken: 0.05630660057067871\n",
      "Epoch 4: iteration 1766/2501 train_loss: 0.45437511801719666 time_taken: 0.05674552917480469\n",
      "Epoch 4: iteration 1767/2501 train_loss: 0.4543522596359253 time_taken: 0.05664873123168945\n",
      "Epoch 4: iteration 1768/2501 train_loss: 0.4543411135673523 time_taken: 0.057350873947143555\n",
      "Epoch 4: iteration 1769/2501 train_loss: 0.45433303713798523 time_taken: 0.05693483352661133\n",
      "Epoch 4: iteration 1770/2501 train_loss: 0.4543241858482361 time_taken: 0.056575775146484375\n",
      "Epoch 4: iteration 1771/2501 train_loss: 0.4543159008026123 time_taken: 0.056490421295166016\n",
      "Epoch 4: iteration 1772/2501 train_loss: 0.45430946350097656 time_taken: 0.05774521827697754\n",
      "Epoch 4: iteration 1773/2501 train_loss: 0.4542982578277588 time_taken: 0.05637645721435547\n",
      "Epoch 4: iteration 1774/2501 train_loss: 0.4542924463748932 time_taken: 0.056650400161743164\n",
      "Epoch 4: iteration 1775/2501 train_loss: 0.4542945325374603 time_taken: 0.05712246894836426\n",
      "Epoch 4: iteration 1776/2501 train_loss: 0.45429179072380066 time_taken: 0.056809425354003906\n",
      "Epoch 4: iteration 1777/2501 train_loss: 0.4542851150035858 time_taken: 0.057248830795288086\n",
      "Epoch 4: iteration 1778/2501 train_loss: 0.4542764723300934 time_taken: 0.05625152587890625\n",
      "Epoch 4: iteration 1779/2501 train_loss: 0.4542742669582367 time_taken: 0.056609392166137695\n",
      "Epoch 4: iteration 1780/2501 train_loss: 0.4542800784111023 time_taken: 0.05658888816833496\n",
      "Epoch 4: iteration 1781/2501 train_loss: 0.45427829027175903 time_taken: 0.05665302276611328\n",
      "Epoch 4: iteration 1782/2501 train_loss: 0.45428672432899475 time_taken: 0.05663919448852539\n",
      "Epoch 4: iteration 1783/2501 train_loss: 0.4542883038520813 time_taken: 0.05667710304260254\n",
      "Epoch 4: iteration 1784/2501 train_loss: 0.45429524779319763 time_taken: 0.05610322952270508\n",
      "Epoch 4: iteration 1785/2501 train_loss: 0.45430678129196167 time_taken: 0.05650901794433594\n",
      "Epoch 4: iteration 1786/2501 train_loss: 0.4543139636516571 time_taken: 0.05714154243469238\n",
      "Epoch 4: iteration 1787/2501 train_loss: 0.45432937145233154 time_taken: 0.0564570426940918\n",
      "Epoch 4: iteration 1788/2501 train_loss: 0.45434367656707764 time_taken: 0.05640840530395508\n",
      "Epoch 4: iteration 1789/2501 train_loss: 0.45435085892677307 time_taken: 0.056420087814331055\n",
      "Epoch 4: iteration 1790/2501 train_loss: 0.4543553590774536 time_taken: 0.05729222297668457\n",
      "Epoch 4: iteration 1791/2501 train_loss: 0.45435649156570435 time_taken: 0.056536197662353516\n",
      "Epoch 4: iteration 1792/2501 train_loss: 0.45435795187950134 time_taken: 0.05693864822387695\n",
      "Epoch 4: iteration 1793/2501 train_loss: 0.4543496370315552 time_taken: 0.05791974067687988\n",
      "Epoch 4: iteration 1794/2501 train_loss: 0.4543454647064209 time_taken: 0.05691862106323242\n",
      "Epoch 4: iteration 1795/2501 train_loss: 0.45433521270751953 time_taken: 0.0568690299987793\n",
      "Epoch 4: iteration 1796/2501 train_loss: 0.4543289542198181 time_taken: 0.05681347846984863\n",
      "Epoch 4: iteration 1797/2501 train_loss: 0.45433512330055237 time_taken: 0.05684494972229004\n",
      "Epoch 4: iteration 1798/2501 train_loss: 0.4543396532535553 time_taken: 0.056551218032836914\n",
      "Epoch 4: iteration 1799/2501 train_loss: 0.45434191823005676 time_taken: 0.05640292167663574\n",
      "Epoch 4: iteration 1800/2501 train_loss: 0.4543518126010895 time_taken: 0.056850433349609375\n",
      "Epoch 4: iteration 1801/2501 train_loss: 0.4543570876121521 time_taken: 0.05644488334655762\n",
      "Epoch 4: iteration 1802/2501 train_loss: 0.45436495542526245 time_taken: 0.05771780014038086\n",
      "Epoch 4: iteration 1803/2501 train_loss: 0.45437589287757874 time_taken: 0.05679965019226074\n",
      "Epoch 4: iteration 1804/2501 train_loss: 0.45439040660858154 time_taken: 0.05671358108520508\n",
      "Epoch 4: iteration 1805/2501 train_loss: 0.45440274477005005 time_taken: 0.05713820457458496\n",
      "Epoch 4: iteration 1806/2501 train_loss: 0.4544161558151245 time_taken: 0.05669665336608887\n",
      "Epoch 4: iteration 1807/2501 train_loss: 0.4544278681278229 time_taken: 0.05717110633850098\n",
      "Epoch 4: iteration 1808/2501 train_loss: 0.4544343948364258 time_taken: 0.05675077438354492\n",
      "Epoch 4: iteration 1809/2501 train_loss: 0.45444339513778687 time_taken: 0.057076454162597656\n",
      "Epoch 4: iteration 1810/2501 train_loss: 0.4544622600078583 time_taken: 0.05700874328613281\n",
      "Epoch 4: iteration 1811/2501 train_loss: 0.4544656574726105 time_taken: 0.057021141052246094\n",
      "Epoch 4: iteration 1812/2501 train_loss: 0.4544670283794403 time_taken: 0.057207345962524414\n",
      "Epoch 4: iteration 1813/2501 train_loss: 0.45447033643722534 time_taken: 0.05694246292114258\n",
      "Epoch 4: iteration 1814/2501 train_loss: 0.4544711709022522 time_taken: 0.056861162185668945\n",
      "Epoch 4: iteration 1815/2501 train_loss: 0.45447033643722534 time_taken: 0.05682206153869629\n",
      "Epoch 4: iteration 1816/2501 train_loss: 0.4544830024242401 time_taken: 0.057100772857666016\n",
      "Epoch 4: iteration 1817/2501 train_loss: 0.45448359847068787 time_taken: 0.056455135345458984\n",
      "Epoch 4: iteration 1818/2501 train_loss: 0.45448920130729675 time_taken: 0.05676770210266113\n",
      "Epoch 4: iteration 1819/2501 train_loss: 0.4544859826564789 time_taken: 0.056948184967041016\n",
      "Epoch 4: iteration 1820/2501 train_loss: 0.4544796049594879 time_taken: 0.056830644607543945\n",
      "Epoch 4: iteration 1821/2501 train_loss: 0.4544762372970581 time_taken: 0.056800127029418945\n",
      "Epoch 4: iteration 1822/2501 train_loss: 0.45447099208831787 time_taken: 0.056935787200927734\n",
      "Epoch 4: iteration 1823/2501 train_loss: 0.4544631540775299 time_taken: 0.05674910545349121\n",
      "Epoch 4: iteration 1824/2501 train_loss: 0.4544620215892792 time_taken: 0.05627560615539551\n",
      "Epoch 4: iteration 1825/2501 train_loss: 0.4544655680656433 time_taken: 0.05673551559448242\n",
      "Epoch 4: iteration 1826/2501 train_loss: 0.45447325706481934 time_taken: 0.057181596755981445\n",
      "Epoch 4: iteration 1827/2501 train_loss: 0.454479455947876 time_taken: 0.05741238594055176\n",
      "Epoch 4: iteration 1828/2501 train_loss: 0.4544937312602997 time_taken: 0.056482791900634766\n",
      "Epoch 4: iteration 1829/2501 train_loss: 0.45450133085250854 time_taken: 0.05698537826538086\n",
      "Epoch 4: iteration 1830/2501 train_loss: 0.45451870560646057 time_taken: 0.05688166618347168\n",
      "Epoch 4: iteration 1831/2501 train_loss: 0.45454347133636475 time_taken: 0.05684018135070801\n",
      "Epoch 4: iteration 1832/2501 train_loss: 0.45457497239112854 time_taken: 0.05649542808532715\n",
      "Epoch 4: iteration 1833/2501 train_loss: 0.4546023905277252 time_taken: 0.057098388671875\n",
      "Epoch 4: iteration 1834/2501 train_loss: 0.45462679862976074 time_taken: 0.056398630142211914\n",
      "Epoch 4: iteration 1835/2501 train_loss: 0.4546552300453186 time_taken: 0.05626392364501953\n",
      "Epoch 4: iteration 1836/2501 train_loss: 0.4546884298324585 time_taken: 0.05649304389953613\n",
      "Epoch 4: iteration 1837/2501 train_loss: 0.4547227919101715 time_taken: 0.05810713768005371\n",
      "Epoch 4: iteration 1838/2501 train_loss: 0.4547575116157532 time_taken: 0.058138370513916016\n",
      "Epoch 4: iteration 1839/2501 train_loss: 0.45478683710098267 time_taken: 0.05708956718444824\n",
      "Epoch 4: iteration 1840/2501 train_loss: 0.4548165202140808 time_taken: 0.05756258964538574\n",
      "Epoch 4: iteration 1841/2501 train_loss: 0.4548385441303253 time_taken: 0.0572056770324707\n",
      "Epoch 4: iteration 1842/2501 train_loss: 0.4548645317554474 time_taken: 0.057085514068603516\n",
      "Epoch 4: iteration 1843/2501 train_loss: 0.454883337020874 time_taken: 0.05665087699890137\n",
      "Epoch 4: iteration 1844/2501 train_loss: 0.4549085795879364 time_taken: 0.05702328681945801\n",
      "Epoch 4: iteration 1845/2501 train_loss: 0.454936146736145 time_taken: 0.056427955627441406\n",
      "Epoch 4: iteration 1846/2501 train_loss: 0.45495325326919556 time_taken: 0.056337594985961914\n",
      "Epoch 4: iteration 1847/2501 train_loss: 0.45495280623435974 time_taken: 0.056142330169677734\n",
      "Epoch 4: iteration 1848/2501 train_loss: 0.4549538493156433 time_taken: 0.056021690368652344\n",
      "Epoch 4: iteration 1849/2501 train_loss: 0.45495882630348206 time_taken: 0.05621743202209473\n",
      "Epoch 4: iteration 1850/2501 train_loss: 0.4549473524093628 time_taken: 0.05638265609741211\n",
      "Epoch 4: iteration 1851/2501 train_loss: 0.4549308121204376 time_taken: 0.05635571479797363\n",
      "Epoch 4: iteration 1852/2501 train_loss: 0.45492327213287354 time_taken: 0.056784629821777344\n",
      "Epoch 4: iteration 1853/2501 train_loss: 0.45490312576293945 time_taken: 0.05693936347961426\n",
      "Epoch 4: iteration 1854/2501 train_loss: 0.4548833668231964 time_taken: 0.057738542556762695\n",
      "Epoch 4: iteration 1855/2501 train_loss: 0.45485684275627136 time_taken: 0.057164907455444336\n",
      "Epoch 4: iteration 1856/2501 train_loss: 0.45481938123703003 time_taken: 0.05698418617248535\n",
      "Epoch 4: iteration 1857/2501 train_loss: 0.45478934049606323 time_taken: 0.056617021560668945\n",
      "Epoch 4: iteration 1858/2501 train_loss: 0.4547479450702667 time_taken: 0.05693459510803223\n",
      "Epoch 4: iteration 1859/2501 train_loss: 0.4547065794467926 time_taken: 0.0572209358215332\n",
      "Epoch 4: iteration 1860/2501 train_loss: 0.4546654522418976 time_taken: 0.056914567947387695\n",
      "Epoch 4: iteration 1861/2501 train_loss: 0.4546273946762085 time_taken: 0.056110382080078125\n",
      "Epoch 4: iteration 1862/2501 train_loss: 0.4545847773551941 time_taken: 0.05696606636047363\n",
      "Epoch 4: iteration 1863/2501 train_loss: 0.4545482397079468 time_taken: 0.05687403678894043\n",
      "Epoch 4: iteration 1864/2501 train_loss: 0.4545125961303711 time_taken: 0.05605602264404297\n",
      "Epoch 4: iteration 1865/2501 train_loss: 0.4544760584831238 time_taken: 0.05693244934082031\n",
      "Epoch 4: iteration 1866/2501 train_loss: 0.4544509947299957 time_taken: 0.05656027793884277\n",
      "Epoch 4: iteration 1867/2501 train_loss: 0.45443353056907654 time_taken: 0.0565335750579834\n",
      "Epoch 4: iteration 1868/2501 train_loss: 0.45441922545433044 time_taken: 0.057163238525390625\n",
      "Epoch 4: iteration 1869/2501 train_loss: 0.4543951749801636 time_taken: 0.05654263496398926\n",
      "Epoch 4: iteration 1870/2501 train_loss: 0.45437610149383545 time_taken: 0.0569913387298584\n",
      "Epoch 4: iteration 1871/2501 train_loss: 0.45435503125190735 time_taken: 0.05789494514465332\n",
      "Epoch 4: iteration 1872/2501 train_loss: 0.4543359875679016 time_taken: 0.05694460868835449\n",
      "Epoch 4: iteration 1873/2501 train_loss: 0.4543182849884033 time_taken: 0.058188438415527344\n",
      "Epoch 4: iteration 1874/2501 train_loss: 0.4542998969554901 time_taken: 0.056874752044677734\n",
      "Epoch 4: iteration 1875/2501 train_loss: 0.4542856812477112 time_taken: 0.05663561820983887\n",
      "Epoch 4: iteration 1876/2501 train_loss: 0.454272598028183 time_taken: 0.05754518508911133\n",
      "Epoch 4: iteration 1877/2501 train_loss: 0.4542464017868042 time_taken: 0.056946754455566406\n",
      "Epoch 4: iteration 1878/2501 train_loss: 0.4542297422885895 time_taken: 0.0562741756439209\n",
      "Epoch 4: iteration 1879/2501 train_loss: 0.4542175531387329 time_taken: 0.08458304405212402\n",
      "Epoch 4: iteration 1880/2501 train_loss: 0.45420584082603455 time_taken: 0.08108901977539062\n",
      "Epoch 4: iteration 1881/2501 train_loss: 0.4541875720024109 time_taken: 0.056828975677490234\n",
      "Epoch 4: iteration 1882/2501 train_loss: 0.454173743724823 time_taken: 0.06194591522216797\n",
      "Epoch 4: iteration 1883/2501 train_loss: 0.4541623294353485 time_taken: 0.05610203742980957\n",
      "Epoch 4: iteration 1884/2501 train_loss: 0.4541501998901367 time_taken: 0.05606865882873535\n",
      "Epoch 4: iteration 1885/2501 train_loss: 0.4541444778442383 time_taken: 0.05604386329650879\n",
      "Epoch 4: iteration 1886/2501 train_loss: 0.4541393220424652 time_taken: 0.056305885314941406\n",
      "Epoch 4: iteration 1887/2501 train_loss: 0.45412886142730713 time_taken: 0.05596184730529785\n",
      "Epoch 4: iteration 1888/2501 train_loss: 0.45413583517074585 time_taken: 0.05612778663635254\n",
      "Epoch 4: iteration 1889/2501 train_loss: 0.4541397988796234 time_taken: 0.056353092193603516\n",
      "Epoch 4: iteration 1890/2501 train_loss: 0.45415356755256653 time_taken: 0.05680537223815918\n",
      "Epoch 4: iteration 1891/2501 train_loss: 0.4541592001914978 time_taken: 0.05648350715637207\n",
      "Epoch 4: iteration 1892/2501 train_loss: 0.45417293906211853 time_taken: 0.05634355545043945\n",
      "Epoch 4: iteration 1893/2501 train_loss: 0.4541895389556885 time_taken: 0.056719064712524414\n",
      "Epoch 4: iteration 1894/2501 train_loss: 0.4542263150215149 time_taken: 0.0562129020690918\n",
      "Epoch 4: iteration 1895/2501 train_loss: 0.4542655348777771 time_taken: 0.05596661567687988\n",
      "Epoch 4: iteration 1896/2501 train_loss: 0.45429280400276184 time_taken: 0.057016849517822266\n",
      "Epoch 4: iteration 1897/2501 train_loss: 0.45432549715042114 time_taken: 0.05681109428405762\n",
      "Epoch 4: iteration 1898/2501 train_loss: 0.45435693860054016 time_taken: 0.05627775192260742\n",
      "Epoch 4: iteration 1899/2501 train_loss: 0.4543938636779785 time_taken: 0.056293487548828125\n",
      "Epoch 4: iteration 1900/2501 train_loss: 0.4544362425804138 time_taken: 0.056494951248168945\n",
      "Epoch 4: iteration 1901/2501 train_loss: 0.4544706642627716 time_taken: 0.05613350868225098\n",
      "Epoch 4: iteration 1902/2501 train_loss: 0.4544985592365265 time_taken: 0.056645870208740234\n",
      "Epoch 4: iteration 1903/2501 train_loss: 0.454521507024765 time_taken: 0.05715012550354004\n",
      "Epoch 4: iteration 1904/2501 train_loss: 0.4545513093471527 time_taken: 0.056501150131225586\n",
      "Epoch 4: iteration 1905/2501 train_loss: 0.45458686351776123 time_taken: 0.05678415298461914\n",
      "Epoch 4: iteration 1906/2501 train_loss: 0.4546176791191101 time_taken: 0.056771039962768555\n",
      "Epoch 4: iteration 1907/2501 train_loss: 0.4546554982662201 time_taken: 0.057097673416137695\n",
      "Epoch 4: iteration 1908/2501 train_loss: 0.4546946883201599 time_taken: 0.0564112663269043\n",
      "Epoch 4: iteration 1909/2501 train_loss: 0.45472458004951477 time_taken: 0.09749054908752441\n",
      "Epoch 4: iteration 1910/2501 train_loss: 0.45474714040756226 time_taken: 0.08127808570861816\n",
      "Epoch 4: iteration 1911/2501 train_loss: 0.45476657152175903 time_taken: 0.06415557861328125\n",
      "Epoch 4: iteration 1912/2501 train_loss: 0.45478129386901855 time_taken: 0.057112932205200195\n",
      "Epoch 4: iteration 1913/2501 train_loss: 0.454802006483078 time_taken: 0.0566868782043457\n",
      "Epoch 4: iteration 1914/2501 train_loss: 0.4548208713531494 time_taken: 0.056777238845825195\n",
      "Epoch 4: iteration 1915/2501 train_loss: 0.45484405755996704 time_taken: 0.05680990219116211\n",
      "Epoch 4: iteration 1916/2501 train_loss: 0.45486924052238464 time_taken: 0.056731224060058594\n",
      "Epoch 4: iteration 1917/2501 train_loss: 0.45488569140434265 time_taken: 0.056453704833984375\n",
      "Epoch 4: iteration 1918/2501 train_loss: 0.4549069404602051 time_taken: 0.056272268295288086\n",
      "Epoch 4: iteration 1919/2501 train_loss: 0.4549216628074646 time_taken: 0.05651259422302246\n",
      "Epoch 4: iteration 1920/2501 train_loss: 0.4549464285373688 time_taken: 0.0565333366394043\n",
      "Epoch 4: iteration 1921/2501 train_loss: 0.4549671411514282 time_taken: 0.05665755271911621\n",
      "Epoch 4: iteration 1922/2501 train_loss: 0.45500168204307556 time_taken: 0.0566561222076416\n",
      "Epoch 4: iteration 1923/2501 train_loss: 0.4550456404685974 time_taken: 0.05708599090576172\n",
      "Epoch 4: iteration 1924/2501 train_loss: 0.4550836682319641 time_taken: 0.056699514389038086\n",
      "Epoch 4: iteration 1925/2501 train_loss: 0.4551108777523041 time_taken: 0.056925058364868164\n",
      "Epoch 4: iteration 1926/2501 train_loss: 0.45514222979545593 time_taken: 0.06058359146118164\n",
      "Epoch 4: iteration 1927/2501 train_loss: 0.455165833234787 time_taken: 0.05656003952026367\n",
      "Epoch 4: iteration 1928/2501 train_loss: 0.4551975727081299 time_taken: 0.0594637393951416\n",
      "Epoch 4: iteration 1929/2501 train_loss: 0.45523470640182495 time_taken: 0.05956602096557617\n",
      "Epoch 4: iteration 1930/2501 train_loss: 0.4552757143974304 time_taken: 0.05740690231323242\n",
      "Epoch 4: iteration 1931/2501 train_loss: 0.4553150534629822 time_taken: 0.056232452392578125\n",
      "Epoch 4: iteration 1932/2501 train_loss: 0.45535802841186523 time_taken: 0.056586503982543945\n",
      "Epoch 4: iteration 1933/2501 train_loss: 0.45540058612823486 time_taken: 0.05621147155761719\n",
      "Epoch 4: iteration 1934/2501 train_loss: 0.4554334580898285 time_taken: 0.05953645706176758\n",
      "Epoch 4: iteration 1935/2501 train_loss: 0.45546385645866394 time_taken: 0.05633425712585449\n",
      "Epoch 4: iteration 1936/2501 train_loss: 0.45549365878105164 time_taken: 0.06195855140686035\n",
      "Epoch 4: iteration 1937/2501 train_loss: 0.45552730560302734 time_taken: 0.05697822570800781\n",
      "Epoch 4: iteration 1938/2501 train_loss: 0.45556285977363586 time_taken: 0.05697202682495117\n",
      "Epoch 4: iteration 1939/2501 train_loss: 0.45559293031692505 time_taken: 0.059515953063964844\n",
      "Epoch 4: iteration 1940/2501 train_loss: 0.4556148052215576 time_taken: 0.05709981918334961\n",
      "Epoch 4: iteration 1941/2501 train_loss: 0.4556431472301483 time_taken: 0.06835341453552246\n",
      "Epoch 4: iteration 1942/2501 train_loss: 0.4556584656238556 time_taken: 0.05625581741333008\n",
      "Epoch 4: iteration 1943/2501 train_loss: 0.4556596279144287 time_taken: 0.055960655212402344\n",
      "Epoch 4: iteration 1944/2501 train_loss: 0.4556601941585541 time_taken: 0.05574321746826172\n",
      "Epoch 4: iteration 1945/2501 train_loss: 0.4556504189968109 time_taken: 0.05666995048522949\n",
      "Epoch 4: iteration 1946/2501 train_loss: 0.45563608407974243 time_taken: 0.0567631721496582\n",
      "Epoch 4: iteration 1947/2501 train_loss: 0.4556187391281128 time_taken: 0.05709266662597656\n",
      "Epoch 4: iteration 1948/2501 train_loss: 0.45559415221214294 time_taken: 0.05681562423706055\n",
      "Epoch 4: iteration 1949/2501 train_loss: 0.4555824398994446 time_taken: 0.05671191215515137\n",
      "Epoch 4: iteration 1950/2501 train_loss: 0.4555743336677551 time_taken: 0.056832313537597656\n",
      "Epoch 4: iteration 1951/2501 train_loss: 0.4555738866329193 time_taken: 0.05672121047973633\n",
      "Epoch 4: iteration 1952/2501 train_loss: 0.4555783271789551 time_taken: 0.0570683479309082\n",
      "Epoch 4: iteration 1953/2501 train_loss: 0.4555928409099579 time_taken: 0.05797004699707031\n",
      "Epoch 4: iteration 1954/2501 train_loss: 0.4555986821651459 time_taken: 0.05699419975280762\n",
      "Epoch 4: iteration 1955/2501 train_loss: 0.4556099474430084 time_taken: 0.05650782585144043\n",
      "Epoch 4: iteration 1956/2501 train_loss: 0.45562276244163513 time_taken: 0.05748939514160156\n",
      "Epoch 4: iteration 1957/2501 train_loss: 0.45563241839408875 time_taken: 0.0571746826171875\n",
      "Epoch 4: iteration 1958/2501 train_loss: 0.455627977848053 time_taken: 0.05738520622253418\n",
      "Epoch 4: iteration 1959/2501 train_loss: 0.45562341809272766 time_taken: 0.05705070495605469\n",
      "Epoch 4: iteration 1960/2501 train_loss: 0.45561814308166504 time_taken: 0.0567631721496582\n",
      "Epoch 4: iteration 1961/2501 train_loss: 0.4556012451648712 time_taken: 0.05709576606750488\n",
      "Epoch 4: iteration 1962/2501 train_loss: 0.4555833339691162 time_taken: 0.05674171447753906\n",
      "Epoch 4: iteration 1963/2501 train_loss: 0.45556455850601196 time_taken: 0.05696892738342285\n",
      "Epoch 4: iteration 1964/2501 train_loss: 0.4555487036705017 time_taken: 0.057361602783203125\n",
      "Epoch 4: iteration 1965/2501 train_loss: 0.45552629232406616 time_taken: 0.057158470153808594\n",
      "Epoch 4: iteration 1966/2501 train_loss: 0.4554963707923889 time_taken: 0.057276248931884766\n",
      "Epoch 4: iteration 1967/2501 train_loss: 0.4554596245288849 time_taken: 0.0563511848449707\n",
      "Epoch 4: iteration 1968/2501 train_loss: 0.4554189145565033 time_taken: 0.05711030960083008\n",
      "Epoch 4: iteration 1969/2501 train_loss: 0.4553779363632202 time_taken: 0.05660820007324219\n",
      "Epoch 4: iteration 1970/2501 train_loss: 0.45533689856529236 time_taken: 0.05648446083068848\n",
      "Epoch 4: iteration 1971/2501 train_loss: 0.45529258251190186 time_taken: 0.05716681480407715\n",
      "Epoch 4: iteration 1972/2501 train_loss: 0.4552661180496216 time_taken: 0.05669569969177246\n",
      "Epoch 4: iteration 1973/2501 train_loss: 0.45524147152900696 time_taken: 0.05653738975524902\n",
      "Epoch 4: iteration 1974/2501 train_loss: 0.4552203416824341 time_taken: 0.056841373443603516\n",
      "Epoch 4: iteration 1975/2501 train_loss: 0.4551938772201538 time_taken: 0.05632281303405762\n",
      "Epoch 4: iteration 1976/2501 train_loss: 0.45516493916511536 time_taken: 0.05659317970275879\n",
      "Epoch 4: iteration 1977/2501 train_loss: 0.4551354944705963 time_taken: 0.05664515495300293\n",
      "Epoch 4: iteration 1978/2501 train_loss: 0.4551127851009369 time_taken: 0.05631613731384277\n",
      "Epoch 4: iteration 1979/2501 train_loss: 0.45507970452308655 time_taken: 0.056664228439331055\n",
      "Epoch 4: iteration 1980/2501 train_loss: 0.455049604177475 time_taken: 0.05737900733947754\n",
      "Epoch 4: iteration 1981/2501 train_loss: 0.4550158977508545 time_taken: 0.05656766891479492\n",
      "Epoch 4: iteration 1982/2501 train_loss: 0.45497551560401917 time_taken: 0.05989384651184082\n",
      "Epoch 4: iteration 1983/2501 train_loss: 0.4549340307712555 time_taken: 0.056680917739868164\n",
      "Epoch 4: iteration 1984/2501 train_loss: 0.4549148976802826 time_taken: 0.0567622184753418\n",
      "Epoch 4: iteration 1985/2501 train_loss: 0.4548891484737396 time_taken: 0.05668473243713379\n",
      "Epoch 4: iteration 1986/2501 train_loss: 0.4548650085926056 time_taken: 0.056786537170410156\n",
      "Epoch 4: iteration 1987/2501 train_loss: 0.45484814047813416 time_taken: 0.057534217834472656\n",
      "Epoch 4: iteration 1988/2501 train_loss: 0.45483529567718506 time_taken: 0.057276248931884766\n",
      "Epoch 4: iteration 1989/2501 train_loss: 0.4548308849334717 time_taken: 0.0564723014831543\n",
      "Epoch 4: iteration 1990/2501 train_loss: 0.45481714606285095 time_taken: 0.05692648887634277\n",
      "Epoch 4: iteration 1991/2501 train_loss: 0.45479434728622437 time_taken: 0.05672025680541992\n",
      "Epoch 4: iteration 1992/2501 train_loss: 0.45477843284606934 time_taken: 0.05624675750732422\n",
      "Epoch 4: iteration 1993/2501 train_loss: 0.4547750651836395 time_taken: 0.056656837463378906\n",
      "Epoch 4: iteration 1994/2501 train_loss: 0.45476943254470825 time_taken: 0.05655264854431152\n",
      "Epoch 4: iteration 1995/2501 train_loss: 0.45478159189224243 time_taken: 0.056472063064575195\n",
      "Epoch 4: iteration 1996/2501 train_loss: 0.45479440689086914 time_taken: 0.06223106384277344\n",
      "Epoch 4: iteration 1997/2501 train_loss: 0.4548131227493286 time_taken: 0.05710029602050781\n",
      "Epoch 4: iteration 1998/2501 train_loss: 0.45482560992240906 time_taken: 0.05649232864379883\n",
      "Epoch 4: iteration 1999/2501 train_loss: 0.45484036207199097 time_taken: 0.05679965019226074\n",
      "Epoch 4: iteration 2000/2501 train_loss: 0.45485055446624756 time_taken: 0.059816837310791016\n",
      "Epoch 4: iteration 2001/2501 train_loss: 0.45485919713974 time_taken: 0.056502342224121094\n",
      "Epoch 4: iteration 2002/2501 train_loss: 0.4548685550689697 time_taken: 0.05655407905578613\n",
      "Epoch 4: iteration 2003/2501 train_loss: 0.45487722754478455 time_taken: 0.056522369384765625\n",
      "Epoch 4: iteration 2004/2501 train_loss: 0.45488986372947693 time_taken: 0.05710482597351074\n",
      "Epoch 4: iteration 2005/2501 train_loss: 0.45490601658821106 time_taken: 0.05621790885925293\n",
      "Epoch 4: iteration 2006/2501 train_loss: 0.454924613237381 time_taken: 0.05601835250854492\n",
      "Epoch 4: iteration 2007/2501 train_loss: 0.4549495577812195 time_taken: 0.05645751953125\n",
      "Epoch 4: iteration 2008/2501 train_loss: 0.45496928691864014 time_taken: 0.056108713150024414\n",
      "Epoch 4: iteration 2009/2501 train_loss: 0.45498400926589966 time_taken: 0.056385040283203125\n",
      "Epoch 4: iteration 2010/2501 train_loss: 0.45499947667121887 time_taken: 0.06181192398071289\n",
      "Epoch 4: iteration 2011/2501 train_loss: 0.45501452684402466 time_taken: 0.05578112602233887\n",
      "Epoch 4: iteration 2012/2501 train_loss: 0.4550347924232483 time_taken: 0.06029558181762695\n",
      "Epoch 4: iteration 2013/2501 train_loss: 0.45505690574645996 time_taken: 0.05605268478393555\n",
      "Epoch 4: iteration 2014/2501 train_loss: 0.45508188009262085 time_taken: 0.058899879455566406\n",
      "Epoch 4: iteration 2015/2501 train_loss: 0.4551016092300415 time_taken: 0.055905818939208984\n",
      "Epoch 4: iteration 2016/2501 train_loss: 0.4551229774951935 time_taken: 0.05605173110961914\n",
      "Epoch 4: iteration 2017/2501 train_loss: 0.4551524519920349 time_taken: 0.05643343925476074\n",
      "Epoch 4: iteration 2018/2501 train_loss: 0.4551912546157837 time_taken: 0.05653667449951172\n",
      "Epoch 4: iteration 2019/2501 train_loss: 0.455219566822052 time_taken: 0.05602431297302246\n",
      "Epoch 4: iteration 2020/2501 train_loss: 0.45525893568992615 time_taken: 0.05599331855773926\n",
      "Epoch 4: iteration 2021/2501 train_loss: 0.455288290977478 time_taken: 0.05660533905029297\n",
      "Epoch 4: iteration 2022/2501 train_loss: 0.45532047748565674 time_taken: 0.056611061096191406\n",
      "Epoch 4: iteration 2023/2501 train_loss: 0.4553487002849579 time_taken: 0.05686593055725098\n",
      "Epoch 4: iteration 2024/2501 train_loss: 0.4553762972354889 time_taken: 0.05738520622253418\n",
      "Epoch 4: iteration 2025/2501 train_loss: 0.45539775490760803 time_taken: 0.056920766830444336\n",
      "Epoch 4: iteration 2026/2501 train_loss: 0.4554269015789032 time_taken: 0.0568997859954834\n",
      "Epoch 4: iteration 2027/2501 train_loss: 0.45545047521591187 time_taken: 0.0564877986907959\n",
      "Epoch 4: iteration 2028/2501 train_loss: 0.45547881722450256 time_taken: 0.05633091926574707\n",
      "Epoch 4: iteration 2029/2501 train_loss: 0.4555176794528961 time_taken: 0.056772470474243164\n",
      "Epoch 4: iteration 2030/2501 train_loss: 0.45555269718170166 time_taken: 0.05645155906677246\n",
      "Epoch 4: iteration 2031/2501 train_loss: 0.4555787146091461 time_taken: 0.058305978775024414\n",
      "Epoch 4: iteration 2032/2501 train_loss: 0.45559996366500854 time_taken: 0.056696414947509766\n",
      "Epoch 4: iteration 2033/2501 train_loss: 0.4556227922439575 time_taken: 0.05663323402404785\n",
      "Epoch 4: iteration 2034/2501 train_loss: 0.45564714074134827 time_taken: 0.05716872215270996\n",
      "Epoch 4: iteration 2035/2501 train_loss: 0.45566892623901367 time_taken: 0.05660748481750488\n",
      "Epoch 4: iteration 2036/2501 train_loss: 0.45568689703941345 time_taken: 0.056214094161987305\n",
      "Epoch 4: iteration 2037/2501 train_loss: 0.45570775866508484 time_taken: 0.05675148963928223\n",
      "Epoch 4: iteration 2038/2501 train_loss: 0.4557337462902069 time_taken: 0.05666375160217285\n",
      "Epoch 4: iteration 2039/2501 train_loss: 0.45575854182243347 time_taken: 0.05667591094970703\n",
      "Epoch 4: iteration 2040/2501 train_loss: 0.4557860493659973 time_taken: 0.056389570236206055\n",
      "Epoch 4: iteration 2041/2501 train_loss: 0.45581483840942383 time_taken: 0.05648398399353027\n",
      "Epoch 4: iteration 2042/2501 train_loss: 0.4558468163013458 time_taken: 0.05626535415649414\n",
      "Epoch 4: iteration 2043/2501 train_loss: 0.45587867498397827 time_taken: 0.05665183067321777\n",
      "Epoch 4: iteration 2044/2501 train_loss: 0.45590054988861084 time_taken: 0.056858062744140625\n",
      "Epoch 4: iteration 2045/2501 train_loss: 0.455922931432724 time_taken: 0.056684255599975586\n",
      "Epoch 4: iteration 2046/2501 train_loss: 0.4559411108493805 time_taken: 0.057091712951660156\n",
      "Epoch 4: iteration 2047/2501 train_loss: 0.45595744252204895 time_taken: 0.05692148208618164\n",
      "Epoch 4: iteration 2048/2501 train_loss: 0.4559800922870636 time_taken: 0.057044029235839844\n",
      "Epoch 4: iteration 2049/2501 train_loss: 0.4560064375400543 time_taken: 0.05666995048522949\n",
      "Epoch 4: iteration 2050/2501 train_loss: 0.45602598786354065 time_taken: 0.05683112144470215\n",
      "Epoch 4: iteration 2051/2501 train_loss: 0.4560485780239105 time_taken: 0.05688977241516113\n",
      "Epoch 4: iteration 2052/2501 train_loss: 0.45607298612594604 time_taken: 0.056859731674194336\n",
      "Epoch 4: iteration 2053/2501 train_loss: 0.45609885454177856 time_taken: 0.056571245193481445\n",
      "Epoch 4: iteration 2054/2501 train_loss: 0.4561232030391693 time_taken: 0.05706167221069336\n",
      "Epoch 4: iteration 2055/2501 train_loss: 0.45613354444503784 time_taken: 0.05655694007873535\n",
      "Epoch 4: iteration 2056/2501 train_loss: 0.45614877343177795 time_taken: 0.05680131912231445\n",
      "Epoch 4: iteration 2057/2501 train_loss: 0.45617422461509705 time_taken: 0.056513309478759766\n",
      "Epoch 4: iteration 2058/2501 train_loss: 0.4561949670314789 time_taken: 0.05648541450500488\n",
      "Epoch 4: iteration 2059/2501 train_loss: 0.45621952414512634 time_taken: 0.056426048278808594\n",
      "Epoch 4: iteration 2060/2501 train_loss: 0.4562418758869171 time_taken: 0.056839942932128906\n",
      "Epoch 4: iteration 2061/2501 train_loss: 0.45626169443130493 time_taken: 0.056539058685302734\n",
      "Epoch 4: iteration 2062/2501 train_loss: 0.45628923177719116 time_taken: 0.05704498291015625\n",
      "Epoch 4: iteration 2063/2501 train_loss: 0.4563187062740326 time_taken: 0.05710124969482422\n",
      "Epoch 4: iteration 2064/2501 train_loss: 0.4563475251197815 time_taken: 0.056523799896240234\n",
      "Epoch 4: iteration 2065/2501 train_loss: 0.4563760459423065 time_taken: 0.05685019493103027\n",
      "Epoch 4: iteration 2066/2501 train_loss: 0.4563925862312317 time_taken: 0.05643057823181152\n",
      "Epoch 4: iteration 2067/2501 train_loss: 0.456404447555542 time_taken: 0.057301998138427734\n",
      "Epoch 4: iteration 2068/2501 train_loss: 0.4564163088798523 time_taken: 0.056449174880981445\n",
      "Epoch 4: iteration 2069/2501 train_loss: 0.45641908049583435 time_taken: 0.05649995803833008\n",
      "Epoch 4: iteration 2070/2501 train_loss: 0.45642390847206116 time_taken: 0.05692863464355469\n",
      "Epoch 4: iteration 2071/2501 train_loss: 0.45641618967056274 time_taken: 0.056606292724609375\n",
      "Epoch 4: iteration 2072/2501 train_loss: 0.45640838146209717 time_taken: 0.08278083801269531\n",
      "Epoch 4: iteration 2073/2501 train_loss: 0.4564037024974823 time_taken: 0.08864212036132812\n",
      "Epoch 4: iteration 2074/2501 train_loss: 0.4563843607902527 time_taken: 0.05914878845214844\n",
      "Epoch 4: iteration 2075/2501 train_loss: 0.4563632905483246 time_taken: 0.05638408660888672\n",
      "Epoch 4: iteration 2076/2501 train_loss: 0.4563441574573517 time_taken: 0.05668044090270996\n",
      "Epoch 4: iteration 2077/2501 train_loss: 0.4563305675983429 time_taken: 0.05717778205871582\n",
      "Epoch 4: iteration 2078/2501 train_loss: 0.45632123947143555 time_taken: 0.05725455284118652\n",
      "Epoch 4: iteration 2079/2501 train_loss: 0.45632025599479675 time_taken: 0.056992292404174805\n",
      "Epoch 4: iteration 2080/2501 train_loss: 0.45632269978523254 time_taken: 0.05718684196472168\n",
      "Epoch 4: iteration 2081/2501 train_loss: 0.456328809261322 time_taken: 0.05696272850036621\n",
      "Epoch 4: iteration 2082/2501 train_loss: 0.4563400447368622 time_taken: 0.0569002628326416\n",
      "Epoch 4: iteration 2083/2501 train_loss: 0.45634526014328003 time_taken: 0.056195974349975586\n",
      "Epoch 4: iteration 2084/2501 train_loss: 0.4563455581665039 time_taken: 0.05649256706237793\n",
      "Epoch 4: iteration 2085/2501 train_loss: 0.45634129643440247 time_taken: 0.05684494972229004\n",
      "Epoch 4: iteration 2086/2501 train_loss: 0.45633450150489807 time_taken: 0.056600093841552734\n",
      "Epoch 4: iteration 2087/2501 train_loss: 0.4563244581222534 time_taken: 0.05682706832885742\n",
      "Epoch 4: iteration 2088/2501 train_loss: 0.4563101828098297 time_taken: 0.056511878967285156\n",
      "Epoch 4: iteration 2089/2501 train_loss: 0.45629146695137024 time_taken: 0.05695939064025879\n",
      "Epoch 4: iteration 2090/2501 train_loss: 0.4562649130821228 time_taken: 0.056462764739990234\n",
      "Epoch 4: iteration 2091/2501 train_loss: 0.45623674988746643 time_taken: 0.056764841079711914\n",
      "Epoch 4: iteration 2092/2501 train_loss: 0.45620712637901306 time_taken: 0.056458473205566406\n",
      "Epoch 4: iteration 2093/2501 train_loss: 0.45617249608039856 time_taken: 0.0568392276763916\n",
      "Epoch 4: iteration 2094/2501 train_loss: 0.45613381266593933 time_taken: 0.05677962303161621\n",
      "Epoch 4: iteration 2095/2501 train_loss: 0.45610401034355164 time_taken: 0.0562744140625\n",
      "Epoch 4: iteration 2096/2501 train_loss: 0.45606184005737305 time_taken: 0.05671095848083496\n",
      "Epoch 4: iteration 2097/2501 train_loss: 0.4560244679450989 time_taken: 0.056418418884277344\n",
      "Epoch 4: iteration 2098/2501 train_loss: 0.4559720456600189 time_taken: 0.05663943290710449\n",
      "Epoch 4: iteration 2099/2501 train_loss: 0.4559308588504791 time_taken: 0.05626392364501953\n",
      "Epoch 4: iteration 2100/2501 train_loss: 0.4558919072151184 time_taken: 0.05765891075134277\n",
      "Epoch 4: iteration 2101/2501 train_loss: 0.45585745573043823 time_taken: 0.05632328987121582\n",
      "Epoch 4: iteration 2102/2501 train_loss: 0.45582786202430725 time_taken: 0.057254791259765625\n",
      "Epoch 4: iteration 2103/2501 train_loss: 0.45579737424850464 time_taken: 0.05616331100463867\n",
      "Epoch 4: iteration 2104/2501 train_loss: 0.4557660222053528 time_taken: 0.05674290657043457\n",
      "Epoch 4: iteration 2105/2501 train_loss: 0.45572468638420105 time_taken: 0.056084394454956055\n",
      "Epoch 4: iteration 2106/2501 train_loss: 0.45568737387657166 time_taken: 0.055948734283447266\n",
      "Epoch 4: iteration 2107/2501 train_loss: 0.4556618332862854 time_taken: 0.056989431381225586\n",
      "Epoch 4: iteration 2108/2501 train_loss: 0.45563650131225586 time_taken: 0.05708622932434082\n",
      "Epoch 4: iteration 2109/2501 train_loss: 0.4556140899658203 time_taken: 0.05661344528198242\n",
      "Epoch 4: iteration 2110/2501 train_loss: 0.45558661222457886 time_taken: 0.05686140060424805\n",
      "Epoch 4: iteration 2111/2501 train_loss: 0.45555928349494934 time_taken: 0.05785202980041504\n",
      "Epoch 4: iteration 2112/2501 train_loss: 0.4555427134037018 time_taken: 0.05666661262512207\n",
      "Epoch 4: iteration 2113/2501 train_loss: 0.45552146434783936 time_taken: 0.05665159225463867\n",
      "Epoch 4: iteration 2114/2501 train_loss: 0.4555119276046753 time_taken: 0.05690479278564453\n",
      "Epoch 4: iteration 2115/2501 train_loss: 0.45549941062927246 time_taken: 0.056534528732299805\n",
      "Epoch 4: iteration 2116/2501 train_loss: 0.4554838240146637 time_taken: 0.05671119689941406\n",
      "Epoch 4: iteration 2117/2501 train_loss: 0.45546668767929077 time_taken: 0.056539058685302734\n",
      "Epoch 4: iteration 2118/2501 train_loss: 0.45544758439064026 time_taken: 0.056563377380371094\n",
      "Epoch 4: iteration 2119/2501 train_loss: 0.4554365575313568 time_taken: 0.05645895004272461\n",
      "Epoch 4: iteration 2120/2501 train_loss: 0.4554165005683899 time_taken: 0.057425498962402344\n",
      "Epoch 4: iteration 2121/2501 train_loss: 0.45540350675582886 time_taken: 0.056891441345214844\n",
      "Epoch 4: iteration 2122/2501 train_loss: 0.45539283752441406 time_taken: 0.056920766830444336\n",
      "Epoch 4: iteration 2123/2501 train_loss: 0.45538467168807983 time_taken: 0.05694389343261719\n",
      "Epoch 4: iteration 2124/2501 train_loss: 0.4553762376308441 time_taken: 0.05663633346557617\n",
      "Epoch 4: iteration 2125/2501 train_loss: 0.4553697407245636 time_taken: 0.05648159980773926\n",
      "Epoch 4: iteration 2126/2501 train_loss: 0.45536506175994873 time_taken: 0.056868553161621094\n",
      "Epoch 4: iteration 2127/2501 train_loss: 0.4553627371788025 time_taken: 0.05634808540344238\n",
      "Epoch 4: iteration 2128/2501 train_loss: 0.45536211133003235 time_taken: 0.05642056465148926\n",
      "Epoch 4: iteration 2129/2501 train_loss: 0.45536094903945923 time_taken: 0.0563051700592041\n",
      "Epoch 4: iteration 2130/2501 train_loss: 0.4553601145744324 time_taken: 0.056946516036987305\n",
      "Epoch 4: iteration 2131/2501 train_loss: 0.4553619921207428 time_taken: 0.05608725547790527\n",
      "Epoch 4: iteration 2132/2501 train_loss: 0.455364853143692 time_taken: 0.056852102279663086\n",
      "Epoch 4: iteration 2133/2501 train_loss: 0.45536985993385315 time_taken: 0.056351661682128906\n",
      "Epoch 4: iteration 2134/2501 train_loss: 0.455369234085083 time_taken: 0.056798696517944336\n",
      "Epoch 4: iteration 2135/2501 train_loss: 0.4553668797016144 time_taken: 0.056107282638549805\n",
      "Epoch 4: iteration 2136/2501 train_loss: 0.45536357164382935 time_taken: 0.056688785552978516\n",
      "Epoch 4: iteration 2137/2501 train_loss: 0.45535361766815186 time_taken: 0.056860923767089844\n",
      "Epoch 4: iteration 2138/2501 train_loss: 0.4553374648094177 time_taken: 0.05633425712585449\n",
      "Epoch 4: iteration 2139/2501 train_loss: 0.45532479882240295 time_taken: 0.056633710861206055\n",
      "Epoch 4: iteration 2140/2501 train_loss: 0.4553046226501465 time_taken: 0.05678558349609375\n",
      "Epoch 4: iteration 2141/2501 train_loss: 0.4552881717681885 time_taken: 0.05604243278503418\n",
      "Epoch 4: iteration 2142/2501 train_loss: 0.4552711844444275 time_taken: 0.05682682991027832\n",
      "Epoch 4: iteration 2143/2501 train_loss: 0.455257773399353 time_taken: 0.05734062194824219\n",
      "Epoch 4: iteration 2144/2501 train_loss: 0.4552420377731323 time_taken: 0.05714821815490723\n",
      "Epoch 4: iteration 2145/2501 train_loss: 0.455233097076416 time_taken: 0.056427001953125\n",
      "Epoch 4: iteration 2146/2501 train_loss: 0.45523130893707275 time_taken: 0.056290388107299805\n",
      "Epoch 4: iteration 2147/2501 train_loss: 0.45522555708885193 time_taken: 0.05656790733337402\n",
      "Epoch 4: iteration 2148/2501 train_loss: 0.4552183151245117 time_taken: 0.05702328681945801\n",
      "Epoch 4: iteration 2149/2501 train_loss: 0.4552057385444641 time_taken: 0.05722451210021973\n",
      "Epoch 4: iteration 2150/2501 train_loss: 0.45518818497657776 time_taken: 0.05743885040283203\n",
      "Epoch 4: iteration 2151/2501 train_loss: 0.45516523718833923 time_taken: 0.0574498176574707\n",
      "Epoch 4: iteration 2152/2501 train_loss: 0.4551418423652649 time_taken: 0.05717206001281738\n",
      "Epoch 4: iteration 2153/2501 train_loss: 0.45511531829833984 time_taken: 0.05657315254211426\n",
      "Epoch 4: iteration 2154/2501 train_loss: 0.4550909101963043 time_taken: 0.05746316909790039\n",
      "Epoch 4: iteration 2155/2501 train_loss: 0.455057293176651 time_taken: 0.0565798282623291\n",
      "Epoch 4: iteration 2156/2501 train_loss: 0.4550210237503052 time_taken: 0.0595555305480957\n",
      "Epoch 4: iteration 2157/2501 train_loss: 0.454984575510025 time_taken: 0.05653858184814453\n",
      "Epoch 4: iteration 2158/2501 train_loss: 0.45495083928108215 time_taken: 0.05711865425109863\n",
      "Epoch 4: iteration 2159/2501 train_loss: 0.4549275040626526 time_taken: 0.056500911712646484\n",
      "Epoch 4: iteration 2160/2501 train_loss: 0.45490923523902893 time_taken: 0.05939602851867676\n",
      "Epoch 4: iteration 2161/2501 train_loss: 0.4548949599266052 time_taken: 0.05651664733886719\n",
      "Epoch 4: iteration 2162/2501 train_loss: 0.4548810124397278 time_taken: 0.055950164794921875\n",
      "Epoch 4: iteration 2163/2501 train_loss: 0.454865425825119 time_taken: 0.059172868728637695\n",
      "Epoch 4: iteration 2164/2501 train_loss: 0.4548616409301758 time_taken: 0.0563204288482666\n",
      "Epoch 4: iteration 2165/2501 train_loss: 0.4548550546169281 time_taken: 0.056000709533691406\n",
      "Epoch 4: iteration 2166/2501 train_loss: 0.45484599471092224 time_taken: 0.0563199520111084\n",
      "Epoch 4: iteration 2167/2501 train_loss: 0.45484045147895813 time_taken: 0.05995774269104004\n",
      "Epoch 4: iteration 2168/2501 train_loss: 0.4548264443874359 time_taken: 0.0559384822845459\n",
      "Epoch 4: iteration 2169/2501 train_loss: 0.45481422543525696 time_taken: 0.0560612678527832\n",
      "Epoch 4: iteration 2170/2501 train_loss: 0.45480117201805115 time_taken: 0.05719947814941406\n",
      "Epoch 4: iteration 2171/2501 train_loss: 0.45479416847229004 time_taken: 0.05785727500915527\n",
      "Epoch 4: iteration 2172/2501 train_loss: 0.45477741956710815 time_taken: 0.05685758590698242\n",
      "Epoch 4: iteration 2173/2501 train_loss: 0.4547531306743622 time_taken: 0.05669450759887695\n",
      "Epoch 4: iteration 2174/2501 train_loss: 0.45473089814186096 time_taken: 0.056453704833984375\n",
      "Epoch 4: iteration 2175/2501 train_loss: 0.4547044634819031 time_taken: 0.05646014213562012\n",
      "Epoch 4: iteration 2176/2501 train_loss: 0.4546767771244049 time_taken: 0.05683612823486328\n",
      "Epoch 4: iteration 2177/2501 train_loss: 0.45465710759162903 time_taken: 0.05647134780883789\n",
      "Epoch 4: iteration 2178/2501 train_loss: 0.454627126455307 time_taken: 0.05643343925476074\n",
      "Epoch 4: iteration 2179/2501 train_loss: 0.45458555221557617 time_taken: 0.05643463134765625\n",
      "Epoch 4: iteration 2180/2501 train_loss: 0.45455554127693176 time_taken: 0.05676531791687012\n",
      "Epoch 4: iteration 2181/2501 train_loss: 0.45452114939689636 time_taken: 0.05655789375305176\n",
      "Epoch 4: iteration 2182/2501 train_loss: 0.4544842839241028 time_taken: 0.0577700138092041\n",
      "Epoch 4: iteration 2183/2501 train_loss: 0.45444732904434204 time_taken: 0.05629086494445801\n",
      "Epoch 4: iteration 2184/2501 train_loss: 0.45441824197769165 time_taken: 0.05678606033325195\n",
      "Epoch 4: iteration 2185/2501 train_loss: 0.45439431071281433 time_taken: 0.05619215965270996\n",
      "Epoch 4: iteration 2186/2501 train_loss: 0.4543766379356384 time_taken: 0.056668996810913086\n",
      "Epoch 4: iteration 2187/2501 train_loss: 0.4543609917163849 time_taken: 0.056519269943237305\n",
      "Epoch 4: iteration 2188/2501 train_loss: 0.45434439182281494 time_taken: 0.0565333366394043\n",
      "Epoch 4: iteration 2189/2501 train_loss: 0.45432302355766296 time_taken: 0.05653691291809082\n",
      "Epoch 4: iteration 2190/2501 train_loss: 0.45429331064224243 time_taken: 0.05670285224914551\n",
      "Epoch 4: iteration 2191/2501 train_loss: 0.45426711440086365 time_taken: 0.05686688423156738\n",
      "Epoch 4: iteration 2192/2501 train_loss: 0.45424866676330566 time_taken: 0.05630636215209961\n",
      "Epoch 4: iteration 2193/2501 train_loss: 0.4543394148349762 time_taken: 0.05672812461853027\n",
      "Epoch 4: iteration 2194/2501 train_loss: 0.4545387625694275 time_taken: 0.05661582946777344\n",
      "Epoch 4: iteration 2195/2501 train_loss: 0.4546096622943878 time_taken: 0.06014251708984375\n",
      "Epoch 4: iteration 2196/2501 train_loss: 0.45470553636550903 time_taken: 0.056386470794677734\n",
      "Epoch 4: iteration 2197/2501 train_loss: 0.4547101557254791 time_taken: 0.056815385818481445\n",
      "Epoch 4: iteration 2198/2501 train_loss: 0.454802006483078 time_taken: 0.05623602867126465\n",
      "Epoch 4: iteration 2199/2501 train_loss: 0.45481473207473755 time_taken: 0.05678200721740723\n",
      "Epoch 4: iteration 2200/2501 train_loss: 0.4548344612121582 time_taken: 0.05684304237365723\n",
      "Epoch 4: iteration 2201/2501 train_loss: 0.4548855125904083 time_taken: 0.05725717544555664\n",
      "Epoch 4: iteration 2202/2501 train_loss: 0.45490139722824097 time_taken: 0.05660581588745117\n",
      "Epoch 4: iteration 2203/2501 train_loss: 0.4549010992050171 time_taken: 0.05681490898132324\n",
      "Epoch 4: iteration 2204/2501 train_loss: 0.45491811633110046 time_taken: 0.05649900436401367\n",
      "Epoch 4: iteration 2205/2501 train_loss: 0.4549151360988617 time_taken: 0.05640101432800293\n",
      "Epoch 4: iteration 2206/2501 train_loss: 0.4548947513103485 time_taken: 0.05676150321960449\n",
      "Epoch 4: iteration 2207/2501 train_loss: 0.45488399267196655 time_taken: 0.05674004554748535\n",
      "Epoch 4: iteration 2208/2501 train_loss: 0.45488059520721436 time_taken: 0.057103633880615234\n",
      "Epoch 4: iteration 2209/2501 train_loss: 0.4548591673374176 time_taken: 0.05711102485656738\n",
      "Epoch 4: iteration 2210/2501 train_loss: 0.45485514402389526 time_taken: 0.05745744705200195\n",
      "Epoch 4: iteration 2211/2501 train_loss: 0.4548482298851013 time_taken: 0.05731964111328125\n",
      "Epoch 4: iteration 2212/2501 train_loss: 0.45484548807144165 time_taken: 0.05734419822692871\n",
      "Epoch 4: iteration 2213/2501 train_loss: 0.45484569668769836 time_taken: 0.05825614929199219\n",
      "Epoch 4: iteration 2214/2501 train_loss: 0.45485103130340576 time_taken: 0.05740213394165039\n",
      "Epoch 4: iteration 2215/2501 train_loss: 0.45486417412757874 time_taken: 0.05636787414550781\n",
      "Epoch 4: iteration 2216/2501 train_loss: 0.454870343208313 time_taken: 0.05729508399963379\n",
      "Epoch 4: iteration 2217/2501 train_loss: 0.45488816499710083 time_taken: 0.056757450103759766\n",
      "Epoch 4: iteration 2218/2501 train_loss: 0.454903244972229 time_taken: 0.05693244934082031\n",
      "Epoch 4: iteration 2219/2501 train_loss: 0.45491331815719604 time_taken: 0.056633949279785156\n",
      "Epoch 4: iteration 2220/2501 train_loss: 0.4549329876899719 time_taken: 0.05655217170715332\n",
      "Epoch 4: iteration 2221/2501 train_loss: 0.4549460709095001 time_taken: 0.05684256553649902\n",
      "Epoch 4: iteration 2222/2501 train_loss: 0.45496347546577454 time_taken: 0.056650638580322266\n",
      "Epoch 4: iteration 2223/2501 train_loss: 0.4549787640571594 time_taken: 0.05629992485046387\n",
      "Epoch 4: iteration 2224/2501 train_loss: 0.45499566197395325 time_taken: 0.05603957176208496\n",
      "Epoch 4: iteration 2225/2501 train_loss: 0.4550143778324127 time_taken: 0.056647300720214844\n",
      "Epoch 4: iteration 2226/2501 train_loss: 0.45502951741218567 time_taken: 0.05653810501098633\n",
      "Epoch 4: iteration 2227/2501 train_loss: 0.4550417363643646 time_taken: 0.05671238899230957\n",
      "Epoch 4: iteration 2228/2501 train_loss: 0.45505478978157043 time_taken: 0.05642557144165039\n",
      "Epoch 4: iteration 2229/2501 train_loss: 0.4550645649433136 time_taken: 0.05621838569641113\n",
      "Epoch 4: iteration 2230/2501 train_loss: 0.4550819993019104 time_taken: 0.05656719207763672\n",
      "Epoch 4: iteration 2231/2501 train_loss: 0.4550991952419281 time_taken: 0.057030439376831055\n",
      "Epoch 4: iteration 2232/2501 train_loss: 0.4551190435886383 time_taken: 0.0581512451171875\n",
      "Epoch 4: iteration 2233/2501 train_loss: 0.45514416694641113 time_taken: 0.05653023719787598\n",
      "Epoch 4: iteration 2234/2501 train_loss: 0.4551669657230377 time_taken: 0.05658411979675293\n",
      "Epoch 4: iteration 2235/2501 train_loss: 0.4551922082901001 time_taken: 0.056601762771606445\n",
      "Epoch 4: iteration 2236/2501 train_loss: 0.4552136957645416 time_taken: 0.057509660720825195\n",
      "Epoch 4: iteration 2237/2501 train_loss: 0.4552405774593353 time_taken: 0.05626869201660156\n",
      "Epoch 4: iteration 2238/2501 train_loss: 0.4552655816078186 time_taken: 0.05689835548400879\n",
      "Epoch 4: iteration 2239/2501 train_loss: 0.45528945326805115 time_taken: 0.05706906318664551\n",
      "Epoch 4: iteration 2240/2501 train_loss: 0.4553150534629822 time_taken: 0.057370901107788086\n",
      "Epoch 4: iteration 2241/2501 train_loss: 0.45534390211105347 time_taken: 0.05614876747131348\n",
      "Epoch 4: iteration 2242/2501 train_loss: 0.45537036657333374 time_taken: 0.05933547019958496\n",
      "Epoch 4: iteration 2243/2501 train_loss: 0.45539674162864685 time_taken: 0.05608630180358887\n",
      "Epoch 4: iteration 2244/2501 train_loss: 0.4554140269756317 time_taken: 0.056980133056640625\n",
      "Epoch 4: iteration 2245/2501 train_loss: 0.4554452896118164 time_taken: 0.05964064598083496\n",
      "Epoch 4: iteration 2246/2501 train_loss: 0.45547428727149963 time_taken: 0.056203603744506836\n",
      "Epoch 4: iteration 2247/2501 train_loss: 0.4554976522922516 time_taken: 0.06048583984375\n",
      "Epoch 4: iteration 2248/2501 train_loss: 0.4555245041847229 time_taken: 0.05660295486450195\n",
      "Epoch 4: iteration 2249/2501 train_loss: 0.4555538594722748 time_taken: 0.057717323303222656\n",
      "Epoch 4: iteration 2250/2501 train_loss: 0.45559248328208923 time_taken: 0.05619239807128906\n",
      "Epoch 4: iteration 2251/2501 train_loss: 0.45562756061553955 time_taken: 0.05610799789428711\n",
      "Epoch 4: iteration 2252/2501 train_loss: 0.4556540250778198 time_taken: 0.0562131404876709\n",
      "Epoch 4: iteration 2253/2501 train_loss: 0.455671101808548 time_taken: 0.059206247329711914\n",
      "Epoch 4: iteration 2254/2501 train_loss: 0.45568767189979553 time_taken: 0.056241512298583984\n",
      "Epoch 4: iteration 2255/2501 train_loss: 0.4556994140148163 time_taken: 0.056236982345581055\n",
      "Epoch 4: iteration 2256/2501 train_loss: 0.4557044208049774 time_taken: 0.05931353569030762\n",
      "Epoch 4: iteration 2257/2501 train_loss: 0.45570236444473267 time_taken: 0.05627918243408203\n",
      "Epoch 4: iteration 2258/2501 train_loss: 0.45569226145744324 time_taken: 0.07837820053100586\n",
      "Epoch 4: iteration 2259/2501 train_loss: 0.45568177103996277 time_taken: 0.06128406524658203\n",
      "Epoch 4: iteration 2260/2501 train_loss: 0.455668181180954 time_taken: 0.059137821197509766\n",
      "Epoch 4: iteration 2261/2501 train_loss: 0.4556516706943512 time_taken: 0.05597853660583496\n",
      "Epoch 4: iteration 2262/2501 train_loss: 0.4556335508823395 time_taken: 0.05757021903991699\n",
      "Epoch 4: iteration 2263/2501 train_loss: 0.45561012625694275 time_taken: 0.05648040771484375\n",
      "Epoch 4: iteration 2264/2501 train_loss: 0.4555814862251282 time_taken: 0.055934906005859375\n",
      "Epoch 4: iteration 2265/2501 train_loss: 0.45555758476257324 time_taken: 0.056127309799194336\n",
      "Epoch 4: iteration 2266/2501 train_loss: 0.45553985238075256 time_taken: 0.06033945083618164\n",
      "Epoch 4: iteration 2267/2501 train_loss: 0.4555210769176483 time_taken: 0.05639982223510742\n",
      "Epoch 4: iteration 2268/2501 train_loss: 0.45550480484962463 time_taken: 0.056294918060302734\n",
      "Epoch 4: iteration 2269/2501 train_loss: 0.455487996339798 time_taken: 0.05728411674499512\n",
      "Epoch 4: iteration 2270/2501 train_loss: 0.45547783374786377 time_taken: 0.05614590644836426\n",
      "Epoch 4: iteration 2271/2501 train_loss: 0.45546889305114746 time_taken: 0.055856943130493164\n",
      "Epoch 4: iteration 2272/2501 train_loss: 0.4554609954357147 time_taken: 0.0559079647064209\n",
      "Epoch 4: iteration 2273/2501 train_loss: 0.4554544687271118 time_taken: 0.05682969093322754\n",
      "Epoch 4: iteration 2274/2501 train_loss: 0.45544707775115967 time_taken: 0.05597352981567383\n",
      "Epoch 4: iteration 2275/2501 train_loss: 0.45543912053108215 time_taken: 0.059297800064086914\n",
      "Epoch 4: iteration 2276/2501 train_loss: 0.4554407298564911 time_taken: 0.05687117576599121\n",
      "Epoch 4: iteration 2277/2501 train_loss: 0.45544949173927307 time_taken: 0.05706906318664551\n",
      "Epoch 4: iteration 2278/2501 train_loss: 0.45545119047164917 time_taken: 0.057633399963378906\n",
      "Epoch 4: iteration 2279/2501 train_loss: 0.45545098185539246 time_taken: 0.05642294883728027\n",
      "Epoch 4: iteration 2280/2501 train_loss: 0.4554506540298462 time_taken: 0.05609416961669922\n",
      "Epoch 4: iteration 2281/2501 train_loss: 0.455454021692276 time_taken: 0.05630850791931152\n",
      "Epoch 4: iteration 2282/2501 train_loss: 0.45545694231987 time_taken: 0.056876420974731445\n",
      "Epoch 4: iteration 2283/2501 train_loss: 0.4554682672023773 time_taken: 0.05660510063171387\n",
      "Epoch 4: iteration 2284/2501 train_loss: 0.45547717809677124 time_taken: 0.05792641639709473\n",
      "Epoch 4: iteration 2285/2501 train_loss: 0.45548203587532043 time_taken: 0.056247711181640625\n",
      "Epoch 4: iteration 2286/2501 train_loss: 0.45548880100250244 time_taken: 0.056375741958618164\n",
      "Epoch 4: iteration 2287/2501 train_loss: 0.455494225025177 time_taken: 0.05645179748535156\n",
      "Epoch 4: iteration 2288/2501 train_loss: 0.45551207661628723 time_taken: 0.05730414390563965\n",
      "Epoch 4: iteration 2289/2501 train_loss: 0.45552775263786316 time_taken: 0.056677818298339844\n",
      "Epoch 4: iteration 2290/2501 train_loss: 0.45554280281066895 time_taken: 0.056043386459350586\n",
      "Epoch 4: iteration 2291/2501 train_loss: 0.4555695056915283 time_taken: 0.05627322196960449\n",
      "Epoch 4: iteration 2292/2501 train_loss: 0.45561033487319946 time_taken: 0.05634641647338867\n",
      "Epoch 4: iteration 2293/2501 train_loss: 0.45563894510269165 time_taken: 0.05602240562438965\n",
      "Epoch 4: iteration 2294/2501 train_loss: 0.45567065477371216 time_taken: 0.05622434616088867\n",
      "Epoch 4: iteration 2295/2501 train_loss: 0.4556991159915924 time_taken: 0.056766510009765625\n",
      "Epoch 4: iteration 2296/2501 train_loss: 0.45572879910469055 time_taken: 0.05641627311706543\n",
      "Epoch 4: iteration 2297/2501 train_loss: 0.4557626247406006 time_taken: 0.05634808540344238\n",
      "Epoch 4: iteration 2298/2501 train_loss: 0.4557914435863495 time_taken: 0.05757761001586914\n",
      "Epoch 4: iteration 2299/2501 train_loss: 0.4558258354663849 time_taken: 0.057187795639038086\n",
      "Epoch 4: iteration 2300/2501 train_loss: 0.4558551609516144 time_taken: 0.05733132362365723\n",
      "Epoch 4: iteration 2301/2501 train_loss: 0.4558864235877991 time_taken: 0.056409597396850586\n",
      "Epoch 4: iteration 2302/2501 train_loss: 0.45591819286346436 time_taken: 0.05649280548095703\n",
      "Epoch 4: iteration 2303/2501 train_loss: 0.45594480633735657 time_taken: 0.05630350112915039\n",
      "Epoch 4: iteration 2304/2501 train_loss: 0.45597052574157715 time_taken: 0.05614495277404785\n",
      "Epoch 4: iteration 2305/2501 train_loss: 0.4559996426105499 time_taken: 0.05642199516296387\n",
      "Epoch 4: iteration 2306/2501 train_loss: 0.45602378249168396 time_taken: 0.057291507720947266\n",
      "Epoch 4: iteration 2307/2501 train_loss: 0.45605167746543884 time_taken: 0.05753898620605469\n",
      "Epoch 4: iteration 2308/2501 train_loss: 0.4560745060443878 time_taken: 0.05703234672546387\n",
      "Epoch 4: iteration 2309/2501 train_loss: 0.4560989737510681 time_taken: 0.05737662315368652\n",
      "Epoch 4: iteration 2310/2501 train_loss: 0.45613202452659607 time_taken: 0.056470394134521484\n",
      "Epoch 4: iteration 2311/2501 train_loss: 0.456168532371521 time_taken: 0.05758357048034668\n",
      "Epoch 4: iteration 2312/2501 train_loss: 0.45619919896125793 time_taken: 0.05686664581298828\n",
      "Epoch 4: iteration 2313/2501 train_loss: 0.45623114705085754 time_taken: 0.058980703353881836\n",
      "Epoch 4: iteration 2314/2501 train_loss: 0.45626696944236755 time_taken: 0.05651712417602539\n",
      "Epoch 4: iteration 2315/2501 train_loss: 0.4563005566596985 time_taken: 0.057084083557128906\n",
      "Epoch 4: iteration 2316/2501 train_loss: 0.45632117986679077 time_taken: 0.05695939064025879\n",
      "Epoch 4: iteration 2317/2501 train_loss: 0.4563625454902649 time_taken: 0.05639028549194336\n",
      "Epoch 4: iteration 2318/2501 train_loss: 0.4563910663127899 time_taken: 0.057486534118652344\n",
      "Epoch 4: iteration 2319/2501 train_loss: 0.4564346373081207 time_taken: 0.05692911148071289\n",
      "Epoch 4: iteration 2320/2501 train_loss: 0.45647555589675903 time_taken: 0.056672096252441406\n",
      "Epoch 4: iteration 2321/2501 train_loss: 0.45650485157966614 time_taken: 0.05689883232116699\n",
      "Epoch 4: iteration 2322/2501 train_loss: 0.45653676986694336 time_taken: 0.0567622184753418\n",
      "Epoch 4: iteration 2323/2501 train_loss: 0.45656129717826843 time_taken: 0.056380510330200195\n",
      "Epoch 4: iteration 2324/2501 train_loss: 0.4565883278846741 time_taken: 0.05687284469604492\n",
      "Epoch 4: iteration 2325/2501 train_loss: 0.45661020278930664 time_taken: 0.057904958724975586\n",
      "Epoch 4: iteration 2326/2501 train_loss: 0.4566248059272766 time_taken: 0.05756235122680664\n",
      "Epoch 4: iteration 2327/2501 train_loss: 0.4566340446472168 time_taken: 0.058043479919433594\n",
      "Epoch 4: iteration 2328/2501 train_loss: 0.456641286611557 time_taken: 0.056864261627197266\n",
      "Epoch 4: iteration 2329/2501 train_loss: 0.4566422402858734 time_taken: 0.056778907775878906\n",
      "Epoch 4: iteration 2330/2501 train_loss: 0.45664262771606445 time_taken: 0.057079315185546875\n",
      "Epoch 4: iteration 2331/2501 train_loss: 0.45664796233177185 time_taken: 0.056856632232666016\n",
      "Epoch 4: iteration 2332/2501 train_loss: 0.45664259791374207 time_taken: 0.05771493911743164\n",
      "Epoch 4: iteration 2333/2501 train_loss: 0.45664092898368835 time_taken: 0.0565183162689209\n",
      "Epoch 4: iteration 2334/2501 train_loss: 0.4566315710544586 time_taken: 0.05662178993225098\n",
      "Epoch 4: iteration 2335/2501 train_loss: 0.45662721991539 time_taken: 0.05647706985473633\n",
      "Epoch 4: iteration 2336/2501 train_loss: 0.4566304683685303 time_taken: 0.05650520324707031\n",
      "Epoch 4: iteration 2337/2501 train_loss: 0.45663169026374817 time_taken: 0.056832313537597656\n",
      "Epoch 4: iteration 2338/2501 train_loss: 0.45663073658943176 time_taken: 0.05650663375854492\n",
      "Epoch 4: iteration 2339/2501 train_loss: 0.4566331207752228 time_taken: 0.05655193328857422\n",
      "Epoch 4: iteration 2340/2501 train_loss: 0.4566326439380646 time_taken: 0.0563509464263916\n",
      "Epoch 4: iteration 2341/2501 train_loss: 0.4566321074962616 time_taken: 0.05649375915527344\n",
      "Epoch 4: iteration 2342/2501 train_loss: 0.45664799213409424 time_taken: 0.0567326545715332\n",
      "Epoch 4: iteration 2343/2501 train_loss: 0.45665034651756287 time_taken: 0.056409597396850586\n",
      "Epoch 4: iteration 2344/2501 train_loss: 0.4566473960876465 time_taken: 0.05672097206115723\n",
      "Epoch 4: iteration 2345/2501 train_loss: 0.4566430151462555 time_taken: 0.05662393569946289\n",
      "Epoch 4: iteration 2346/2501 train_loss: 0.4566437005996704 time_taken: 0.057259559631347656\n",
      "Epoch 4: iteration 2347/2501 train_loss: 0.45664241909980774 time_taken: 0.05669593811035156\n",
      "Epoch 4: iteration 2348/2501 train_loss: 0.4566335380077362 time_taken: 0.0570375919342041\n",
      "Epoch 4: iteration 2349/2501 train_loss: 0.4566267132759094 time_taken: 0.05647397041320801\n",
      "Epoch 4: iteration 2350/2501 train_loss: 0.45661357045173645 time_taken: 0.05688834190368652\n",
      "Epoch 4: iteration 2351/2501 train_loss: 0.45659953355789185 time_taken: 0.0569462776184082\n",
      "Epoch 4: iteration 2352/2501 train_loss: 0.45658862590789795 time_taken: 0.05656147003173828\n",
      "Epoch 4: iteration 2353/2501 train_loss: 0.456570565700531 time_taken: 0.056876182556152344\n",
      "Epoch 4: iteration 2354/2501 train_loss: 0.45654743909835815 time_taken: 0.05684232711791992\n",
      "Epoch 4: iteration 2355/2501 train_loss: 0.4565248489379883 time_taken: 0.057201385498046875\n",
      "Epoch 4: iteration 2356/2501 train_loss: 0.4564957916736603 time_taken: 0.05760598182678223\n",
      "Epoch 4: iteration 2357/2501 train_loss: 0.45647159218788147 time_taken: 0.05743551254272461\n",
      "Epoch 4: iteration 2358/2501 train_loss: 0.45644238591194153 time_taken: 0.056938886642456055\n",
      "Epoch 4: iteration 2359/2501 train_loss: 0.45640289783477783 time_taken: 0.05767011642456055\n",
      "Epoch 4: iteration 2360/2501 train_loss: 0.4563663601875305 time_taken: 0.05725359916687012\n",
      "Epoch 4: iteration 2361/2501 train_loss: 0.4563290476799011 time_taken: 0.056661128997802734\n",
      "Epoch 4: iteration 2362/2501 train_loss: 0.4562968611717224 time_taken: 0.057352304458618164\n",
      "Epoch 4: iteration 2363/2501 train_loss: 0.4562605619430542 time_taken: 0.05645751953125\n",
      "Epoch 4: iteration 2364/2501 train_loss: 0.4562213122844696 time_taken: 0.05652642250061035\n",
      "Epoch 4: iteration 2365/2501 train_loss: 0.456185519695282 time_taken: 0.05655407905578613\n",
      "Epoch 4: iteration 2366/2501 train_loss: 0.4561510682106018 time_taken: 0.0562129020690918\n",
      "Epoch 4: iteration 2367/2501 train_loss: 0.4561169743537903 time_taken: 0.05758404731750488\n",
      "Epoch 4: iteration 2368/2501 train_loss: 0.4560825526714325 time_taken: 0.05677032470703125\n",
      "Epoch 4: iteration 2369/2501 train_loss: 0.4560530483722687 time_taken: 0.057360172271728516\n",
      "Epoch 4: iteration 2370/2501 train_loss: 0.45601606369018555 time_taken: 0.05690479278564453\n",
      "Epoch 4: iteration 2371/2501 train_loss: 0.4559890329837799 time_taken: 0.057409048080444336\n",
      "Epoch 4: iteration 2372/2501 train_loss: 0.45596426725387573 time_taken: 0.05694174766540527\n",
      "Epoch 4: iteration 2373/2501 train_loss: 0.4559353291988373 time_taken: 0.05670738220214844\n",
      "Epoch 4: iteration 2374/2501 train_loss: 0.45591118931770325 time_taken: 0.05661368370056152\n",
      "Epoch 4: iteration 2375/2501 train_loss: 0.45589569211006165 time_taken: 0.05686807632446289\n",
      "Epoch 4: iteration 2376/2501 train_loss: 0.45587801933288574 time_taken: 0.05717825889587402\n",
      "Epoch 4: iteration 2377/2501 train_loss: 0.4558585286140442 time_taken: 0.05754446983337402\n",
      "Epoch 4: iteration 2378/2501 train_loss: 0.45583856105804443 time_taken: 0.05741167068481445\n",
      "Epoch 4: iteration 2379/2501 train_loss: 0.4558316171169281 time_taken: 0.05686306953430176\n",
      "Epoch 4: iteration 2380/2501 train_loss: 0.4558255076408386 time_taken: 0.05688810348510742\n",
      "Epoch 4: iteration 2381/2501 train_loss: 0.45581868290901184 time_taken: 0.05660295486450195\n",
      "Epoch 4: iteration 2382/2501 train_loss: 0.45580989122390747 time_taken: 0.05722379684448242\n",
      "Epoch 4: iteration 2383/2501 train_loss: 0.4558079242706299 time_taken: 0.05724453926086426\n",
      "Epoch 4: iteration 2384/2501 train_loss: 0.4558042883872986 time_taken: 0.05734372138977051\n",
      "Epoch 4: iteration 2385/2501 train_loss: 0.4557969868183136 time_taken: 0.05715370178222656\n",
      "Epoch 4: iteration 2386/2501 train_loss: 0.45578712224960327 time_taken: 0.05692648887634277\n",
      "Epoch 4: iteration 2387/2501 train_loss: 0.45577651262283325 time_taken: 0.05778861045837402\n",
      "Epoch 4: iteration 2388/2501 train_loss: 0.45576900243759155 time_taken: 0.05686807632446289\n",
      "Epoch 4: iteration 2389/2501 train_loss: 0.4557560980319977 time_taken: 0.05695962905883789\n",
      "Epoch 4: iteration 2390/2501 train_loss: 0.4557362496852875 time_taken: 0.05766558647155762\n",
      "Epoch 4: iteration 2391/2501 train_loss: 0.4557189345359802 time_taken: 0.057892560958862305\n",
      "Epoch 4: iteration 2392/2501 train_loss: 0.45569953322410583 time_taken: 0.05628705024719238\n",
      "Epoch 4: iteration 2393/2501 train_loss: 0.45567479729652405 time_taken: 0.05693364143371582\n",
      "Epoch 4: iteration 2394/2501 train_loss: 0.45565998554229736 time_taken: 0.05655264854431152\n",
      "Epoch 4: iteration 2395/2501 train_loss: 0.455648273229599 time_taken: 0.056696176528930664\n",
      "Epoch 4: iteration 2396/2501 train_loss: 0.45563754439353943 time_taken: 0.056571006774902344\n",
      "Epoch 4: iteration 2397/2501 train_loss: 0.4556344151496887 time_taken: 0.05644345283508301\n",
      "Epoch 4: iteration 2398/2501 train_loss: 0.4556255340576172 time_taken: 0.05693316459655762\n",
      "Epoch 4: iteration 2399/2501 train_loss: 0.4556177854537964 time_taken: 0.05656886100769043\n",
      "Epoch 4: iteration 2400/2501 train_loss: 0.455610066652298 time_taken: 0.0567777156829834\n",
      "Epoch 4: iteration 2401/2501 train_loss: 0.4556064009666443 time_taken: 0.056261301040649414\n",
      "Epoch 4: iteration 2402/2501 train_loss: 0.45559582114219666 time_taken: 0.05717635154724121\n",
      "Epoch 4: iteration 2403/2501 train_loss: 0.4555843770503998 time_taken: 0.05682229995727539\n",
      "Epoch 4: iteration 2404/2501 train_loss: 0.4555753469467163 time_taken: 0.0565791130065918\n",
      "Epoch 4: iteration 2405/2501 train_loss: 0.4555641710758209 time_taken: 0.056672096252441406\n",
      "Epoch 4: iteration 2406/2501 train_loss: 0.45555412769317627 time_taken: 0.05655789375305176\n",
      "Epoch 4: iteration 2407/2501 train_loss: 0.45553770661354065 time_taken: 0.06081342697143555\n",
      "Epoch 4: iteration 2408/2501 train_loss: 0.4555249512195587 time_taken: 0.056382179260253906\n",
      "Epoch 4: iteration 2409/2501 train_loss: 0.45551827549934387 time_taken: 0.05722165107727051\n",
      "Epoch 4: iteration 2410/2501 train_loss: 0.4555116891860962 time_taken: 0.06107306480407715\n",
      "Epoch 4: iteration 2411/2501 train_loss: 0.4555007219314575 time_taken: 0.056446075439453125\n",
      "Epoch 4: iteration 2412/2501 train_loss: 0.4554949104785919 time_taken: 0.05649375915527344\n",
      "Epoch 4: iteration 2413/2501 train_loss: 0.4554920196533203 time_taken: 0.05642223358154297\n",
      "Epoch 4: iteration 2414/2501 train_loss: 0.45548492670059204 time_taken: 0.05647635459899902\n",
      "Epoch 4: iteration 2415/2501 train_loss: 0.4554806649684906 time_taken: 0.05743527412414551\n",
      "Epoch 4: iteration 2416/2501 train_loss: 0.4554833769798279 time_taken: 0.05627942085266113\n",
      "Epoch 4: iteration 2417/2501 train_loss: 0.45548945665359497 time_taken: 0.05620241165161133\n",
      "Epoch 4: iteration 2418/2501 train_loss: 0.4554928243160248 time_taken: 0.05759906768798828\n",
      "Epoch 4: iteration 2419/2501 train_loss: 0.4554951786994934 time_taken: 0.05651450157165527\n",
      "Epoch 4: iteration 2420/2501 train_loss: 0.4554986357688904 time_taken: 0.05715441703796387\n",
      "Epoch 4: iteration 2421/2501 train_loss: 0.4554996192455292 time_taken: 0.05667424201965332\n",
      "Epoch 4: iteration 2422/2501 train_loss: 0.4555095136165619 time_taken: 0.05651211738586426\n",
      "Epoch 4: iteration 2423/2501 train_loss: 0.4555172920227051 time_taken: 0.05653262138366699\n",
      "Epoch 4: iteration 2424/2501 train_loss: 0.4555271565914154 time_taken: 0.05640697479248047\n",
      "Epoch 4: iteration 2425/2501 train_loss: 0.45553600788116455 time_taken: 0.056450843811035156\n",
      "Epoch 4: iteration 2426/2501 train_loss: 0.45554235577583313 time_taken: 0.05672955513000488\n",
      "Epoch 4: iteration 2427/2501 train_loss: 0.45555368065834045 time_taken: 0.05632925033569336\n",
      "Epoch 4: iteration 2428/2501 train_loss: 0.45556730031967163 time_taken: 0.05674457550048828\n",
      "Epoch 4: iteration 2429/2501 train_loss: 0.45557886362075806 time_taken: 0.0567929744720459\n",
      "Epoch 4: iteration 2430/2501 train_loss: 0.45559653639793396 time_taken: 0.056825876235961914\n",
      "Epoch 4: iteration 2431/2501 train_loss: 0.4556131362915039 time_taken: 0.057271718978881836\n",
      "Epoch 4: iteration 2432/2501 train_loss: 0.45562827587127686 time_taken: 0.05646872520446777\n",
      "Epoch 4: iteration 2433/2501 train_loss: 0.45564550161361694 time_taken: 0.057005882263183594\n",
      "Epoch 4: iteration 2434/2501 train_loss: 0.45566943287849426 time_taken: 0.05709552764892578\n",
      "Epoch 4: iteration 2435/2501 train_loss: 0.4556922912597656 time_taken: 0.05636739730834961\n",
      "Epoch 4: iteration 2436/2501 train_loss: 0.4557095766067505 time_taken: 0.057245731353759766\n",
      "Epoch 4: iteration 2437/2501 train_loss: 0.4557347297668457 time_taken: 0.05641603469848633\n",
      "Epoch 4: iteration 2438/2501 train_loss: 0.4557572901248932 time_taken: 0.05683279037475586\n",
      "Epoch 4: iteration 2439/2501 train_loss: 0.45578432083129883 time_taken: 0.056635379791259766\n",
      "Epoch 4: iteration 2440/2501 train_loss: 0.4558127522468567 time_taken: 0.05725598335266113\n",
      "Epoch 4: iteration 2441/2501 train_loss: 0.4558459520339966 time_taken: 0.0570673942565918\n",
      "Epoch 4: iteration 2442/2501 train_loss: 0.4558761417865753 time_taken: 0.05717325210571289\n",
      "Epoch 4: iteration 2443/2501 train_loss: 0.45591074228286743 time_taken: 0.05620622634887695\n",
      "Epoch 4: iteration 2444/2501 train_loss: 0.4559442102909088 time_taken: 0.05601954460144043\n",
      "Epoch 4: iteration 2445/2501 train_loss: 0.45597413182258606 time_taken: 0.056643009185791016\n",
      "Epoch 4: iteration 2446/2501 train_loss: 0.45599472522735596 time_taken: 0.05705618858337402\n",
      "Epoch 4: iteration 2447/2501 train_loss: 0.4560166299343109 time_taken: 0.0613861083984375\n",
      "Epoch 4: iteration 2448/2501 train_loss: 0.45603010058403015 time_taken: 0.05635499954223633\n",
      "Epoch 4: iteration 2449/2501 train_loss: 0.4560389816761017 time_taken: 0.056191205978393555\n",
      "Epoch 4: iteration 2450/2501 train_loss: 0.4560476243495941 time_taken: 0.05630826950073242\n",
      "Epoch 4: iteration 2451/2501 train_loss: 0.4560476541519165 time_taken: 0.05659675598144531\n",
      "Epoch 4: iteration 2452/2501 train_loss: 0.4560474753379822 time_taken: 0.05669260025024414\n",
      "Epoch 4: iteration 2453/2501 train_loss: 0.45604437589645386 time_taken: 0.05630326271057129\n",
      "Epoch 4: iteration 2454/2501 train_loss: 0.45603451132774353 time_taken: 0.0566716194152832\n",
      "Epoch 4: iteration 2455/2501 train_loss: 0.4560263156890869 time_taken: 0.055768728256225586\n",
      "Epoch 4: iteration 2456/2501 train_loss: 0.456011027097702 time_taken: 0.05655789375305176\n",
      "Epoch 4: iteration 2457/2501 train_loss: 0.4559938609600067 time_taken: 0.057146549224853516\n",
      "Epoch 4: iteration 2458/2501 train_loss: 0.4559749662876129 time_taken: 0.05626368522644043\n",
      "Epoch 4: iteration 2459/2501 train_loss: 0.4559539556503296 time_taken: 0.056345462799072266\n",
      "Epoch 4: iteration 2460/2501 train_loss: 0.4559333622455597 time_taken: 0.05619096755981445\n",
      "Epoch 4: iteration 2461/2501 train_loss: 0.4559170603752136 time_taken: 0.05631518363952637\n",
      "Epoch 4: iteration 2462/2501 train_loss: 0.4559088349342346 time_taken: 0.05583810806274414\n",
      "Epoch 4: iteration 2463/2501 train_loss: 0.455902636051178 time_taken: 0.05602884292602539\n",
      "Epoch 4: iteration 2464/2501 train_loss: 0.45589423179626465 time_taken: 0.05644083023071289\n",
      "Epoch 4: iteration 2465/2501 train_loss: 0.45589351654052734 time_taken: 0.05709528923034668\n",
      "Epoch 4: iteration 2466/2501 train_loss: 0.4558950662612915 time_taken: 0.056427955627441406\n",
      "Epoch 4: iteration 2467/2501 train_loss: 0.4558931589126587 time_taken: 0.05661725997924805\n",
      "Epoch 4: iteration 2468/2501 train_loss: 0.45589137077331543 time_taken: 0.056464195251464844\n",
      "Epoch 4: iteration 2469/2501 train_loss: 0.45587947964668274 time_taken: 0.05636882781982422\n",
      "Epoch 4: iteration 2470/2501 train_loss: 0.4558653235435486 time_taken: 0.05637216567993164\n",
      "Epoch 4: iteration 2471/2501 train_loss: 0.4558599889278412 time_taken: 0.05690646171569824\n",
      "Epoch 4: iteration 2472/2501 train_loss: 0.4558538794517517 time_taken: 0.05736517906188965\n",
      "Epoch 4: iteration 2473/2501 train_loss: 0.4558391273021698 time_taken: 0.05678105354309082\n",
      "Epoch 4: iteration 2474/2501 train_loss: 0.4558252990245819 time_taken: 0.05668067932128906\n",
      "Epoch 4: iteration 2475/2501 train_loss: 0.45581260323524475 time_taken: 0.056227922439575195\n",
      "Epoch 4: iteration 2476/2501 train_loss: 0.45581045746803284 time_taken: 0.056593894958496094\n",
      "Epoch 4: iteration 2477/2501 train_loss: 0.4558207094669342 time_taken: 0.05650615692138672\n",
      "Epoch 4: iteration 2478/2501 train_loss: 0.45583298802375793 time_taken: 0.056507110595703125\n",
      "Epoch 4: iteration 2479/2501 train_loss: 0.4558403789997101 time_taken: 0.05618453025817871\n",
      "Epoch 4: iteration 2480/2501 train_loss: 0.45587530732154846 time_taken: 0.056400299072265625\n",
      "Epoch 4: iteration 2481/2501 train_loss: 0.45592284202575684 time_taken: 0.05641341209411621\n",
      "Epoch 4: iteration 2482/2501 train_loss: 0.4559505581855774 time_taken: 0.057280778884887695\n",
      "Epoch 4: iteration 2483/2501 train_loss: 0.45598745346069336 time_taken: 0.057169198989868164\n",
      "Epoch 4: iteration 2484/2501 train_loss: 0.45603081583976746 time_taken: 0.05689835548400879\n",
      "Epoch 4: iteration 2485/2501 train_loss: 0.4560944139957428 time_taken: 0.05644965171813965\n",
      "Epoch 4: iteration 2486/2501 train_loss: 0.4561719000339508 time_taken: 0.05672335624694824\n",
      "Epoch 4: iteration 2487/2501 train_loss: 0.4562487304210663 time_taken: 0.05588889122009277\n",
      "Epoch 4: iteration 2488/2501 train_loss: 0.4563184380531311 time_taken: 0.05569267272949219\n",
      "Epoch 4: iteration 2489/2501 train_loss: 0.4563625156879425 time_taken: 0.05563497543334961\n",
      "Epoch 4: iteration 2490/2501 train_loss: 0.4564046859741211 time_taken: 0.05702567100524902\n",
      "Epoch 4: iteration 2491/2501 train_loss: 0.4564257860183716 time_taken: 0.05612826347351074\n",
      "Epoch 4: iteration 2492/2501 train_loss: 0.4564536213874817 time_taken: 0.05552816390991211\n",
      "Epoch 4: iteration 2493/2501 train_loss: 0.4564781188964844 time_taken: 0.055960655212402344\n",
      "Epoch 4: iteration 2494/2501 train_loss: 0.4565034806728363 time_taken: 0.056070804595947266\n",
      "Epoch 4: iteration 2495/2501 train_loss: 0.45653235912323 time_taken: 0.05586385726928711\n",
      "Epoch 4: iteration 2496/2501 train_loss: 0.4565473198890686 time_taken: 0.05587029457092285\n",
      "Epoch 4: iteration 2497/2501 train_loss: 0.4565696120262146 time_taken: 0.05594205856323242\n",
      "Epoch 4: iteration 2498/2501 train_loss: 0.45658639073371887 time_taken: 0.05607318878173828\n",
      "Epoch 4: iteration 2499/2501 train_loss: 0.45660048723220825 time_taken: 0.05556750297546387\n",
      "Epoch 4: iteration 2500/2501 train_loss: 0.45660969614982605 time_taken: 0.05430769920349121\n",
      "Finished epoch 4 took 442.5495181083679\n"
     ]
    }
   ],
   "source": [
    "train_loss_results_MLP = train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_loss_results_MLP)\n",
    "\n",
    "plt.title(\"training loss\")\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"MSE loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.savefig(\"training_loss.png\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f4add30e3a0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights(\"ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "project.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
