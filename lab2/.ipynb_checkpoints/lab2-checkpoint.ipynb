{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining SBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "# QUESTION: \n",
    "## SHOULD WE TRAIN FROM SCRATCH OR CAN WE START FROM bert-base-uncased or any other starting point?\n",
    "\n",
    "## TODO: Add validation set and test on testing set for SBERT classification\n",
    "\n",
    "## TODO: After finishing training for classification, save the model please to stop training everytime <3\n",
    "\n",
    "## TODO: After training on the classification data, check how to \"fine-tune\" on the STS regression data (maybe only the head without the bert itself?)\n",
    "## Check my question please <3 https://docs.google.com/document/d/1YeohuAr55fKF2nI1RiCgpq_Wa3Yn-CLAwfPoBmViNIM/edit\n",
    "\n",
    "class SBERT(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SBERT, self).__init__()\n",
    "        # sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\n",
    "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "        self.model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "                \n",
    "        self.pooling = nn.AvgPool1d(kernel_size=3,stride=1)\n",
    "        # 768 / 3 -> 256\n",
    "        self.linear = nn.Linear(in_features=2298, out_features=3) # 2298=(768-2)*3; 153 is the embedding dimension after pooling and stuff..\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, sent1, sent2, objective):\n",
    "        encoded_input1 = self.tokenizer(sent1, padding=True, truncation=True, return_tensors='pt')\n",
    "        output1 = self.model(**encoded_input1)\n",
    "        output1 = self.pooling(output1[\"pooler_output\"])\n",
    "\n",
    "        encoded_input2 = self.tokenizer(sent2, padding=True, truncation=True, return_tensors='pt')\n",
    "        output2 = self.model(**encoded_input2)\n",
    "        output2 = self.pooling(output2[\"pooler_output\"])\n",
    "                \n",
    "        if objective == \"regression\":\n",
    "            return cosine_similarity(output1.detach().numpy(),output2.detach().numpy())\n",
    "\n",
    "        if objective == \"classification\":\n",
    "            diff = abs(torch.subtract(output1,output2))\n",
    "            concat = torch.cat([output1,output2,diff],axis=1)            \n",
    "            result = self.linear(concat)\n",
    "            out = self.softmax(result)\n",
    "            return out\n",
    "\n",
    "        # return output\n",
    "\n",
    "#     def regression_objective(self, text1, text2):\n",
    "#         vec1 = self.forward(text1).detach().numpy()\n",
    "#         vec2 = self.forward(text2).detach().numpy()\n",
    "#         return cosine_similarity(vec1,vec2)\n",
    "    \n",
    "#     def classification_objective(self,text1,text2):\n",
    "#         vec1 = self.forward(text1)\n",
    "#         vec2 = self.forward(text2)\n",
    "        \n",
    "#         diff = abs(torch.subtract(vec1,vec2))\n",
    "\n",
    "#         concat = torch.cat([vec1,vec2,diff])\n",
    "        \n",
    "#         result = self.linear(concat)\n",
    "        \n",
    "#         out = self.softmax(result)\n",
    "#         pred = torch.argmax(out,axis=0)\n",
    "        \n",
    "#         return pred\n",
    "\n",
    "sbert = SBERT()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SBERT(\n",
       "  (model): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (pooling): AvgPool1d(kernel_size=(3,), stride=(1,), padding=(0,))\n",
       "  (linear): Linear(in_features=2298, out_features=3, bias=True)\n",
       "  (softmax): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sbert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Objective Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.6</td>\n",
       "      <td>A group of men play soccer on the beach.</td>\n",
       "      <td>A group of boys are playing soccer on the beach.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>One woman is measuring another woman's ankle.</td>\n",
       "      <td>A woman measures another woman's ankle.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.2</td>\n",
       "      <td>A man is cutting up a cucumber.</td>\n",
       "      <td>A man is slicing a cucumber.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.5</td>\n",
       "      <td>A man is playing a harp.</td>\n",
       "      <td>A man is playing a keyboard.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.8</td>\n",
       "      <td>A woman is cutting onions.</td>\n",
       "      <td>A woman is cutting tofu.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   score                                      sentence1  \\\n",
       "0    3.6       A group of men play soccer on the beach.   \n",
       "1    5.0  One woman is measuring another woman's ankle.   \n",
       "2    4.2                A man is cutting up a cucumber.   \n",
       "3    1.5                       A man is playing a harp.   \n",
       "4    1.8                     A woman is cutting onions.   \n",
       "\n",
       "                                          sentence2  \n",
       "0  A group of boys are playing soccer on the beach.  \n",
       "1           A woman measures another woman's ankle.  \n",
       "2                      A man is slicing a cucumber.  \n",
       "3                      A man is playing a keyboard.  \n",
       "4                          A woman is cutting tofu.  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_test = pd.read_csv(\"Stsbenchmark/sts-test.csv\",header=0,names=[\"main-caption\",\"genre\",\"filename\",\"year\",\"score\",\"sentence1\",\"sentence2\"])#,usecols=['score','sentence1','sentence2'])\n",
    "\n",
    "df_test = df_test[['score','sentence1','sentence2']]\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "score        0\n",
       "sentence1    0\n",
       "sentence2    5\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "score        0\n",
       "sentence1    0\n",
       "sentence2    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_score(value, leftMin=0, leftMax=5, rightMin=-1, rightMax=1):\n",
    "    # Figure out how 'wide' each range is\n",
    "    leftSpan = leftMax - leftMin\n",
    "    rightSpan = rightMax - rightMin\n",
    "\n",
    "    # Convert the left range into a 0-1 range (float)\n",
    "    valueScaled = float(value - leftMin) / float(leftSpan)\n",
    "\n",
    "    # Convert the 0-1 range into a value in the right range.\n",
    "    return rightMin + (valueScaled * rightSpan)\n",
    "\n",
    "def map_to_label(x): # assuming x is between -1 and 1\n",
    "    threshold = 0.25\n",
    "    if abs(x- (-1) ) <= threshold: return 1\n",
    "    if abs(x- (-0.5) ) <= threshold: return 2\n",
    "    if abs(x- (0) ) <= threshold: return 3\n",
    "    if abs(x- (0.5) ) <= threshold: return 4\n",
    "    if abs(x- (1) ) <= threshold: return 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "preds = []\n",
    "trues = []\n",
    "for i,row in df_test.iterrows():\n",
    "    sentence1 = row.sentence1\n",
    "    sentence2 = row.sentence2\n",
    "    \n",
    "    score_theoretical = row.score\n",
    "    \n",
    "    try:\n",
    "        # score_pred = sbert.regression_objective(sentence1,sentence2)\n",
    "        score_pred = sbert(sentence1,sentence2,objective=\"regression\")\n",
    "        label_pred = map_to_label(score_pred)\n",
    "        \n",
    "        score_theoretical = map_score(score_theoretical)        \n",
    "        label_true = map_to_label(score_theoretical)\n",
    "        \n",
    "        preds.append(label_pred)\n",
    "        trues.append(label_true)\n",
    "        \n",
    "    except:\n",
    "        print(\"i\",i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"1\": {\n",
      "        \"f1-score\": 0.0,\n",
      "        \"precision\": 0.0,\n",
      "        \"recall\": 0.0,\n",
      "        \"support\": 169\n",
      "    },\n",
      "    \"2\": {\n",
      "        \"f1-score\": 0.011627906976744186,\n",
      "        \"precision\": 1.0,\n",
      "        \"recall\": 0.005847953216374269,\n",
      "        \"support\": 171\n",
      "    },\n",
      "    \"3\": {\n",
      "        \"f1-score\": 0.0,\n",
      "        \"precision\": 0.0,\n",
      "        \"recall\": 0.0,\n",
      "        \"support\": 252\n",
      "    },\n",
      "    \"4\": {\n",
      "        \"f1-score\": 0.07482993197278912,\n",
      "        \"precision\": 0.275,\n",
      "        \"recall\": 0.04330708661417323,\n",
      "        \"support\": 254\n",
      "    },\n",
      "    \"5\": {\n",
      "        \"f1-score\": 0.239622641509434,\n",
      "        \"precision\": 0.1364124597207304,\n",
      "        \"recall\": 0.9844961240310077,\n",
      "        \"support\": 129\n",
      "    },\n",
      "    \"accuracy\": 0.14256410256410257,\n",
      "    \"macro avg\": {\n",
      "        \"f1-score\": 0.06521609609179346,\n",
      "        \"precision\": 0.28228249194414606,\n",
      "        \"recall\": 0.20673023277231106,\n",
      "        \"support\": 975\n",
      "    },\n",
      "    \"weighted avg\": {\n",
      "        \"f1-score\": 0.0532374313526448,\n",
      "        \"precision\": 0.2650740587733069,\n",
      "        \"recall\": 0.14256410256410257,\n",
      "        \"support\": 975\n",
      "    }\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ali/anaconda3/envs/py38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import json\n",
    "\n",
    "report = classification_report(trues, preds,output_dict=True)\n",
    "print(json.dumps(report, sort_keys=True, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Objective Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "json_list = list(open(\"snli_1.0/snli_1.0_train.jsonl\",\"r\"))\n",
    "\n",
    "label2int = {\"contradiction\": 0, \"entailment\": 1, \"neutral\": 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {'sentence1': [], 'sentence2': [], 'gold_label': []}\n",
    "for json_str in json_list:\n",
    "    try:\n",
    "        result = json.loads(json_str)\n",
    "        result['gold_label']=label2int[result['gold_label']]\n",
    "        for key in data:\n",
    "            data[key].append(result[key])\n",
    "    except:\n",
    "        pass\n",
    "df_train = pd.DataFrame.from_dict(data)#.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset,DataLoader\n",
    "\n",
    "class SNLI_Dataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        sent1 = row['sentence1']\n",
    "        sent2 = row['sentence2']\n",
    "        label = row['gold_label']\n",
    "        return (sent1, sent2), label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = SNLI_Dataset(df_train)\n",
    "train_dataloader = DataLoader(training_data, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(sbert.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- outputs of shape (N,C) where N is the batch size C is the number of classes\n",
    "- target of shape (N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=0 iteration=0/1 loss=0.9991500973701477\n",
      "epoch=1 iteration=0/1 loss=0.9819676280021667\n",
      "epoch=2 iteration=0/1 loss=0.9626067876815796\n",
      "epoch=3 iteration=0/1 loss=0.9417279958724976\n",
      "epoch=4 iteration=0/1 loss=0.9187717437744141\n",
      "epoch=5 iteration=0/1 loss=0.8931153416633606\n",
      "epoch=6 iteration=0/1 loss=0.8695991635322571\n",
      "epoch=7 iteration=0/1 loss=0.8479693531990051\n",
      "epoch=8 iteration=0/1 loss=0.8287663459777832\n",
      "epoch=9 iteration=0/1 loss=0.8116615414619446\n",
      "epoch=10 iteration=0/1 loss=0.7956103086471558\n",
      "epoch=11 iteration=0/1 loss=0.7812157273292542\n",
      "epoch=12 iteration=0/1 loss=0.7702778577804565\n",
      "epoch=13 iteration=0/1 loss=0.76219642162323\n",
      "epoch=14 iteration=0/1 loss=0.7545262575149536\n",
      "epoch=15 iteration=0/1 loss=0.7498899698257446\n",
      "epoch=16 iteration=0/1 loss=0.7453569769859314\n",
      "epoch=17 iteration=0/1 loss=0.7419780492782593\n",
      "epoch=18 iteration=0/1 loss=0.7394949197769165\n",
      "epoch=19 iteration=0/1 loss=0.7367589473724365\n",
      "epoch=20 iteration=0/1 loss=0.735549807548523\n",
      "epoch=21 iteration=0/1 loss=0.7331656217575073\n",
      "epoch=22 iteration=0/1 loss=0.7329444289207458\n",
      "epoch=23 iteration=0/1 loss=0.7325953245162964\n",
      "epoch=24 iteration=0/1 loss=0.7318664789199829\n",
      "epoch=25 iteration=0/1 loss=0.7283893823623657\n",
      "epoch=26 iteration=0/1 loss=0.7313235998153687\n",
      "epoch=27 iteration=0/1 loss=0.7315142154693604\n",
      "epoch=28 iteration=0/1 loss=0.7342182397842407\n",
      "epoch=29 iteration=0/1 loss=0.727489709854126\n",
      "epoch=30 iteration=0/1 loss=0.7268660068511963\n",
      "epoch=31 iteration=0/1 loss=0.7292481064796448\n",
      "epoch=32 iteration=0/1 loss=0.7239695191383362\n",
      "epoch=33 iteration=0/1 loss=0.7224016189575195\n",
      "epoch=34 iteration=0/1 loss=0.7237626910209656\n",
      "epoch=35 iteration=0/1 loss=0.7189257740974426\n",
      "epoch=36 iteration=0/1 loss=0.7151655554771423\n",
      "epoch=37 iteration=0/1 loss=0.7181419730186462\n",
      "epoch=38 iteration=0/1 loss=0.7111197113990784\n",
      "epoch=39 iteration=0/1 loss=0.713861882686615\n",
      "epoch=40 iteration=0/1 loss=0.7072368860244751\n",
      "epoch=41 iteration=0/1 loss=0.6978334188461304\n",
      "epoch=42 iteration=0/1 loss=0.7178983688354492\n",
      "epoch=43 iteration=0/1 loss=0.718485951423645\n",
      "epoch=44 iteration=0/1 loss=0.7334425449371338\n",
      "epoch=45 iteration=0/1 loss=0.7373417615890503\n",
      "epoch=46 iteration=0/1 loss=0.7377431988716125\n",
      "epoch=47 iteration=0/1 loss=0.7363050580024719\n",
      "epoch=48 iteration=0/1 loss=0.7331472635269165\n",
      "epoch=49 iteration=0/1 loss=0.7277696132659912\n",
      "epoch=50 iteration=0/1 loss=0.7195956110954285\n",
      "epoch=51 iteration=0/1 loss=0.7082614302635193\n",
      "epoch=52 iteration=0/1 loss=0.694537878036499\n",
      "epoch=53 iteration=0/1 loss=0.6804137825965881\n",
      "epoch=54 iteration=0/1 loss=0.6675502061843872\n",
      "epoch=55 iteration=0/1 loss=0.6573978662490845\n",
      "epoch=56 iteration=0/1 loss=0.6512638330459595\n",
      "epoch=57 iteration=0/1 loss=0.6496508717536926\n",
      "epoch=58 iteration=0/1 loss=0.6503015756607056\n",
      "epoch=59 iteration=0/1 loss=0.6486628651618958\n",
      "epoch=60 iteration=0/1 loss=0.6449267864227295\n",
      "epoch=61 iteration=0/1 loss=0.6395868062973022\n",
      "epoch=62 iteration=0/1 loss=0.6341701745986938\n",
      "epoch=63 iteration=0/1 loss=0.6295932531356812\n",
      "epoch=64 iteration=0/1 loss=0.6261321306228638\n",
      "epoch=65 iteration=0/1 loss=0.6223281621932983\n",
      "epoch=66 iteration=0/1 loss=0.6191962957382202\n",
      "epoch=67 iteration=0/1 loss=0.6161402463912964\n",
      "epoch=68 iteration=0/1 loss=0.6131076812744141\n",
      "epoch=69 iteration=0/1 loss=0.6100608110427856\n",
      "epoch=70 iteration=0/1 loss=0.6069434285163879\n",
      "epoch=71 iteration=0/1 loss=0.6038081049919128\n",
      "epoch=72 iteration=0/1 loss=0.6008145809173584\n",
      "epoch=73 iteration=0/1 loss=0.5981199741363525\n",
      "epoch=74 iteration=0/1 loss=0.5957783460617065\n",
      "epoch=75 iteration=0/1 loss=0.5938041806221008\n",
      "epoch=76 iteration=0/1 loss=0.5921333432197571\n",
      "epoch=77 iteration=0/1 loss=0.5906773805618286\n",
      "epoch=78 iteration=0/1 loss=0.5893096923828125\n",
      "epoch=79 iteration=0/1 loss=0.5879258513450623\n",
      "epoch=80 iteration=0/1 loss=0.5865181684494019\n",
      "epoch=81 iteration=0/1 loss=0.5850970149040222\n",
      "epoch=82 iteration=0/1 loss=0.583691418170929\n",
      "epoch=83 iteration=0/1 loss=0.5823687314987183\n",
      "epoch=84 iteration=0/1 loss=0.581175684928894\n",
      "epoch=85 iteration=0/1 loss=0.5801205635070801\n",
      "epoch=86 iteration=0/1 loss=0.5791694521903992\n",
      "epoch=87 iteration=0/1 loss=0.5782932043075562\n",
      "epoch=88 iteration=0/1 loss=0.5774667263031006\n",
      "epoch=89 iteration=0/1 loss=0.5766695141792297\n",
      "epoch=90 iteration=0/1 loss=0.5759044885635376\n",
      "epoch=91 iteration=0/1 loss=0.5751611590385437\n",
      "epoch=92 iteration=0/1 loss=0.5744431018829346\n",
      "epoch=93 iteration=0/1 loss=0.573759913444519\n",
      "epoch=94 iteration=0/1 loss=0.5731180906295776\n",
      "epoch=95 iteration=0/1 loss=0.5725212693214417\n",
      "epoch=96 iteration=0/1 loss=0.571967601776123\n",
      "epoch=97 iteration=0/1 loss=0.5714470148086548\n",
      "epoch=98 iteration=0/1 loss=0.5709564089775085\n",
      "epoch=99 iteration=0/1 loss=0.5704923272132874\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "training_data = SNLI_Dataset(df_train)\n",
    "train_dataloader = DataLoader(training_data, batch_size=16, shuffle=False)\n",
    "\n",
    "n_epochs = 100\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "\n",
    "    for i,((sent1,sent2),label) in enumerate(train_dataloader):\n",
    "        \n",
    "        output = sbert(sent1,sent2,objective=\"classification\")\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        loss = criterion(output, label)\n",
    "        \n",
    "        print(f\"epoch={epoch+1} iteration={i+1}/{len(train_dataloader)} loss={loss.detach().numpy()}\")\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # break\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>gold_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A person on a horse jumps over a broken down a...</td>\n",
       "      <td>A person is training his horse for a competition.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A person on a horse jumps over a broken down a...</td>\n",
       "      <td>A person is at a diner, ordering an omelette.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A person on a horse jumps over a broken down a...</td>\n",
       "      <td>A person is outdoors, on a horse.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Children smiling and waving at camera</td>\n",
       "      <td>They are smiling at their parents</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Children smiling and waving at camera</td>\n",
       "      <td>There are children present</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           sentence1  \\\n",
       "0  A person on a horse jumps over a broken down a...   \n",
       "1  A person on a horse jumps over a broken down a...   \n",
       "2  A person on a horse jumps over a broken down a...   \n",
       "3              Children smiling and waving at camera   \n",
       "4              Children smiling and waving at camera   \n",
       "\n",
       "                                           sentence2  gold_label  \n",
       "0  A person is training his horse for a competition.           2  \n",
       "1      A person is at a diner, ordering an omelette.           0  \n",
       "2                  A person is outdoors, on a horse.           1  \n",
       "3                  They are smiling at their parents           2  \n",
       "4                         There are children present           1  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "for idx in range(5):\n",
    "    pred = torch.argmax(sbert(df_train.iloc[idx].sentence1,df_train.iloc[idx].sentence2,\"classification\")).numpy().item()\n",
    "    true = df_train.iloc[idx]['gold_label']\n",
    "    print(pred==true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
