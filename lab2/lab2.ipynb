{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining SBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from transformers import BertModel, BertConfig, BertTokenizer\n",
    "from scipy import spatial\n",
    "\n",
    "# QUESTION: \n",
    "## SHOULD WE TRAIN FROM SCRATCH OR CAN WE START FROM bert-base-uncased or any other starting point?\n",
    "##### DONE: BertConfig() starts from random weights\n",
    "\n",
    "## TODO: Add validation set and test on testing set for SBERT classification\n",
    "##### keep the model running for a while and then test .....\n",
    "\n",
    "## TODO: After finishing training for classification, save the model please to stop training everytime <3\n",
    "##### sure.. but we can just run the model \n",
    "\n",
    "## TODO: After training on the classification data, check how to \"fine-tune\" on the STS regression data (maybe only the head without the bert itself?)\n",
    "## Check my question please <3 https://docs.google.com/document/d/1YeohuAr55fKF2nI1RiCgpq_Wa3Yn-CLAwfPoBmViNIM/edit\n",
    "\n",
    "class SBERT(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SBERT, self).__init__()\n",
    "        \n",
    "        # self.model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "        configuration = BertConfig()\n",
    "        self.model = BertModel(configuration)\n",
    "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "        \n",
    "        self.pooling = nn.AvgPool1d(kernel_size=3,stride=1)\n",
    "        # 768 / 3 -> 256\n",
    "        self.linear = nn.Linear(in_features=2298, out_features=3) # 2298=(768-2)*3; 153 is the embedding dimension after pooling and stuff..\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, sent1, sent2=None, objective=None):\n",
    "        \n",
    "        if objective==\"embedding\":\n",
    "            encoded_input1 = self.tokenizer(sent1, padding=True, truncation=True, return_tensors='pt')\n",
    "            output1 = self.model(**encoded_input1)\n",
    "            output1 = self.pooling(output1[\"pooler_output\"])\n",
    "            return output1\n",
    "\n",
    "        encoded_input2 = self.tokenizer(sent2, padding=True, truncation=True, return_tensors='pt')\n",
    "        output2 = self.model(**encoded_input2)\n",
    "        output2 = self.pooling(output2[\"pooler_output\"])\n",
    "                        \n",
    "        if objective == \"regression\":\n",
    "            return torch.cosine_similarity(output1, output2)\n",
    "\n",
    "        if objective == \"classification\":\n",
    "            diff = abs(torch.subtract(output1,output2))\n",
    "            concat = torch.cat([output1,output2,diff],axis=1)            \n",
    "            result = self.linear(concat)\n",
    "            out = self.softmax(result)\n",
    "            return out\n",
    "\n",
    "sbert = SBERT()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SBERT(\n",
       "  (model): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (pooling): AvgPool1d(kernel_size=(3,), stride=(1,), padding=(0,))\n",
       "  (linear): Linear(in_features=2298, out_features=3, bias=True)\n",
       "  (softmax): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sbert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Objective Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# False in ex1\n",
    "# True in ex2\n",
    "comparing_models = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if comparing_models: \n",
    "    PATH = \"models/classification_regression.pt\"\n",
    "    sbert = SBERT()\n",
    "    sbert.load_state_dict(torch.load(PATH))\n",
    "    sbert.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.6</td>\n",
       "      <td>A group of men play soccer on the beach.</td>\n",
       "      <td>A group of boys are playing soccer on the beach.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>One woman is measuring another woman's ankle.</td>\n",
       "      <td>A woman measures another woman's ankle.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.2</td>\n",
       "      <td>A man is cutting up a cucumber.</td>\n",
       "      <td>A man is slicing a cucumber.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.5</td>\n",
       "      <td>A man is playing a harp.</td>\n",
       "      <td>A man is playing a keyboard.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.8</td>\n",
       "      <td>A woman is cutting onions.</td>\n",
       "      <td>A woman is cutting tofu.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   score                                      sentence1  \\\n",
       "0    3.6       A group of men play soccer on the beach.   \n",
       "1    5.0  One woman is measuring another woman's ankle.   \n",
       "2    4.2                A man is cutting up a cucumber.   \n",
       "3    1.5                       A man is playing a harp.   \n",
       "4    1.8                     A woman is cutting onions.   \n",
       "\n",
       "                                          sentence2  \n",
       "0  A group of boys are playing soccer on the beach.  \n",
       "1           A woman measures another woman's ankle.  \n",
       "2                      A man is slicing a cucumber.  \n",
       "3                      A man is playing a keyboard.  \n",
       "4                          A woman is cutting tofu.  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_test = pd.read_csv(\"Stsbenchmark/sts-test.csv\",header=0,names=[\"main-caption\",\"genre\",\"filename\",\"year\",\"score\",\"sentence1\",\"sentence2\"])#,usecols=['score','sentence1','sentence2'])\n",
    "\n",
    "df_test = df_test[['score','sentence1','sentence2']]\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 5.0)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ls = list(df_test.score)\n",
    "minn = min(ls)\n",
    "maxx = max(ls)\n",
    "(minn,maxx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_score(value, leftMin=0, leftMax=5, rightMin=-1, rightMax=1):\n",
    "    # Figure out how 'wide' each range is\n",
    "    leftSpan = leftMax - leftMin\n",
    "    rightSpan = rightMax - rightMin\n",
    "\n",
    "    # Convert the left range into a 0-1 range (float)\n",
    "    valueScaled = float(value - leftMin) / float(leftSpan)\n",
    "\n",
    "    # Convert the 0-1 range into a value in the right range.\n",
    "    return rightMin + (valueScaled * rightSpan)\n",
    "\n",
    "df_test['score'] = df_test['score'].apply(map_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-1.0, 1.0)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ls = list(df_test.score)\n",
    "minn = min(ls)\n",
    "maxx = max(ls)\n",
    "(minn,maxx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "score        0\n",
       "sentence1    0\n",
       "sentence2    5\n",
       "dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "score        0\n",
       "sentence1    0\n",
       "sentence2    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset,DataLoader\n",
    "\n",
    "class STS_Dataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        sent1 = row['sentence1']\n",
    "        sent2 = row['sentence2']\n",
    "        label = row['score']\n",
    "        return (sent1, sent2), label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0 mse_loss=0.3016123210005845\n",
      "iteration 1 mse_loss=0.00011680365134125736\n",
      "iteration 2 mse_loss=0.09559995642233725\n",
      "iteration 3 mse_loss=1.9298555970244489\n",
      "iteration 4 mse_loss=1.6108494147353256\n",
      "iteration 5 mse_loss=0.347147715096959\n",
      "iteration 6 mse_loss=1.2303078383498274\n",
      "iteration 7 mse_loss=1.2303078383498274\n",
      "iteration 8 mse_loss=1.6993532136582077\n",
      "iteration 9 mse_loss=1.6993532136582077\n",
      "iteration 10 mse_loss=0.00011680365134125736\n",
      "iteration 11 mse_loss=3.05967414389182\n",
      "iteration 12 mse_loss=0.052529168229588225\n",
      "iteration 13 mse_loss=1.4141786265425764\n",
      "iteration 14 mse_loss=1.6108494147353256\n",
      "iteration 15 mse_loss=0.052529168229588225\n",
      "iteration 16 mse_loss=0.3016123210005845\n",
      "iteration 17 mse_loss=0.3016123210005845\n",
      "iteration 18 mse_loss=2.277661779313573\n",
      "iteration 19 mse_loss=1.0592370501570787\n",
      "iteration 20 mse_loss=3.6450157202773177\n",
      "iteration 21 mse_loss=0.09559995642233725\n",
      "iteration 22 mse_loss=0.052529168229588225\n",
      "iteration 23 mse_loss=1.1863401413016406\n",
      "iteration 24 mse_loss=1.4141786265425764\n",
      "iteration 25 mse_loss=2.8533710527472578\n",
      "iteration 26 mse_loss=1.2303078383498274\n",
      "iteration 27 mse_loss=2.7862033556990706\n",
      "iteration 28 mse_loss=1.2303078383498274\n",
      "iteration 29 mse_loss=0.5029538973860824\n",
      "iteration 30 mse_loss=0.004787591844090291\n",
      "iteration 31 mse_loss=2.0425909911208233\n",
      "iteration 32 mse_loss=0.08363225937415011\n",
      "iteration 33 mse_loss=0.3958831091933336\n",
      "iteration 34 mse_loss=3.1541490979363904\n",
      "iteration 35 mse_loss=3.3459449320845684\n",
      "iteration 36 mse_loss=2.277661779313573\n",
      "iteration 37 mse_loss=0.00011680365134125736\n",
      "iteration 38 mse_loss=3.1470491282315725\n",
      "iteration 39 mse_loss=0.23930922985602265\n",
      "iteration 40 mse_loss=0.6228246855788315\n",
      "iteration 41 mse_loss=0.3016123210005845\n",
      "iteration 42 mse_loss=3.2012095379881944\n",
      "iteration 43 mse_loss=1.9298555970244489\n",
      "iteration 44 mse_loss=2.7862033556990706\n",
      "iteration 45 mse_loss=2.7862033556990706\n",
      "iteration 46 mse_loss=3.05967414389182\n",
      "iteration 47 mse_loss=0.052529168229588225\n",
      "iteration 48 mse_loss=1.662017111783513\n",
      "iteration 49 mse_loss=3.3459449320845684\n",
      "iteration 50 mse_loss=2.0425909911208233\n",
      "iteration 51 mse_loss=3.3459449320845684\n",
      "iteration 52 mse_loss=2.7862033556990706\n",
      "iteration 53 mse_loss=1.4141786265425764\n",
      "iteration 54 mse_loss=3.748066674321889\n",
      "iteration 55 mse_loss=0.1514707446150863\n",
      "iteration 56 mse_loss=3.543401246232747\n",
      "iteration 57 mse_loss=0.3958831091933336\n",
      "iteration 58 mse_loss=2.277661779313573\n",
      "iteration 59 mse_loss=0.00011680365134125736\n",
      "iteration 60 mse_loss=3.956886508470067\n",
      "iteration 61 mse_loss=0.22014153280783538\n",
      "iteration 62 mse_loss=2.8533710527472578\n",
      "iteration 63 mse_loss=0.3958831091933336\n",
      "iteration 64 mse_loss=3.956886508470067\n",
      "iteration 65 mse_loss=3.6450157202773177\n",
      "iteration 66 mse_loss=0.1514707446150863\n",
      "iteration 67 mse_loss=3.2012095379881944\n",
      "iteration 68 mse_loss=0.22014153280783538\n",
      "iteration 69 mse_loss=1.0592370501570787\n",
      "iteration 70 mse_loss=0.007955288892277552\n",
      "iteration 71 mse_loss=3.956886508470067\n",
      "iteration 72 mse_loss=0.23930922985602265\n",
      "iteration 73 mse_loss=0.9009662619643295\n",
      "iteration 74 mse_loss=3.956886508470067\n",
      "iteration 75 mse_loss=2.8533710527472578\n",
      "iteration 76 mse_loss=3.956886508470067\n",
      "iteration 77 mse_loss=0.22014153280783538\n",
      "iteration 78 mse_loss=0.7554954737715807\n",
      "iteration 79 mse_loss=3.956886508470067\n",
      "iteration 80 mse_loss=2.7862033556990706\n",
      "iteration 81 mse_loss=0.6228246855788315\n",
      "iteration 82 mse_loss=2.525532567506322\n",
      "iteration 83 mse_loss=3.956886508470067\n",
      "iteration 84 mse_loss=2.525532567506322\n",
      "iteration 85 mse_loss=0.3958831091933336\n",
      "iteration 86 mse_loss=0.00011680365134125736\n",
      "iteration 87 mse_loss=1.1151200042016494\n",
      "iteration 88 mse_loss=2.0425909911208233\n",
      "iteration 89 mse_loss=2.8533710527472578\n",
      "iteration 90 mse_loss=0.3294673053403366\n",
      "iteration 91 mse_loss=2.7862033556990706\n",
      "iteration 92 mse_loss=0.347147715096959\n",
      "iteration 93 mse_loss=1.4141786265425764\n",
      "iteration 94 mse_loss=0.007955288892277552\n",
      "iteration 95 mse_loss=0.1514707446150863\n",
      "iteration 96 mse_loss=0.0357937741332138\n",
      "iteration 97 mse_loss=1.9298555970244489\n",
      "iteration 98 mse_loss=1.0592370501570787\n",
      "iteration 99 mse_loss=3.956886508470067\n",
      "iteration 100 mse_loss=3.3459449320845684\n",
      "iteration 101 mse_loss=0.978501656060704\n",
      "iteration 102 mse_loss=0.9009662619643295\n",
      "iteration 103 mse_loss=0.3016123210005845\n",
      "iteration 104 mse_loss=0.6228246855788315\n",
      "iteration 105 mse_loss=3.956886508470067\n",
      "iteration 106 mse_loss=1.8203202029280743\n",
      "iteration 107 mse_loss=2.2176940822653854\n",
      "iteration 108 mse_loss=0.3016123210005845\n",
      "iteration 109 mse_loss=1.4141786265425764\n",
      "iteration 110 mse_loss=0.3016123210005845\n",
      "iteration 111 mse_loss=0.7554954737715807\n",
      "iteration 112 mse_loss=0.052529168229588225\n",
      "iteration 113 mse_loss=3.956886508470067\n",
      "iteration 114 mse_loss=3.956886508470067\n",
      "iteration 115 mse_loss=0.23930922985602265\n",
      "iteration 116 mse_loss=0.978501656060704\n",
      "iteration 117 mse_loss=3.956886508470067\n",
      "iteration 118 mse_loss=2.7862033556990706\n",
      "iteration 119 mse_loss=2.525532567506322\n",
      "iteration 120 mse_loss=3.956886508470067\n",
      "iteration 121 mse_loss=3.56904802322913\n",
      "iteration 122 mse_loss=3.3459449320845684\n",
      "iteration 123 mse_loss=3.956886508470067\n",
      "iteration 124 mse_loss=0.00011680365134125736\n",
      "iteration 125 mse_loss=3.493880326180943\n",
      "iteration 126 mse_loss=0.7906631708197676\n",
      "iteration 127 mse_loss=0.00011680365134125736\n",
      "iteration 128 mse_loss=0.08363225937415011\n",
      "iteration 129 mse_loss=0.3958831091933336\n",
      "iteration 130 mse_loss=1.8203202029280743\n",
      "iteration 131 mse_loss=0.9009662619643295\n",
      "iteration 132 mse_loss=0.00011680365134125736\n",
      "iteration 133 mse_loss=0.5029538973860824\n",
      "iteration 134 mse_loss=0.004787591844090291\n",
      "iteration 135 mse_loss=0.00011680365134125736\n",
      "iteration 136 mse_loss=1.0592370501570787\n",
      "iteration 137 mse_loss=1.4141786265425764\n",
      "iteration 138 mse_loss=0.00011680365134125736\n",
      "iteration 139 mse_loss=0.00011680365134125736\n",
      "iteration 140 mse_loss=0.3958831091933336\n",
      "iteration 141 mse_loss=0.0357937741332138\n",
      "iteration 142 mse_loss=0.09559995642233725\n",
      "iteration 143 mse_loss=1.2303078383498274\n",
      "iteration 144 mse_loss=1.0592370501570787\n",
      "iteration 145 mse_loss=0.22014153280783538\n",
      "iteration 146 mse_loss=0.978501656060704\n",
      "iteration 147 mse_loss=1.4141786265425764\n",
      "iteration 148 mse_loss=2.8533710527472578\n",
      "iteration 149 mse_loss=1.4141786265425764\n",
      "iteration 150 mse_loss=1.2303078383498274\n",
      "iteration 151 mse_loss=0.1514707446150863\n",
      "iteration 152 mse_loss=0.5029538973860824\n",
      "iteration 153 mse_loss=0.22014153280783538\n",
      "iteration 154 mse_loss=0.23930922985602265\n",
      "iteration 155 mse_loss=3.2012095379881944\n",
      "iteration 156 mse_loss=2.7862033556990706\n",
      "iteration 157 mse_loss=0.00011680365134125736\n",
      "iteration 158 mse_loss=2.277661779313573\n",
      "iteration 159 mse_loss=0.00011680365134125736\n",
      "iteration 160 mse_loss=0.7554954737715807\n",
      "iteration 161 mse_loss=2.277661779313573\n",
      "iteration 162 mse_loss=0.5029538973860824\n",
      "iteration 163 mse_loss=0.022258380036839345\n",
      "iteration 164 mse_loss=0.1514707446150863\n",
      "iteration 165 mse_loss=0.22014153280783538\n",
      "iteration 166 mse_loss=0.3958831091933336\n",
      "iteration 167 mse_loss=0.022258380036839345\n",
      "iteration 168 mse_loss=0.9009662619643295\n",
      "iteration 169 mse_loss=1.6108494147353256\n",
      "iteration 170 mse_loss=2.8533710527472578\n",
      "iteration 171 mse_loss=0.1514707446150863\n",
      "iteration 172 mse_loss=0.7906631708197676\n",
      "iteration 173 mse_loss=0.22014153280783538\n",
      "iteration 174 mse_loss=0.9009662619643295\n",
      "iteration 175 mse_loss=1.4141786265425764\n",
      "iteration 176 mse_loss=0.22014153280783538\n",
      "iteration 177 mse_loss=3.0835094008882034\n",
      "iteration 178 mse_loss=3.3459449320845684\n",
      "iteration 179 mse_loss=3.56904802322913\n",
      "iteration 180 mse_loss=0.7554954737715807\n",
      "iteration 181 mse_loss=0.5029538973860824\n",
      "iteration 182 mse_loss=3.2012095379881944\n",
      "iteration 183 mse_loss=1.1863401413016406\n",
      "iteration 184 mse_loss=3.956886508470067\n",
      "iteration 185 mse_loss=3.956886508470067\n",
      "iteration 186 mse_loss=3.4819277346532336\n",
      "iteration 187 mse_loss=2.8533710527472578\n",
      "iteration 188 mse_loss=3.3459449320845684\n",
      "iteration 189 mse_loss=0.09559995642233725\n",
      "iteration 190 mse_loss=0.23930922985602265\n",
      "iteration 191 mse_loss=1.8203202029280743\n",
      "iteration 192 mse_loss=0.6228246855788315\n",
      "iteration 193 mse_loss=0.1514707446150863\n",
      "iteration 194 mse_loss=0.6228246855788315\n",
      "iteration 195 mse_loss=0.23930922985602265\n",
      "iteration 196 mse_loss=3.3459449320845684\n",
      "iteration 197 mse_loss=3.956886508470067\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 198 mse_loss=0.6228246855788315\n",
      "iteration 199 mse_loss=3.3459449320845684\n",
      "iteration 200 mse_loss=3.3459449320845684\n",
      "iteration 201 mse_loss=3.56904802322913\n",
      "iteration 202 mse_loss=3.56904802322913\n",
      "iteration 203 mse_loss=3.3459449320845684\n",
      "iteration 204 mse_loss=3.3459449320845684\n",
      "iteration 205 mse_loss=0.5029538973860824\n",
      "iteration 206 mse_loss=3.956886508470067\n",
      "iteration 207 mse_loss=1.2303078383498274\n",
      "iteration 208 mse_loss=2.7862033556990706\n",
      "iteration 209 mse_loss=2.7862033556990706\n",
      "iteration 210 mse_loss=3.493880326180943\n",
      "iteration 211 mse_loss=3.956886508470067\n",
      "iteration 212 mse_loss=2.8533710527472578\n",
      "iteration 213 mse_loss=1.1151200042016494\n",
      "iteration 214 mse_loss=2.1199139451653943\n",
      "iteration 215 mse_loss=2.277661779313573\n",
      "iteration 216 mse_loss=0.09559995642233725\n",
      "iteration 217 mse_loss=0.22014153280783538\n",
      "iteration 218 mse_loss=0.6228246855788315\n",
      "iteration 219 mse_loss=3.2012095379881944\n",
      "iteration 220 mse_loss=3.956886508470067\n",
      "iteration 221 mse_loss=3.4447078861291396\n",
      "iteration 222 mse_loss=1.9298555970244489\n",
      "iteration 223 mse_loss=3.6955926403291217\n",
      "iteration 224 mse_loss=3.2012095379881944\n",
      "iteration 225 mse_loss=2.2176940822653854\n",
      "iteration 226 mse_loss=1.8203202029280743\n",
      "iteration 227 mse_loss=3.956886508470067\n",
      "iteration 228 mse_loss=2.525532567506322\n",
      "iteration 229 mse_loss=3.956886508470067\n",
      "iteration 230 mse_loss=3.956886508470067\n",
      "iteration 231 mse_loss=0.1514707446150863\n",
      "iteration 232 mse_loss=0.7906631708197676\n",
      "iteration 233 mse_loss=0.4303260632379042\n",
      "iteration 234 mse_loss=0.347147715096959\n",
      "iteration 235 mse_loss=3.663367007568882\n",
      "iteration 236 mse_loss=3.956886508470067\n",
      "iteration 237 mse_loss=3.56904802322913\n",
      "iteration 238 mse_loss=3.3988330339592636\n",
      "iteration 239 mse_loss=0.5029538973860824\n",
      "iteration 240 mse_loss=3.956886508470067\n",
      "iteration 241 mse_loss=3.956886508470067\n",
      "iteration 242 mse_loss=3.956886508470067\n",
      "iteration 243 mse_loss=1.662017111783513\n",
      "iteration 244 mse_loss=3.956886508470067\n",
      "iteration 245 mse_loss=0.7906631708197676\n",
      "iteration 246 mse_loss=1.6108494147353256\n",
      "iteration 247 mse_loss=3.956886508470067\n",
      "iteration 248 mse_loss=3.956886508470067\n",
      "iteration 249 mse_loss=0.7554954737715807\n",
      "iteration 250 mse_loss=0.052529168229588225\n",
      "iteration 251 mse_loss=0.1514707446150863\n",
      "iteration 252 mse_loss=0.9009662619643295\n",
      "iteration 253 mse_loss=2.277661779313573\n",
      "iteration 254 mse_loss=0.5029538973860824\n",
      "iteration 255 mse_loss=2.7862033556990706\n",
      "iteration 256 mse_loss=0.3958831091933336\n",
      "iteration 257 mse_loss=1.4141786265425764\n",
      "iteration 258 mse_loss=3.956886508470067\n",
      "iteration 259 mse_loss=0.022258380036839345\n",
      "iteration 260 mse_loss=0.1514707446150863\n",
      "iteration 261 mse_loss=0.22014153280783538\n",
      "iteration 262 mse_loss=0.1514707446150863\n",
      "iteration 263 mse_loss=0.7554954737715807\n",
      "iteration 264 mse_loss=0.3016123210005845\n",
      "iteration 265 mse_loss=1.6108494147353256\n",
      "iteration 266 mse_loss=0.3016123210005845\n",
      "iteration 267 mse_loss=2.277661779313573\n",
      "iteration 268 mse_loss=0.00011680365134125736\n",
      "iteration 269 mse_loss=0.1514707446150863\n",
      "iteration 270 mse_loss=3.956886508470067\n",
      "iteration 271 mse_loss=0.3958831091933336\n",
      "iteration 272 mse_loss=0.052529168229588225\n",
      "iteration 273 mse_loss=0.09559995642233725\n",
      "iteration 274 mse_loss=0.00011680365134125736\n",
      "iteration 275 mse_loss=3.6450157202773177\n",
      "iteration 276 mse_loss=3.6450157202773177\n",
      "iteration 277 mse_loss=0.1514707446150863\n",
      "iteration 278 mse_loss=0.9009662619643295\n",
      "iteration 279 mse_loss=3.05967414389182\n",
      "iteration 280 mse_loss=2.277661779313573\n",
      "iteration 281 mse_loss=0.22014153280783538\n",
      "iteration 282 mse_loss=0.09559995642233725\n",
      "iteration 283 mse_loss=0.7554954737715807\n",
      "iteration 284 mse_loss=0.09559995642233725\n",
      "iteration 285 mse_loss=1.0592370501570787\n",
      "iteration 286 mse_loss=0.3016123210005845\n",
      "iteration 287 mse_loss=0.22014153280783538\n",
      "iteration 288 mse_loss=3.05967414389182\n",
      "iteration 289 mse_loss=0.004787591844090291\n",
      "iteration 290 mse_loss=2.277661779313573\n",
      "iteration 291 mse_loss=1.0592370501570787\n",
      "iteration 292 mse_loss=0.09559995642233725\n",
      "iteration 293 mse_loss=3.956886508470067\n",
      "iteration 294 mse_loss=3.6450157202773177\n",
      "iteration 295 mse_loss=0.3958831091933336\n",
      "iteration 296 mse_loss=0.6228246855788315\n",
      "iteration 297 mse_loss=0.5029538973860824\n",
      "iteration 298 mse_loss=0.6228246855788315\n",
      "iteration 299 mse_loss=0.052529168229588225\n",
      "iteration 300 mse_loss=1.6108494147353256\n",
      "iteration 301 mse_loss=1.4141786265425764\n",
      "iteration 302 mse_loss=0.004787591844090291\n",
      "iteration 303 mse_loss=0.1514707446150863\n",
      "iteration 304 mse_loss=1.2303078383498274\n",
      "iteration 305 mse_loss=0.09559995642233725\n",
      "iteration 306 mse_loss=0.3958831091933336\n",
      "iteration 307 mse_loss=0.09559995642233725\n",
      "iteration 308 mse_loss=0.3958831091933336\n",
      "iteration 309 mse_loss=1.0592370501570787\n",
      "iteration 310 mse_loss=2.525532567506322\n",
      "iteration 311 mse_loss=1.8203202029280743\n",
      "iteration 312 mse_loss=0.5029538973860824\n",
      "iteration 313 mse_loss=0.3958831091933336\n",
      "iteration 314 mse_loss=0.1514707446150863\n",
      "iteration 315 mse_loss=0.6228246855788315\n",
      "iteration 316 mse_loss=0.22014153280783538\n",
      "iteration 317 mse_loss=3.956886508470067\n",
      "iteration 318 mse_loss=3.956886508470067\n",
      "iteration 319 mse_loss=0.9009662619643295\n",
      "iteration 320 mse_loss=0.9009662619643295\n",
      "iteration 321 mse_loss=0.22014153280783538\n",
      "iteration 322 mse_loss=0.9009662619643295\n",
      "iteration 323 mse_loss=0.7554954737715807\n",
      "iteration 324 mse_loss=3.956886508470067\n",
      "iteration 325 mse_loss=0.9009662619643295\n",
      "iteration 326 mse_loss=0.022258380036839345\n",
      "iteration 327 mse_loss=0.22014153280783538\n",
      "iteration 328 mse_loss=0.3958831091933336\n",
      "iteration 329 mse_loss=0.00011680365134125736\n",
      "iteration 330 mse_loss=0.022258380036839345\n",
      "iteration 331 mse_loss=0.6228246855788315\n",
      "iteration 332 mse_loss=1.2303078383498274\n",
      "iteration 333 mse_loss=0.22014153280783538\n",
      "iteration 334 mse_loss=1.2303078383498274\n",
      "iteration 335 mse_loss=0.3016123210005845\n",
      "iteration 336 mse_loss=0.1514707446150863\n",
      "iteration 337 mse_loss=3.3459449320845684\n",
      "iteration 338 mse_loss=3.956886508470067\n",
      "iteration 339 mse_loss=0.22014153280783538\n",
      "iteration 340 mse_loss=0.00011680365134125736\n",
      "iteration 341 mse_loss=0.004787591844090291\n",
      "iteration 342 mse_loss=1.0592370501570787\n",
      "iteration 343 mse_loss=0.7554954737715807\n",
      "iteration 344 mse_loss=2.0425909911208233\n",
      "iteration 345 mse_loss=0.3016123210005845\n",
      "iteration 346 mse_loss=3.956886508470067\n",
      "iteration 347 mse_loss=0.09559995642233725\n",
      "iteration 348 mse_loss=3.3459449320845684\n",
      "iteration 349 mse_loss=0.22014153280783538\n",
      "iteration 350 mse_loss=0.1514707446150863\n",
      "iteration 351 mse_loss=2.277661779313573\n",
      "iteration 352 mse_loss=0.1514707446150863\n",
      "iteration 353 mse_loss=0.6228246855788315\n",
      "iteration 354 mse_loss=3.956886508470067\n",
      "iteration 355 mse_loss=1.0592370501570787\n",
      "iteration 356 mse_loss=0.3958831091933336\n",
      "iteration 357 mse_loss=2.7862033556990706\n",
      "iteration 358 mse_loss=0.09559995642233725\n",
      "iteration 359 mse_loss=0.052529168229588225\n",
      "iteration 360 mse_loss=0.1514707446150863\n",
      "iteration 361 mse_loss=1.6108494147353256\n",
      "iteration 362 mse_loss=0.7554954737715807\n",
      "iteration 363 mse_loss=0.00011680365134125736\n",
      "iteration 364 mse_loss=3.956886508470067\n",
      "iteration 365 mse_loss=3.6450157202773177\n",
      "iteration 366 mse_loss=0.1514707446150863\n",
      "iteration 367 mse_loss=0.22014153280783538\n",
      "iteration 368 mse_loss=0.052529168229588225\n",
      "iteration 369 mse_loss=0.5029538973860824\n",
      "iteration 370 mse_loss=0.022258380036839345\n",
      "iteration 371 mse_loss=3.956886508470067\n",
      "iteration 372 mse_loss=2.525532567506322\n",
      "iteration 373 mse_loss=2.7862033556990706\n",
      "iteration 374 mse_loss=0.1514707446150863\n",
      "iteration 375 mse_loss=1.8203202029280743\n",
      "iteration 376 mse_loss=3.956886508470067\n",
      "iteration 377 mse_loss=0.3958831091933336\n",
      "iteration 378 mse_loss=2.525532567506322\n",
      "iteration 379 mse_loss=0.1514707446150863\n",
      "iteration 380 mse_loss=0.6228246855788315\n",
      "iteration 381 mse_loss=0.6228246855788315\n",
      "iteration 382 mse_loss=2.8533710527472578\n",
      "iteration 383 mse_loss=0.3958831091933336\n",
      "iteration 384 mse_loss=0.7554954737715807\n",
      "iteration 385 mse_loss=0.004787591844090291\n",
      "iteration 386 mse_loss=2.0425909911208233\n",
      "iteration 387 mse_loss=1.0592370501570787\n",
      "iteration 388 mse_loss=1.6108494147353256\n",
      "iteration 389 mse_loss=0.004787591844090291\n",
      "iteration 390 mse_loss=2.0425909911208233\n",
      "iteration 391 mse_loss=3.3459449320845684\n",
      "iteration 392 mse_loss=2.123409766988286\n",
      "iteration 393 mse_loss=1.0592370501570787\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 394 mse_loss=3.3459449320845684\n",
      "iteration 395 mse_loss=3.05967414389182\n",
      "iteration 396 mse_loss=0.004787591844090291\n",
      "iteration 397 mse_loss=0.7554954737715807\n",
      "iteration 398 mse_loss=1.4141786265425764\n",
      "iteration 399 mse_loss=0.9009662619643295\n",
      "iteration 400 mse_loss=3.956886508470067\n",
      "iteration 401 mse_loss=1.0592370501570787\n",
      "iteration 402 mse_loss=0.1514707446150863\n",
      "iteration 403 mse_loss=0.1514707446150863\n",
      "iteration 404 mse_loss=0.1514707446150863\n",
      "iteration 405 mse_loss=3.956886508470067\n",
      "iteration 406 mse_loss=0.5029538973860824\n",
      "iteration 407 mse_loss=2.0425909911208233\n",
      "iteration 408 mse_loss=0.3016123210005845\n",
      "iteration 409 mse_loss=0.052529168229588225\n",
      "iteration 410 mse_loss=0.00011680365134125736\n",
      "iteration 411 mse_loss=1.6108494147353256\n",
      "iteration 412 mse_loss=0.004787591844090291\n",
      "iteration 413 mse_loss=3.05967414389182\n",
      "iteration 414 mse_loss=2.0425909911208233\n",
      "iteration 415 mse_loss=3.6450157202773177\n",
      "iteration 416 mse_loss=0.09559995642233725\n",
      "iteration 417 mse_loss=0.022258380036839345\n",
      "iteration 418 mse_loss=0.1514707446150863\n",
      "iteration 419 mse_loss=0.022258380036839345\n",
      "iteration 420 mse_loss=1.6108494147353256\n",
      "iteration 421 mse_loss=0.022258380036839345\n",
      "iteration 422 mse_loss=3.6450157202773177\n",
      "iteration 423 mse_loss=0.9009662619643295\n",
      "iteration 424 mse_loss=0.22014153280783538\n",
      "iteration 425 mse_loss=3.956886508470067\n",
      "iteration 426 mse_loss=0.00011680365134125736\n",
      "iteration 427 mse_loss=0.3016123210005845\n",
      "iteration 428 mse_loss=0.022258380036839345\n",
      "iteration 429 mse_loss=1.4141786265425764\n",
      "iteration 430 mse_loss=0.00011680365134125736\n",
      "iteration 431 mse_loss=3.956886508470067\n",
      "iteration 432 mse_loss=0.3958831091933336\n",
      "iteration 433 mse_loss=3.956886508470067\n",
      "iteration 434 mse_loss=1.4141786265425764\n",
      "iteration 435 mse_loss=1.4141786265425764\n",
      "iteration 436 mse_loss=0.022258380036839345\n",
      "iteration 437 mse_loss=0.6228246855788315\n",
      "iteration 438 mse_loss=0.022258380036839345\n",
      "iteration 439 mse_loss=1.4141786265425764\n",
      "iteration 440 mse_loss=0.9009662619643295\n",
      "iteration 441 mse_loss=3.3459449320845684\n",
      "iteration 442 mse_loss=0.9009662619643295\n",
      "iteration 443 mse_loss=0.09559995642233725\n",
      "iteration 444 mse_loss=3.956886508470067\n",
      "iteration 445 mse_loss=1.2303078383498274\n",
      "iteration 446 mse_loss=0.1514707446150863\n",
      "iteration 447 mse_loss=3.956886508470067\n",
      "iteration 448 mse_loss=1.4141786265425764\n",
      "iteration 449 mse_loss=0.6228246855788315\n",
      "iteration 450 mse_loss=0.9009662619643295\n",
      "iteration 451 mse_loss=3.956886508470067\n",
      "iteration 452 mse_loss=3.956886508470067\n",
      "iteration 453 mse_loss=0.004787591844090291\n",
      "iteration 454 mse_loss=0.6228246855788315\n",
      "iteration 455 mse_loss=1.2303078383498274\n",
      "iteration 456 mse_loss=0.052529168229588225\n",
      "iteration 457 mse_loss=2.7862033556990706\n",
      "iteration 458 mse_loss=0.3958831091933336\n",
      "iteration 459 mse_loss=3.956886508470067\n",
      "iteration 460 mse_loss=3.05967414389182\n",
      "iteration 461 mse_loss=3.956886508470067\n",
      "iteration 462 mse_loss=1.0592370501570787\n",
      "iteration 463 mse_loss=0.3958831091933336\n",
      "iteration 464 mse_loss=0.1514707446150863\n",
      "iteration 465 mse_loss=1.4141786265425764\n",
      "iteration 466 mse_loss=0.1514707446150863\n",
      "iteration 467 mse_loss=0.004787591844090291\n",
      "iteration 468 mse_loss=3.05967414389182\n",
      "iteration 469 mse_loss=1.0592370501570787\n",
      "iteration 470 mse_loss=0.052529168229588225\n",
      "iteration 471 mse_loss=1.0592370501570787\n",
      "iteration 472 mse_loss=0.004787591844090291\n",
      "iteration 473 mse_loss=0.3958831091933336\n",
      "iteration 474 mse_loss=0.7554954737715807\n",
      "iteration 475 mse_loss=2.7862033556990706\n",
      "iteration 476 mse_loss=1.2303078383498274\n",
      "iteration 477 mse_loss=0.22014153280783538\n",
      "iteration 478 mse_loss=3.3459449320845684\n",
      "iteration 479 mse_loss=0.022258380036839345\n",
      "iteration 480 mse_loss=0.6228246855788315\n",
      "iteration 481 mse_loss=0.022258380036839345\n",
      "iteration 482 mse_loss=2.7862033556990706\n",
      "iteration 483 mse_loss=0.1514707446150863\n",
      "iteration 484 mse_loss=2.277661779313573\n",
      "iteration 485 mse_loss=0.5029538973860824\n",
      "iteration 486 mse_loss=0.3016123210005845\n",
      "iteration 487 mse_loss=0.3958831091933336\n",
      "iteration 488 mse_loss=0.00011680365134125736\n",
      "iteration 489 mse_loss=0.1514707446150863\n",
      "iteration 490 mse_loss=0.1514707446150863\n",
      "iteration 491 mse_loss=0.7554954737715807\n",
      "iteration 492 mse_loss=0.22014153280783538\n",
      "iteration 493 mse_loss=0.9009662619643295\n",
      "iteration 494 mse_loss=1.4141786265425764\n",
      "iteration 495 mse_loss=2.7862033556990706\n",
      "iteration 496 mse_loss=0.00011680365134125736\n",
      "iteration 497 mse_loss=2.525532567506322\n",
      "iteration 498 mse_loss=0.00011680365134125736\n",
      "iteration 499 mse_loss=1.0592370501570787\n",
      "iteration 500 mse_loss=1.4141786265425764\n",
      "iteration 501 mse_loss=1.2303078383498274\n",
      "iteration 502 mse_loss=0.3958831091933336\n",
      "iteration 503 mse_loss=2.7862033556990706\n",
      "iteration 504 mse_loss=0.022258380036839345\n",
      "iteration 505 mse_loss=0.7554954737715807\n",
      "iteration 506 mse_loss=1.4141786265425764\n",
      "iteration 507 mse_loss=0.9009662619643295\n",
      "iteration 508 mse_loss=3.6450157202773177\n",
      "iteration 509 mse_loss=2.0425909911208233\n",
      "iteration 510 mse_loss=1.8203202029280743\n",
      "iteration 511 mse_loss=0.5029538973860824\n",
      "iteration 512 mse_loss=3.6450157202773177\n",
      "iteration 513 mse_loss=1.0592370501570787\n",
      "iteration 514 mse_loss=3.6450157202773177\n",
      "iteration 515 mse_loss=2.0425909911208233\n",
      "iteration 516 mse_loss=1.6108494147353256\n",
      "iteration 517 mse_loss=1.8203202029280743\n",
      "iteration 518 mse_loss=0.22014153280783538\n",
      "iteration 519 mse_loss=2.525532567506322\n",
      "iteration 520 mse_loss=2.277661779313573\n",
      "iteration 521 mse_loss=0.1514707446150863\n",
      "iteration 522 mse_loss=1.4141786265425764\n",
      "iteration 523 mse_loss=0.9009662619643295\n",
      "iteration 524 mse_loss=0.22014153280783538\n",
      "iteration 525 mse_loss=0.9009662619643295\n",
      "iteration 526 mse_loss=3.6450157202773177\n",
      "iteration 527 mse_loss=0.6228246855788315\n",
      "iteration 528 mse_loss=1.6108494147353256\n",
      "iteration 529 mse_loss=3.05967414389182\n",
      "iteration 530 mse_loss=3.05967414389182\n",
      "iteration 531 mse_loss=3.6450157202773177\n",
      "iteration 532 mse_loss=3.05967414389182\n",
      "iteration 533 mse_loss=3.6450157202773177\n",
      "iteration 534 mse_loss=2.525532567506322\n",
      "iteration 535 mse_loss=0.3958831091933336\n",
      "iteration 536 mse_loss=2.0425909911208233\n",
      "iteration 537 mse_loss=1.4141786265425764\n",
      "iteration 538 mse_loss=0.7554954737715807\n",
      "iteration 539 mse_loss=0.5029538973860824\n",
      "iteration 540 mse_loss=2.7862033556990706\n",
      "iteration 541 mse_loss=1.6108494147353256\n",
      "iteration 542 mse_loss=1.2303078383498274\n",
      "iteration 543 mse_loss=0.09559995642233725\n",
      "iteration 544 mse_loss=0.00011680365134125736\n",
      "iteration 545 mse_loss=2.277661779313573\n",
      "iteration 546 mse_loss=0.7554954737715807\n",
      "iteration 547 mse_loss=0.052529168229588225\n",
      "iteration 548 mse_loss=0.052529168229588225\n",
      "iteration 549 mse_loss=0.3016123210005845\n",
      "iteration 550 mse_loss=2.277661779313573\n",
      "iteration 551 mse_loss=2.0425909911208233\n",
      "iteration 552 mse_loss=0.3958831091933336\n",
      "iteration 553 mse_loss=2.7862033556990706\n",
      "iteration 554 mse_loss=0.7554954737715807\n",
      "iteration 555 mse_loss=0.5029538973860824\n",
      "iteration 556 mse_loss=1.8203202029280743\n",
      "iteration 557 mse_loss=0.00011680365134125736\n",
      "iteration 558 mse_loss=0.3016123210005845\n",
      "iteration 559 mse_loss=0.3016123210005845\n",
      "iteration 560 mse_loss=3.3459449320845684\n",
      "iteration 561 mse_loss=1.6108494147353256\n",
      "iteration 562 mse_loss=2.277661779313573\n",
      "iteration 563 mse_loss=2.277661779313573\n",
      "iteration 564 mse_loss=1.2303078383498274\n",
      "iteration 565 mse_loss=0.00011680365134125736\n",
      "iteration 566 mse_loss=0.9009662619643295\n",
      "iteration 567 mse_loss=3.956886508470067\n",
      "iteration 568 mse_loss=0.7554954737715807\n",
      "iteration 569 mse_loss=0.5029538973860824\n",
      "iteration 570 mse_loss=1.8203202029280743\n",
      "iteration 571 mse_loss=3.6450157202773177\n",
      "iteration 572 mse_loss=0.22014153280783538\n",
      "iteration 573 mse_loss=0.1514707446150863\n",
      "iteration 574 mse_loss=0.7554954737715807\n",
      "iteration 575 mse_loss=0.00011680365134125736\n",
      "iteration 576 mse_loss=0.3958831091933336\n",
      "iteration 577 mse_loss=0.7554954737715807\n",
      "iteration 578 mse_loss=2.0425909911208233\n",
      "iteration 579 mse_loss=2.277661779313573\n",
      "iteration 580 mse_loss=0.5029538973860824\n",
      "iteration 581 mse_loss=0.6228246855788315\n",
      "iteration 582 mse_loss=1.2303078383498274\n",
      "iteration 583 mse_loss=1.4141786265425764\n",
      "iteration 584 mse_loss=0.22014153280783538\n",
      "iteration 585 mse_loss=1.8203202029280743\n",
      "iteration 586 mse_loss=0.004787591844090291\n",
      "iteration 587 mse_loss=2.277661779313573\n",
      "iteration 588 mse_loss=1.0592370501570787\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 589 mse_loss=1.6108494147353256\n",
      "iteration 590 mse_loss=0.9009662619643295\n",
      "iteration 591 mse_loss=0.22014153280783538\n",
      "iteration 592 mse_loss=2.277661779313573\n",
      "iteration 593 mse_loss=3.6450157202773177\n",
      "iteration 594 mse_loss=0.22014153280783538\n",
      "iteration 595 mse_loss=1.0592370501570787\n",
      "iteration 596 mse_loss=3.3459449320845684\n",
      "iteration 597 mse_loss=0.3958831091933336\n",
      "iteration 598 mse_loss=0.09559995642233725\n",
      "iteration 599 mse_loss=1.0592370501570787\n",
      "iteration 600 mse_loss=2.7862033556990706\n",
      "iteration 601 mse_loss=0.052529168229588225\n",
      "iteration 602 mse_loss=0.6228246855788315\n",
      "iteration 603 mse_loss=1.4141786265425764\n",
      "iteration 604 mse_loss=0.6228246855788315\n",
      "iteration 605 mse_loss=1.2303078383498274\n",
      "iteration 606 mse_loss=1.6108494147353256\n",
      "iteration 607 mse_loss=0.7554954737715807\n",
      "iteration 608 mse_loss=0.7554954737715807\n",
      "iteration 609 mse_loss=0.00011680365134125736\n",
      "iteration 610 mse_loss=1.2303078383498274\n",
      "iteration 611 mse_loss=2.277661779313573\n",
      "iteration 612 mse_loss=1.8203202029280743\n",
      "iteration 613 mse_loss=0.7554954737715807\n",
      "iteration 614 mse_loss=1.6108494147353256\n",
      "iteration 615 mse_loss=0.9009662619643295\n",
      "iteration 616 mse_loss=3.6450157202773177\n",
      "iteration 617 mse_loss=1.0592370501570787\n",
      "iteration 618 mse_loss=0.09559995642233725\n",
      "iteration 619 mse_loss=1.2303078383498274\n",
      "iteration 620 mse_loss=1.8203202029280743\n",
      "iteration 621 mse_loss=2.7862033556990706\n",
      "iteration 622 mse_loss=0.00011680365134125736\n",
      "iteration 623 mse_loss=2.277661779313573\n",
      "iteration 624 mse_loss=0.6228246855788315\n",
      "iteration 625 mse_loss=0.6228246855788315\n",
      "iteration 626 mse_loss=3.956886508470067\n",
      "iteration 627 mse_loss=3.956886508470067\n",
      "iteration 628 mse_loss=1.4141786265425764\n",
      "iteration 629 mse_loss=3.956886508470067\n",
      "iteration 630 mse_loss=0.00011680365134125736\n",
      "iteration 631 mse_loss=0.6228246855788315\n",
      "iteration 632 mse_loss=1.4141786265425764\n",
      "iteration 633 mse_loss=3.956886508470067\n",
      "iteration 634 mse_loss=1.4141786265425764\n",
      "iteration 635 mse_loss=0.00011680365134125736\n",
      "iteration 636 mse_loss=2.525532567506322\n",
      "iteration 637 mse_loss=0.1514707446150863\n",
      "iteration 638 mse_loss=0.1514707446150863\n",
      "iteration 639 mse_loss=2.525532567506322\n",
      "iteration 640 mse_loss=2.525532567506322\n",
      "iteration 641 mse_loss=2.525532567506322\n",
      "iteration 642 mse_loss=0.1514707446150863\n",
      "iteration 643 mse_loss=2.525532567506322\n",
      "iteration 644 mse_loss=0.00011680365134125736\n",
      "iteration 645 mse_loss=0.1514707446150863\n",
      "iteration 646 mse_loss=0.1514707446150863\n",
      "iteration 647 mse_loss=0.1514707446150863\n",
      "iteration 648 mse_loss=0.1514707446150863\n",
      "iteration 649 mse_loss=0.6228246855788315\n",
      "iteration 650 mse_loss=0.1514707446150863\n",
      "iteration 651 mse_loss=3.956886508470067\n",
      "iteration 652 mse_loss=3.956886508470067\n",
      "iteration 653 mse_loss=2.525532567506322\n",
      "iteration 654 mse_loss=0.1514707446150863\n",
      "iteration 655 mse_loss=0.00011680365134125736\n",
      "iteration 656 mse_loss=1.4141786265425764\n",
      "iteration 657 mse_loss=0.1514707446150863\n",
      "iteration 658 mse_loss=3.956886508470067\n",
      "iteration 659 mse_loss=1.4141786265425764\n",
      "iteration 660 mse_loss=2.525532567506322\n",
      "iteration 661 mse_loss=3.956886508470067\n",
      "iteration 662 mse_loss=1.4141786265425764\n",
      "iteration 663 mse_loss=0.00011680365134125736\n",
      "iteration 664 mse_loss=2.525532567506322\n",
      "iteration 665 mse_loss=0.6228246855788315\n",
      "iteration 666 mse_loss=1.4141786265425764\n",
      "iteration 667 mse_loss=0.00011680365134125736\n",
      "iteration 668 mse_loss=1.4141786265425764\n",
      "iteration 669 mse_loss=2.525532567506322\n",
      "iteration 670 mse_loss=0.00011680365134125736\n",
      "iteration 671 mse_loss=3.956886508470067\n",
      "iteration 672 mse_loss=0.00011680365134125736\n",
      "iteration 673 mse_loss=0.00011680365134125736\n",
      "iteration 674 mse_loss=3.956886508470067\n",
      "iteration 675 mse_loss=1.4141786265425764\n",
      "iteration 676 mse_loss=0.1514707446150863\n",
      "iteration 677 mse_loss=3.956886508470067\n",
      "iteration 678 mse_loss=1.4141786265425764\n",
      "iteration 679 mse_loss=0.6228246855788315\n",
      "iteration 680 mse_loss=3.956886508470067\n",
      "iteration 681 mse_loss=0.6228246855788315\n",
      "iteration 682 mse_loss=2.525532567506322\n",
      "iteration 683 mse_loss=0.6228246855788315\n",
      "iteration 684 mse_loss=1.4141786265425764\n",
      "iteration 685 mse_loss=0.1514707446150863\n",
      "iteration 686 mse_loss=3.956886508470067\n",
      "iteration 687 mse_loss=0.1514707446150863\n",
      "iteration 688 mse_loss=0.1514707446150863\n",
      "iteration 689 mse_loss=1.4141786265425764\n",
      "iteration 690 mse_loss=1.4141786265425764\n",
      "iteration 691 mse_loss=0.00011680365134125736\n",
      "iteration 692 mse_loss=1.4141786265425764\n",
      "iteration 693 mse_loss=1.4141786265425764\n",
      "iteration 694 mse_loss=3.956886508470067\n",
      "iteration 695 mse_loss=1.4141786265425764\n",
      "iteration 696 mse_loss=3.956886508470067\n",
      "iteration 697 mse_loss=1.4141786265425764\n",
      "iteration 698 mse_loss=0.1514707446150863\n",
      "iteration 699 mse_loss=0.1514707446150863\n",
      "iteration 700 mse_loss=2.525532567506322\n",
      "iteration 701 mse_loss=0.1514707446150863\n",
      "iteration 702 mse_loss=0.1514707446150863\n",
      "iteration 703 mse_loss=1.4141786265425764\n",
      "iteration 704 mse_loss=1.4141786265425764\n",
      "iteration 705 mse_loss=1.4141786265425764\n",
      "iteration 706 mse_loss=3.956886508470067\n",
      "iteration 707 mse_loss=0.6228246855788315\n",
      "iteration 708 mse_loss=2.525532567506322\n",
      "iteration 709 mse_loss=0.00011680365134125736\n",
      "iteration 710 mse_loss=2.525532567506322\n",
      "iteration 711 mse_loss=3.956886508470067\n",
      "iteration 712 mse_loss=1.4141786265425764\n",
      "iteration 713 mse_loss=1.4141786265425764\n",
      "iteration 714 mse_loss=3.956886508470067\n",
      "iteration 715 mse_loss=0.6228246855788315\n",
      "iteration 716 mse_loss=0.6228246855788315\n",
      "iteration 717 mse_loss=0.6228246855788315\n",
      "iteration 718 mse_loss=0.00011680365134125736\n",
      "iteration 719 mse_loss=0.00011680365134125736\n",
      "iteration 720 mse_loss=0.1514707446150863\n",
      "iteration 721 mse_loss=2.525532567506322\n",
      "iteration 722 mse_loss=3.956886508470067\n",
      "iteration 723 mse_loss=0.00011680365134125736\n",
      "iteration 724 mse_loss=3.956886508470067\n",
      "iteration 725 mse_loss=0.1514707446150863\n",
      "iteration 726 mse_loss=0.00011680365134125736\n",
      "iteration 727 mse_loss=0.6228246855788315\n",
      "iteration 728 mse_loss=0.6228246855788315\n",
      "iteration 729 mse_loss=0.6228246855788315\n",
      "iteration 730 mse_loss=1.4141786265425764\n",
      "iteration 731 mse_loss=2.525532567506322\n",
      "iteration 732 mse_loss=3.956886508470067\n",
      "iteration 733 mse_loss=1.4141786265425764\n",
      "iteration 734 mse_loss=3.956886508470067\n",
      "iteration 735 mse_loss=1.4141786265425764\n",
      "iteration 736 mse_loss=0.00011680365134125736\n",
      "iteration 737 mse_loss=0.6228246855788315\n",
      "iteration 738 mse_loss=0.6228246855788315\n",
      "iteration 739 mse_loss=0.00011680365134125736\n",
      "iteration 740 mse_loss=0.6228246855788315\n",
      "iteration 741 mse_loss=1.4141786265425764\n",
      "iteration 742 mse_loss=2.525532567506322\n",
      "iteration 743 mse_loss=2.525532567506322\n",
      "iteration 744 mse_loss=0.00011680365134125736\n",
      "iteration 745 mse_loss=2.525532567506322\n",
      "iteration 746 mse_loss=1.4141786265425764\n",
      "iteration 747 mse_loss=0.1514707446150863\n",
      "iteration 748 mse_loss=3.956886508470067\n",
      "iteration 749 mse_loss=1.4141786265425764\n",
      "iteration 750 mse_loss=2.525532567506322\n",
      "iteration 751 mse_loss=0.6228246855788315\n",
      "iteration 752 mse_loss=2.525532567506322\n",
      "iteration 753 mse_loss=2.525532567506322\n",
      "iteration 754 mse_loss=0.00011680365134125736\n",
      "iteration 755 mse_loss=0.00011680365134125736\n",
      "iteration 756 mse_loss=0.00011680365134125736\n",
      "iteration 757 mse_loss=3.956886508470067\n",
      "iteration 758 mse_loss=0.1514707446150863\n",
      "iteration 759 mse_loss=0.1514707446150863\n",
      "iteration 760 mse_loss=3.956886508470067\n",
      "iteration 761 mse_loss=3.956886508470067\n",
      "iteration 762 mse_loss=1.4141786265425764\n",
      "iteration 763 mse_loss=0.1514707446150863\n",
      "iteration 764 mse_loss=0.00011680365134125736\n",
      "iteration 765 mse_loss=0.6228246855788315\n",
      "iteration 766 mse_loss=0.6228246855788315\n",
      "iteration 767 mse_loss=0.1514707446150863\n",
      "iteration 768 mse_loss=2.525532567506322\n",
      "iteration 769 mse_loss=3.956886508470067\n",
      "iteration 770 mse_loss=1.4141786265425764\n",
      "iteration 771 mse_loss=1.4141786265425764\n",
      "iteration 772 mse_loss=0.00011680365134125736\n",
      "iteration 773 mse_loss=0.1514707446150863\n",
      "iteration 774 mse_loss=0.00011680365134125736\n",
      "iteration 775 mse_loss=2.525532567506322\n",
      "iteration 776 mse_loss=3.956886508470067\n",
      "iteration 777 mse_loss=1.4141786265425764\n",
      "iteration 778 mse_loss=3.956886508470067\n"
     ]
    }
   ],
   "source": [
    "training_data_regression = STS_Dataset(df_test)\n",
    "train_dataloader_regression = DataLoader(training_data_regression, batch_size=1, shuffle=False)\n",
    "\n",
    "losses = []\n",
    "criterion = nn.MSELoss()\n",
    "sbert.eval()\n",
    "for i,((sent1,sent2),label) in enumerate(train_dataloader_regression):\n",
    "    \n",
    "    output = sbert(sentence1,sentence2,objective=\"regression\")\n",
    "\n",
    "    loss = criterion(output,label)\n",
    "    \n",
    "    print(f\"iteration {i} mse_loss={loss}\")\n",
    "    \n",
    "    losses.append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import classification_report\n",
    "# import json\n",
    "\n",
    "# report = classification_report(trues, preds,output_dict=True)\n",
    "# print(json.dumps(report, sort_keys=True, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Objective Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "json_list = list(open(\"snli_1.0/snli_1.0_train.jsonl\",\"r\"))\n",
    "\n",
    "label2int = {\"contradiction\": 0, \"entailment\": 1, \"neutral\": 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {'sentence1': [], 'sentence2': [], 'gold_label': []}\n",
    "for json_str in json_list:\n",
    "    try:\n",
    "        result = json.loads(json_str)\n",
    "        result['gold_label']=label2int[result['gold_label']]\n",
    "        for key in data:\n",
    "            data[key].append(result[key])\n",
    "    except:\n",
    "        pass\n",
    "df_train = pd.DataFrame.from_dict(data).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>gold_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A person on a horse jumps over a broken down a...</td>\n",
       "      <td>A person is training his horse for a competition.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A person on a horse jumps over a broken down a...</td>\n",
       "      <td>A person is at a diner, ordering an omelette.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A person on a horse jumps over a broken down a...</td>\n",
       "      <td>A person is outdoors, on a horse.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Children smiling and waving at camera</td>\n",
       "      <td>They are smiling at their parents</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Children smiling and waving at camera</td>\n",
       "      <td>There are children present</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           sentence1  \\\n",
       "0  A person on a horse jumps over a broken down a...   \n",
       "1  A person on a horse jumps over a broken down a...   \n",
       "2  A person on a horse jumps over a broken down a...   \n",
       "3              Children smiling and waving at camera   \n",
       "4              Children smiling and waving at camera   \n",
       "\n",
       "                                           sentence2  gold_label  \n",
       "0  A person is training his horse for a competition.           2  \n",
       "1      A person is at a diner, ordering an omelette.           0  \n",
       "2                  A person is outdoors, on a horse.           1  \n",
       "3                  They are smiling at their parents           2  \n",
       "4                         There are children present           1  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset,DataLoader\n",
    "\n",
    "class SNLI_Dataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        sent1 = row['sentence1']\n",
    "        sent2 = row['sentence2']\n",
    "        label = row['gold_label']\n",
    "        return (sent1, sent2), label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = SNLI_Dataset(df_train)\n",
    "train_dataloader = DataLoader(training_data, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(sbert.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- outputs of shape (N,C) where N is the batch size C is the number of classes\n",
    "- target of shape (N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=1 iteration=1/1 loss=1.1248085498809814\n",
      "epoch=2 iteration=1/1 loss=1.1213394403457642\n",
      "epoch=3 iteration=1/1 loss=1.116319179534912\n",
      "epoch=4 iteration=1/1 loss=1.1178715229034424\n",
      "epoch=5 iteration=1/1 loss=1.1034400463104248\n",
      "epoch=6 iteration=1/1 loss=1.0994272232055664\n",
      "epoch=7 iteration=1/1 loss=1.1001434326171875\n",
      "epoch=8 iteration=1/1 loss=1.0792795419692993\n",
      "epoch=9 iteration=1/1 loss=1.086229920387268\n",
      "epoch=10 iteration=1/1 loss=1.0764697790145874\n",
      "epoch=11 iteration=1/1 loss=1.0764305591583252\n",
      "epoch=12 iteration=1/1 loss=1.080661416053772\n",
      "epoch=13 iteration=1/1 loss=1.0829098224639893\n",
      "epoch=14 iteration=1/1 loss=1.0621845722198486\n",
      "epoch=15 iteration=1/1 loss=1.0699632167816162\n",
      "epoch=16 iteration=1/1 loss=1.0708560943603516\n",
      "epoch=17 iteration=1/1 loss=1.0716842412948608\n",
      "epoch=18 iteration=1/1 loss=1.0721025466918945\n",
      "epoch=19 iteration=1/1 loss=1.067765712738037\n",
      "epoch=20 iteration=1/1 loss=1.060341477394104\n",
      "epoch=21 iteration=1/1 loss=1.0495812892913818\n",
      "epoch=22 iteration=1/1 loss=1.043954610824585\n",
      "epoch=23 iteration=1/1 loss=1.0576391220092773\n",
      "epoch=24 iteration=1/1 loss=1.0487099885940552\n",
      "epoch=25 iteration=1/1 loss=1.0492286682128906\n",
      "epoch=26 iteration=1/1 loss=1.0533020496368408\n",
      "epoch=27 iteration=1/1 loss=1.0616271495819092\n",
      "epoch=28 iteration=1/1 loss=1.0422762632369995\n",
      "epoch=29 iteration=1/1 loss=1.037724256515503\n",
      "epoch=30 iteration=1/1 loss=1.052344560623169\n",
      "epoch=31 iteration=1/1 loss=1.0504634380340576\n",
      "epoch=32 iteration=1/1 loss=1.0412975549697876\n",
      "epoch=33 iteration=1/1 loss=1.040104627609253\n",
      "epoch=34 iteration=1/1 loss=1.0260810852050781\n",
      "epoch=35 iteration=1/1 loss=1.0587940216064453\n",
      "epoch=36 iteration=1/1 loss=1.0416263341903687\n",
      "epoch=37 iteration=1/1 loss=1.060150384902954\n",
      "epoch=38 iteration=1/1 loss=1.0375982522964478\n",
      "epoch=39 iteration=1/1 loss=1.0375220775604248\n",
      "epoch=40 iteration=1/1 loss=1.0466725826263428\n",
      "epoch=41 iteration=1/1 loss=1.037799596786499\n",
      "epoch=42 iteration=1/1 loss=1.0485109090805054\n",
      "epoch=43 iteration=1/1 loss=1.0505940914154053\n",
      "epoch=44 iteration=1/1 loss=1.0534229278564453\n",
      "epoch=45 iteration=1/1 loss=1.0473997592926025\n",
      "epoch=46 iteration=1/1 loss=1.0445529222488403\n",
      "epoch=47 iteration=1/1 loss=1.0431684255599976\n",
      "epoch=48 iteration=1/1 loss=1.0375103950500488\n",
      "epoch=49 iteration=1/1 loss=1.0383915901184082\n",
      "epoch=50 iteration=1/1 loss=1.0398061275482178\n",
      "epoch=51 iteration=1/1 loss=1.0410016775131226\n",
      "epoch=52 iteration=1/1 loss=1.0447046756744385\n",
      "epoch=53 iteration=1/1 loss=1.035147786140442\n",
      "epoch=54 iteration=1/1 loss=1.032949686050415\n",
      "epoch=55 iteration=1/1 loss=1.0248680114746094\n",
      "epoch=56 iteration=1/1 loss=1.043359398841858\n",
      "epoch=57 iteration=1/1 loss=1.0097272396087646\n",
      "epoch=58 iteration=1/1 loss=1.033890962600708\n",
      "epoch=59 iteration=1/1 loss=1.018316626548767\n",
      "epoch=60 iteration=1/1 loss=1.019553780555725\n",
      "epoch=61 iteration=1/1 loss=1.0193852186203003\n",
      "epoch=62 iteration=1/1 loss=1.0146520137786865\n",
      "epoch=63 iteration=1/1 loss=1.014883279800415\n",
      "epoch=64 iteration=1/1 loss=1.0165058374404907\n",
      "epoch=65 iteration=1/1 loss=1.0218907594680786\n",
      "epoch=66 iteration=1/1 loss=1.0208219289779663\n",
      "epoch=67 iteration=1/1 loss=1.021173357963562\n",
      "epoch=68 iteration=1/1 loss=1.0249450206756592\n",
      "epoch=69 iteration=1/1 loss=1.0181087255477905\n",
      "epoch=70 iteration=1/1 loss=0.9747282266616821\n",
      "epoch=71 iteration=1/1 loss=1.00774347782135\n",
      "epoch=72 iteration=1/1 loss=0.9838709831237793\n",
      "epoch=73 iteration=1/1 loss=0.9920879602432251\n",
      "epoch=74 iteration=1/1 loss=0.9923645257949829\n",
      "epoch=75 iteration=1/1 loss=0.9887253642082214\n",
      "epoch=76 iteration=1/1 loss=0.984524130821228\n",
      "epoch=77 iteration=1/1 loss=0.9689114689826965\n",
      "epoch=78 iteration=1/1 loss=0.9796220660209656\n",
      "epoch=79 iteration=1/1 loss=0.9830985069274902\n",
      "epoch=80 iteration=1/1 loss=0.9729399681091309\n",
      "epoch=81 iteration=1/1 loss=0.9636725187301636\n",
      "epoch=82 iteration=1/1 loss=0.9620658755302429\n",
      "epoch=83 iteration=1/1 loss=0.968779444694519\n",
      "epoch=84 iteration=1/1 loss=0.9269342422485352\n",
      "epoch=85 iteration=1/1 loss=0.9414509534835815\n",
      "epoch=86 iteration=1/1 loss=0.9463289976119995\n",
      "epoch=87 iteration=1/1 loss=0.9300695657730103\n",
      "epoch=88 iteration=1/1 loss=0.9177072644233704\n",
      "epoch=89 iteration=1/1 loss=0.9088060259819031\n",
      "epoch=90 iteration=1/1 loss=0.9109093546867371\n",
      "epoch=91 iteration=1/1 loss=0.9086437225341797\n",
      "epoch=92 iteration=1/1 loss=0.8888586759567261\n",
      "epoch=93 iteration=1/1 loss=0.902706503868103\n",
      "epoch=94 iteration=1/1 loss=0.8929517865180969\n",
      "epoch=95 iteration=1/1 loss=0.8814294934272766\n",
      "epoch=96 iteration=1/1 loss=0.8715556859970093\n",
      "epoch=97 iteration=1/1 loss=0.8668515086174011\n",
      "epoch=98 iteration=1/1 loss=0.8655346035957336\n",
      "epoch=99 iteration=1/1 loss=0.8441318273544312\n",
      "epoch=100 iteration=1/1 loss=0.8376344442367554\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "training_data = SNLI_Dataset(df_train)\n",
    "train_dataloader = DataLoader(training_data, batch_size=16, shuffle=False)\n",
    "\n",
    "n_epochs = 100\n",
    "sbert.train()\n",
    "losses = []\n",
    "for epoch in range(n_epochs):\n",
    "\n",
    "    for i,((sent1,sent2),label) in enumerate(train_dataloader):\n",
    "        \n",
    "        output = sbert(sent1,sent2,objective=\"classification\")\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        loss = criterion(output, label)\n",
    "        \n",
    "        losses.append(loss)\n",
    "        \n",
    "        print(f\"epoch={epoch+1} iteration={i+1}/{len(train_dataloader)} loss={loss.detach().numpy()}\")\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # break\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "for idx in range(5):\n",
    "    pred = torch.argmax(sbert(df_train.iloc[idx].sentence1,df_train.iloc[idx].sentence2,\"classification\")).numpy().item()\n",
    "    true = df_train.iloc[idx]['gold_label']\n",
    "    print(pred==true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"models/classification.pt\"\n",
    "torch.save(sbert.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fine-tuning using the regression objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SBERT(\n",
       "  (model): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (pooling): AvgPool1d(kernel_size=(3,), stride=(1,), padding=(0,))\n",
       "  (linear): Linear(in_features=2298, out_features=3, bias=True)\n",
       "  (softmax): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = \"models/classification.pt\"\n",
    "\n",
    "sbert = SBERT()\n",
    "sbert.load_state_dict(torch.load(PATH))\n",
    "sbert.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.80</td>\n",
       "      <td>A man is playing a large flute.</td>\n",
       "      <td>A man is playing a flute.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.80</td>\n",
       "      <td>A man is spreading shreded cheese on a pizza.</td>\n",
       "      <td>A man is spreading shredded cheese on an uncoo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.60</td>\n",
       "      <td>Three men are playing chess.</td>\n",
       "      <td>Two men are playing chess.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.25</td>\n",
       "      <td>A man is playing the cello.</td>\n",
       "      <td>A man seated is playing the cello.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.25</td>\n",
       "      <td>Some men are fighting.</td>\n",
       "      <td>Two men are fighting.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   score                                      sentence1  \\\n",
       "0   3.80                A man is playing a large flute.   \n",
       "1   3.80  A man is spreading shreded cheese on a pizza.   \n",
       "2   2.60                   Three men are playing chess.   \n",
       "3   4.25                    A man is playing the cello.   \n",
       "4   4.25                         Some men are fighting.   \n",
       "\n",
       "                                           sentence2  \n",
       "0                          A man is playing a flute.  \n",
       "1  A man is spreading shredded cheese on an uncoo...  \n",
       "2                         Two men are playing chess.  \n",
       "3                 A man seated is playing the cello.  \n",
       "4                              Two men are fighting.  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_train = pd.read_csv(\"Stsbenchmark/sts-train.csv\",header=0,names=[\"main-caption\",\"genre\",\"filename\",\"year\",\"score\",\"sentence1\",\"sentence2\"])#,usecols=['score','sentence1','sentence2'])\n",
    "df_test = pd.read_csv(\"Stsbenchmark/sts-test.csv\",header=0,names=[\"main-caption\",\"genre\",\"filename\",\"year\",\"score\",\"sentence1\",\"sentence2\"])#,usecols=['score','sentence1','sentence2'])\n",
    "\n",
    "df_train = df_train[['score','sentence1','sentence2']]\n",
    "df_test = df_test[['score','sentence1','sentence2']]\n",
    "\n",
    "df_train.head()\n",
    "# df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 5.0)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ls = list(df_train.score)\n",
    "minn = min(ls)\n",
    "maxx = max(ls)\n",
    "(minn,maxx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_score(value, leftMin=0, leftMax=5, rightMin=-1, rightMax=1):\n",
    "    # Figure out how 'wide' each range is\n",
    "    leftSpan = leftMax - leftMin\n",
    "    rightSpan = rightMax - rightMin\n",
    "\n",
    "    # Convert the left range into a 0-1 range (float)\n",
    "    valueScaled = float(value - leftMin) / float(leftSpan)\n",
    "\n",
    "    # Convert the 0-1 range into a value in the right range.\n",
    "    return rightMin + (valueScaled * rightSpan)\n",
    "\n",
    "df_train['score'] = df_train['score'].apply(map_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-1.0, 1.0)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ls = list(df_train.score)\n",
    "minn = min(ls)\n",
    "maxx = max(ls)\n",
    "(minn,maxx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset,DataLoader\n",
    "\n",
    "class STS_Dataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        sent1 = row['sentence1']\n",
    "        sent2 = row['sentence2']\n",
    "        label = row['score']\n",
    "        return (sent1, sent2), label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.6167], grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sbert(\"I love pizza\",\"I love burger\",objective=\"regression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(sbert.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_regression = STS_Dataset(df_train)\n",
    "train_dataloader_regression = DataLoader(training_data_regression, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=1 iteration=1/62 loss=0.3414393365383148\n",
      "epoch=1 iteration=2/62 loss=0.5225234627723694\n",
      "epoch=1 iteration=3/62 loss=0.5447043776512146\n",
      "epoch=1 iteration=4/62 loss=0.9775974750518799\n",
      "epoch=1 iteration=5/62 loss=0.8285077214241028\n",
      "epoch=1 iteration=6/62 loss=0.9737005829811096\n",
      "epoch=1 iteration=7/62 loss=0.7615697383880615\n",
      "epoch=1 iteration=8/62 loss=0.7637732625007629\n",
      "epoch=1 iteration=9/62 loss=0.27583539485931396\n",
      "epoch=1 iteration=10/62 loss=0.4577804207801819\n",
      "epoch=1 iteration=11/62 loss=0.42774084210395813\n",
      "epoch=1 iteration=12/62 loss=0.6824129223823547\n",
      "epoch=1 iteration=13/62 loss=0.5674241185188293\n",
      "epoch=1 iteration=14/62 loss=0.6364807486534119\n",
      "epoch=1 iteration=15/62 loss=0.7143394947052002\n",
      "epoch=1 iteration=16/62 loss=0.5169401168823242\n",
      "epoch=1 iteration=17/62 loss=0.39554280042648315\n",
      "epoch=1 iteration=18/62 loss=0.48140937089920044\n",
      "epoch=1 iteration=19/62 loss=0.4177089333534241\n",
      "epoch=1 iteration=20/62 loss=0.4531996548175812\n",
      "epoch=1 iteration=21/62 loss=0.3222440481185913\n",
      "epoch=1 iteration=22/62 loss=0.33722788095474243\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 1\n",
    "\n",
    "losses = []\n",
    "for epoch in range(n_epochs):\n",
    "\n",
    "    for i,((sent1,sent2),label) in enumerate(train_dataloader_regression):\n",
    "        \n",
    "        output = sbert(sent1,sent2,objective=\"regression\")\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        label = label.float()\n",
    "        loss = criterion(output, label)\n",
    "        \n",
    "        losses.append(loss)\n",
    "        \n",
    "        print(f\"epoch={epoch+1} iteration={i+1}/{len(train_dataloader_regression)} loss={loss.detach().numpy()}\")\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # break\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"models/classification_regression.pt\"\n",
    "torch.save(sbert.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use your best fine-tuned model and create a small semantic search system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SBERT(\n",
       "  (model): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (pooling): AvgPool1d(kernel_size=(3,), stride=(1,), padding=(0,))\n",
       "  (linear): Linear(in_features=2298, out_features=3, bias=True)\n",
       "  (softmax): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = \"models/classification_regression.pt\"\n",
    "sbert = SBERT()\n",
    "sbert.load_state_dict(torch.load(PATH))\n",
    "sbert.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "list_ = []\n",
    "path = \"datasets/News_Category_Dataset_v2.json\"\n",
    "with open(path) as files:\n",
    "    for file in files:\n",
    "        list_.append(json.loads(file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>headline</th>\n",
       "      <th>authors</th>\n",
       "      <th>link</th>\n",
       "      <th>short_description</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CRIME</td>\n",
       "      <td>There Were 2 Mass Shootings In Texas Last Week...</td>\n",
       "      <td>Melissa Jeltsen</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/texas-ama...</td>\n",
       "      <td>She left her husband. He killed their children...</td>\n",
       "      <td>2018-05-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>Will Smith Joins Diplo And Nicky Jam For The 2...</td>\n",
       "      <td>Andy McDonald</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/will-smit...</td>\n",
       "      <td>Of course it has a song.</td>\n",
       "      <td>2018-05-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>Hugh Grant Marries For The First Time At Age 57</td>\n",
       "      <td>Ron Dicker</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/hugh-gran...</td>\n",
       "      <td>The actor and his longtime girlfriend Anna Ebe...</td>\n",
       "      <td>2018-05-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>Jim Carrey Blasts 'Castrato' Adam Schiff And D...</td>\n",
       "      <td>Ron Dicker</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/jim-carre...</td>\n",
       "      <td>The actor gives Dems an ass-kicking for not fi...</td>\n",
       "      <td>2018-05-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>Julianna Margulies Uses Donald Trump Poop Bags...</td>\n",
       "      <td>Ron Dicker</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/julianna-...</td>\n",
       "      <td>The \"Dietland\" actress said using the bags is ...</td>\n",
       "      <td>2018-05-26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        category                                           headline  \\\n",
       "0          CRIME  There Were 2 Mass Shootings In Texas Last Week...   \n",
       "1  ENTERTAINMENT  Will Smith Joins Diplo And Nicky Jam For The 2...   \n",
       "2  ENTERTAINMENT    Hugh Grant Marries For The First Time At Age 57   \n",
       "3  ENTERTAINMENT  Jim Carrey Blasts 'Castrato' Adam Schiff And D...   \n",
       "4  ENTERTAINMENT  Julianna Margulies Uses Donald Trump Poop Bags...   \n",
       "\n",
       "           authors                                               link  \\\n",
       "0  Melissa Jeltsen  https://www.huffingtonpost.com/entry/texas-ama...   \n",
       "1    Andy McDonald  https://www.huffingtonpost.com/entry/will-smit...   \n",
       "2       Ron Dicker  https://www.huffingtonpost.com/entry/hugh-gran...   \n",
       "3       Ron Dicker  https://www.huffingtonpost.com/entry/jim-carre...   \n",
       "4       Ron Dicker  https://www.huffingtonpost.com/entry/julianna-...   \n",
       "\n",
       "                                   short_description        date  \n",
       "0  She left her husband. He killed their children...  2018-05-26  \n",
       "1                           Of course it has a song.  2018-05-26  \n",
       "2  The actor and his longtime girlfriend Anna Ebe...  2018-05-26  \n",
       "3  The actor gives Dems an ass-kicking for not fi...  2018-05-26  \n",
       "4  The \"Dietland\" actress said using the bags is ...  2018-05-26  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_news = pd.DataFrame(list_)\n",
    "df_news.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length before splitting: 200853\n",
      "Length after splitting: 215043\n",
      "Data increased by 14190 sentences\n"
     ]
    }
   ],
   "source": [
    "sent1 = list(df_news.headline)\n",
    "print(\"Length before splitting:\",len(sent1))\n",
    "sent2 = [x for sentence in sent1 for x in sentence.split(\".\")]\n",
    "sent2 = [x for x in sent2 if x]\n",
    "print(\"Length after splitting:\",len(sent2))\n",
    "print(f\"Data increased by {len(sent2)-len(sent1)} sentences\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['There Were 2 Mass Shootings In Texas Last Week, But Only 1 On TV',\n",
       " \"Will Smith Joins Diplo And Nicky Jam For The 2018 World Cup's Official Song\",\n",
       " 'Hugh Grant Marries For The First Time At Age 57',\n",
       " \"Jim Carrey Blasts 'Castrato' Adam Schiff And Democrats In New Artwork\",\n",
       " 'Julianna Margulies Uses Donald Trump Poop Bags To Pick Up After Her Dog']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent2[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sentence = \"Sweden is a very safe place.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embeddings(sentences):\n",
    "    embeddings = []\n",
    "    for i,sentence in enumerate(sentences):\n",
    "        print(f\"Finished iteration {i}/{len(sentences)}\",end=\"\\r\")\n",
    "        \n",
    "        embeddings.append(sbert(sentence,objective=\"embedding\"))\n",
    "\n",
    "    embeddings = torch.FloatTensor(embeddings)\n",
    "    torch.save(x, 'datasets/embeddings.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished iteration 1061/215043\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/ali/anaconda3/envs/py38/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3444, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_89163/908439655.py\", line 1, in <module>\n",
      "    create_embeddings(sent2)\n",
      "  File \"/tmp/ipykernel_89163/686597705.py\", line 6, in create_embeddings\n",
      "    embeddings.append(sbert(sentence,objective=\"embedding\"))\n",
      "  File \"/home/ali/anaconda3/envs/py38/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/tmp/ipykernel_89163/255337989.py\", line 37, in forward\n",
      "    output1 = self.model(**encoded_input1)\n",
      "  File \"/home/ali/anaconda3/envs/py38/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/ali/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\", line 991, in forward\n",
      "    encoder_outputs = self.encoder(\n",
      "  File \"/home/ali/anaconda3/envs/py38/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/ali/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\", line 582, in forward\n",
      "    layer_outputs = layer_module(\n",
      "  File \"/home/ali/anaconda3/envs/py38/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/ali/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\", line 510, in forward\n",
      "    layer_output = apply_chunking_to_forward(\n",
      "  File \"/home/ali/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/modeling_utils.py\", line 2186, in apply_chunking_to_forward\n",
      "    return forward_fn(*input_tensors)\n",
      "  File \"/home/ali/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\", line 523, in feed_forward_chunk\n",
      "    layer_output = self.output(intermediate_output, attention_output)\n",
      "  File \"/home/ali/anaconda3/envs/py38/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/ali/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\", line 438, in forward\n",
      "    hidden_states = self.dense(hidden_states)\n",
      "  File \"/home/ali/anaconda3/envs/py38/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/ali/anaconda3/envs/py38/lib/python3.8/site-packages/torch/nn/modules/linear.py\", line 103, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "  File \"/home/ali/anaconda3/envs/py38/lib/python3.8/site-packages/torch/nn/functional.py\", line 1848, in linear\n",
      "    return torch._C._nn.linear(input, weight, bias)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ali/anaconda3/envs/py38/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2064, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ali/anaconda3/envs/py38/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/ali/anaconda3/envs/py38/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/ali/anaconda3/envs/py38/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/home/ali/anaconda3/envs/py38/lib/python3.8/inspect.py\", line 1503, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/home/ali/anaconda3/envs/py38/lib/python3.8/inspect.py\", line 1461, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/home/ali/anaconda3/envs/py38/lib/python3.8/inspect.py\", line 708, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/home/ali/anaconda3/envs/py38/lib/python3.8/inspect.py\", line 751, in getmodule\n",
      "    f = getabsfile(module)\n",
      "  File \"/home/ali/anaconda3/envs/py38/lib/python3.8/inspect.py\", line 721, in getabsfile\n",
      "    return os.path.normcase(os.path.abspath(_filename))\n",
      "  File \"/home/ali/anaconda3/envs/py38/lib/python3.8/posixpath.py\", line 381, in abspath\n",
      "    return normpath(path)\n",
      "  File \"/home/ali/anaconda3/envs/py38/lib/python3.8/posixpath.py\", line 355, in normpath\n",
      "    comps = path.split(sep)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/ali/anaconda3/envs/py38/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3444, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_89163/908439655.py\", line 1, in <module>\n",
      "    create_embeddings(sent2)\n",
      "  File \"/tmp/ipykernel_89163/686597705.py\", line 6, in create_embeddings\n",
      "    embeddings.append(sbert(sentence,objective=\"embedding\"))\n",
      "  File \"/home/ali/anaconda3/envs/py38/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/tmp/ipykernel_89163/255337989.py\", line 37, in forward\n",
      "    output1 = self.model(**encoded_input1)\n",
      "  File \"/home/ali/anaconda3/envs/py38/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/ali/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\", line 991, in forward\n",
      "    encoder_outputs = self.encoder(\n",
      "  File \"/home/ali/anaconda3/envs/py38/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/ali/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\", line 582, in forward\n",
      "    layer_outputs = layer_module(\n",
      "  File \"/home/ali/anaconda3/envs/py38/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/ali/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\", line 510, in forward\n",
      "    layer_output = apply_chunking_to_forward(\n",
      "  File \"/home/ali/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/modeling_utils.py\", line 2186, in apply_chunking_to_forward\n",
      "    return forward_fn(*input_tensors)\n",
      "  File \"/home/ali/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\", line 523, in feed_forward_chunk\n",
      "    layer_output = self.output(intermediate_output, attention_output)\n",
      "  File \"/home/ali/anaconda3/envs/py38/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/ali/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\", line 438, in forward\n",
      "    hidden_states = self.dense(hidden_states)\n",
      "  File \"/home/ali/anaconda3/envs/py38/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/ali/anaconda3/envs/py38/lib/python3.8/site-packages/torch/nn/modules/linear.py\", line 103, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "  File \"/home/ali/anaconda3/envs/py38/lib/python3.8/site-packages/torch/nn/functional.py\", line 1848, in linear\n",
      "    return torch._C._nn.linear(input, weight, bias)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ali/anaconda3/envs/py38/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2064, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ali/anaconda3/envs/py38/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3364, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"/home/ali/anaconda3/envs/py38/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3461, in run_code\n",
      "    self.showtraceback(running_compiled_code=True)\n",
      "  File \"/home/ali/anaconda3/envs/py38/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2066, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(etype,\n",
      "  File \"/home/ali/anaconda3/envs/py38/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1367, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"/home/ali/anaconda3/envs/py38/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1267, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"/home/ali/anaconda3/envs/py38/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1124, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"/home/ali/anaconda3/envs/py38/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1082, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"/home/ali/anaconda3/envs/py38/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 382, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ali/anaconda3/envs/py38/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2064, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ali/anaconda3/envs/py38/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/ali/anaconda3/envs/py38/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/ali/anaconda3/envs/py38/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/home/ali/anaconda3/envs/py38/lib/python3.8/inspect.py\", line 1503, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/home/ali/anaconda3/envs/py38/lib/python3.8/inspect.py\", line 1461, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/home/ali/anaconda3/envs/py38/lib/python3.8/inspect.py\", line 708, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/home/ali/anaconda3/envs/py38/lib/python3.8/inspect.py\", line 754, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"/home/ali/anaconda3/envs/py38/lib/python3.8/posixpath.py\", line 391, in realpath\n",
      "    path, ok = _joinrealpath(filename[:0], filename, {})\n",
      "  File \"/home/ali/anaconda3/envs/py38/lib/python3.8/posixpath.py\", line 411, in _joinrealpath\n",
      "    name, _, rest = rest.partition(sep)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/ali/anaconda3/envs/py38/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3444, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_89163/908439655.py\", line 1, in <module>\n",
      "    create_embeddings(sent2)\n",
      "  File \"/tmp/ipykernel_89163/686597705.py\", line 6, in create_embeddings\n",
      "    embeddings.append(sbert(sentence,objective=\"embedding\"))\n",
      "  File \"/home/ali/anaconda3/envs/py38/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/tmp/ipykernel_89163/255337989.py\", line 37, in forward\n",
      "    output1 = self.model(**encoded_input1)\n",
      "  File \"/home/ali/anaconda3/envs/py38/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/ali/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\", line 991, in forward\n",
      "    encoder_outputs = self.encoder(\n",
      "  File \"/home/ali/anaconda3/envs/py38/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/ali/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\", line 582, in forward\n",
      "    layer_outputs = layer_module(\n",
      "  File \"/home/ali/anaconda3/envs/py38/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/ali/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\", line 510, in forward\n",
      "    layer_output = apply_chunking_to_forward(\n",
      "  File \"/home/ali/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/modeling_utils.py\", line 2186, in apply_chunking_to_forward\n",
      "    return forward_fn(*input_tensors)\n",
      "  File \"/home/ali/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\", line 523, in feed_forward_chunk\n",
      "    layer_output = self.output(intermediate_output, attention_output)\n",
      "  File \"/home/ali/anaconda3/envs/py38/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/ali/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\", line 438, in forward\n",
      "    hidden_states = self.dense(hidden_states)\n",
      "  File \"/home/ali/anaconda3/envs/py38/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/ali/anaconda3/envs/py38/lib/python3.8/site-packages/torch/nn/modules/linear.py\", line 103, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "  File \"/home/ali/anaconda3/envs/py38/lib/python3.8/site-packages/torch/nn/functional.py\", line 1848, in linear\n",
      "    return torch._C._nn.linear(input, weight, bias)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ali/anaconda3/envs/py38/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2064, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ali/anaconda3/envs/py38/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3364, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"/home/ali/anaconda3/envs/py38/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3461, in run_code\n",
      "    self.showtraceback(running_compiled_code=True)\n",
      "  File \"/home/ali/anaconda3/envs/py38/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2066, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(etype,\n",
      "  File \"/home/ali/anaconda3/envs/py38/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1367, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"/home/ali/anaconda3/envs/py38/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1267, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"/home/ali/anaconda3/envs/py38/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1124, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"/home/ali/anaconda3/envs/py38/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1082, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"/home/ali/anaconda3/envs/py38/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 382, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ali/anaconda3/envs/py38/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2064, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ali/anaconda3/envs/py38/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2947, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/home/ali/anaconda3/envs/py38/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/home/ali/anaconda3/envs/py38/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3172, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/home/ali/anaconda3/envs/py38/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3383, in run_ast_nodes\n",
      "    self.showtraceback()\n",
      "  File \"/home/ali/anaconda3/envs/py38/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2066, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(etype,\n",
      "  File \"/home/ali/anaconda3/envs/py38/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1367, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"/home/ali/anaconda3/envs/py38/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1267, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"/home/ali/anaconda3/envs/py38/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1142, in structured_traceback\n",
      "    formatted_exceptions += self.format_exception_as_a_whole(etype, evalue, etb, lines_of_context,\n",
      "  File \"/home/ali/anaconda3/envs/py38/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1082, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"/home/ali/anaconda3/envs/py38/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 382, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ali/anaconda3/envs/py38/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2064, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ali/anaconda3/envs/py38/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/ali/anaconda3/envs/py38/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/ali/anaconda3/envs/py38/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/home/ali/anaconda3/envs/py38/lib/python3.8/inspect.py\", line 1503, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/home/ali/anaconda3/envs/py38/lib/python3.8/inspect.py\", line 1461, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/home/ali/anaconda3/envs/py38/lib/python3.8/inspect.py\", line 708, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/home/ali/anaconda3/envs/py38/lib/python3.8/inspect.py\", line 751, in getmodule\n",
      "    f = getabsfile(module)\n",
      "  File \"/home/ali/anaconda3/envs/py38/lib/python3.8/inspect.py\", line 720, in getabsfile\n",
      "    _filename = getsourcefile(object) or getfile(object)\n",
      "  File \"/home/ali/anaconda3/envs/py38/lib/python3.8/inspect.py\", line 705, in getsourcefile\n",
      "    if os.path.exists(filename):\n",
      "  File \"/home/ali/anaconda3/envs/py38/lib/python3.8/genericpath.py\", line 19, in exists\n",
      "    os.stat(path)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "create_embeddings(sent2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_engine():\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
